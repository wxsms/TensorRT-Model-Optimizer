Search.setIndex({"docnames": ["deployment/1_tensorrt_llm_deployment", "examples/0_all_examples", "examples/1_cifar_resnet", "examples/2_bert_prune_distill_quantize", "getting_started/1_overview", "getting_started/2_installation", "getting_started/3_quantization", "getting_started/4_pruning", "getting_started/5_distillation", "getting_started/6_sparsity", "guides/1_quantization", "guides/2_pruning", "guides/3_nas", "guides/4_distillation", "guides/5_sparsity", "guides/6_save_load", "guides/7_speculative_decoding", "guides/_basic_quantization", "guides/_choosing_quant_methods", "guides/_onnx_quantization", "guides/_pytorch_quantization", "index", "reference/0_changelog", "reference/1_modelopt_api", "reference/generated/modelopt.deploy", "reference/generated/modelopt.deploy.llm", "reference/generated/modelopt.deploy.llm.generate", "reference/generated/modelopt.deploy.llm.nemo_utils", "reference/generated/modelopt.onnx", "reference/generated/modelopt.onnx.op_types", "reference/generated/modelopt.onnx.quantization", "reference/generated/modelopt.onnx.quantization.calib_utils", "reference/generated/modelopt.onnx.quantization.extensions", "reference/generated/modelopt.onnx.quantization.fp8", "reference/generated/modelopt.onnx.quantization.graph_utils", "reference/generated/modelopt.onnx.quantization.gs_patching", "reference/generated/modelopt.onnx.quantization.int4", "reference/generated/modelopt.onnx.quantization.int8", "reference/generated/modelopt.onnx.quantization.operators", "reference/generated/modelopt.onnx.quantization.ort_patching", "reference/generated/modelopt.onnx.quantization.ort_utils", "reference/generated/modelopt.onnx.quantization.partitioning", "reference/generated/modelopt.onnx.quantization.qdq_utils", "reference/generated/modelopt.onnx.quantization.quant_utils", "reference/generated/modelopt.onnx.quantization.quantize", "reference/generated/modelopt.onnx.quantization.trt_utils", "reference/generated/modelopt.onnx.utils", "reference/generated/modelopt.torch", "reference/generated/modelopt.torch.distill", "reference/generated/modelopt.torch.distill.config", "reference/generated/modelopt.torch.distill.distillation", "reference/generated/modelopt.torch.distill.distillation_model", "reference/generated/modelopt.torch.distill.loss_balancers", "reference/generated/modelopt.torch.distill.losses", "reference/generated/modelopt.torch.distill.mode", "reference/generated/modelopt.torch.distill.plugins", "reference/generated/modelopt.torch.distill.registry", "reference/generated/modelopt.torch.export", "reference/generated/modelopt.torch.export.distribute", "reference/generated/modelopt.torch.export.hf_config_map", "reference/generated/modelopt.torch.export.layer_utils", "reference/generated/modelopt.torch.export.model_config", "reference/generated/modelopt.torch.export.model_config_export", "reference/generated/modelopt.torch.export.model_config_utils", "reference/generated/modelopt.torch.export.postprocess", "reference/generated/modelopt.torch.export.scaling_factor_utils", "reference/generated/modelopt.torch.export.tensorrt_llm_type", "reference/generated/modelopt.torch.export.tensorrt_llm_utils", "reference/generated/modelopt.torch.export.transformer_engine", "reference/generated/modelopt.torch.export.unified_export_hf", "reference/generated/modelopt.torch.export.vllm", "reference/generated/modelopt.torch.nas", "reference/generated/modelopt.torch.nas.algorithms", "reference/generated/modelopt.torch.nas.autonas", "reference/generated/modelopt.torch.nas.config", "reference/generated/modelopt.torch.nas.conversion", "reference/generated/modelopt.torch.nas.hparams", "reference/generated/modelopt.torch.nas.hparams.concat", "reference/generated/modelopt.torch.nas.hparams.container", "reference/generated/modelopt.torch.nas.mode", "reference/generated/modelopt.torch.nas.modules", "reference/generated/modelopt.torch.nas.modules.container", "reference/generated/modelopt.torch.nas.modules.conv", "reference/generated/modelopt.torch.nas.modules.linear", "reference/generated/modelopt.torch.nas.modules.norm", "reference/generated/modelopt.torch.nas.modules.utils", "reference/generated/modelopt.torch.nas.plugins", "reference/generated/modelopt.torch.nas.registry", "reference/generated/modelopt.torch.nas.search_space", "reference/generated/modelopt.torch.nas.traced_hp", "reference/generated/modelopt.torch.nas.utils", "reference/generated/modelopt.torch.opt", "reference/generated/modelopt.torch.opt.config", "reference/generated/modelopt.torch.opt.conversion", "reference/generated/modelopt.torch.opt.dynamic", "reference/generated/modelopt.torch.opt.hparam", "reference/generated/modelopt.torch.opt.mode", "reference/generated/modelopt.torch.opt.plugins", "reference/generated/modelopt.torch.opt.plugins.huggingface", "reference/generated/modelopt.torch.opt.searcher", "reference/generated/modelopt.torch.opt.utils", "reference/generated/modelopt.torch.prune", "reference/generated/modelopt.torch.prune.config", "reference/generated/modelopt.torch.prune.fastnas", "reference/generated/modelopt.torch.prune.gradnas", "reference/generated/modelopt.torch.prune.mcore_gpt_minitron", "reference/generated/modelopt.torch.prune.mode", "reference/generated/modelopt.torch.prune.plugins", "reference/generated/modelopt.torch.prune.pruning", "reference/generated/modelopt.torch.quantization", "reference/generated/modelopt.torch.quantization.algorithms", "reference/generated/modelopt.torch.quantization.calib", "reference/generated/modelopt.torch.quantization.calib.calibrator", "reference/generated/modelopt.torch.quantization.calib.histogram", "reference/generated/modelopt.torch.quantization.calib.max", "reference/generated/modelopt.torch.quantization.config", "reference/generated/modelopt.torch.quantization.conversion", "reference/generated/modelopt.torch.quantization.export_onnx", "reference/generated/modelopt.torch.quantization.extensions", "reference/generated/modelopt.torch.quantization.mode", "reference/generated/modelopt.torch.quantization.model_calib", "reference/generated/modelopt.torch.quantization.model_quant", "reference/generated/modelopt.torch.quantization.nn", "reference/generated/modelopt.torch.quantization.nn.functional", "reference/generated/modelopt.torch.quantization.nn.modules", "reference/generated/modelopt.torch.quantization.nn.modules.clip", "reference/generated/modelopt.torch.quantization.nn.modules.quant_activations", "reference/generated/modelopt.torch.quantization.nn.modules.quant_batchnorm", "reference/generated/modelopt.torch.quantization.nn.modules.quant_conv", "reference/generated/modelopt.torch.quantization.nn.modules.quant_instancenorm", "reference/generated/modelopt.torch.quantization.nn.modules.quant_linear", "reference/generated/modelopt.torch.quantization.nn.modules.quant_module", "reference/generated/modelopt.torch.quantization.nn.modules.quant_pooling", "reference/generated/modelopt.torch.quantization.nn.modules.quant_rnn", "reference/generated/modelopt.torch.quantization.nn.modules.tensor_quantizer", "reference/generated/modelopt.torch.quantization.optim", "reference/generated/modelopt.torch.quantization.plugins", "reference/generated/modelopt.torch.quantization.qtensor", "reference/generated/modelopt.torch.quantization.qtensor.base_qtensor", "reference/generated/modelopt.torch.quantization.qtensor.int4_tensor", "reference/generated/modelopt.torch.quantization.qtensor.nf4_tensor", "reference/generated/modelopt.torch.quantization.qtensor.nvfp4_tensor", "reference/generated/modelopt.torch.quantization.quant_modules", "reference/generated/modelopt.torch.quantization.tensor_quant", "reference/generated/modelopt.torch.quantization.utils", "reference/generated/modelopt.torch.sparsity", "reference/generated/modelopt.torch.sparsity.config", "reference/generated/modelopt.torch.sparsity.magnitude", "reference/generated/modelopt.torch.sparsity.mode", "reference/generated/modelopt.torch.sparsity.module", "reference/generated/modelopt.torch.sparsity.plugins", "reference/generated/modelopt.torch.sparsity.searcher", "reference/generated/modelopt.torch.sparsity.sparsegpt", "reference/generated/modelopt.torch.sparsity.sparsification", "reference/generated/modelopt.torch.speculative", "reference/generated/modelopt.torch.speculative.config", "reference/generated/modelopt.torch.speculative.medusa", "reference/generated/modelopt.torch.speculative.medusa.conversion", "reference/generated/modelopt.torch.speculative.medusa.medusa_model", "reference/generated/modelopt.torch.speculative.mode", "reference/generated/modelopt.torch.speculative.plugins", "reference/generated/modelopt.torch.speculative.speculative_decoding", "reference/generated/modelopt.torch.trace", "reference/generated/modelopt.torch.trace.analyzer", "reference/generated/modelopt.torch.trace.modules", "reference/generated/modelopt.torch.trace.modules.concat", "reference/generated/modelopt.torch.trace.modules.nn", "reference/generated/modelopt.torch.trace.plugins", "reference/generated/modelopt.torch.trace.symbols", "reference/generated/modelopt.torch.trace.tracer", "reference/generated/modelopt.torch.utils", "reference/generated/modelopt.torch.utils.cpp_extension", "reference/generated/modelopt.torch.utils.dataset_utils", "reference/generated/modelopt.torch.utils.distributed", "reference/generated/modelopt.torch.utils.graph", "reference/generated/modelopt.torch.utils.list", "reference/generated/modelopt.torch.utils.logging", "reference/generated/modelopt.torch.utils.network", "reference/generated/modelopt.torch.utils.perf", "reference/generated/modelopt.torch.utils.random", "reference/generated/modelopt.torch.utils.tensor", "support/1_contact", "support/2_faqs"], "filenames": ["deployment/1_tensorrt_llm_deployment.rst", "examples/0_all_examples.rst", "examples/1_cifar_resnet.ipynb", "examples/2_bert_prune_distill_quantize.rst", "getting_started/1_overview.rst", "getting_started/2_installation.rst", "getting_started/3_quantization.rst", "getting_started/4_pruning.rst", "getting_started/5_distillation.rst", "getting_started/6_sparsity.rst", "guides/1_quantization.rst", "guides/2_pruning.rst", "guides/3_nas.rst", "guides/4_distillation.rst", "guides/5_sparsity.rst", "guides/6_save_load.rst", "guides/7_speculative_decoding.rst", "guides/_basic_quantization.rst", "guides/_choosing_quant_methods.rst", "guides/_onnx_quantization.rst", "guides/_pytorch_quantization.rst", "index.rst", "reference/0_changelog.rst", "reference/1_modelopt_api.rst", "reference/generated/modelopt.deploy.rst", "reference/generated/modelopt.deploy.llm.rst", "reference/generated/modelopt.deploy.llm.generate.rst", "reference/generated/modelopt.deploy.llm.nemo_utils.rst", "reference/generated/modelopt.onnx.rst", "reference/generated/modelopt.onnx.op_types.rst", "reference/generated/modelopt.onnx.quantization.rst", "reference/generated/modelopt.onnx.quantization.calib_utils.rst", "reference/generated/modelopt.onnx.quantization.extensions.rst", "reference/generated/modelopt.onnx.quantization.fp8.rst", "reference/generated/modelopt.onnx.quantization.graph_utils.rst", "reference/generated/modelopt.onnx.quantization.gs_patching.rst", "reference/generated/modelopt.onnx.quantization.int4.rst", "reference/generated/modelopt.onnx.quantization.int8.rst", "reference/generated/modelopt.onnx.quantization.operators.rst", "reference/generated/modelopt.onnx.quantization.ort_patching.rst", "reference/generated/modelopt.onnx.quantization.ort_utils.rst", "reference/generated/modelopt.onnx.quantization.partitioning.rst", "reference/generated/modelopt.onnx.quantization.qdq_utils.rst", "reference/generated/modelopt.onnx.quantization.quant_utils.rst", "reference/generated/modelopt.onnx.quantization.quantize.rst", "reference/generated/modelopt.onnx.quantization.trt_utils.rst", "reference/generated/modelopt.onnx.utils.rst", "reference/generated/modelopt.torch.rst", "reference/generated/modelopt.torch.distill.rst", "reference/generated/modelopt.torch.distill.config.rst", "reference/generated/modelopt.torch.distill.distillation.rst", "reference/generated/modelopt.torch.distill.distillation_model.rst", "reference/generated/modelopt.torch.distill.loss_balancers.rst", "reference/generated/modelopt.torch.distill.losses.rst", "reference/generated/modelopt.torch.distill.mode.rst", "reference/generated/modelopt.torch.distill.plugins.rst", "reference/generated/modelopt.torch.distill.registry.rst", "reference/generated/modelopt.torch.export.rst", "reference/generated/modelopt.torch.export.distribute.rst", "reference/generated/modelopt.torch.export.hf_config_map.rst", "reference/generated/modelopt.torch.export.layer_utils.rst", "reference/generated/modelopt.torch.export.model_config.rst", "reference/generated/modelopt.torch.export.model_config_export.rst", "reference/generated/modelopt.torch.export.model_config_utils.rst", "reference/generated/modelopt.torch.export.postprocess.rst", "reference/generated/modelopt.torch.export.scaling_factor_utils.rst", "reference/generated/modelopt.torch.export.tensorrt_llm_type.rst", "reference/generated/modelopt.torch.export.tensorrt_llm_utils.rst", "reference/generated/modelopt.torch.export.transformer_engine.rst", "reference/generated/modelopt.torch.export.unified_export_hf.rst", "reference/generated/modelopt.torch.export.vllm.rst", "reference/generated/modelopt.torch.nas.rst", "reference/generated/modelopt.torch.nas.algorithms.rst", "reference/generated/modelopt.torch.nas.autonas.rst", "reference/generated/modelopt.torch.nas.config.rst", "reference/generated/modelopt.torch.nas.conversion.rst", "reference/generated/modelopt.torch.nas.hparams.rst", "reference/generated/modelopt.torch.nas.hparams.concat.rst", "reference/generated/modelopt.torch.nas.hparams.container.rst", "reference/generated/modelopt.torch.nas.mode.rst", "reference/generated/modelopt.torch.nas.modules.rst", "reference/generated/modelopt.torch.nas.modules.container.rst", "reference/generated/modelopt.torch.nas.modules.conv.rst", "reference/generated/modelopt.torch.nas.modules.linear.rst", "reference/generated/modelopt.torch.nas.modules.norm.rst", "reference/generated/modelopt.torch.nas.modules.utils.rst", "reference/generated/modelopt.torch.nas.plugins.rst", "reference/generated/modelopt.torch.nas.registry.rst", "reference/generated/modelopt.torch.nas.search_space.rst", "reference/generated/modelopt.torch.nas.traced_hp.rst", "reference/generated/modelopt.torch.nas.utils.rst", "reference/generated/modelopt.torch.opt.rst", "reference/generated/modelopt.torch.opt.config.rst", "reference/generated/modelopt.torch.opt.conversion.rst", "reference/generated/modelopt.torch.opt.dynamic.rst", "reference/generated/modelopt.torch.opt.hparam.rst", "reference/generated/modelopt.torch.opt.mode.rst", "reference/generated/modelopt.torch.opt.plugins.rst", "reference/generated/modelopt.torch.opt.plugins.huggingface.rst", "reference/generated/modelopt.torch.opt.searcher.rst", "reference/generated/modelopt.torch.opt.utils.rst", "reference/generated/modelopt.torch.prune.rst", "reference/generated/modelopt.torch.prune.config.rst", "reference/generated/modelopt.torch.prune.fastnas.rst", "reference/generated/modelopt.torch.prune.gradnas.rst", "reference/generated/modelopt.torch.prune.mcore_gpt_minitron.rst", "reference/generated/modelopt.torch.prune.mode.rst", "reference/generated/modelopt.torch.prune.plugins.rst", "reference/generated/modelopt.torch.prune.pruning.rst", "reference/generated/modelopt.torch.quantization.rst", "reference/generated/modelopt.torch.quantization.algorithms.rst", "reference/generated/modelopt.torch.quantization.calib.rst", "reference/generated/modelopt.torch.quantization.calib.calibrator.rst", "reference/generated/modelopt.torch.quantization.calib.histogram.rst", "reference/generated/modelopt.torch.quantization.calib.max.rst", "reference/generated/modelopt.torch.quantization.config.rst", "reference/generated/modelopt.torch.quantization.conversion.rst", "reference/generated/modelopt.torch.quantization.export_onnx.rst", "reference/generated/modelopt.torch.quantization.extensions.rst", "reference/generated/modelopt.torch.quantization.mode.rst", "reference/generated/modelopt.torch.quantization.model_calib.rst", "reference/generated/modelopt.torch.quantization.model_quant.rst", "reference/generated/modelopt.torch.quantization.nn.rst", "reference/generated/modelopt.torch.quantization.nn.functional.rst", "reference/generated/modelopt.torch.quantization.nn.modules.rst", "reference/generated/modelopt.torch.quantization.nn.modules.clip.rst", "reference/generated/modelopt.torch.quantization.nn.modules.quant_activations.rst", "reference/generated/modelopt.torch.quantization.nn.modules.quant_batchnorm.rst", "reference/generated/modelopt.torch.quantization.nn.modules.quant_conv.rst", "reference/generated/modelopt.torch.quantization.nn.modules.quant_instancenorm.rst", "reference/generated/modelopt.torch.quantization.nn.modules.quant_linear.rst", "reference/generated/modelopt.torch.quantization.nn.modules.quant_module.rst", "reference/generated/modelopt.torch.quantization.nn.modules.quant_pooling.rst", "reference/generated/modelopt.torch.quantization.nn.modules.quant_rnn.rst", "reference/generated/modelopt.torch.quantization.nn.modules.tensor_quantizer.rst", "reference/generated/modelopt.torch.quantization.optim.rst", "reference/generated/modelopt.torch.quantization.plugins.rst", "reference/generated/modelopt.torch.quantization.qtensor.rst", "reference/generated/modelopt.torch.quantization.qtensor.base_qtensor.rst", "reference/generated/modelopt.torch.quantization.qtensor.int4_tensor.rst", "reference/generated/modelopt.torch.quantization.qtensor.nf4_tensor.rst", "reference/generated/modelopt.torch.quantization.qtensor.nvfp4_tensor.rst", "reference/generated/modelopt.torch.quantization.quant_modules.rst", "reference/generated/modelopt.torch.quantization.tensor_quant.rst", "reference/generated/modelopt.torch.quantization.utils.rst", "reference/generated/modelopt.torch.sparsity.rst", "reference/generated/modelopt.torch.sparsity.config.rst", "reference/generated/modelopt.torch.sparsity.magnitude.rst", "reference/generated/modelopt.torch.sparsity.mode.rst", "reference/generated/modelopt.torch.sparsity.module.rst", "reference/generated/modelopt.torch.sparsity.plugins.rst", "reference/generated/modelopt.torch.sparsity.searcher.rst", "reference/generated/modelopt.torch.sparsity.sparsegpt.rst", "reference/generated/modelopt.torch.sparsity.sparsification.rst", "reference/generated/modelopt.torch.speculative.rst", "reference/generated/modelopt.torch.speculative.config.rst", "reference/generated/modelopt.torch.speculative.medusa.rst", "reference/generated/modelopt.torch.speculative.medusa.conversion.rst", "reference/generated/modelopt.torch.speculative.medusa.medusa_model.rst", "reference/generated/modelopt.torch.speculative.mode.rst", "reference/generated/modelopt.torch.speculative.plugins.rst", "reference/generated/modelopt.torch.speculative.speculative_decoding.rst", "reference/generated/modelopt.torch.trace.rst", "reference/generated/modelopt.torch.trace.analyzer.rst", "reference/generated/modelopt.torch.trace.modules.rst", "reference/generated/modelopt.torch.trace.modules.concat.rst", "reference/generated/modelopt.torch.trace.modules.nn.rst", "reference/generated/modelopt.torch.trace.plugins.rst", "reference/generated/modelopt.torch.trace.symbols.rst", "reference/generated/modelopt.torch.trace.tracer.rst", "reference/generated/modelopt.torch.utils.rst", "reference/generated/modelopt.torch.utils.cpp_extension.rst", "reference/generated/modelopt.torch.utils.dataset_utils.rst", "reference/generated/modelopt.torch.utils.distributed.rst", "reference/generated/modelopt.torch.utils.graph.rst", "reference/generated/modelopt.torch.utils.list.rst", "reference/generated/modelopt.torch.utils.logging.rst", "reference/generated/modelopt.torch.utils.network.rst", "reference/generated/modelopt.torch.utils.perf.rst", "reference/generated/modelopt.torch.utils.random.rst", "reference/generated/modelopt.torch.utils.tensor.rst", "support/1_contact.rst", "support/2_faqs.rst"], "titles": ["TensorRT-LLM Deployment", "All GitHub Examples", "ResNet20 on CIFAR-10: Pruning", "HF BERT: Prune, Distill &amp; Quantize", "Overview", "Installation", "Quick Start: Quantization", "Quick Start: Pruning", "Quick Start: Distillation", "Quick Start: Sparsity", "Quantization", "Pruning", "NAS", "Distillation", "Sparsity", "Saving &amp; Restoring", "Speculative Decoding", "Basic Concepts", "Best practices to choose the right quantization methods", "ONNX Quantization (Beta)", "PyTorch Quantization", "Welcome to Model Optimizer (ModelOpt) documentation!", "Model Optimizer Changelog", "modelopt API", "deploy", "llm", "generate", "nemo_utils", "onnx", "op_types", "quantization", "calib_utils", "extensions", "fp8", "graph_utils", "gs_patching", "int4", "int8", "operators", "ort_patching", "ort_utils", "partitioning", "qdq_utils", "quant_utils", "modelopt.onnx.quantization.quantize", "trt_utils", "utils", "torch", "distill", "config", "distillation", "distillation_model", "loss_balancers", "losses", "mode", "plugins", "registry", "export", "distribute", "hf_config_map", "layer_utils", "model_config", "model_config_export", "model_config_utils", "postprocess", "scaling_factor_utils", "tensorrt_llm_type", "tensorrt_llm_utils", "transformer_engine", "unified_export_hf", "vllm", "nas", "algorithms", "autonas", "config", "conversion", "hparams", "concat", "container", "mode", "modules", "container", "conv", "linear", "norm", "utils", "plugins", "registry", "search_space", "traced_hp", "utils", "opt", "config", "conversion", "dynamic", "hparam", "mode", "plugins", "huggingface", "searcher", "utils", "prune", "config", "fastnas", "gradnas", "mcore_gpt_minitron", "mode", "plugins", "pruning", "quantization", "algorithms", "calib", "calibrator", "histogram", "max", "config", "conversion", "export_onnx", "extensions", "mode", "model_calib", "model_quant", "nn", "functional", "modules", "clip", "quant_activations", "quant_batchnorm", "quant_conv", "quant_instancenorm", "quant_linear", "quant_module", "quant_pooling", "quant_rnn", "tensor_quantizer", "optim", "plugins", "qtensor", "base_qtensor", "int4_tensor", "nf4_tensor", "nvfp4_tensor", "quant_modules", "tensor_quant", "utils", "sparsity", "config", "magnitude", "mode", "module", "plugins", "searcher", "sparsegpt", "sparsification", "speculative", "config", "medusa", "conversion", "medusa_model", "mode", "plugins", "speculative_decoding", "trace", "analyzer", "modules", "concat", "nn", "plugins", "symbols", "tracer", "utils", "cpp_extension", "dataset_utils", "distributed", "graph", "list", "logging", "network", "perf", "random", "tensor", "Contact us", "FAQs"], "terms": {"pleas": [0, 5, 6, 7, 8, 10, 11, 12, 13, 14, 18, 19, 20, 22, 26, 72, 75, 91, 93, 108, 115, 121, 136, 153, 160, 182], "read": [0, 12, 31, 58], "workflow": [0, 2, 4, 11, 15, 96, 99, 101], "first": [0, 2, 3, 5, 8, 11, 14, 18, 34, 36, 44, 46, 58, 60, 90, 121, 171, 177], "befor": [0, 3, 5, 11, 12, 15, 17, 34, 53, 72, 73, 74, 79, 94, 98, 99, 103, 105, 106, 108, 115, 119, 131, 133, 177, 179], "go": [0, 3, 11, 12], "through": [0, 3, 4, 8, 9, 12, 17, 20, 60, 89, 120, 121, 143, 168], "thi": [0, 2, 3, 5, 7, 8, 9, 11, 12, 13, 14, 15, 16, 18, 19, 20, 22, 27, 29, 33, 34, 36, 38, 39, 40, 41, 43, 44, 45, 46, 49, 51, 52, 53, 54, 58, 60, 61, 63, 64, 67, 72, 74, 75, 79, 89, 90, 92, 93, 94, 95, 98, 99, 101, 104, 106, 108, 110, 113, 115, 116, 119, 120, 121, 123, 133, 134, 136, 138, 140, 142, 143, 144, 147, 148, 149, 153, 158, 159, 160, 165, 168, 169, 172, 177, 179, 182], "section": [0, 11, 12, 13, 14], "modelopt": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 16, 17, 19, 20, 22, 34, 40, 50, 59, 61, 88, 90, 91, 92, 93, 96, 98, 101, 111, 115, 116, 121, 161, 172, 179, 182], "toolkit": [0, 5, 10], "automat": [0, 3, 4, 12, 14, 15, 20, 22, 72, 75, 94, 98, 108, 147, 153], "convers": [0, 13, 18, 29, 33, 44, 50, 88, 94, 98, 161, 179, 182], "engin": [0, 19, 22, 26, 61, 62], "acceler": [0, 3, 4, 6, 9, 14, 16], "inferenc": 0, "i": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 26, 27, 29, 33, 34, 36, 38, 40, 41, 42, 43, 44, 45, 46, 49, 50, 51, 52, 53, 54, 58, 60, 61, 62, 63, 64, 67, 72, 73, 74, 75, 79, 88, 89, 90, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 108, 110, 113, 114, 115, 116, 119, 120, 121, 123, 131, 133, 134, 138, 142, 143, 144, 146, 147, 148, 149, 153, 161, 165, 166, 168, 169, 172, 173, 177, 179, 182], "achiev": [0, 2, 3, 8, 10, 12, 14, 16, 20, 22, 94], "huggingfac": [0, 3, 5, 6, 8, 20, 22, 26, 27, 57, 61, 136], "nemo": [0, 2, 4, 5, 6, 11, 12, 20, 22, 27, 57, 61, 105, 108, 136], "build": [0, 3, 5, 11, 12, 19, 22, 27, 34, 60, 61, 62, 103, 108, 153, 169], "from": [0, 1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 17, 18, 22, 26, 27, 31, 34, 39, 40, 41, 42, 44, 46, 49, 51, 60, 61, 63, 65, 66, 72, 73, 88, 89, 91, 92, 93, 94, 95, 98, 99, 104, 108, 113, 115, 116, 121, 134, 138, 143, 144, 147, 152, 153, 165, 168, 169, 172, 175, 177, 179, 180], "after": [0, 2, 3, 5, 7, 9, 12, 13, 14, 15, 16, 17, 19, 20, 22, 34, 40, 52, 58, 73, 74, 75, 91, 93, 94, 96, 99, 103, 104, 115, 116, 120, 153, 158, 168, 177], "can": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 29, 34, 43, 44, 54, 61, 62, 72, 74, 75, 77, 79, 88, 90, 91, 92, 93, 94, 96, 99, 102, 103, 104, 105, 106, 108, 110, 115, 116, 119, 121, 134, 136, 143, 146, 148, 159, 160, 165, 168, 172, 177, 178, 179, 182], "format": [0, 3, 4, 6, 10, 14, 18, 19, 20, 22, 31, 44, 49, 58, 61, 62, 63, 65, 72, 75, 99, 108, 110, 121, 134, 138, 139, 140, 172, 177], "store": [0, 3, 7, 12, 14, 22, 34, 44, 45, 49, 62, 72, 93, 94, 95, 99, 103, 104, 108, 139, 140, 143, 165, 169], "A": [0, 2, 3, 11, 12, 13, 14, 16, 17, 18, 20, 22, 26, 41, 42, 44, 49, 50, 51, 53, 56, 58, 60, 62, 63, 72, 73, 75, 87, 88, 89, 90, 92, 93, 94, 95, 96, 99, 101, 103, 108, 110, 113, 114, 115, 116, 120, 121, 125, 133, 134, 138, 143, 144, 151, 153, 158, 161, 166, 168, 169, 172, 177, 178], "singl": [0, 2, 3, 12, 13, 17, 19, 34, 43, 49, 51, 63, 64, 65, 72, 90, 95, 96, 108, 121, 133, 134, 168, 177], "json": [0, 3, 49, 58, 62, 63, 69, 74, 92, 102, 115, 146, 155], "file": [0, 2, 3, 19, 22, 33, 34, 36, 37, 43, 44, 46, 58, 60, 62, 67, 92, 93, 171], "record": [0, 12, 93, 96, 169], "structur": 0, "metadata": [0, 14, 73, 93, 103, 115, 148, 157], "config": [0, 2, 3, 6, 7, 9, 12, 13, 14, 15, 16, 22, 26, 27, 50, 54, 58, 59, 60, 61, 62, 63, 64, 67, 69, 72, 73, 75, 79, 88, 90, 93, 94, 99, 103, 104, 105, 106, 108, 110, 119, 121, 139, 140, 148, 151, 152, 153, 157, 159, 161, 179], "group": [0, 2, 3, 11, 12, 18, 22, 58, 65, 115, 121, 134, 173], "safetensor": [0, 62], "each": [0, 3, 12, 14, 16, 17, 20, 22, 34, 36, 44, 49, 51, 52, 58, 62, 65, 67, 73, 74, 89, 91, 93, 94, 95, 96, 102, 110, 115, 116, 139, 140, 144, 146, 153, 169, 179], "local": [0, 3, 5, 58, 90], "calibr": [0, 2, 3, 6, 7, 9, 11, 12, 14, 18, 20, 22, 31, 33, 34, 36, 42, 44, 62, 72, 74, 75, 108, 110, 111, 113, 114, 115, 116, 120, 121, 128, 130, 131, 133, 134, 153, 172], "gpu": [0, 2, 3, 4, 5, 14, 18, 22, 62, 113, 178, 179], "rank": [0, 2, 7, 11, 12, 58, 61, 62, 64, 65, 104, 115, 121, 134, 144, 173, 178], "weight": [0, 2, 3, 4, 7, 9, 11, 12, 14, 17, 18, 20, 22, 27, 34, 36, 42, 44, 45, 46, 51, 52, 58, 60, 61, 62, 63, 64, 65, 67, 69, 75, 93, 94, 110, 113, 115, 116, 120, 121, 131, 133, 143, 144, 147, 149, 153], "scale": [0, 19, 22, 31, 36, 42, 60, 61, 62, 63, 65, 115, 120, 138, 139, 140, 143], "factor": [0, 18, 36, 42, 60, 61, 62, 63, 65, 110, 115, 120, 143], "per": [0, 3, 13, 17, 18, 20, 22, 43, 50, 62, 63, 65, 75, 108, 110, 115, 121, 134, 138, 143, 153, 157, 161, 168], "The": [0, 2, 3, 4, 6, 7, 8, 11, 13, 14, 15, 16, 17, 18, 19, 20, 22, 26, 27, 34, 36, 42, 43, 49, 50, 51, 52, 54, 58, 60, 61, 62, 63, 64, 65, 67, 69, 72, 73, 75, 79, 80, 88, 89, 90, 92, 93, 94, 99, 104, 106, 108, 110, 115, 116, 119, 120, 121, 123, 134, 138, 139, 140, 143, 144, 147, 148, 153, 155, 158, 159, 161, 163, 168, 169, 172, 174, 176, 177, 179], "api": [0, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 19, 20, 21, 22, 26, 27, 48, 50, 62, 75, 98, 101, 108, 120, 121, 142, 145, 153, 161], "export_tensorrt_llm_checkpoint": [0, 62], "us": [0, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 16, 17, 18, 19, 22, 29, 34, 36, 37, 43, 44, 45, 49, 50, 51, 53, 54, 58, 62, 63, 65, 70, 72, 73, 74, 75, 79, 88, 89, 90, 91, 92, 93, 94, 98, 99, 102, 103, 104, 105, 106, 108, 110, 113, 114, 115, 116, 119, 120, 121, 123, 125, 133, 134, 142, 143, 146, 147, 149, 153, 155, 161, 165, 168, 169, 171, 172, 173, 177, 178, 179, 182], "follow": [0, 2, 3, 5, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 34, 50, 54, 60, 72, 75, 79, 88, 93, 99, 106, 108, 115, 119, 121, 143, 153, 158, 161, 168, 169], "torch": [0, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 20, 22, 40, 48, 50, 52, 58, 60, 62, 63, 69, 70, 72, 80, 81, 82, 83, 84, 88, 90, 91, 93, 94, 98, 99, 101, 108, 111, 113, 115, 116, 117, 121, 133, 134, 138, 139, 140, 143, 158, 161, 165, 166, 168, 169, 171, 172, 173, 177, 179, 180], "import": [0, 2, 3, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 19, 20, 22, 92, 93, 95, 98, 105, 110, 115, 116, 121, 172, 177, 179], "inference_mod": 0, "decoder_typ": [0, 60, 61, 62], "type": [0, 3, 13, 14, 22, 26, 27, 29, 31, 33, 34, 36, 37, 40, 41, 42, 43, 44, 45, 46, 49, 50, 51, 52, 53, 54, 58, 60, 61, 62, 63, 64, 65, 69, 72, 73, 75, 76, 79, 85, 88, 89, 90, 92, 93, 94, 95, 96, 99, 100, 103, 104, 105, 106, 108, 110, 113, 115, 116, 119, 120, 121, 128, 130, 131, 133, 134, 138, 139, 140, 143, 144, 147, 148, 151, 152, 153, 157, 158, 159, 161, 163, 165, 166, 168, 169, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182], "str": [0, 3, 26, 27, 29, 31, 33, 34, 36, 37, 40, 41, 42, 44, 45, 46, 49, 50, 51, 52, 53, 54, 58, 60, 61, 62, 63, 64, 65, 67, 69, 70, 72, 73, 74, 75, 79, 85, 88, 90, 92, 93, 94, 99, 100, 102, 103, 104, 105, 106, 108, 110, 113, 115, 116, 117, 119, 120, 121, 133, 134, 146, 147, 148, 151, 152, 153, 157, 159, 161, 163, 168, 169, 171, 172, 173, 175, 176, 177], "e": [0, 2, 3, 5, 8, 9, 11, 12, 13, 14, 15, 17, 18, 20, 22, 36, 44, 53, 62, 72, 75, 88, 94, 96, 99, 108, 115, 121, 133, 143, 165, 168, 169, 171, 177], "g": [0, 2, 3, 5, 9, 11, 12, 14, 17, 20, 22, 62, 72, 75, 88, 94, 96, 108, 115, 117, 143, 165, 168, 171, 177], "gptj": [0, 12, 62], "llama": [0, 11, 22, 62], "gptnext": [0, 62], "dtype": [0, 3, 35, 42, 44, 60, 61, 62, 69, 134, 138, 139, 140, 143, 177], "data": [0, 2, 3, 6, 7, 8, 9, 11, 12, 14, 18, 19, 20, 22, 31, 34, 43, 44, 45, 46, 60, 62, 69, 72, 104, 108, 111, 113, 115, 120, 121, 134, 138, 139, 140, 153, 172, 177, 180], "unquant": [0, 17, 62, 69], "layer": [0, 2, 4, 7, 11, 13, 14, 20, 22, 34, 41, 44, 45, 49, 51, 58, 60, 61, 62, 63, 65, 67, 69, 72, 74, 75, 88, 95, 102, 104, 108, 110, 115, 121, 133, 146, 153, 158, 162, 163, 164, 166, 168, 169, 177], "export_dir": [0, 62, 67, 69, 70], "directori": [0, 3, 16, 19, 26, 44, 46, 58, 62, 67], "where": [0, 3, 12, 14, 16, 17, 20, 34, 36, 44, 51, 72, 99, 103, 108, 110, 115, 121, 131, 165, 168, 177], "inference_tensor_parallel": [0, 22, 62, 64], "number": [0, 2, 3, 11, 12, 20, 36, 53, 65, 72, 90, 94, 95, 108, 110, 113, 114, 115, 121, 125, 138, 143, 155, 172, 173, 176, 177, 179], "infer": [0, 2, 4, 6, 9, 12, 14, 15, 16, 18, 22, 40, 61, 62, 64, 72, 90, 93, 99, 108, 172], "time": [0, 2, 3, 5, 12, 16, 18, 22, 62, 72, 108, 121, 153, 171, 175], "tensor": [0, 3, 8, 12, 13, 14, 17, 18, 20, 22, 26, 31, 34, 36, 42, 44, 46, 51, 52, 53, 58, 60, 61, 62, 63, 64, 65, 85, 90, 94, 95, 104, 110, 113, 114, 115, 117, 121, 123, 125, 131, 133, 134, 137, 138, 139, 140, 143, 144, 147, 152, 158, 168, 169, 177], "parallel": [0, 2, 3, 11, 12, 14, 16, 22, 60, 62, 64, 144, 177], "inference_pipeline_parallel": [0, 62, 64], "pipelin": [0, 2, 4, 8, 11, 12, 13, 14, 20, 22, 62, 121], "If": [0, 2, 3, 5, 11, 12, 13, 14, 15, 16, 18, 19, 20, 31, 34, 44, 45, 46, 49, 50, 51, 52, 58, 60, 61, 64, 65, 72, 74, 75, 88, 90, 93, 94, 95, 102, 104, 108, 110, 113, 114, 115, 116, 120, 121, 125, 134, 144, 146, 153, 161, 168, 172, 177, 182], "call": [0, 3, 5, 7, 12, 13, 14, 15, 16, 20, 22, 40, 43, 51, 92, 94, 98, 116, 121, 131, 133, 134, 149, 153, 168, 172], "success": [0, 5], "save": [0, 2, 3, 7, 9, 10, 11, 13, 19, 20, 21, 22, 44, 46, 51, 58, 61, 62, 69, 70, 72, 79, 91, 93, 98, 99, 106, 108, 114, 119, 134, 143], "otherwis": [0, 3, 12, 58, 60, 62, 79, 116, 143, 165, 174], "state_dict": [0, 2, 7, 11, 12, 14, 15, 49, 51, 58, 72, 93, 99, 108, 121], "instead": [0, 11, 12, 15, 16, 22, 43, 58, 72, 74, 88, 90, 94, 95, 96, 102, 110, 113, 142, 143, 146, 168, 169, 172], "fp16": [0, 18, 19, 33, 34, 42, 44, 134], "bf16": [0, 3, 18], "fp8": [0, 4, 17, 18, 19, 20, 22, 34, 42, 44, 60, 61, 62, 115, 117, 121, 134, 143], "int8_sq": [0, 61], "int4_awq": [0, 22], "gpt2": [0, 62], "ye": [0, 2], "No": [0, 3, 12, 121], "2": [0, 2, 3, 4, 5, 9, 11, 12, 14, 22, 31, 34, 36, 43, 66, 77, 88, 102, 104, 110, 121, 143, 147, 155, 168], "3": [0, 2, 5, 7, 11, 12, 22, 60, 115, 121, 143, 168], "mistral": [0, 12], "mixtral": [0, 22], "8x7b": 0, "falcon": 0, "40b": 0, "180b": 0, "7b": 0, "mpt": 0, "30b": 0, "baichuan": 0, "1": [0, 2, 3, 5, 7, 11, 12, 16, 20, 22, 26, 31, 34, 36, 44, 52, 53, 60, 61, 62, 63, 64, 66, 72, 74, 75, 77, 88, 102, 104, 108, 110, 113, 115, 121, 143, 144, 155, 165, 168, 172, 175, 177, 179], "chatglm2": 0, "6b": [0, 11, 14], "bloom": 0, "phi": [0, 67], "nemotron": 0, "8": [0, 2, 3, 4, 5, 18, 19, 20, 36, 60, 67, 102, 113, 114, 115, 121, 128, 130, 131, 133, 143, 171, 177], "gemma": [0, 22], "2b": 0, "recurr": [0, 29, 60, 61], "starcod": [0, 22], "qwen": [0, 22], "5": [0, 2, 3, 12, 36, 41, 52, 72, 74, 75, 77, 88, 102, 108, 115], "onc": [0, 3, 11, 12, 15, 40, 98, 113], "avail": [0, 2, 3, 4, 5, 6, 11, 12, 13, 14, 17, 22, 31, 50, 56, 75, 87, 95, 108, 153, 161, 173], "deploi": [0, 5, 18, 22], "relat": [1, 12, 13, 14, 34, 36, 41, 46, 56, 88, 90, 103, 168], "optim": [1, 3, 6, 10, 11, 12, 13, 14, 15, 24, 28, 30, 43, 47, 50, 62, 66, 68, 70, 71, 72, 73, 75, 91, 93, 96, 99, 100, 103, 104, 108, 110, 115, 133, 153, 154, 156, 161], "techniqu": [1, 6, 9, 14, 17, 20, 22], "like": [1, 2, 4, 6, 7, 10, 11, 12, 14, 16, 17, 19, 20, 22, 31, 41, 44, 52, 72, 75, 88, 93, 94, 99, 108, 114, 134, 177], "quantiz": [1, 5, 7, 11, 15, 21, 22, 29, 33, 34, 36, 37, 38, 40, 41, 42, 43, 45, 60, 61, 62, 63, 64, 65, 68, 69, 70, 96, 110, 111, 113, 114, 116, 117, 119, 120, 121, 122, 124, 126, 127, 128, 129, 130, 131, 132, 133, 134, 136, 137, 138, 139, 140, 141, 142, 143, 144, 159, 172], "ptq": [1, 3, 4, 17, 22, 34], "qat": [1, 3, 4, 6, 22], "sparsiti": [1, 15, 21, 22, 146, 147, 148, 149, 150, 151, 153], "distil": [1, 7, 11, 15, 21, 22, 49, 51, 52, 53, 54, 55, 56, 161], "prune": [1, 13, 15, 21, 22, 71, 75, 90, 96, 102, 103, 104, 105, 106, 107, 168], "tensorrt": [1, 3, 5, 6, 10, 11, 18, 19, 20, 21, 22, 26, 31, 34, 44, 45, 60, 61, 62, 66, 67, 69, 121], "llm": [1, 4, 5, 6, 10, 11, 18, 20, 21, 22, 26, 57, 60, 61, 62, 64, 66, 67, 69, 115, 121], "deploy": [1, 2, 3, 4, 5, 8, 10, 11, 12, 18, 20, 22, 24, 25, 47, 62, 69, 72, 99, 121], "more": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 18, 20, 22, 54, 72, 79, 88, 90, 91, 92, 94, 104, 105, 106, 108, 115, 116, 121, 123, 134, 139, 140, 143, 153, 177], "access": [1, 14, 29, 58, 90, 92, 94, 115], "repositori": [1, 2, 4, 5, 10], "com": [1, 2, 3, 5, 26, 27, 29, 62, 143, 177], "nvidia": [1, 2, 3, 5, 9, 10, 11, 14, 20, 22, 26, 27, 62, 105, 108, 115, 147], "model": [1, 3, 10, 13, 17, 18, 24, 26, 27, 28, 30, 31, 33, 34, 36, 37, 41, 42, 44, 45, 46, 47, 49, 50, 51, 54, 58, 60, 61, 62, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 79, 88, 90, 91, 93, 94, 96, 98, 99, 100, 103, 104, 105, 106, 108, 110, 113, 115, 116, 117, 119, 120, 121, 134, 142, 144, 148, 153, 155, 157, 158, 159, 161, 163, 168, 169, 172, 177, 179, 182], "tutori": 2, "jupyt": 2, "notebook": [2, 7, 11], "download": [2, 3, 19], "here": [2, 3, 6, 7, 9, 11, 12, 15, 20, 41, 43, 52, 94, 95, 98, 103, 105, 115, 116, 121, 133, 177], "It": [2, 3, 4, 11, 12, 13, 20, 58, 63, 72, 89, 90, 96, 108, 115, 119, 121, 133, 134, 138, 143, 147, 153, 168, 177], "would": [2, 11, 12, 51, 52, 75, 108, 113, 115, 153, 165], "take": [2, 3, 5, 7, 11, 12, 14, 16, 20, 72, 88, 90, 92, 95, 108, 113, 115, 116, 120, 121, 134, 143, 153, 171, 177], "about": [2, 3, 6, 7, 8, 9, 11, 12, 13, 14, 54, 56, 79, 87, 91, 104, 106, 115, 121, 134, 168], "hour": [2, 3], "googl": [2, 36, 42, 143], "colab": 2, "run": [2, 3, 5, 7, 12, 13, 16, 19, 20, 22, 27, 34, 72, 73, 99, 105, 108, 113, 121, 153, 177], "fast": [2, 5, 104, 121], "you": [2, 3, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 22, 72, 74, 90, 92, 93, 102, 108, 115, 121, 136, 142, 146, 153, 160, 177, 182], "better": [2, 3, 11, 12, 14, 19, 20, 104], "expect": [2, 3, 13, 41, 67], "slightli": 2, "differ": [2, 3, 4, 7, 10, 11, 12, 13, 17, 18, 29, 50, 52, 53, 75, 89, 94, 108, 115, 133, 153, 161, 168, 172], "accuraci": [2, 3, 4, 7, 8, 10, 11, 12, 13, 14, 17, 18, 20, 22, 72, 108], "than": [2, 3, 8, 11, 12, 13, 14, 20, 27, 46, 94, 115], "report": [2, 19, 72, 178], "below": [2, 3, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 94, 115, 121, 168, 177], "depend": [2, 3, 5, 11, 12, 22, 34, 89, 94, 95, 162, 163, 165, 168, 169], "system": [2, 94], "purpos": [2, 3, 13, 56, 91, 143], "demonstr": 2, "best": [2, 3, 10, 11, 12, 19, 20, 22, 26, 36, 44, 72, 73, 99, 103, 108, 110, 121, 147], "In": [2, 3, 11, 12, 13, 18, 72, 94, 104, 108, 110, 115, 116, 121, 168, 177], "we": [2, 3, 5, 6, 11, 12, 13, 14, 16, 17, 18, 20, 34, 36, 60, 61, 62, 64, 72, 73, 88, 89, 92, 93, 94, 95, 96, 99, 103, 104, 108, 110, 113, 119, 121, 133, 136, 143, 149, 150, 153, 160, 165, 168, 172, 177, 179, 182], "make": [2, 3, 5, 11, 12, 13, 27, 43, 64, 75, 90, 94, 138, 144, 165, 168, 182], "faster": [2, 5, 8, 11, 13, 16, 22, 43, 95], "our": [2, 3, 5, 11, 92], "target": [2, 3, 4, 11, 12, 16, 58, 62, 63, 64, 69, 90, 93, 94, 139, 140, 165, 169, 172, 177], "constraint": [2, 3, 7, 12, 20, 22, 72, 73, 99, 108, 110, 115, 121], "without": [2, 3, 5, 8, 11, 12, 14, 51, 62, 75, 90, 94, 165, 177], "sacrif": 2, "much": [2, 3, 5, 11, 13, 20, 115], "By": [2, 5, 19, 22, 38, 72, 115], "end": [2, 3, 4, 6, 7, 9, 11, 12, 13, 22, 34, 72, 108, 115, 121, 165, 177, 178], "understand": [2, 11, 12], "how": [2, 3, 6, 8, 11, 12, 13, 15, 18, 20, 22, 27, 53, 91, 95, 115, 136, 143, 160, 177], "user": [2, 4, 6, 7, 8, 11, 12, 13, 14, 16, 18, 19, 20, 22, 29, 34, 40, 58, 91, 93, 94, 95, 115, 121, 161], "provid": [2, 3, 4, 7, 9, 11, 12, 13, 14, 16, 17, 19, 20, 22, 31, 34, 40, 43, 44, 52, 58, 65, 72, 74, 75, 88, 89, 90, 91, 92, 93, 94, 99, 101, 102, 108, 111, 121, 138, 146, 153, 168, 172, 177], "perform": [2, 3, 4, 6, 8, 9, 13, 18, 20, 22, 26, 33, 36, 37, 58, 63, 75, 90, 108, 113, 115, 120, 121, 134, 140, 143, 158, 178], "architectur": [2, 5, 11, 13, 14, 15, 62, 90, 93, 94, 108, 179], "fit": [2, 3, 22, 61], "your": [2, 3, 5, 11, 13, 14, 15, 16, 18, 20, 22, 53, 72, 108, 115, 121, 136, 153, 160, 182], "downstream": [2, 4, 11, 12, 15], "task": [2, 3, 11, 12, 13, 15, 22, 52, 72, 90, 93, 99, 108, 121], "all": [2, 3, 4, 5, 11, 12, 14, 21, 22, 34, 39, 41, 42, 44, 46, 58, 60, 61, 62, 64, 72, 74, 75, 77, 88, 90, 92, 93, 94, 100, 102, 104, 113, 114, 116, 121, 133, 134, 144, 146, 147, 149, 165, 168, 169, 173, 177, 179], "just": [2, 3, 6, 12, 61, 88, 119, 177], "few": [2, 5, 11, 12, 13, 16, 121, 168, 171], "line": [2, 13, 19], "code": [2, 13, 20, 43, 54, 62, 66, 69, 79, 106, 119, 136, 148, 159, 160, 179], "": [2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 24, 34, 36, 40, 42, 44, 45, 49, 50, 51, 53, 54, 58, 60, 72, 75, 79, 88, 90, 92, 93, 94, 96, 106, 108, 114, 115, 119, 123, 133, 148, 153, 159, 161, 168, 169, 172, 175, 177], "simpl": [2, 12, 13, 14, 19, 20, 89, 125, 168, 178], "let": [2, 3, 20, 94], "instal": [2, 3, 21, 22, 45, 144], "step": [2, 3, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 19, 36, 44, 73, 88, 93, 96, 99, 105, 115, 134], "pip": [2, 3, 5, 22], "extra": [2, 3, 5, 22, 27, 134, 169, 177], "index": [2, 3, 5, 134, 168], "url": [2, 3, 5], "http": [2, 3, 5, 26, 27, 29, 53, 62, 104, 105, 123, 143, 177], "pypi": [2, 3, 4, 5], "math": [2, 3, 14, 17], "o": [2, 3, 5, 16, 34], "random": [2, 3, 19, 22, 31, 46, 73, 88, 90], "numpi": [2, 3, 19, 31, 42, 44, 46, 114, 134, 180], "np": [2, 3, 19, 63, 113], "nn": [2, 3, 8, 11, 12, 20, 49, 52, 60, 72, 74, 75, 80, 81, 82, 83, 84, 88, 93, 94, 99, 102, 108, 113, 115, 116, 130, 132, 134, 138, 146, 168, 177, 182], "function": [2, 3, 6, 7, 8, 11, 12, 13, 16, 20, 27, 29, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 50, 51, 52, 53, 58, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 75, 85, 88, 89, 90, 92, 93, 95, 96, 98, 99, 100, 103, 104, 108, 110, 113, 115, 116, 117, 118, 120, 121, 125, 133, 134, 135, 138, 140, 142, 143, 144, 147, 148, 149, 152, 153, 157, 158, 161, 163, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180], "f": [2, 3, 15, 20, 93, 116], "torchvis": [2, 7, 8, 11, 12, 13], "transform": [2, 3, 4, 5, 12, 14, 15, 16, 19, 22, 60, 61, 63, 98, 121, 158, 160], "basicblock": 2, "tqdm": [2, 3], "auto": [2, 3, 16, 92, 172], "seed": [2, 3, 46, 179], "123": [2, 3], "manual_se": 2, "devic": [2, 3, 12, 16, 34, 44, 131, 138, 172, 177, 178], "cuda": [2, 3, 5, 33, 34, 36, 37, 44, 98, 115, 118, 133, 143, 171, 178], "For": [2, 3, 4, 5, 14, 15, 17, 18, 19, 20, 26, 44, 52, 62, 64, 74, 75, 90, 92, 93, 94, 95, 96, 102, 104, 108, 115, 120, 121, 134, 143, 146, 169, 177], "work": [2, 5, 12, 13, 17, 19, 33, 34, 58, 136, 160, 177], "well": [2, 3, 11, 12, 13, 14, 16, 18, 20, 74, 75, 94, 102, 146, 169, 177, 178], "known": [2, 13, 44], "consist": [2, 12, 17, 27, 88, 92, 94, 133], "60k": 2, "32x32": 2, "class": [2, 3, 8, 13, 20, 22, 26, 27, 31, 36, 38, 49, 51, 52, 53, 54, 58, 61, 66, 73, 75, 77, 78, 79, 88, 89, 90, 92, 93, 94, 95, 96, 99, 103, 104, 105, 106, 110, 111, 112, 113, 114, 115, 116, 119, 123, 125, 128, 129, 130, 131, 132, 133, 134, 137, 138, 139, 140, 141, 143, 147, 148, 149, 151, 152, 158, 159, 165, 166, 168, 169, 177, 178], "split": [2, 3, 62, 63, 64, 113], "50k": 2, "10k": 2, "test": [2, 3, 10, 12], "further": [2, 4, 8, 11, 12, 15, 16, 104, 140], "5k": 2, "randomli": [2, 14, 72, 73], "out": [2, 3, 6, 7, 8, 9, 11, 12, 13, 14, 43, 50, 52, 54, 79, 90, 106, 115, 136, 160], "valid": [2, 3, 7, 11, 12, 26, 46, 64, 92, 94, 121, 163, 165], "def": [2, 3, 6, 7, 8, 11, 12, 20, 90, 116, 121, 168], "get_cifar10_dataload": 2, "train_batch_s": 2, "int": [2, 3, 26, 36, 42, 44, 46, 53, 58, 60, 61, 62, 63, 64, 65, 67, 73, 77, 94, 95, 100, 103, 110, 113, 115, 117, 121, 133, 134, 138, 139, 140, 143, 144, 147, 155, 158, 165, 166, 168, 172, 173, 175, 177], "return": [2, 3, 7, 8, 11, 12, 13, 14, 20, 22, 26, 27, 29, 31, 33, 34, 36, 37, 40, 41, 42, 43, 44, 45, 46, 49, 50, 51, 52, 53, 54, 58, 60, 61, 62, 63, 64, 65, 67, 69, 72, 73, 75, 77, 79, 85, 88, 89, 90, 92, 93, 94, 95, 99, 100, 103, 104, 105, 106, 108, 110, 113, 114, 115, 116, 118, 119, 120, 121, 134, 138, 139, 140, 143, 144, 147, 148, 151, 152, 153, 157, 158, 159, 161, 163, 165, 166, 168, 169, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180], "val": [2, 166, 175], "loader": [2, 6, 7, 8, 9, 11, 20, 72, 108, 121, 153, 177], "normal": [2, 12, 20, 29, 38, 72, 95, 108, 127, 129, 153, 177], "mean": [2, 12, 16, 20, 36, 44, 62, 104, 153, 175], "0": [2, 3, 5, 11, 12, 16, 19, 26, 33, 34, 36, 37, 44, 46, 52, 53, 61, 62, 66, 67, 73, 74, 75, 77, 88, 90, 102, 104, 113, 115, 128, 130, 133, 134, 143, 158, 172, 177, 178, 179], "4914": 2, "4822": 2, "4465": 2, "std": [2, 175], "2470": 2, "2435": 2, "2616": 2, "train_dataset": 2, "cifar10": 2, "root": [2, 34, 60, 93, 169], "true": [2, 3, 11, 12, 16, 20, 26, 33, 34, 36, 37, 44, 45, 46, 49, 51, 61, 62, 64, 67, 72, 74, 75, 79, 90, 93, 94, 99, 110, 113, 115, 116, 121, 125, 128, 130, 131, 133, 134, 143, 144, 163, 168, 174, 177], "compos": [2, 60], "totensor": 2, "randomhorizontalflip": 2, "randomcrop": 2, "32": [2, 11, 12, 74, 95, 102, 115], "4": [2, 3, 4, 9, 11, 12, 14, 16, 17, 18, 20, 31, 43, 60, 72, 77, 102, 108, 115, 121, 143, 147], "n_trainval": 2, "len": [2, 3], "n_train": 2, "9": [2, 11, 12, 67, 102], "id": [2, 3, 27, 34, 44, 63, 165], "arang": 2, "shuffl": [2, 3, 179], "train_id": 2, "val_id": 2, "arrai": [2, 3, 19, 42, 43, 44, 114, 134, 180], "val_dataset": 2, "test_dataset": 2, "fals": [2, 3, 12, 33, 34, 36, 37, 42, 44, 45, 46, 49, 51, 61, 62, 72, 74, 75, 79, 90, 92, 93, 94, 99, 113, 114, 115, 116, 121, 125, 128, 130, 131, 133, 134, 138, 143, 168, 172, 174, 177, 182], "num_work": 2, "min": [2, 3, 11, 12, 18, 36, 44, 72, 95, 123, 125, 166, 171, 175], "cpu_count": 2, "train_load": [2, 7, 8, 11, 12, 20], "util": [2, 3, 8, 11, 12, 13, 14, 22, 25, 27, 29, 31, 34, 40, 41, 42, 43, 45, 58, 60, 63, 64, 65, 67, 70, 88, 93, 96, 116, 117, 120, 152, 157, 168, 171, 172, 173, 174, 175, 176, 177, 178, 180], "dataload": [2, 3, 11, 12, 14, 20, 172], "pin_memori": 2, "val_load": [2, 7, 11, 12], "batch_siz": [2, 3, 19, 46, 133, 172], "1024": [2, 31, 115], "test_load": 2, "print": [2, 5, 11, 12, 20, 33, 34, 44, 72, 88, 90, 108, 121, 153, 176], "variant": [2, 18, 27, 43], "name": [2, 3, 5, 19, 22, 34, 36, 41, 42, 44, 46, 51, 52, 54, 60, 69, 72, 74, 75, 79, 88, 92, 94, 99, 100, 102, 106, 108, 110, 115, 116, 119, 121, 144, 146, 148, 159, 168, 171, 172, 177, 178], "20": [2, 3], "sinc": [2, 3, 16, 20, 72, 92, 108, 113, 119], "ar": [2, 3, 4, 5, 7, 8, 11, 12, 13, 14, 15, 16, 17, 18, 20, 22, 27, 34, 36, 37, 41, 44, 46, 49, 50, 52, 60, 61, 62, 63, 64, 67, 72, 74, 75, 77, 88, 90, 92, 93, 94, 99, 102, 104, 108, 115, 116, 120, 121, 131, 133, 134, 143, 144, 146, 153, 161, 165, 168, 169, 171, 177], "veri": [2, 3, 18], "small": [2, 18, 20, 103, 165], "find": [2, 3, 10, 11, 12, 13, 14, 20, 34, 36, 41, 44, 46, 103, 110, 147], "detail": [2, 3, 6, 7, 8, 10, 11, 12, 17, 18, 19, 20, 22, 44, 49, 72, 74, 99, 102, 105, 108, 115, 116, 121, 134, 143, 146, 153, 155, 158], "paper": [2, 11, 36, 53, 104, 115, 123, 153], "an": [2, 3, 4, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 19, 20, 22, 33, 34, 36, 37, 40, 43, 46, 49, 50, 54, 58, 60, 62, 64, 72, 73, 74, 75, 79, 88, 89, 90, 93, 94, 95, 96, 98, 102, 103, 104, 108, 110, 113, 114, 115, 116, 119, 120, 121, 123, 134, 143, 146, 148, 153, 161, 165, 168, 177, 179], "exampl": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 22, 26, 27, 44, 46, 52, 74, 75, 77, 88, 90, 92, 93, 95, 96, 98, 102, 104, 116, 120, 121, 136, 146, 160, 168, 172, 179], "regular": [2, 6, 12, 14, 17, 20, 44, 65, 72, 73, 75, 91, 94, 95, 148, 153, 165], "pytorch": [2, 3, 5, 10, 11, 12, 14, 15, 18, 22, 53, 75, 90, 91, 94, 115, 116, 120, 121, 123, 125, 143, 144, 172, 177, 180], "anyth": [2, 121], "new": [2, 15, 19, 22, 42, 54, 73, 79, 89, 90, 92, 94, 103, 106, 119, 138, 144], "add": [2, 3, 13, 16, 22, 34, 37, 41, 44, 72, 93, 108, 121, 158, 168, 169, 177], "some": [2, 3, 5, 7, 11, 12, 20, 34, 41, 43, 49, 51, 60, 67, 96, 114, 123, 168], "helper": [2, 36, 43], "_weights_init": 2, "m": [2, 3, 19, 34, 115, 143, 147, 169], "isinst": [2, 3, 13], "linear": [2, 3, 4, 11, 12, 20, 22, 29, 34, 60, 61, 63, 74, 88, 102, 110, 115, 121, 130, 131, 144, 146, 158, 168], "conv2d": [2, 11, 12, 74, 75, 88, 95, 102, 115, 128, 143, 146, 168], "init": [2, 38, 131, 133, 158, 165], "kaiming_normal_": 2, "lambdalay": 2, "modul": [2, 3, 5, 8, 13, 14, 16, 22, 24, 25, 27, 28, 30, 32, 35, 36, 38, 39, 45, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 60, 61, 62, 65, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 97, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 115, 116, 118, 119, 120, 121, 122, 125, 126, 127, 129, 131, 132, 133, 134, 135, 136, 137, 138, 142, 144, 145, 146, 148, 150, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 165, 166, 167, 168, 169, 170, 171, 172, 174, 177, 182], "__init__": [2, 20, 26, 27, 31, 36, 38, 52, 53, 58, 61, 88, 90, 93, 94, 95, 99, 104, 110, 113, 114, 116, 125, 133, 134, 138, 158, 165, 166, 168, 169, 178], "self": [2, 3, 20, 89, 90, 93, 94, 95, 116, 131, 133, 165, 168], "lambd": 2, "super": [2, 3, 12, 20, 116], "forward": [2, 3, 6, 7, 8, 9, 11, 12, 17, 20, 34, 51, 52, 53, 67, 72, 75, 90, 99, 108, 116, 120, 121, 123, 125, 131, 133, 134, 143, 152, 153, 158, 163, 169, 172, 177, 182], "x": [2, 3, 5, 9, 14, 20, 34, 36, 44, 72, 108, 113, 114, 147, 158, 175, 177], "num_block": 2, "num_class": 2, "in_plan": 2, "16": [2, 3, 11, 18, 31, 34, 88, 95, 108], "sequenti": [2, 12, 74, 75, 81, 88, 102, 115, 134, 146], "kernel_s": [2, 74, 88, 90, 102, 168, 177], "stride": [2, 3, 113], "pad": [2, 3, 61, 63, 64, 177], "bia": [2, 3, 20, 61, 116, 143], "batchnorm2d": [2, 74, 88, 102], "relu": [2, 34], "_make_lay": 2, "64": [2, 3, 11, 12, 31, 64, 115], "adaptiveavgpool2d": [2, 132], "flatten": 2, "appli": [2, 3, 4, 9, 13, 14, 15, 18, 22, 33, 36, 37, 51, 52, 93, 115, 121, 129, 134, 143, 147, 172], "plane": 2, "downsampl": 2, "none": [2, 3, 5, 20, 26, 27, 31, 33, 34, 36, 37, 40, 42, 44, 45, 46, 49, 51, 52, 53, 54, 58, 60, 61, 62, 63, 64, 65, 67, 72, 73, 74, 79, 85, 88, 89, 90, 92, 93, 94, 95, 99, 100, 102, 103, 104, 105, 106, 108, 110, 113, 114, 115, 116, 119, 120, 121, 128, 130, 131, 133, 134, 138, 139, 140, 143, 144, 146, 148, 149, 151, 153, 163, 165, 166, 168, 169, 171, 172, 173, 176, 177, 178, 179], "lambda": [2, 3, 9, 13, 14, 90, 104], "constant": [2, 3, 34, 42, 46, 60, 63, 67, 115, 165, 168], "append": [2, 3, 16, 94, 121], "ckpt": 2, "load_state_dict": [2, 7, 8, 11, 51, 93, 138], "load": [2, 3, 7, 12, 13, 14, 15, 16, 18, 19, 27, 32, 45, 46, 51, 58, 63, 64, 93, 98, 99, 103, 118, 134, 171, 172], "resnet32": 2, "cosinelrwithwarmup": 2, "lr_schedul": [2, 3], "_lrschedul": 2, "warmup_step": 2, "decay_step": 2, "warmup_lr": 2, "float": [2, 3, 17, 26, 36, 42, 43, 44, 52, 53, 60, 61, 65, 72, 90, 95, 99, 103, 104, 108, 110, 113, 115, 117, 121, 128, 130, 131, 133, 140, 143, 152, 175, 176, 177, 178, 179], "last_epoch": 2, "get_lr": 2, "base_lr": 2, "els": [2, 3, 34, 46, 60], "current_step": 2, "co": [2, 3], "pi": 2, "get_optimizer_schedul": 2, "lr": [2, 3], "weight_decai": [2, 3], "sgd": 2, "filter": [2, 20, 115, 116, 121], "p": [2, 3], "requires_grad": [2, 3], "paramet": [2, 11, 12, 20, 22, 26, 27, 29, 31, 33, 34, 36, 37, 40, 41, 42, 43, 44, 45, 46, 50, 51, 52, 53, 58, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 72, 73, 75, 85, 88, 89, 90, 92, 93, 94, 95, 99, 100, 103, 104, 105, 108, 110, 111, 113, 114, 115, 116, 117, 120, 121, 125, 133, 134, 138, 139, 140, 143, 144, 147, 148, 149, 151, 152, 153, 157, 158, 161, 163, 165, 166, 168, 169, 171, 172, 174, 175, 176, 177, 179, 180], "momentum": 2, "train_one_epoch": 2, "loss_fn": [2, 8], "given": [2, 3, 4, 7, 8, 9, 11, 12, 15, 22, 29, 34, 42, 46, 65, 72, 73, 90, 92, 94, 99, 100, 108, 115, 116, 121, 134, 144, 147, 152, 153, 168, 169, 172, 176, 177, 179], "epoch": [2, 3, 11, 12, 20], "epoch_loss": 2, "img": 2, "label": [2, 3, 8, 53, 172, 177], "output": [2, 3, 8, 13, 16, 19, 20, 26, 34, 41, 42, 44, 46, 49, 51, 53, 60, 72, 90, 94, 108, 110, 115, 121, 134, 143, 158, 168, 177], "loss": [2, 3, 4, 7, 8, 11, 17, 20, 36, 49, 51, 52, 72, 104, 108, 110, 121, 153], "item": [2, 3, 44, 64, 92, 168], "zero_grad": [2, 3, 8, 177], "backward": [2, 3, 7, 8, 11, 17, 22, 34, 62, 67, 72, 104, 108, 121, 123, 143, 169, 177], "no_grad": [2, 3], "percentag": [2, 3, 11, 72, 108], "eval": [2, 3, 72, 73, 75, 108, 182], "correct": [2, 5, 73, 103, 110, 116, 121, 131], "total": [2, 3, 11, 12, 51, 52, 104, 115], "predict": [2, 3, 4, 16, 53, 172], "argmax": 2, "dim": [2, 3, 22, 115, 138, 165], "detach": [2, 3, 180], "cpu": [2, 3, 11, 33, 34, 36, 37, 44, 64, 113], "sum": [2, 3, 34, 52, 77, 104, 110, 147], "100": [2, 3, 113], "loss_fn_default": 2, "cross_entropi": 2, "train_model": 2, "num_epoch": 2, "print_freq": 2, "25": [2, 11, 12, 18, 102], "ckpt_path": 2, "temp_saved_model": 2, "pth": [2, 3, 7, 11, 12, 14, 15, 98], "allow": [2, 3, 4, 13, 14, 19, 20, 22, 51, 94, 99], "u": [2, 3, 21, 165], "obtain": [2, 3, 8, 11, 12, 13, 14, 16, 52, 88], "need": [2, 3, 5, 8, 11, 12, 13, 15, 16, 17, 20, 22, 52, 58, 60, 61, 67, 72, 93, 94, 95, 98, 108, 115, 121, 142, 143, 177], "best_val_acc": 2, "best_ep": 2, "ep": [2, 20, 34, 44, 61, 116], "rang": [2, 3, 12, 17, 36, 44, 95, 115, 123, 134, 143, 144], "train_loss": [2, 3], "val_acc": 2, "3d": [2, 26, 128, 129], "t": [2, 3, 5, 34, 41, 44, 88, 90, 99, 113, 119, 123, 133, 144, 169, 179], "4f": 2, "2f": 2, "gave": 2, "uncom": 2, "statement": [2, 20], "see": [2, 3, 6, 7, 8, 11, 12, 13, 14, 15, 18, 19, 20, 22, 27, 72, 94, 104, 108, 113, 114, 115, 116, 121, 143, 153, 177], "6": [2, 3, 11, 19, 77], "should": [2, 3, 6, 11, 12, 13, 15, 19, 20, 22, 31, 34, 40, 41, 43, 44, 50, 52, 60, 61, 72, 73, 75, 89, 90, 92, 93, 94, 95, 98, 103, 108, 115, 116, 120, 121, 138, 153, 158, 161, 168, 177], "30": [2, 3], "hyperparamet": [2, 11, 76, 88, 89, 90, 94, 95, 99, 108], "compar": [2, 3, 11, 12, 17, 115, 133, 177], "origin": [2, 3, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 44, 50, 51, 52, 63, 69, 72, 75, 90, 93, 94, 95, 108, 110, 115, 116, 131, 133, 138, 158, 165, 177, 179], "setup": [2, 3, 6, 8, 9, 20, 104, 116], "describ": [2, 5, 11, 12, 13, 14, 15, 16, 20, 36, 50, 54, 72, 75, 78, 79, 88, 89, 93, 94, 106, 108, 119, 134, 148, 153, 159, 161, 168, 169], "also": [2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 20, 22, 42, 44, 63, 72, 75, 88, 90, 94, 96, 103, 110, 113, 115, 116, 121, 123, 168, 177, 179], "reduc": [2, 4, 6, 9, 12, 13, 14, 16, 17, 49, 51, 52, 53, 72, 108, 115, 121, 133, 140, 144, 153, 179], "whole": [2, 3, 13, 17, 96, 168, 169], "cost": [2, 4, 11, 17, 103], "7": [2, 3, 36, 77], "512": [2, 11, 12, 20, 31, 34, 115, 121, 172], "120": 2, "learning_r": [2, 3], "128": [2, 3, 11, 20, 108, 113, 115, 121, 143], "1e": [2, 3, 61], "batch_per_epoch": 2, "alreadi": [2, 3, 5, 13, 41, 49, 93], "verifi": [2, 20], "45000": 2, "5000": 2, "10000": 2, "resnet20_model": 2, "0049": 2, "22": 2, "82": 2, "0006": 2, "78": 2, "84": 2, "50": [2, 3, 18], "0004": 2, "85": [2, 73], "06": 2, "75": [2, 102], "0002": 2, "88": 2, "12": [2, 3, 5, 12, 22, 171], "0001": 2, "90": 2, "34": 2, "0000": 2, "80": 2, "92": 2, "119": 2, "97": 2, "have": [2, 3, 5, 11, 12, 14, 16, 17, 18, 20, 22, 31, 42, 44, 52, 58, 75, 92, 94, 104, 115, 116, 121, 165, 168, 177], "now": [2, 3, 11, 12, 22, 41, 119], "establish": 2, "so": [2, 3, 11, 20, 44, 57, 61, 92, 94, 113, 114, 133, 165], "far": [2, 57, 114], "seen": [2, 177], "advanc": [2, 4, 6, 9, 17, 110], "state": [2, 3, 4, 7, 11, 12, 13, 20, 51, 54, 58, 65, 72, 73, 79, 93, 96, 98, 99, 105, 106, 108, 110, 119, 131, 134, 144, 151, 165, 168, 177], "art": [2, 4], "algorithm": [2, 3, 4, 6, 7, 11, 12, 18, 19, 20, 22, 36, 50, 73, 75, 79, 88, 91, 92, 93, 96, 99, 101, 103, 104, 105, 106, 108, 115, 120, 121, 145, 148, 151, 152, 153, 161], "enabl": [2, 3, 4, 6, 13, 14, 15, 16, 20, 22, 34, 51, 90, 95, 98, 110, 115, 121, 128, 130, 131, 133, 134, 144, 165, 168, 171], "one": [2, 3, 5, 8, 11, 12, 13, 16, 17, 34, 44, 60, 61, 64, 88, 90, 93, 94, 113, 116, 136, 144, 147, 160, 165, 168], "complementari": 2, "mode": [2, 3, 7, 8, 9, 11, 12, 13, 22, 34, 44, 49, 50, 72, 73, 74, 75, 92, 93, 99, 102, 103, 108, 115, 133, 134, 144, 146, 153, 155, 161], "creat": [2, 3, 5, 13, 14, 19, 20, 34, 40, 42, 58, 62, 93, 113, 115, 134, 138, 147, 152, 158, 172, 177], "space": [2, 3, 7, 44, 72, 73, 75, 88, 90, 94, 99, 100, 103, 108, 110, 179], "method": [2, 4, 7, 8, 9, 10, 11, 12, 14, 15, 20, 27, 34, 36, 43, 44, 72, 75, 89, 90, 92, 93, 94, 99, 108, 113, 115, 116, 120, 121, 131, 133, 134, 138, 140, 143, 156, 169, 173, 177, 182], "recommend": [2, 3, 4, 5, 7, 11, 12, 18, 20, 72, 108, 115, 143, 153], "comput": [2, 3, 8, 11, 12, 13, 17, 18, 20, 22, 36, 49, 51, 52, 53, 72, 95, 108, 113, 115, 121, 134, 139, 140, 144, 147, 153, 174, 175, 180], "vision": [2, 11, 12, 19, 22, 108], "pretrain": [2, 3, 4, 7, 8, 11], "which": [2, 3, 5, 7, 8, 11, 12, 13, 15, 16, 17, 20, 22, 34, 41, 43, 51, 72, 74, 88, 89, 91, 92, 93, 95, 99, 102, 103, 104, 108, 110, 113, 115, 116, 120, 121, 123, 131, 133, 134, 144, 146, 147, 168, 177, 179], "maxim": [2, 11, 17, 72, 99, 108, 147, 169], "score": [2, 3, 7, 11, 12, 16, 72, 95, 99, 104, 108, 110, 121, 153], "while": [2, 3, 4, 8, 11, 12, 17, 20, 22, 72, 94, 99, 104, 110, 142], "meet": [2, 11, 12, 13, 18, 20, 34, 110, 144], "mcore_gpt_minitron": [2, 11, 102, 106, 108], "develop": [2, 4, 11], "research": [2, 11, 177], "gpt": [2, 11, 12, 14, 22, 108, 110], "style": [2, 11, 12, 22, 88, 108, 143], "megatron": [2, 4, 11, 12, 22, 105, 108, 136, 150], "lm": [2, 4, 11], "framework": [2, 4, 5, 10, 11, 20, 22], "activ": [2, 5, 11, 12, 13, 17, 18, 20, 34, 36, 42, 44, 60, 61, 75, 77, 85, 88, 90, 94, 95, 105, 110, 115, 121, 126, 143, 149, 158, 177], "magnitud": [2, 11, 14, 105, 148, 153], "mlp": [2, 4, 11, 12, 60, 61, 66, 121], "attent": [2, 4, 11, 12, 16, 20, 22, 60, 61, 65, 104, 105], "head": [2, 4, 11, 12, 16, 22, 34, 60, 104, 105, 155, 161], "gqa": [2, 11, 12], "queri": [2, 11], "gradna": [2, 3, 7, 11, 12, 72, 102, 106, 108], "light": [2, 7, 11], "languag": [2, 3, 11, 16, 104, 108], "hug": [2, 3, 11, 12, 20, 22, 69, 108], "face": [2, 3, 5, 11, 12, 20, 22, 69, 108, 121, 161], "bert": [2, 7, 11, 12, 21, 22, 108, 110], "j": [2, 11, 14, 22, 108], "gradient": [2, 3, 7, 11, 72, 104, 108, 110, 121, 123, 143, 144, 153, 177], "inform": [2, 3, 7, 8, 11, 12, 13, 56, 61, 62, 63, 65, 69, 72, 87, 93, 108, 110, 115, 133, 134, 147, 153, 164, 166, 168], "checkout": [2, 6, 7, 9, 11], "github": [2, 3, 4, 5, 6, 9, 10, 21, 26, 27, 29, 62, 143, 177, 181], "convert": [2, 3, 4, 8, 11, 14, 20, 22, 33, 34, 42, 43, 44, 50, 52, 54, 60, 61, 62, 63, 65, 67, 68, 69, 70, 72, 73, 74, 75, 79, 90, 93, 94, 99, 102, 103, 106, 108, 119, 138, 139, 140, 146, 148, 153, 157, 159, 161, 165, 169, 176, 177, 179, 180, 182], "its": [2, 3, 5, 8, 11, 12, 13, 14, 16, 22, 42, 50, 60, 67, 72, 75, 88, 93, 94, 99, 108, 110, 115, 116, 121, 134, 153, 161, 168, 169, 177], "flop": [2, 3, 7, 11, 12, 72, 90, 99, 108], "latenc": [2, 11, 12, 16, 19, 72, 99], "opt": [2, 3, 7, 11, 12, 14, 15, 16, 18, 20, 22, 88, 93, 98], "mtp": [2, 3, 4, 7, 11, 12, 106], "gener": [2, 3, 4, 7, 11, 16, 17, 19, 29, 34, 44, 46, 53, 61, 63, 72, 88, 89, 90, 91, 92, 93, 94, 95, 100, 115, 147, 151, 168, 179], "sai": 2, "look": [2, 3, 11, 12, 20, 41, 52, 92, 94, 163], "most": [2, 3, 7, 11, 12, 14, 17, 18, 20, 72], "30m": 2, "param": [2, 3, 11, 12, 19, 72, 108, 177], "upper": [2, 11, 12, 72, 73, 99, 108, 125], "bound": [2, 3, 11, 12, 18, 52, 65, 72, 73, 90, 99, 108, 125, 168], "valu": [2, 3, 12, 13, 17, 19, 20, 22, 34, 42, 43, 46, 49, 50, 51, 52, 53, 54, 61, 65, 66, 72, 75, 77, 79, 92, 94, 95, 103, 104, 106, 108, 110, 114, 115, 117, 119, 120, 121, 131, 134, 143, 144, 148, 149, 153, 159, 161, 168, 177], "either": [2, 3, 8, 11, 13, 14, 16, 34, 40, 44, 90, 94, 168, 177], "absolut": [2, 11, 72, 114, 143, 144], "30e6": 2, "string": [2, 26, 50, 60, 67, 75, 88, 90, 93, 108, 113, 115, 116, 120, 121, 147, 153, 161, 176, 177], "addit": [2, 5, 8, 11, 12, 13, 16, 22, 36, 38, 44, 60, 72, 73, 89, 92, 93, 94, 99, 108, 110, 115, 116, 121, 153, 168], "final": [2, 7, 11, 12, 16, 20, 53, 60, 94, 99], "specifi": [2, 3, 4, 7, 11, 12, 13, 14, 20, 44, 46, 49, 50, 52, 54, 74, 75, 79, 88, 89, 90, 93, 94, 96, 102, 106, 108, 110, 113, 115, 116, 119, 120, 121, 138, 144, 146, 147, 148, 153, 159, 161, 171, 172, 178, 180], "custom": [2, 3, 5, 12, 13, 15, 19, 22, 27, 42, 44, 45, 75, 92, 94, 115, 116, 138], "configur": [2, 3, 6, 9, 11, 12, 13, 14, 16, 20, 22, 40, 49, 50, 72, 73, 74, 75, 88, 90, 92, 94, 95, 96, 99, 100, 102, 103, 108, 110, 116, 121, 138, 146, 153, 155, 161, 172, 179], "get": [2, 3, 5, 7, 11, 26, 36, 42, 45, 60, 65, 73, 85, 89, 90, 92, 94, 96, 99, 100, 104, 105, 110, 115, 134, 138, 144, 147, 151, 152, 165, 168, 169, 172, 177, 178], "grain": [2, 14, 17], "select": [2, 3, 20, 29, 36, 44, 57, 73, 90, 94, 120, 147, 179], "rel": 2, "smaller": [2, 4, 8, 11, 13, 14], "finer": 2, "could": [2, 3, 8, 13, 18, 20, 26, 94, 95, 115, 116, 121, 168], "effect": [2, 4, 6, 9, 13, 17, 20, 121, 143], "case": [2, 3, 6, 9, 12, 13, 14, 18, 20, 34, 52, 64, 69, 72, 94, 108, 115], "why": 2, "howev": [2, 12, 20, 94, 110, 121, 165], "default": [2, 3, 5, 8, 11, 12, 19, 20, 22, 29, 34, 38, 40, 44, 49, 53, 60, 62, 72, 73, 74, 75, 79, 88, 90, 92, 94, 95, 99, 102, 104, 105, 108, 110, 113, 115, 116, 125, 134, 143, 144, 146, 147, 151, 152, 153, 155, 168, 169, 176, 177, 179], "itself": [2, 13, 16, 134], "channel": [2, 11, 12, 17, 18, 19, 53, 94, 113, 115, 134, 144, 177], "choic": [2, 3, 12, 18, 20, 44, 88, 90, 94, 95, 104, 110, 121, 179], "fastnasconfig": [2, 11, 102, 108], "channel_divisor": [2, 11, 74, 88, 102], "feature_divisor": [2, 74, 102], "dummy_input": [2, 3, 7, 11, 12, 72, 90, 99, 108, 177], "randn": [2, 7, 11, 12, 19], "wrap": [2, 6, 7, 8, 11, 12, 13, 20, 49, 75, 92, 93, 138, 169, 177], "onli": [2, 3, 5, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 20, 22, 29, 33, 34, 36, 38, 41, 42, 44, 49, 50, 57, 60, 61, 63, 67, 72, 75, 92, 94, 98, 103, 104, 108, 113, 115, 120, 121, 123, 125, 133, 134, 143, 149, 163, 168, 169, 176, 177], "input": [2, 3, 4, 6, 7, 8, 9, 11, 12, 14, 16, 19, 20, 22, 26, 31, 34, 36, 38, 41, 42, 43, 44, 45, 46, 51, 65, 72, 77, 90, 94, 108, 113, 115, 116, 117, 121, 123, 125, 129, 131, 133, 134, 138, 139, 140, 143, 144, 153, 158, 165, 168, 172, 177, 180], "act": [2, 7, 8, 11, 12, 36], "score_func": [2, 7, 11, 12, 72, 99, 108, 182], "pruned_model": [2, 3, 7, 11], "_": [2, 3, 52, 90], "data_load": [2, 3, 6, 7, 9, 11, 12, 14, 20, 72, 108, 121, 153, 177], "checkpoint": [2, 3, 4, 7, 9, 11, 12, 13, 14, 16, 22, 49, 51, 61, 62, 63, 66, 67, 69, 70, 72, 91, 93, 98, 99, 108, 110, 134], "modelopt_seaarch_checkpoint_fastna": 2, "futur": [2, 11, 12, 14, 16, 20, 22, 153], "modelopt_pruned_model_fastna": 2, "profil": [2, 26, 72, 108, 177], "39": 2, "centroid": [2, 11, 12, 72, 179], "max": [2, 3, 11, 12, 17, 18, 20, 22, 26, 33, 36, 44, 61, 72, 77, 95, 115, 120, 121, 123, 125, 128, 130, 131, 133, 143, 166, 175], "result": [2, 3, 12, 72, 88, 90, 94, 108, 121, 158, 169, 179], "ratio": [2, 11, 12, 53, 72, 115, 147], "24": 2, "33m": [2, 12], "27": [2, 12], "57m": 2, "40": [2, 12], "55m": 2, "67": [2, 74], "94k": 2, "141": 2, "63k": 2, "268": 2, "35k": 2, "95": 2, "satisfi": [2, 11, 12, 72, 99, 108, 171], "00m": 2, "summari": [2, 11, 12, 20, 88, 90, 121], "depth": [2, 4, 12, 78, 81, 166], "out_channel": [2, 11, 12, 94], "in_channel": [2, 11, 12, 95], "conv1": [2, 11, 12], "bn1": [2, 11, 12], "num_featur": [2, 11, 12], "conv2": [2, 11, 12], "48": 2, "hparam": [2, 11, 12, 72, 77, 78, 88, 89, 90, 94, 100, 103, 104, 110], "size": [2, 3, 4, 5, 11, 12, 13, 17, 18, 22, 36, 43, 44, 46, 49, 58, 60, 61, 65, 72, 94, 100, 108, 115, 134, 138, 139, 140, 147, 158, 172, 173, 177], "12e": 2, "02": 2, "note": [2, 3, 5, 8, 11, 12, 20, 27, 29, 33, 34, 38, 40, 41, 46, 49, 51, 58, 72, 74, 75, 93, 94, 95, 102, 108, 119, 133, 146, 149, 165, 168, 169], "within": [2, 4, 11, 12, 13, 19, 96, 108, 115, 143, 144, 165, 169, 176], "begin": [2, 99], "pre": [2, 5, 7, 11, 12, 13, 14, 20, 41, 42, 44, 65, 90, 99, 105, 133], "estim": [2, 17, 22, 95, 104, 105, 110, 115, 121, 143], "runtim": [2, 5, 11, 12, 72, 108, 153], "longer": [2, 3, 11, 12, 14, 20, 22, 64, 94, 115, 142, 153], "minut": [2, 5, 11, 12, 18], "consid": [2, 3, 11, 12, 18, 29], "subsampl": [2, 11, 12, 121], "subset": [2, 11, 12, 34, 44, 73], "org": [2, 3, 53, 104, 105, 123], "doc": [2, 3, 7, 26, 62, 92, 143], "stabl": [2, 4], "html": 2, "subset_dataset": [2, 11, 12], "indic": [2, 3, 11, 12, 36, 44, 45, 50, 72, 73, 75, 77, 88, 93, 95, 99, 103, 104, 108, 115, 119, 143, 153, 161, 165, 168, 177, 179], "collect": [2, 3, 12, 20, 27, 34, 41, 58, 110, 111, 113, 114, 115, 134, 152, 169], "statist": [2, 3, 11, 20, 72, 111, 115, 121, 134, 144], "18": [2, 5, 12, 13], "00": 2, "lt": [2, 115], "76it": 2, "cur": 2, "num_satisfi": [2, 73], "11": [2, 5, 171], "17": 2, "43": [2, 11], "39it": 2, "best_subnet_constraint": 2, "173": 2, "88k": 2, "29": 2, "64m": 2, "60": [2, 7, 11, 72, 108], "37": 2, "As": [2, 8, 13, 143], "6m": 2, "ha": [2, 3, 5, 8, 11, 13, 18, 20, 22, 31, 34, 44, 45, 46, 58, 72, 93, 94, 95, 99, 121, 125, 144, 168], "drop": [2, 3, 12, 22], "common": [2, 7, 11, 17, 20, 27, 41, 43, 46, 63, 168], "necessari": [2, 3, 5, 8, 13, 75, 90, 133, 134, 138, 149], "To": [2, 3, 5, 7, 8, 10, 11, 12, 13, 14, 15, 16, 20, 22, 74, 102, 115, 121, 146], "simpli": [2, 7, 8, 11, 12, 20, 72, 94, 165], "repeat": [2, 11, 12, 20, 60, 169, 175], "1x": [2, 3, 11, 12], "5x": [2, 11, 12], "learn": [2, 3, 4, 6, 7, 8, 9, 11, 12, 13, 14, 17, 20, 51, 54, 79, 91, 106, 115, 121, 125, 134, 144], "rate": [2, 3, 11, 12, 20], "constitut": [2, 12, 96], "trade": [2, 10, 12, 20], "off": [2, 10, 12, 20, 90], "between": [2, 3, 8, 10, 11, 12, 13, 49, 51, 59, 88, 113, 169], "15": [2, 3], "modelopt_pruned_model_fastnas_finetun": 2, "0011": 2, "79": 2, "0003": 2, "87": 2, "62": 2, "58": 2, "70": 2, "101": 2, "13": [2, 5], "vanilla": [2, 89, 94], "optimized_model": 2, "28": [2, 11], "conclus": 2, "comparison": [2, 11], "summar": [2, 12, 18, 22], "268k": 2, "174k": 2, "improv": [2, 12, 18], "littl": [2, 11, 12, 18], "good": [2, 11, 12, 34], "job": 2, "next": [2, 6, 7, 8, 9, 11, 12, 16, 22, 31, 34, 148], "show": [3, 6, 8, 11, 15, 20, 49, 74, 92, 102, 115, 146, 155], "compress": [3, 4, 13, 14, 18, 110, 138], "larg": [3, 4, 16, 18, 43], "question": 3, "answer": 3, "combin": [3, 8, 13, 15, 16], "specif": [3, 5, 11, 12, 13, 14, 18, 34, 54, 72, 74, 75, 94, 96, 102, 108, 110, 115, 116, 138, 146, 164, 165, 166, 168, 172], "fine": [3, 7, 9, 13, 14, 17, 20, 72, 99, 108, 153, 165], "tune": [3, 7, 9, 13, 14, 17, 20, 72, 99, 108, 153], "int8": [3, 4, 6, 18, 19, 22, 33, 34, 42, 44, 60, 115, 117, 134, 140], "precis": [3, 10, 18, 19, 20, 34, 44, 115, 134], "post": [3, 4, 6, 17, 22, 90, 99, 177], "train": [3, 4, 6, 7, 13, 15, 16, 22, 50, 64, 72, 73, 75, 90, 103, 108, 133, 153, 182], "awar": [3, 4, 6, 11, 12, 22], "export": [3, 6, 10, 13, 14, 20, 22, 50, 54, 60, 62, 63, 64, 66, 67, 69, 70, 72, 73, 74, 75, 79, 88, 91, 94, 96, 99, 106, 108, 115, 117, 119, 134, 142, 144, 148, 153, 177], "onnx": [3, 4, 5, 6, 10, 18, 20, 22, 29, 30, 31, 33, 34, 36, 37, 40, 41, 42, 43, 45, 46, 72, 99, 108, 115, 117, 142, 143, 177], "option": [3, 5, 7, 11, 12, 14, 15, 16, 22, 34, 41, 44, 60, 65, 72, 88, 93, 94, 95, 99, 105, 108, 116, 121, 153, 179], "been": [3, 16, 22, 93, 121, 168], "24gb": 3, "a5000": 3, "complet": 3, "stage": [3, 75, 88, 134], "spent": 3, "view": [3, 17], "integr": [3, 4, 8, 22], "point": [3, 11, 17, 18, 36, 42, 44, 115], "highlight": 3, "sourc": [3, 26, 54, 62, 79, 106, 119, 136, 148, 159, 160, 171], "script": [3, 4, 13, 27], "bert_prune_distill_quant": 3, "py": [3, 22, 27, 29, 62, 177], "adapt": [3, 11], "run_qa_no_train": 3, "utils_qa": 3, "blob": [3, 26, 27, 29, 62, 143, 177], "c52b515e948fc12ff58ad773a0385860d0162f61": 3, "copyright": 3, "2021": 3, "inc": 3, "team": 3, "right": [3, 10, 115, 119], "reserv": 3, "licens": [3, 5], "under": [3, 20, 62], "apach": 3, "version": [3, 5, 20, 29, 43, 53, 61, 67, 94, 130, 132, 143, 144, 165, 171], "mai": [3, 5, 8, 12, 13, 14, 17, 20, 72, 93, 94, 108, 121, 143, 153, 171], "except": [3, 22, 60, 67, 74, 102, 103, 134, 146, 165, 169, 176], "complianc": 3, "copi": [3, 20, 22, 29, 115], "www": 3, "unless": [3, 144], "requir": [3, 6, 7, 9, 11, 12, 13, 14, 18, 20, 22, 44, 61, 72, 75, 89, 90, 108, 115, 119, 120, 121, 134, 171], "applic": [3, 12, 16], "law": 3, "agre": 3, "write": [3, 13, 44, 58, 136, 160], "softwar": [3, 4, 10], "distribut": [3, 11, 12, 14, 16, 22], "AS": 3, "basi": [3, 121], "warranti": 3, "OR": 3, "condit": [3, 34], "OF": 3, "ani": [3, 5, 7, 8, 12, 13, 15, 22, 26, 34, 36, 42, 44, 49, 50, 51, 52, 54, 58, 62, 63, 67, 72, 73, 74, 75, 79, 88, 90, 92, 93, 94, 95, 98, 99, 102, 103, 104, 105, 106, 108, 110, 115, 119, 121, 134, 144, 146, 148, 149, 151, 152, 153, 157, 159, 161, 163, 165, 168, 169, 171, 174, 175, 177, 179], "kind": 3, "express": [3, 44, 74, 75, 102, 146], "impli": [3, 121], "govern": [3, 92], "permiss": 3, "limit": [3, 18], "spdx": 3, "filecopyrighttext": 3, "c": [3, 5, 13, 32, 43, 118, 168, 171], "2024": 3, "corpor": 3, "affili": 3, "identifi": [3, 5, 12, 41, 88, 163], "mit": 3, "herebi": 3, "grant": 3, "free": [3, 4, 168], "charg": 3, "person": 3, "associ": [3, 88, 89, 95, 104, 168], "document": [3, 5, 7, 8, 10, 11, 12, 22, 72, 108, 115, 153], "deal": 3, "restrict": [3, 11, 88, 94, 110, 121], "includ": [3, 4, 5, 11, 12, 13, 17, 22, 26, 36, 44, 61, 88, 94, 115, 134, 165, 168, 172], "modifi": [3, 11, 12, 14, 15, 20, 29, 34, 38, 42, 46, 51, 72, 88, 92, 93, 94, 108, 121, 149, 158, 165], "merg": [3, 61, 62, 63, 64, 65, 110], "publish": 3, "sublicens": 3, "sell": 3, "permit": 3, "whom": 3, "furnish": 3, "do": [3, 11, 14, 15, 34, 41, 52, 58, 94, 104, 115, 119, 143, 182], "subject": [3, 18, 29, 121], "abov": [3, 11, 12, 15, 75], "notic": 3, "shall": 3, "substanti": 3, "portion": 3, "THE": 3, "BUT": 3, "NOT": [3, 113, 143], "TO": 3, "merchant": 3, "FOR": [3, 163], "particular": [3, 12, 104, 110], "AND": 3, "noninfring": 3, "IN": 3, "NO": 3, "event": 3, "author": 3, "holder": 3, "BE": 3, "liabl": 3, "claim": 3, "damag": 3, "other": [3, 5, 11, 12, 14, 15, 17, 22, 27, 58, 64, 75, 88, 94, 110, 115, 116, 120, 165, 168, 182], "liabil": 3, "whether": [3, 12, 29, 33, 34, 42, 43, 45, 51, 54, 58, 60, 62, 72, 73, 74, 75, 79, 90, 93, 94, 95, 99, 103, 108, 119, 143, 153, 163, 165, 166, 168, 172, 173, 177], "action": 3, "contract": 3, "tort": 3, "aris": [3, 165], "connect": [3, 12, 34, 158, 163], "WITH": 3, "showcas": [3, 22], "squad": 3, "argpars": 3, "log": [3, 33, 110], "dict": [3, 7, 11, 12, 13, 19, 26, 31, 34, 41, 42, 44, 46, 49, 50, 51, 52, 54, 58, 61, 62, 63, 65, 67, 69, 72, 73, 74, 75, 79, 88, 89, 90, 92, 93, 94, 96, 99, 102, 103, 104, 105, 106, 108, 110, 115, 116, 119, 121, 134, 146, 148, 151, 152, 153, 157, 159, 161, 163, 168, 169, 175, 177], "list": [3, 4, 5, 17, 20, 26, 33, 34, 36, 37, 40, 41, 44, 45, 46, 50, 51, 52, 58, 60, 61, 62, 64, 65, 67, 73, 75, 85, 88, 90, 93, 108, 110, 114, 115, 116, 121, 133, 134, 153, 161, 165, 166, 168, 171, 180], "tupl": [3, 8, 12, 13, 34, 36, 41, 45, 46, 49, 50, 51, 54, 58, 60, 62, 72, 73, 75, 79, 90, 93, 94, 95, 99, 100, 103, 104, 106, 108, 110, 113, 114, 115, 119, 121, 133, 134, 139, 140, 144, 147, 148, 152, 153, 157, 159, 161, 168, 175, 177], "dataset": [3, 9, 11, 12, 121, 172], "evalu": [3, 6, 11, 12, 22, 27, 72, 75, 99, 108, 121, 182], "get_logg": 3, "set_se": 3, "automodelforquestionansw": 3, "autotoken": [3, 16], "datacollatorwithpad": 3, "evalpredict": 3, "pretrainedtoken": [3, 27, 172], "schedulertyp": 3, "default_data_col": 3, "get_schedul": 3, "mtd": [3, 4, 8, 13, 52], "mto": [3, 7, 11, 12, 13, 14, 15, 16, 20, 22, 93, 98], "mtq": [3, 6, 15, 20, 22, 115, 116, 142, 172], "_deploi": [3, 5, 22], "get_onnx_byt": 3, "logger": 3, "__name__": 3, "parse_arg": 3, "input_arg": 3, "parser": 3, "argumentpars": 3, "descript": [3, 177], "finetun": [3, 11], "argument": [3, 13, 14, 22, 29, 36, 44, 50, 51, 52, 72, 75, 88, 90, 93, 94, 95, 99, 103, 108, 113, 115, 120, 121, 143, 153, 161, 163, 169, 171, 172, 177], "add_argu": 3, "model_name_or_path": 3, "uncas": 3, "word": [3, 16, 26], "mask": [3, 14, 51, 53, 104, 147, 149, 151, 152, 153], "help": [3, 11, 12, 17, 38, 72, 177], "path": [3, 16, 19, 22, 26, 27, 31, 33, 34, 44, 45, 46, 58, 62, 64, 67, 69, 70, 72, 108, 134, 171], "do_train": 3, "store_tru": 3, "per_device_train_batch_s": 3, "batch": [3, 6, 18, 20, 26, 36, 44, 46, 72, 94, 108, 115, 121, 127, 153, 172, 177], "per_device_eval_batch_s": 3, "5e": 3, "initi": [3, 7, 8, 11, 12, 14, 15, 16, 20, 26, 31, 34, 36, 42, 49, 75, 88, 89, 93, 94, 95, 104, 110, 113, 114, 116, 125, 131, 134, 138, 142, 149, 165, 168, 169, 172, 173, 177, 178], "potenti": [3, 8, 11, 12, 13, 17, 51, 90], "warmup": 3, "period": 3, "decai": [3, 12], "lr_scheduler_typ": 3, "schedul": [3, 11, 12, 20], "cosin": [3, 12], "cosine_with_restart": 3, "polynomi": 3, "constant_with_warmup": 3, "num_warmup_step": 3, "num_train_epoch": 3, "max_train_step": 3, "overrid": [3, 51, 99, 138], "gradient_accumulation_step": 3, "updat": [3, 5, 16, 17, 20, 22, 36, 42, 46, 54, 60, 64, 65, 67, 73, 79, 92, 93, 94, 103, 106, 116, 119, 134, 148, 153], "accumul": [3, 34, 44, 177], "pass": [3, 7, 11, 13, 17, 20, 51, 52, 53, 58, 72, 89, 90, 94, 108, 115, 120, 121, 123, 134, 143, 144, 158, 163, 169, 177, 182], "preprocessing_num_work": 3, "process": [3, 8, 11, 13, 14, 16, 17, 19, 36, 44, 50, 54, 58, 62, 63, 64, 74, 75, 79, 90, 93, 94, 99, 102, 104, 105, 106, 108, 146, 153, 161, 163, 165, 172, 173, 176, 177, 179, 182], "preprocess": [3, 172], "output_dir": 3, "with_track": 3, "experi": [3, 5], "tracker": 3, "checkpointing_step": 3, "variou": [3, 4, 9, 15, 16, 42, 76, 91, 93, 104, 108, 116, 134, 153], "everi": [3, 43], "n": [3, 5, 34, 104, 147], "resume_from_last_ckpt": 3, "continu": [3, 4, 11, 12, 14, 153], "latest": [3, 5], "misc": [3, 22], "max_seq_length": 3, "384": 3, "maximum": [3, 12, 17, 65, 72, 108, 114, 144, 172], "sequenc": [3, 29, 42, 43, 88, 90, 95, 96, 110, 133, 174, 179], "length": [3, 16, 26, 95, 133, 144, 172], "token": [3, 16, 22, 26, 27, 70, 115, 172], "truncat": 3, "shorter": 3, "pad_to_max_lengh": 3, "pad_to_max_length": 3, "sampl": [3, 7, 11, 12, 16, 20, 26, 31, 72, 73, 88, 90, 94, 103, 172, 177, 179], "dynam": [3, 12, 13, 22, 35, 38, 56, 74, 75, 80, 81, 82, 83, 84, 87, 88, 92, 100, 102, 115, 143, 149, 153, 168, 177], "doc_strid": 3, "when": [3, 5, 7, 12, 13, 14, 15, 18, 22, 34, 49, 51, 58, 63, 75, 88, 90, 92, 93, 94, 95, 98, 113, 115, 133, 134, 149, 168, 169, 172, 182], "up": [3, 4, 5, 6, 11, 12, 14, 16, 18, 50, 58, 75, 91, 94, 99, 108, 134, 153, 161], "long": [3, 177], "chunk": 3, "n_best_siz": 3, "max_answer_length": 3, "becaus": [3, 11, 34, 36, 67, 90, 121, 171, 177], "start": [3, 5, 11, 13, 34, 63, 178], "anoth": [3, 34, 93, 94, 165, 166], "debug": [3, 63, 115, 163], "max_train_sampl": 3, "quicker": 3, "max_eval_sampl": 3, "do_modelopt_prun": 3, "modelopt_prune_flops_perc": 3, "retain": [3, 14, 144], "modelopt_quantize_cfg": 3, "do_modelopt_distil": 3, "teacher": [3, 4, 8, 49, 50, 51, 53], "must": [3, 13, 17, 20, 36, 54, 74, 75, 79, 90, 93, 94, 95, 106, 108, 115, 119, 133, 144, 168, 177], "temperatur": [3, 26, 53], "restor": [3, 11, 13, 16, 21, 22, 49, 54, 63, 72, 73, 79, 91, 93, 98, 103, 106, 108, 116, 119, 134, 148, 157, 159], "modelopt_save_fil": 3, "insid": [3, 5, 6, 60, 72, 108, 153], "modelopt_restore_path": 3, "onnx_export_fil": 3, "arg": [3, 8, 12, 13, 16, 22, 27, 49, 51, 72, 75, 90, 93, 94, 99, 108, 131, 133, 134, 135, 138, 141, 142, 149, 158, 165, 166, 168, 169, 176, 177, 179, 180], "saniti": 3, "check": [3, 7, 9, 12, 19, 27, 34, 45, 46, 54, 64, 73, 79, 90, 92, 93, 94, 99, 100, 103, 106, 133, 134, 136, 144, 160, 169, 174, 177], "rais": [3, 11, 52, 72, 75, 90, 93, 114, 125, 143, 144], "valueerror": [3, 52, 125, 143, 144], "get_datasets_and_dataload": 3, "answer_column_nam": 3, "own": [3, 8, 12, 13, 15, 20, 53, 64, 94, 115, 136, 160], "csv": 3, "txt": 3, "public": 3, "hub": 3, "column": [3, 36, 44, 60, 61, 144], "text": [3, 16, 26, 27, 172], "found": [3, 17, 34, 53, 72, 92, 94, 105, 108, 168], "easili": [3, 4, 8], "tweak": [3, 19], "behavior": [3, 19, 90, 93, 94, 116, 123, 168], "prepare_train_featur": 3, "lot": 3, "whitespac": 3, "left": 3, "context": [3, 16, 18, 26, 51, 61, 90, 94, 110, 116, 131, 133, 142, 143, 144, 176], "fail": [3, 46, 169], "remov": [3, 4, 11, 12, 14, 22, 34, 42, 46, 58, 94, 147, 152, 168, 177], "question_column_nam": 3, "q": [3, 34, 36, 42, 44, 60, 61, 121], "lstrip": 3, "mayb": 3, "keep": [3, 44, 89, 103, 110, 133, 138], "overflow": 3, "possibl": [3, 11, 12, 13, 72, 73, 88, 92, 94, 108, 147], "give": [3, 18, 104, 177], "sever": [3, 13, 94], "featur": [3, 4, 5, 8, 9, 12, 13, 14, 15, 16, 22, 53, 95, 99], "those": [3, 34, 41, 42, 74, 75, 90, 102, 146, 182], "overlap": 3, "bit": [3, 4, 17, 18, 20, 43, 110, 113, 114, 115, 121, 143], "previou": [3, 11, 19, 20], "tokenized_exampl": 3, "pad_on_right": 3, "context_column_nam": 3, "only_second": 3, "only_first": 3, "max_length": [3, 27], "return_overflowing_token": 3, "return_offsets_map": 3, "might": [3, 18, 20, 93, 94, 121, 143, 177], "map": [3, 4, 13, 17, 34, 36, 41, 42, 51, 53, 59, 62, 67, 88, 89, 103, 108, 110, 115, 116, 121, 163, 168], "correspond": [3, 5, 11, 16, 42, 49, 52, 54, 72, 77, 79, 88, 93, 94, 95, 103, 106, 108, 115, 119, 121, 148, 177, 179], "kei": [3, 13, 19, 20, 22, 34, 36, 50, 52, 63, 65, 74, 75, 88, 90, 92, 93, 94, 102, 108, 115, 116, 120, 121, 146, 153, 161, 168, 177], "sample_map": 3, "pop": [3, 168], "overflow_to_sample_map": 3, "offset": 3, "charact": 3, "posit": [3, 16, 51, 60, 72, 108, 115], "start_posit": 3, "end_posit": 3, "offset_map": 3, "enumer": [3, 72, 108], "imposs": 3, "cl": [3, 92, 98, 138], "input_id": 3, "cls_index": 3, "cls_token_id": 3, "grab": 3, "know": 3, "what": [3, 7, 92, 103], "sequence_id": 3, "One": [3, 13, 34, 44, 113], "span": 3, "contain": [3, 5, 7, 11, 12, 39, 45, 50, 60, 62, 63, 65, 69, 72, 73, 75, 76, 88, 90, 91, 92, 93, 94, 99, 108, 119, 121, 134, 139, 140, 153, 159, 161, 164, 166, 168, 169, 177], "sample_index": 3, "set": [3, 5, 6, 11, 12, 14, 15, 16, 20, 22, 26, 34, 35, 40, 41, 42, 49, 50, 51, 52, 54, 60, 62, 67, 72, 73, 75, 79, 88, 90, 91, 92, 93, 94, 95, 99, 103, 104, 106, 108, 110, 113, 115, 116, 119, 121, 134, 138, 148, 149, 153, 161, 165, 166, 168, 169, 177], "answer_start": 3, "start_char": 3, "end_char": 3, "current": [3, 5, 10, 11, 12, 14, 19, 20, 22, 33, 36, 72, 73, 75, 77, 89, 92, 93, 94, 95, 108, 110, 121, 133, 136, 148, 150, 153, 160, 171, 173], "token_start_index": 3, "token_end_index": 3, "detect": [3, 22, 93], "move": [3, 43, 113, 138, 180], "two": [3, 8, 13, 14, 34, 43, 46, 60, 62, 116, 177], "last": [3, 16, 53, 72, 93, 108, 115, 177], "edg": 3, "prepare_validation_featur": 3, "substr": 3, "example_id": 3, "context_index": 3, "part": [3, 34], "easi": [3, 4, 9, 14, 19], "determin": [3, 8, 12, 13, 103, 111, 165, 168, 172, 179], "k": [3, 16, 60, 61, 121], "load_dataset": 3, "guarante": [3, 16], "concurr": 3, "raw_dataset": 3, "standard": [3, 11, 16, 93, 94, 95, 99, 108, 138, 153, 169, 177], "python": [3, 4, 5, 19, 22, 29, 63, 133, 179], "panda": 3, "datafram": 3, "etc": [3, 4, 5, 11, 12, 15, 19, 20, 34, 36, 44, 110, 115, 121, 134], "loading_dataset": 3, "slighlti": 3, "column_nam": 3, "side": 3, "padding_sid": 3, "model_max_length": 3, "warn": [3, 12, 22, 92, 176, 177], "larger": [3, 13, 16, 46, 115], "agument": 3, "main_process_first": 3, "num_proc": 3, "remove_column": 3, "load_from_cache_fil": 3, "desc": 3, "increas": [3, 4, 11, 12, 121], "dure": [3, 11, 12, 14, 16, 17, 20, 44, 51, 54, 72, 73, 74, 75, 79, 88, 93, 103, 106, 108, 115, 134, 140, 153, 168, 169, 182], "creation": 3, "again": [3, 49, 94], "info": [3, 8, 11, 12, 34, 72, 92, 108, 177], "wa": [3, 20, 22, 99, 177], "done": [3, 12, 15, 19, 20, 43, 153], "ot": 3, "collat": 3, "everyth": [3, 113], "data_col": 3, "mix": [3, 75], "pad_to_multiple_of": 3, "multipl": [3, 8, 11, 12, 13, 16, 22, 34, 44, 51, 64, 65, 93, 94, 115, 134, 165, 177], "core": [3, 12, 14, 22, 105, 108, 133], "hardwar": [3, 10, 14], "capabl": [3, 89, 92], "volta": 3, "collate_fn": 3, "evaluate_model": 3, "eval_exampl": 3, "eval_dataset": 3, "eval_dataload": 3, "prefix": [3, 16, 63, 134], "create_and_fill_np_arrai": 3, "start_or_end_logit": 3, "max_len": 3, "fill": [3, 13, 147], "len_of_validation_data": 3, "max_length_of_output_tensor": 3, "enter": 3, "logit": [3, 4, 8, 13, 26, 53], "logits_concat": 3, "float64": 3, "popul": [3, 73, 179], "gather_for_metr": 3, "output_logit": 3, "replac": [3, 5, 13, 19, 20, 22, 40, 42, 90, 94, 115, 116, 121, 131, 133, 134, 144], "newli": 3, "And": [3, 52, 60, 61], "iter": [3, 9, 11, 12, 26, 31, 36, 51, 60, 62, 67, 72, 73, 89, 90, 93, 94, 103, 108, 121, 133, 134, 153, 168, 172, 177], "chang": [3, 12, 19, 22, 29, 51, 90, 93, 110, 114, 116, 121, 168], "shape": [3, 7, 11, 12, 19, 26, 29, 31, 34, 42, 46, 53, 61, 64, 90, 104, 114, 133, 134, 143, 168], "col": 3, "postprocess_qa_predict": 3, "ndarrai": [3, 31, 36, 42, 43, 44, 46, 63, 67, 180], "version_2_with_neg": 3, "bool": [3, 26, 33, 34, 36, 37, 42, 43, 44, 45, 46, 49, 51, 54, 60, 61, 62, 64, 72, 73, 74, 75, 79, 90, 92, 93, 94, 99, 100, 103, 113, 115, 117, 119, 121, 133, 134, 138, 143, 147, 148, 163, 165, 166, 168, 169, 172, 173, 174, 177], "null_score_diff_threshold": 3, "them": [3, 12, 20, 22, 43, 44, 46, 53, 61, 64, 75, 91, 94, 121, 134, 138, 165, 177], "base": [3, 9, 10, 11, 14, 16, 18, 22, 26, 27, 31, 36, 38, 44, 49, 50, 51, 52, 53, 54, 58, 61, 66, 71, 72, 73, 74, 75, 77, 78, 79, 81, 82, 83, 84, 85, 88, 89, 90, 92, 93, 94, 95, 99, 101, 102, 103, 104, 105, 106, 108, 110, 112, 113, 114, 115, 116, 119, 120, 121, 123, 125, 128, 129, 130, 131, 132, 133, 134, 138, 139, 140, 141, 143, 146, 147, 148, 149, 151, 152, 155, 158, 159, 161, 165, 166, 168, 169, 176, 177, 178], "postprocess": [3, 58, 62, 120], "non": [3, 13, 19, 27, 29, 34, 41, 49, 51, 60, 72, 93, 94, 108, 147, 177], "respect": [3, 4, 13, 14, 17, 92, 108, 115, 121], "Its": 3, "dimens": [3, 12, 17, 36, 43, 44, 46, 53, 115, 138, 144, 168], "match": [3, 19, 20, 34, 41, 72, 74, 75, 88, 92, 102, 108, 115, 116, 121, 146, 174, 176], "element": [3, 14, 34, 43, 72, 108, 147, 175, 177, 179], "underli": [3, 90, 94], "threshold": [3, 14], "null": [3, 49, 115, 146], "less": [3, 11, 12, 20, 133], "minu": 3, "minimum": [3, 12], "align": [3, 22], "fact": 3, "thei": [3, 20, 22, 46, 49, 74, 94, 102, 115, 121, 134, 146, 153, 177], "want": [3, 5, 11, 12, 14, 15, 20, 58, 74, 88, 89, 90, 93, 94, 99, 102, 103, 115, 119, 143, 146, 153, 179], "dictionari": [3, 13, 14, 19, 20, 22, 31, 34, 36, 42, 46, 49, 50, 51, 62, 63, 65, 72, 74, 75, 92, 93, 94, 99, 102, 108, 115, 116, 120, 121, 146, 153, 161, 168, 177], "n_best": 3, "mention": [3, 12], "ad": [3, 22, 34, 44, 54, 72, 93, 94, 108, 134, 143, 153, 155, 161, 165, 168], "start_logit": 3, "end_logit": 3, "all_start_logit": 3, "all_end_logit": 3, "got": 3, "example_id_to_index": 3, "features_per_exampl": 3, "defaultdict": 3, "all_predict": 3, "ordereddict": 3, "all_nbest_json": 3, "scores_diff_json": 3, "loop": [3, 4, 6, 8, 9, 12, 20, 43, 72, 73, 99, 108, 153, 172], "over": [3, 4, 11, 12, 13, 26, 36, 46, 88, 92, 94, 99, 103, 104, 121, 129, 168, 172], "example_index": 3, "feature_indic": 3, "min_null_predict": 3, "prelim_predict": 3, "feature_index": 3, "token_is_max_context": 3, "feature_null_scor": 3, "greater": 3, "start_index": 3, "argsort": 3, "tolist": 3, "end_index": 3, "don": [3, 5, 34, 44, 99, 119], "scope": 3, "null_scor": 3, "n_best_pr": 3, "sort": [3, 13, 72, 77, 88, 95, 104, 108, 166], "revers": [3, 133], "back": [3, 12, 22, 34, 91, 94, 138, 165], "low": [3, 10, 17, 18, 20, 22, 115], "gather": [3, 58, 72, 108, 121], "pred": 3, "rare": 3, "fake": [3, 20, 93, 115, 134, 138, 143, 165], "avoid": [3, 13, 20, 49, 51, 115, 182], "failur": [3, 169], "insert": [3, 19, 20, 34, 42, 93, 110], "empti": [3, 58, 62, 64, 72, 88, 108, 143, 146, 168, 177], "softmax": [3, 34, 41], "stai": [3, 17], "independ": [3, 165], "tf": [3, 177], "logsumexp": 3, "trick": 3, "exp_scor": 3, "exp": 3, "prob": 3, "probabl": 3, "zip": 3, "pick": [3, 16], "best_non_null_pr": 3, "Then": [3, 16, 77], "score_diff": 3, "serializ": 3, "cast": [3, 34, 44], "v": [3, 34, 60, 61, 121, 177], "float16": [3, 61, 62, 69, 134], "float32": [3, 43, 134, 143], "isdir": 3, "environmenterror": 3, "prediction_fil": 3, "join": 3, "_predict": 3, "nbest_fil": 3, "nbest_predict": 3, "_nbest_predict": 3, "null_odds_fil": 3, "null_odd": 3, "_null_odd": 3, "open": 3, "w": [3, 19, 36, 94, 147], "writer": 3, "dump": [3, 49, 92], "indent": 3, "nbest_pr": 3, "metric": [3, 12, 72, 99, 108], "formatted_predict": 3, "prediction_text": 3, "refer": [3, 4, 6, 7, 10, 11, 12, 13, 14, 19, 20, 22, 26, 27, 29, 34, 72, 91, 95, 108, 133, 134, 153, 168, 177], "ex": [3, 31, 34], "label_id": 3, "num": [3, 176], "being": [3, 22, 94, 104], "pad_across_process": 3, "pad_index": 3, "clear": [3, 165, 177, 178], "intermedi": [3, 13, 34, 44, 72, 108, 121], "compute_kd_loss": [3, 8, 13, 51, 52], "concaten": [3, 77], "start_logits_concat": 3, "end_logits_concat": 3, "outputs_numpi": 3, "eval_metr": 3, "defin": [3, 6, 7, 8, 9, 11, 12, 13, 14, 16, 17, 20, 41, 59, 61, 90, 91, 96, 99, 115, 116, 121, 123, 134, 148, 168, 179], "factori": [3, 61], "teacher_factori": [3, 8], "from_pretrain": [3, 14, 15, 16, 22, 98], "startendlogitsdistillationloss": 3, "logitsdistillationloss": [3, 8, 13, 53], "outputs_": 3, "outputs_t": 3, "loss_start": 3, "loss_end": 3, "train_and_evaluate_model": 3, "no_decai": 3, "layernorm": [3, 20, 60, 61, 66, 74, 102, 116], "optimizer_grouped_paramet": 3, "named_paramet": 3, "nd": 3, "adamw": 3, "around": [3, 20], "overrode_max_train_step": 3, "num_update_steps_per_epoch": 3, "ceil": [3, 43], "num_training_step": 3, "prepar": [3, 67, 96, 110, 152, 172], "recalcul": 3, "afterward": [3, 53, 94], "figur": 3, "mani": [3, 7, 11, 14, 16, 143], "isdigit": 3, "main": [3, 11, 26, 27, 29, 38, 50, 62, 71, 73, 75, 161], "experiment_config": 3, "var": 3, "tensorboard": 3, "cannot": [3, 12, 34, 49, 72, 108, 153, 165, 168, 177], "enum": [3, 168], "raw": [3, 46], "init_track": 3, "total_batch_s": 3, "num_process": 3, "instantan": [3, 171], "progress": [3, 121, 177], "bar": [3, 177], "machin": 3, "progress_bar": [3, 177], "disabl": [3, 20, 22, 90, 110, 121, 133, 134, 144, 165, 166, 168], "is_local_main_process": 3, "completed_step": 3, "starting_epoch": 3, "resume_step": 3, "recent": 3, "dir": [3, 22, 27, 58], "scandir": 3, "is_dir": 3, "startswith": 3, "epoch_": 3, "step_": 3, "scratch": [3, 7, 11, 13], "latest_dir": 3, "getctim": 3, "load_stat": 3, "extract": 3, "basenam": 3, "multipli": [3, 14, 53], "reflect": [3, 11], "real": [3, 19, 20, 115, 120, 131, 134, 137, 138], "total_loss": 3, "skip": [3, 5, 11, 12, 20, 34, 88, 94, 113, 115, 121, 168], "resum": [3, 7, 11, 12, 20, 91], "active_dataload": 3, "skip_first_batch": 3, "unwrap": [3, 75, 92, 93, 177], "to_tupl": 3, "track": [3, 89, 110, 114], "behind": [3, 11, 13, 17], "scene": 3, "sync_gradi": 3, "save_st": [3, 16], "break": [3, 8, 22, 72, 108], "ignor": [3, 12, 27, 121], "attr": 3, "wait_for_everyon": 3, "is_main_process": 3, "eval_": 3, "accelerator_log_kwarg": 3, "log_with": 3, "project_dir": 3, "basicconfig": 3, "asctim": 3, "levelnam": 3, "messag": [3, 169, 176], "datefmt": 3, "d": [3, 63, 110], "y": [3, 36, 72, 108, 177], "h": [3, 19, 147], "level": [3, 26, 34, 72, 94, 108, 121, 153], "main_process_onli": 3, "set_verbosity_warn": 3, "set_verbosity_info": 3, "set_verbosity_error": 3, "handl": [3, 13, 20, 22, 55, 73, 86, 88, 89, 93, 94, 97, 107, 136, 138, 150, 160, 165, 167], "makedir": 3, "exist_ok": 3, "use_fast": 3, "save_modelopt_model": 3, "save_path": 3, "assert": [3, 46, 93], "exist": [3, 4, 11, 12, 13, 14, 58, 60, 72, 89, 93, 94, 98, 108, 133], "doe": [3, 9, 11, 14, 18, 22, 38, 44, 75, 90, 93, 94, 95, 115, 119, 121], "synchron": [3, 58, 134, 173, 179], "across": [3, 14, 17, 58, 61, 64, 94, 134, 179], "same": [3, 8, 11, 13, 15, 16, 17, 22, 36, 44, 46, 58, 61, 72, 74, 93, 94, 102, 103, 104, 108, 121, 133, 134, 143, 146, 153, 168, 177, 179], "search": [3, 20, 22, 36, 72, 73, 74, 75, 79, 88, 90, 91, 93, 94, 99, 100, 103, 104, 105, 106, 108, 110, 115, 121, 148, 151, 152, 153, 168, 179], "na": [3, 7, 11, 21, 54, 74, 79, 86, 87, 90, 101, 106, 179], "mtn": [3, 12, 54, 79, 90, 177, 179, 182], "collect_func": [3, 9, 14, 22, 72, 108, 153, 177], "loss_func": [3, 11, 20, 22, 72, 108, 121], "forward_loop": [3, 6, 9, 15, 20, 72, 99, 108, 115, 120, 121, 153, 172], "num_sampl": [3, 6, 9, 20, 172], "256": [3, 12], "num_batch": 3, "idx": [3, 52, 166], "getattr": [3, 94], "empty_cach": 3, "distillationmodel": [3, 13, 50, 51, 52], "kd_config": 3, "teacher_model": [3, 8, 13, 49, 51], "criterion": [3, 8, 13, 49, 51, 52], "kd_loss": [3, 8, 13, 50], "wb": 3, "onnx_opset": 3, "14": 3, "__main__": 3, "unprun": 3, "recov": [3, 7, 11, 12, 16, 20], "99": [3, 113], "f1": 3, "93": 3, "converg": [3, 4], "1_prune": 3, "sh": [3, 5, 22, 27], "bin": [3, 19, 113], "bash": [3, 5], "flops_perc": 3, "base_dir": 3, "bert_large_pruned_": 3, "_percent": 3, "modelopt_arg": 3, "fi": 3, "launch": 3, "multi_gpu": 3, "mixed_precis": [3, 62, 65, 69], "slight": 3, "abl": [3, 12], "2_int8_quant": 3, "int8_quant": 3, "quantized_model": [3, 20], "int8_default_cfg": [3, 20, 115], "3_onnx_export": 3, "python3": 3, "pruned_model_int8": 3, "minim": [4, 13, 17, 22, 99, 110, 115], "present": [4, 8, 13, 46], "signific": [4, 12, 168], "challeng": 4, "ai": 4, "grow": 4, "complex": 4, "librari": [4, 5, 7, 15, 22, 44], "compris": [4, 18], "accept": [4, 13, 16, 22, 133, 143], "stack": [4, 10, 119], "produc": [4, 16, 34, 46], "seamlessli": [4, 12, 13], "ecosystem": 4, "readi": [4, 6, 11, 50, 73], "plan": 4, "enterpris": 4, "diffus": [4, 5, 15, 22, 136], "nim": 4, "visit": 4, "recip": [4, 110], "2x": [4, 14], "4x": 4, "speed": [4, 6, 9, 14, 16], "preserv": [4, 17, 75, 93, 168], "qualiti": [4, 13, 20], "highli": [4, 11, 14, 20], "int4": [4, 18, 19, 20, 22, 34, 44, 115, 134, 139], "support": [4, 5, 6, 7, 9, 10, 11, 13, 14, 15, 16, 18, 19, 20, 22, 27, 33, 35, 36, 37, 40, 42, 44, 45, 51, 57, 60, 61, 72, 75, 93, 94, 99, 108, 113, 115, 116, 119, 120, 121, 122, 123, 124, 136, 142, 144, 150, 153, 158, 160, 165, 177, 182], "smoothquant": [4, 6, 17, 18, 20, 115, 120, 134], "awq": [4, 6, 17, 18, 20, 36, 61, 64, 115, 139], "doubl": [4, 115, 140], "both": [4, 5, 6, 8, 12, 13, 14, 17, 18, 20, 22, 36, 50, 94, 131, 165, 168], "page": 4, "memori": [4, 6, 9, 10, 14, 18, 20, 22, 46, 62, 64, 115, 140, 177, 178], "footprint": [4, 6, 9, 14], "deep": [4, 6, 9, 17], "mt": [4, 9, 14], "sparsifi": [4, 9, 14, 22, 153], "pattern": [4, 9, 14, 34, 41, 44, 74, 88, 102, 115, 121, 146, 147, 153, 174, 176], "sparsif": [4, 22, 145, 148], "asp": [4, 9, 14, 147], "sparsegpt": [4, 9, 14, 148, 153], "pt": [4, 20, 93], "sat": [4, 22], "latter": 4, "degrad": [4, 11, 12, 18, 20, 104], "knowledg": [4, 8, 22, 49, 51, 52, 54], "effici": [4, 13, 14, 133, 139, 140], "student": [4, 8, 49, 50, 51, 52, 53], "tradit": 4, "becom": [4, 13, 18, 44], "invas": 4, "unnecessari": 4, "conv": [4, 20, 22, 33, 37, 41, 60, 61, 168], "linux": 5, "x86_64": 5, "aarch64": [5, 22], "sbsa": [5, 22], "docker": 5, "imag": [5, 177], "easiest": 5, "wai": [5, 11, 14, 15, 16, 17, 20, 94, 165, 177], "command": [5, 19], "clone": [5, 90], "git": 5, "cd": 5, "tag": 5, "io": 5, "modelopt_exampl": 5, "dockerfil": 5, "exclud": [5, 34, 44], "certain": [5, 12, 41, 93, 94, 103, 104, 116, 121], "shm": [5, 58], "20g": 5, "rm": 5, "__version__": 5, "altern": [5, 7, 13, 15, 19], "ngc": 5, "come": [5, 11, 12, 143], "sure": [5, 12, 90, 94], "conda": 5, "virtual": 5, "desir": [5, 6, 7, 12, 13, 42, 50, 75, 93, 108, 153, 161, 168], "instruct": 5, "wish": [5, 13], "correctli": [5, 12, 14, 15, 20, 90, 92, 134, 136], "compat": [5, 12, 22, 60, 62, 67, 70, 75, 93, 94, 121, 138, 169, 177], "conjunct": [5, 99, 182], "triton": 5, "eas": [5, 34], "issu": [5, 22, 49, 177, 181], "seamless": 5, "still": [5, 12, 13, 75, 94, 110], "choos": [5, 10, 22, 72, 108, 115, 153, 179], "via": [5, 11, 12, 13, 14, 16, 18, 36, 54, 72, 79, 88, 89, 90, 93, 94, 99, 106, 108, 119, 148, 149, 159, 168, 177, 179], "review": 5, "term": [5, 11, 13, 14], "suggest": [5, 18, 121], "upgrad": [5, 22], "appropri": [5, 6, 9, 89, 95, 115, 134], "shown": [5, 11, 12, 15, 74, 75, 102, 146, 168], "19": 5, "partial": [5, 34, 165, 169], "barebon": 5, "addition": [5, 34, 93, 121], "3rd": 5, "parti": [5, 55, 86, 97, 107, 136, 150, 160, 167], "packag": [5, 22, 24, 57, 109, 133, 144, 173], "third": [5, 34, 55, 86, 97, 107, 136, 150, 160, 167], "hf": [5, 7, 11, 21, 22, 27, 59, 69], "compil": [5, 19, 29, 34, 37, 41, 44, 171], "kernel": [5, 12, 18, 34, 41, 177], "subsequ": [5, 12, 14, 72, 99, 108, 171], "invok": [5, 13, 176], "extens": [5, 27, 88, 143, 171], "ext": 5, "precompil": [5, 118], "get_model": [6, 9, 20], "rough": 6, "calib_s": [6, 9, 20], "get_dataload": [6, 20], "int8_smoothquant_cfg": [6, 20, 115], "guid": [6, 8, 9, 12, 15, 20, 22], "usag": [6, 7, 8, 9, 12, 13, 14, 16, 20, 72, 75, 89, 92, 98, 108, 140, 172, 178], "resnet20": [7, 11, 21], "cifar": [7, 11, 21], "10": [7, 11, 18, 19, 20, 21], "minitron": [7, 11, 105, 108], "fastna": [7, 11, 12, 72, 90, 102, 104, 106, 108], "involv": [7, 8, 13, 58, 73], "three": [7, 11, 18, 34, 121], "sub": [7, 11, 41, 72, 73, 90, 91, 99, 169], "net": [7, 11, 72, 73, 90, 99, 177], "serach": [7, 11], "resnet50": [7, 8, 11, 12, 13], "pretrained_weight": [7, 8, 11], "dummi": [7, 11, 12, 90, 131], "similar": [7, 11, 12, 125, 134], "224": [7, 11, 12], "244": [7, 11], "prune_constraint": [7, 11], "prune_r": [7, 11], "stat": [7, 11, 12, 34, 72, 99, 108, 121, 153, 175], "pruner": [7, 11], "searcher": [7, 11, 12, 73, 103, 104, 105, 110, 147, 152], "bn": [7, 11, 12, 34], "subnet": [7, 72, 73, 74, 75, 88, 90, 94, 99, 103, 108, 148, 179], "re": [7, 11, 12, 13, 14, 16, 49, 94], "modelopt_fastnas_search_checkpoint": [7, 11], "modelopt_pruned_model": [7, 11], "wrapper": [8, 26, 51, 75, 93, 138, 177], "among": [8, 13, 95], "higher": [8, 11, 12, 14, 121], "usuali": 8, "serv": [8, 13, 18], "resnet18": 8, "student_model": [8, 13], "callabl": [8, 13, 20, 49, 51, 52, 54, 72, 75, 79, 88, 89, 90, 93, 95, 99, 104, 106, 108, 110, 115, 116, 119, 120, 121, 133, 148, 153, 159, 165, 168, 169, 172, 177], "least": [8, 41, 92], "simplifi": [8, 101, 165], "assum": [8, 34, 53, 60, 72, 108, 165, 177], "distillation_config": [8, 13], "receiv": 8, "order": [8, 12, 13, 20, 27, 34, 44, 52, 72, 74, 93, 94, 95, 102, 108, 115, 146, 165, 177], "loss_balanc": [8, 13, 49, 51], "staticlossbalanc": [8, 13, 52], "omit": [8, 13], "distillation_model": [8, 13], "model_cl": [8, 75, 93], "kwarg": [8, 13, 27, 36, 37, 44, 49, 51, 72, 75, 92, 93, 94, 108, 120, 131, 133, 134, 135, 138, 139, 140, 141, 142, 149, 165, 166, 168, 176, 177, 179, 180], "usual": [8, 11, 12, 13, 14, 93, 94, 99], "get_train_load": 8, "get_user_loss_fn": 8, "train_dataload": 8, "loss_tot": 8, "student_loss": [8, 51, 52], "dataparallel": [8, 75], "trainer": [8, 16], "revert": [8, 94, 165], "modif": [8, 11, 12, 13, 15, 22, 91, 93], "attach": 8, "get_train_dataload": 9, "sparsity_config": [9, 14], "driven": [9, 14], "sparse_magnitud": [9, 14, 146, 153], "pure": [9, 13, 92], "substitut": [9, 110], "simul": [10, 20, 134], "actual": [10, 13, 18, 34, 73, 93, 94, 95, 99, 105, 168, 177], "speedup": [10, 19, 20], "basic": [10, 12, 13, 14, 16, 31, 40, 43, 52, 89, 94, 99, 121, 143, 168], "concept": [10, 91, 115], "practic": [10, 26], "beta": 10, "aka": [11, 12], "unifi": [11, 22, 69, 113], "aggress": [11, 12], "These": [11, 16, 22, 115], "convolut": [11, 12, 34, 128], "network": [11, 12, 17, 58, 90, 152], "measur": [11, 12, 18, 63, 104, 178], "3e": 11, "equal": [11, 46, 95], "place": [11, 12, 13, 20, 41, 60, 72, 92, 93, 94, 108, 121, 153, 163, 165, 179], "distributeddataparallel": [11, 75, 93, 182], "fulli": [11, 22, 75, 94, 134], "shard": [11, 22, 177], "fsdp": [11, 22, 49, 51], "henc": [11, 12, 15, 94, 121, 149], "feasibl": 11, "ss_config": 11, "candid": [11, 12, 16, 73, 94], "overal": [11, 101], "274": 11, "34m": 11, "28g": 11, "59g": [11, 12], "73": 11, "70m": 11, "75m": 11, "50m": [11, 12], "75g": 11, "layer1": [11, 12], "layer4": [11, 12], "96": 11, "416": 11, "448": 11, "480": 11, "2048": [11, 12, 113, 115], "bn2": [11, 12], "conv3": [11, 12], "36": 11, "48e": 11, "pruneabl": 11, "slower": [11, 13], "adjust": [11, 12, 17, 20, 65, 116, 120], "accordingli": [11, 65, 88, 94, 116, 168], "unabl": 11, "perhap": 11, "too": 11, "try": [11, 12, 18, 180], "cannnot": 11, "interrupt": 11, "errror": 11, "ensur": [11, 12, 45, 73, 88, 90, 94, 121, 177], "explain": 11, "reus": 11, "ahead": 11, "forget": [11, 15], "modelopt_pruned_finetuned_model": 11, "hand": [11, 14], "neural": 11, "redund": [11, 12], "compon": [11, 12, 18, 52], "conceptu": 11, "overhead": [11, 133], "simpler": [11, 101], "approxim": [11, 103, 110, 153, 179], "therefor": [11, 16, 93, 94], "expens": [11, 16], "directli": [11, 20, 50, 88, 90, 94, 104, 134, 143], "autona": [12, 72, 74, 75, 79, 90, 103], "suitabl": [12, 172], "layerwis": [12, 63, 69], "uniqu": [12, 52, 62, 94, 104, 147, 177], "nativ": [12, 20, 22, 41, 166], "conveni": [12, 92], "even": [12, 13, 20, 36, 104, 169], "modelopt_model": [12, 15, 90], "autonasconfig": [12, 74, 75], "out_channels_ratio": [12, 75], "model_or_model_factori": 12, "accord": [12, 88, 90, 92, 94, 123, 143, 153, 165, 177], "togeth": [12, 16, 19, 20, 61, 77, 93, 94, 165, 168], "gflop": [12, 108], "0e9": 12, "against": [12, 115, 116, 121, 176], "is_sat": 12, "search_space_stat": 12, "487": 12, "92m": 12, "84g": 12, "84m": 12, "00g": 12, "352": 12, "90e": 12, "infrastructur": [12, 91, 101], "3x": 12, "anneal": 12, "rest": [12, 14, 103, 104], "proce": 12, "calcul": [12, 13, 17, 44, 65, 72, 99, 104, 108, 143, 144, 147], "search_constraint": 12, "search_r": 12, "searched_model": 12, "modelopt_search_checkpoint": 12, "modelopt_searched_model": 12, "At": 12, "implement": [12, 13, 14, 17, 34, 41, 43, 51, 53, 54, 58, 60, 76, 79, 81, 82, 83, 84, 91, 94, 99, 103, 104, 105, 106, 123, 125, 133, 138, 139, 140, 141, 143, 158, 164, 165, 166], "quickli": 12, "encount": [12, 169], "problem": 12, "deriv": 12, "searchabl": [12, 88, 90, 94, 165, 168], "unit": [12, 88, 90, 94, 96, 177], "conv1d": [12, 61, 74, 102, 128], "conv3d": [12, 74, 102, 128], "convtranspose1d": [12, 74, 102, 128], "convtranspose2d": [12, 74, 102, 128], "convtranspose3d": [12, 74, 102, 128], "residu": [12, 34, 41, 158], "block": [12, 14, 18, 20, 36, 44, 60, 65, 94, 108, 115, 134, 139, 140, 143, 153, 158, 179], "llama3": 12, "hidden": [12, 61, 133, 158], "megatronmodul": 12, "nlp": [12, 27], "language_model": 12, "megatron_gpt_model": 12, "megatrongptmodel": 12, "use_cach": [12, 61], "modeling_bert": 12, "bertattent": 12, "modeling_gptj": 12, "gptjattent": 12, "suffic": 12, "repres": [12, 42, 77, 94, 95, 143, 165, 166, 177], "behav": 12, "roughli": 12, "broken": [12, 36], "down": 12, "trace": [12, 88, 89, 163, 165, 167, 168, 169], "resolv": [12, 89], "implicitli": 12, "fx": [12, 169], "tracer": [12, 163], "error": [12, 72, 75, 90, 93, 115, 119, 135, 142, 176], "affect": [12, 94, 168, 177], "definit": [12, 115, 121], "occur": [12, 34, 60, 67, 115], "find_unused_paramet": 12, "branch": 12, "full": [12, 22, 58, 60, 61, 92, 93, 115], "faq": [12, 21], "terminologi": [12, 13, 14, 16], "isol": 12, "discret": 12, "parameter": 12, "individu": [12, 60, 72, 75, 91, 94, 108, 134, 153], "distinct": 12, "oper": [12, 14, 17, 18, 22, 29, 44, 75, 90, 108, 165, 169, 175, 177], "character": 12, "smallest": 12, "closest": [12, 175, 179], "largest": [12, 14, 88], "relev": [12, 63, 72, 92, 168], "sapc": 12, "simultan": [12, 16, 94], "entir": [12, 121], "vari": 12, "procedur": [12, 72, 91, 92, 99, 108, 121], "account": 12, "accur": 12, "boost": [12, 13], "flexibl": [12, 14, 168], "constrain": [12, 17], "fewer": [12, 72, 108, 153], "due": [12, 14, 20, 104, 110], "exhibit": [12, 89, 168], "wors": 12, "direct": [13, 20, 133], "transfer": [13, 93, 113], "power": [13, 16], "meta": [13, 50, 51, 134, 138, 148], "abstract": [13, 52, 73, 99, 112, 143], "awai": 13, "interact": [13, 165], "orign": 13, "form": [13, 72, 75, 93, 177], "model_cls_or_cal": [13, 177], "model_export": 13, "upon": [13, 20, 88, 94], "thu": [13, 34, 72, 108, 153], "namespac": 13, "anymor": [13, 94], "though": [13, 143], "subclass": [13, 20, 94, 110, 115, 138, 161], "learnabl": 13, "fix": [13, 17, 22, 41, 96, 134, 153], "separ": [13, 17, 44, 45, 93, 113, 169], "scalar": [13, 51, 53, 72, 108, 121, 123, 134], "broader": 13, "auxilliari": 13, "hope": 13, "master": [13, 143, 173, 176, 177], "reduct": [13, 29, 52, 53], "reach": 13, "exceed": 13, "lotteri": 13, "ticket": 13, "hypothesi": 13, "reason": [13, 143], "b": [13, 36, 72, 108], "often": [13, 18, 20, 41], "ideal": [13, 113], "untrain": 13, "possess": 13, "satisfactori": 13, "object": [13, 34, 36, 42, 58, 61, 75, 88, 89, 93, 94, 95, 104, 133, 134, 138, 143, 168, 169, 177], "enact": 13, "mse": [13, 113], "assumpt": 13, "high": [13, 17, 18, 26, 34, 44, 72, 108, 153], "imit": 13, "pair": [13, 22, 49, 51, 120], "pairwis": 13, "Will": 13, "classifi": 13, "atd": 13, "captur": [13, 15, 121], "especi": [13, 16], "backpropag": [13, 51], "whose": [13, 90], "interfac": [13, 52, 88, 93, 96, 99, 151], "distillationlossbalanc": [13, 51, 52], "aforement": 13, "ones": [13, 88, 131, 147], "scenario": [13, 17, 18], "classif": 13, "altogeth": 13, "prefer": [13, 19], "whatev": 13, "ground": 13, "truth": 13, "dens": [14, 61], "retrain": 14, "simplest": [14, 17, 20], "automodelforcausallm": [14, 15, 16, 98], "eleutherai": 14, "calib_dataload": [14, 20], "sparse_model": 14, "modelopt_sparse_model": 14, "along": [14, 17, 22, 115, 138, 144], "later": [14, 15, 18, 20, 74, 88, 102, 134, 146], "unmodifi": [14, 16, 93, 94], "plain": 14, "enforc": [14, 74, 92, 93, 94, 95, 153, 163], "overview": [14, 16, 17, 21], "fraction": 14, "zero": [14, 36, 42, 44, 113, 143, 147], "broadli": 14, "categor": [14, 29], "matrix": [14, 147, 152], "lead": [14, 116], "poor": 14, "exploit": 14, "throughput": [14, 18, 19], "special": [14, 20, 34, 52, 94, 115, 116, 165], "contigu": [14, 63, 64], "nonzero": 14, "benefit": 14, "bandwidth": [14, 17, 18], "deliv": 14, "On": 14, "amper": [14, 18], "four": 14, "There": [14, 16, 143, 165], "commonli": [14, 17], "approach": [14, 16], "brain": 14, "surgeon": 14, "modelopt_st": [15, 22, 93, 98, 134], "custom_method_to_save_model_weight": 15, "although": [15, 94, 95, 168], "thereof": 15, "were": [15, 177], "restore_from_modelopt_st": [15, 93], "custom_method_to_load_model_weight": 15, "save_pretrain": [15, 22, 98], "enable_huggingface_checkpoint": [15, 16, 22, 98], "program": [15, 98, 110], "model_path": [15, 98], "modelopt_": 15, "mtsp": 16, "compute_loss": 16, "frozen": [16, 20, 149], "medua": 16, "tinyllama": 16, "1b": 16, "chat": 16, "v1": 16, "pad_token_id": [16, 27], "eos_token_id": [16, 27], "medusa_config": 16, "medusa_num_head": [16, 155, 158], "medusa_num_lay": [16, 155, 158], "medusa_model": 16, "training_arg": 16, "data_modul": 16, "_move_model_to_devic": 16, "plugin": [16, 22, 44, 45, 98], "replace_medusa_compute_loss": 16, "medusa_only_head": 16, "resume_from_checkpoint": 16, "save_model": 16, "autoregress": 16, "serial": [16, 49, 58, 177], "slow": 16, "propos": [16, 93], "critic": 16, "typic": [16, 17, 18, 19, 20], "short": [16, 74, 102, 146], "draft": 16, "regress": 16, "attain": 16, "scheme": [16, 49, 51, 115], "decid": [16, 113, 143], "popular": [16, 18], "introduc": [16, 22, 27], "tree": [16, 168], "mechan": [16, 94], "emploi": 16, "longest": 16, "plausibl": 16, "topic": 17, "width": [17, 26], "integ": [17, 18, 36, 113, 114, 115, 134, 143], "sign": [17, 43, 134, 143], "mantissa": [17, 115], "expon": [17, 115], "explan": 17, "unscal": 17, "share": [17, 44, 46, 58, 62, 121], "divid": 17, "global": [17, 42, 90, 114, 121], "gptq": 17, "unchang": [17, 94], "round": [17, 36, 61], "nearest": [17, 36], "entropi": [17, 37, 44, 113], "straight": [17, 143], "ste": 17, "clip": [17, 36, 37, 44, 115, 123, 134, 143], "explicit": [17, 19, 168], "graph": [17, 22, 34, 41, 42, 46, 88, 169, 180], "represent": [17, 54, 62, 79, 106, 115, 119, 148, 159, 165, 168], "qdq": [17, 19, 34, 38, 41, 42, 115], "node": [17, 19, 20, 22, 34, 36, 41, 42, 44, 46, 62, 165, 169], "primari": 18, "cach": [18, 20, 22, 26, 31, 42, 44, 178], "regim": 18, "superior": 18, "densiti": 18, "crucial": 18, "consequ": [18, 94], "lower": [18, 73, 75, 92, 125], "priorit": [18, 92], "caus": [18, 41, 88], "strong": 18, "earlier": [18, 74, 75, 88, 102, 146], "sq": 18, "toler": 18, "tabl": [18, 115], "tradeoff": 18, "medium": 18, "ada": 18, "hopper": 18, "w4a16": [18, 115], "wise": [18, 20, 34, 51, 62, 115, 162, 163], "ten": 18, "w4a8": [18, 61, 115], "impact": 18, "ll": 18, "eq": 19, "advantag": [19, 20], "offer": [19, 20], "expert": [19, 20, 60, 61], "white": 19, "box": 19, "design": [19, 71, 72, 75, 108], "rule": [19, 20, 34, 88, 92, 94, 110, 121, 149], "link": [19, 22, 63, 110, 165, 166], "npz": [19, 62, 67], "npy": 19, "calib_data": 19, "multi": [19, 58, 104], "input_nam": [19, 34, 46], "input_name2": 19, "shape2": 19, "savez": 19, "moq": 19, "calibration_data": [19, 31, 44], "calibration_data_path": 19, "onnx_path": [19, 31, 33, 34, 36, 37, 44, 45, 46], "output_path": [19, 44], "quant": [19, 42, 44, 119], "quantize_mod": [19, 34, 44], "calibraton": 19, "tool": [19, 27, 29, 91], "friendli": [19, 22, 37], "op_types_to_quant": [19, 29, 33, 37, 40, 44], "op_types_to_exclud": [19, 33, 34, 37, 44], "trtexec": 19, "usr": 19, "src": [19, 34], "saveengin": 19, "field": [19, 49, 61, 63, 74, 92, 102, 115, 146, 155], "flag": [19, 22, 44, 93, 165], "implicit": 19, "cover": 20, "successfulli": 20, "print_quant_summari": [20, 121], "flow": [20, 29], "sample_input": 20, "onnx_fil": 20, "resourc": 20, "calib_set": 20, "durat": 20, "suffici": [20, 38], "effective_bit": [20, 22, 121], "fp8_default_cfg": [20, 115, 121], "sensit": [20, 103, 104, 121], "forward_step": [20, 22, 121], "search_state_dict": 20, "quantization_format": [20, 121], "w4a8_awq_beta_cfg": [20, 115, 121], "auto_quantize_model": 20, "hood": 20, "patch": [20, 35, 39, 40, 73, 75, 88, 90, 94, 103, 165], "quantizerattributeconfig": [20, 22, 113, 114, 115, 116, 121, 128, 130, 131, 133, 134], "set_from_attribute_config": [20, 22, 116, 134], "explicitli": [20, 35, 92, 94], "quant_x": 20, "quantizer_custom": 20, "num_bit": [20, 60, 110, 113, 114, 115, 117, 128, 130, 131, 133, 134, 143], "block_siz": [20, 36, 44, 63, 115, 128, 130, 131, 133, 134, 138, 139, 140, 143], "who": 20, "wildcard": [20, 75, 88, 115, 116, 121], "quant_cfg": [20, 63, 69, 115, 116, 121, 172], "bmm": 20, "output_quant": [20, 60, 131], "regist": [20, 22, 89, 92, 94, 95, 110, 116, 143, 152, 168, 169], "unsupport": [20, 169], "kv": [20, 26, 60], "quantlayernorm": [20, 116], "normalized_shap": [20, 116], "_setup": [20, 94, 116], "input_quant": [20, 115, 116, 121, 131, 133], "weight_quant": [20, 110, 113, 115, 116, 121, 131, 133], "anywher": 20, "layer_norm": [20, 116], "instanti": [20, 27, 90, 98], "attribut": [20, 22, 42, 60, 94, 115, 116, 121, 134, 138, 177], "original_cl": [20, 94, 116], "quantized_cl": [20, 116], "fold": [20, 94, 110, 121], "inferec": 20, "fold_weight": [20, 121], "user_evaluate_func": 20, "refactor": 20, "extend": [20, 92, 94], "quick": 21, "specul": [21, 22, 155, 160, 161], "decod": [21, 22, 27, 60, 61, 62, 67, 154, 155, 158, 161], "changelog": 21, "contact": 21, "deprec": [22, 113, 135, 142, 173, 176], "llm_ptq": 22, "huggingface_exampl": 22, "auto_quant": [22, 110, 121], "forward_backward_step": [22, 121], "compatbil": 22, "gh200": 22, "auto_qaunt": 22, "lm_evaluation_har": 22, "benchmark": 22, "perf": [22, 26, 34], "modelopt_to_tensorrt_llm": 22, "execut": [22, 34, 44], "op": [22, 29, 34, 37, 38, 40, 41, 44, 45, 93, 169], "jax": 22, "cupi": 22, "mcore": 22, "num_lay": [22, 105, 133], "hidden_s": [22, 60, 61, 105, 158], "dataset_util": 22, "get_dataset_dataload": [22, 172], "chain": [22, 119], "dq": [22, 34, 42, 44], "medusa": [22, 60, 155, 157, 158, 159, 161], "amax": [22, 65, 113, 114, 115, 117, 120, 134, 143, 144], "export_hf_checkpoint": [22, 69], "pack": [22, 43, 63, 69, 133, 138, 139, 140], "vllm": 22, "flux": 22, "dev": 22, "set_data_parallel_group": [22, 173], "set_tensor_parallel_group": [22, 173], "releas": 22, "quantdescriptor": 22, "tensorquant": [22, 60, 115, 116, 121, 131, 133, 134], "backend": [22, 173], "rnn": [22, 133], "lstm": 22, "gru": 22, "dbrx": 22, "experiment": [22, 120, 121, 143, 169], "qlora": 22, "nf4": [22, 140], "offici": 22, "medusamodel": [22, 158, 161], "gptmodel": 22, "recurrentgemma": [22, 61], "spars": [22, 146, 147, 148, 149, 151, 152, 153], "renam": 22, "ammo": 22, "product": 22, "inference_gpu": 22, "model_config_export": 22, "torch_to_tensorrt_llm_checkpoint": [22, 62], "float8": 22, "window": [22, 29], "win_amd64": 22, "wheel": 22, "submodul": [22, 60, 74, 75, 94, 102, 144, 146, 169], "bug": 22, "opset": 22, "neg": 22, "pb": 22, "tmp": [22, 62, 69, 70], "folder": 22, "tensorrt_llm": [25, 26, 27, 61, 62, 66, 67], "runner": 26, "hlapi": 26, "engine_dir": 26, "kv_cache_config": 26, "medusa_choic": 26, "tokenizerbas": 26, "md": [26, 62, 143], "generate_context_logit": 26, "prompt": 26, "top_p": 26, "nucleu": 26, "keep_input_prompt": 26, "prommpt": 26, "context_logit": 26, "generate_text": 26, "max_new_token": 26, "stop_word": 26, "stop": [26, 73, 103, 178], "max_beam_width": 26, "2d": [26, 128], "beam": 26, "generate_token": 26, "sequence_len": 26, "properti": [26, 27, 51, 54, 58, 61, 73, 77, 79, 92, 93, 94, 95, 99, 103, 104, 105, 106, 110, 114, 119, 133, 134, 148, 151, 152, 159, 165, 166, 168], "instanc": [26, 49, 50, 51, 63, 72, 90, 93, 94, 100, 108, 115, 116, 121, 129, 134, 138, 153, 161, 168, 172], "max_input_len": 26, "customsentencepiecetoken": 27, "sentencepiecetoken": 27, "nemo_exampl": 27, "constructor": [27, 51, 52, 53, 90, 115, 165, 166, 177], "legaci": 27, "batch_decod": 27, "batch_encode_plu": 27, "mmethod": 27, "encod": [27, 67], "return_tensor": 27, "eos_token": 27, "pad_token": 27, "get_nemo_token": 27, "tokenizer_cfg_path": 27, "logic": [27, 43, 60, 67, 99, 165], "get_nmt_token": 27, "tokenizer_util": 27, "get_tokenzi": 27, "tokenizer_dir_or_path": 27, "subpackag": [28, 30, 47, 48], "is_binary_op": 29, "binari": [29, 103, 104], "is_control_flow_op": 29, "control": [29, 115], "categori": 29, "is_conversion_op": 29, "is_copy_op": 29, "is_default_quantizable_op_by_ort": 29, "ort": [29, 38, 39, 40, 45], "nodes_to_quant": [29, 33, 37, 41, 44], "microsoft": 29, "onnxruntim": 29, "registri": [29, 88, 89, 92, 93, 94], "is_fusible_reduction_op": 29, "fusibl": [29, 41], "is_generator_op": 29, "is_irregular_mem_access_op": 29, "irreggular": 29, "mem": 29, "is_linear_op": 29, "is_modifier_op": 29, "is_multiclass_op": 29, "multiclass": 29, "is_non_reshape_copy_op": 29, "reshap": [29, 147], "is_normalization_op": 29, "is_pointwise_or_elementwise_op": 29, "pointwis": [29, 41, 53], "elementwis": 29, "is_pooling_or_window_op": 29, "pool": [29, 132], "is_recurrent_op": 29, "is_selection_op": 29, "is_sequence_op": 29, "is_shape_op": 29, "is_unary_op": 29, "unari": 29, "calibrationdataprovid": 31, "calibrationdataread": [31, 33, 36, 37], "calibration_shap": [31, 33, 34, 37, 44], "intial": [31, 58], "timestep": 31, "encoder_hidden_st": 31, "768": 31, "get_next": 31, "reader": 31, "randomdataprovid": 31, "onnx_model": [31, 34, 36, 42, 46], "modelproto": [31, 33, 36, 37, 42, 45, 46], "import_scales_from_calib_cach": 31, "cache_path": 31, "float_scal": 31, "tensor_nam": 31, "gemm": [33, 36, 37], "int8_to_fp8": 33, "verbos": [33, 34, 37, 42, 44, 72, 108, 121, 153], "calibration_method": [33, 36, 37, 44], "calibration_data_read": [33, 36, 37], "calibration_cache_path": [33, 37, 44], "calibration_ep": [33, 34, 36, 37, 40, 44], "trt": [33, 34, 37, 42, 44, 64, 66, 67], "nodes_to_exclud": [33, 34, 36, 37, 44], "use_external_data_format": [33, 34, 36, 37, 44, 45], "intermediate_generated_fil": [33, 34, 37], "trt_extra_plugin_lib_path": [33, 37, 40], "high_precision_dtyp": [33, 34, 37, 44], "mha_accumulation_dtyp": [33, 44], "fp32": [33, 34, 37, 42, 44], "matmul": [33, 34, 37, 41, 44], "placement": 34, "add_fp16_fp32_cast": 34, "custom_ops_to_cast_to_fp16": 34, "cast_to_fp16": 34, "cast_to_fp32": 34, "build_non_residual_input_map": 34, "subgraph": [34, 36, 41], "modern": 34, "convnet": 34, "classify_partition_nod": 34, "partit": [34, 44], "outsid": 34, "algo": 34, "dst": 34, "convert_fp16_io": 34, "expand_node_names_from_pattern": 34, "name_pattern": 34, "expand": 34, "graphproto": [34, 42, 46], "filter_quantizable_kgen_head": 34, "cask_fusible_partit": 34, "kgen_partit": 34, "quantizable_op_typ": [34, 41], "kgen": [34, 41], "cask": [34, 41], "find_fp8_mha_partit": 34, "mha": [34, 41, 44], "bmm1": [34, 44], "mul": [34, 37, 41, 42], "div": [34, 41], "bmm2": [34, 44], "find_mha_partit": [34, 41], "find_nodes_from_matmul_to_exclud": 34, "gemv": 34, "tensorcor": 34, "delet": 34, "inferenec": 34, "prioriti": [34, 44, 75], "find_nodes_from_mha_to_exclud": 34, "disable_mha_qdq": [34, 44], "head_siz": [34, 60], "maskadd": 34, "seq_len": 34, "is_fp8fp16": 34, "find_nodes_to_exclud": 34, "exclus": [34, 168], "get_fusible_backbon": 34, "backbon": [34, 41, 75, 88], "fuse": [34, 41, 42, 121], "tri": 34, "biasadd": 34, "constmul": 34, "get_tensor_consumer_nod": 34, "consum": [34, 42, 46, 69], "nodeproto": 34, "get_tensor_producer_nod": 34, "extern": [34, 46], "has_const_input": 34, "has_path_typ": 34, "path_typ": 34, "is_forward": 34, "wild_card_typ": 34, "path_nod": 34, "wrt": [34, 104, 110], "travers": [34, 41], "wild": 34, "card": 34, "insert_fp8_mha_cast": 34, "input0": [34, 46], "second": [34, 46], "input1": [34, 46], "forbid": 34, "insert_matmul_cast": 34, "matmul_nod": 34, "is_const_input": 34, "const": 34, "foldabl": 34, "print_stat": 34, "remove_partial_input_qdq": 34, "no_quantize_input": 34, "mark": [34, 168], "onnx_graphsurgeon": 35, "patch_gs_modul": 35, "graphsurgeon": [35, 42], "woq": 36, "awqcliphelp": 36, "alpha_step": [36, 115], "05": [36, 61, 102, 115], "min_alpha": 36, "update_best_param": 36, "awqlitehelp": 36, "lite": [36, 44, 115], "alpha": [36, 44, 115], "dq_tensor": 36, "zp": 36, "dequant": [36, 42, 134, 138, 139, 140, 141, 143], "find_scal": 36, "use_zero_point": [36, 44], "get_act_scal": 36, "get_act_to_weight_map_and_act_to_wa_pack_map": 36, "wa_pack": 36, "get_scal": 36, "x_max": 36, "w_max": 36, "reduce_across_tp": 36, "get_weight_scal": 36, "get_x_w_mean_for_subgraph": 36, "wa_pack_idx_list": 36, "augmented_onnx_path": 36, "quant_tensor": 36, "awq_clip": [36, 44, 115, 120], "lm_head": [36, 60, 61, 63, 64, 67, 74, 102, 115, 121, 146], "keyword": [36, 44, 72, 94, 108, 113, 171, 177], "awqlite_alpha_step": [36, 44], "awqclip_alpha_step": [36, 44], "awqclip_alpha_min": [36, 44], "awqclip_bsz_col": [36, 44], "quantize_rtn": 36, "gemm_io_typ": 36, "dq_onli": [36, 42, 44], "rtn": 36, "ab": [36, 53, 123], "round_to_even": 36, "denot": 36, "ti": 36, "alwai": 36, "cin": 36, "plug": 36, "rh": 36, "protobuf": [36, 42], "intern": [36, 42, 85, 94, 168, 179, 182], "enum_type_wrapp": [36, 42], "enumtypewrapp": [36, 42], "0x7f4d2fb110d0": [36, 42], "run_awq_scale_search_per_nod": 36, "session": 36, "awq_lit": [36, 44, 115, 120], "tqdm_msg_append_str": 36, "enable_weight_clip": 36, "enable_fast_path_using_high_sysram": 36, "output_data": 36, "clip_alpha": 36, "run_awq_scale_search_per_subgraph": 36, "sibl": 36, "heurist": 37, "averagepool": 37, "batchnorm": 37, "convtranspos": [37, 38], "globalaveragepool": 37, "maxpool": 37, "top": [38, 93, 94], "qdqconvtranspos": 38, "qdqoperatorbas": 38, "onnx_quant": 38, "onnx_nod": 38, "qdqnormal": 38, "intend": [38, 94], "patch_ort_modul": 39, "shoul": 40, "ort_client": 40, "configure_ort": 40, "op_typ": [40, 44, 46], "create_inference_sess": 40, "onnx_path_or_model": 40, "inferencesess": 40, "byte": [40, 43, 46, 178], "get_quantizable_op_typ": 40, "_configure_ort": 40, "suppli": [40, 44], "find_fusible_partit": 41, "partitioned_nod": 41, "non_residual_input": 41, "find_hardcoded_pattern": 41, "tail": 41, "mtl_v1": 41, "reducesum": 41, "pow": 41, "sqrt": 41, "find_layer_norm_partit": 41, "norm": [41, 104], "find_non_quantizable_partitions_from_pattern": 41, "counterpart": [41, 94, 121], "find_quantizable_nod": 41, "yet": [41, 121], "get_skiped_output_lay": 41, "paritially_quantizable_nod": 41, "insert_dq_nod": 42, "quantized_weight": 42, "zero_point": 42, "insert_pre_quant_scale_nod": 42, "input_tensor": [42, 115, 144], "pre_quant_scal": [42, 65, 110, 134], "insert_qdq_nod": 42, "weight_map": 42, "make_gs_awq_scal": 42, "_basename_": 42, "make_gs_dequantize_nod": 42, "make_gs_dequantize_output": 42, "variabl": [42, 46, 72, 81, 108, 115, 133, 134, 177], "make_gs_pre_quant_scale_nod": 42, "make_gs_pre_quant_scale_output": 42, "make_gs_quantize_nod": 42, "make_gs_quantize_output": 42, "make_gs_quantized_weight": 42, "wq": 42, "make_gs_scal": 42, "make_gs_zp": 42, "qdq_to_dq": 42, "dangl": [42, 168], "replace_scale_valu": 42, "act_scales_dict": 42, "use_trt_qdq_op": 42, "pack_float32_to_4bit_cpp_bas": 43, "4bit": 43, "concecut": 43, "pack_float32_to_4bit": 43, "round_and_pack": 43, "suppos": 43, "unsign": [43, 113, 114, 115, 117, 128, 130, 131, 133, 134, 143], "pack_float32_to_4bit_optim": 43, "mainli": 43, "reli": [43, 75], "therebi": 43, "remain": [43, 94], "keep_intermediate_fil": 44, "trt_plugin": [44, 45], "trt_plugins_precis": 44, "awq_ful": [44, 115, 120], "rtn_dq": 44, "filenam": 44, "suffix": [44, 52, 176], "throughout": 44, "semicolon": 44, "lib_1": 44, "lib_2": 44, "tensorrtexecutionprovid": 44, "op_type_1": 44, "op_type_2": 44, "model_nam": 44, "get_custom_lay": 45, "load_onnx_model": 45, "boolean": [45, 113, 114, 125, 134, 143, 144], "duplicate_shared_const": 46, "duplic": [46, 90, 94, 147], "find_lowest_common_ancestor": 46, "node1": 46, "node2": 46, "lowest": 46, "ancestor": 46, "lca": 46, "distanc": 46, "gen_random_input": 46, "shapes_spec": 46, "get_all_input_nam": 46, "get_batch_s": 46, "get_batch_size_from_byt": 46, "onnx_byt": 46, "get_child_nod": 46, "get_input_nam": 46, "external_inputs_onli": 46, "external_input_nam": 46, "initializer_nam": 46, "get_input_names_from_byt": 46, "model_byt": 46, "get_input_shap": 46, "get_input_shapes_from_byt": 46, "get_node_nam": 46, "get_node_names_from_byt": 46, "get_output_nam": 46, "get_output_names_from_byt": 46, "get_output_shap": 46, "get_parent_nod": 46, "get_variable_input": 46, "is_valid_onnx_model": 46, "file_path": 46, "name_onnx_nod": 46, "assign": [46, 89, 94, 115], "statu": 46, "parse_shapes_spec": 46, "pars": 46, "spec": 46, "1x3x256x256": 46, "1x3x128x128": 46, "randomize_weight": 46, "randomize_weights_onnx_byt": 46, "remove_weights_data": 46, "save_onnx": 46, "save_as_external_data": 46, "2gb": 46, "save_onnx_bytes_to_dir": 46, "onnx_dir": 46, "onnx_nam": 46, "udpate_domain": 46, "domain": 46, "validate_batch_s": 46, "validate_onnx": 46, "modeloptconfig": [49, 74, 92, 102, 115, 146, 155], "kdlossconfig": [49, 50], "modeloptbaseconfig": [49, 54, 73, 74, 79, 92, 93, 103, 106, 115, 119, 146, 148, 155, 159], "expose_minimal_state_dict": [49, 51], "_loss": [49, 51, 53], "student_layer_nam": 49, "teacher_layer_nam": 49, "loss_modul": [49, 51], "hide": [49, 51], "unnecessarili": [49, 51], "balanc": [49, 51, 52, 115], "weigh": [49, 51], "init_model_from_model_lik": [49, 177], "model_dump": [49, 92], "dataclass": 49, "turn": [50, 161], "_modedescriptor": [50, 54, 75, 79, 93, 106, 108, 119, 148, 153, 159, 161], "encapsul": [50, 51], "inner": 50, "dynamicmodul": [51, 56, 85, 87, 88, 90, 94, 95, 100, 104, 131, 133, 149, 158, 177], "loss_reduction_fn": 51, "skip_balanc": 51, "prior": [51, 52], "situat": 51, "hide_loss_modul": 51, "manag": [51, 73, 90, 91, 93, 94, 103, 104, 116, 134, 142, 144], "temporarili": [51, 90, 94], "hide_teacher_model": 51, "fetch": 51, "modulelist": [51, 60], "aggreg": 52, "student_loss_kei": 52, "mod1_": 52, "mod1_t": 52, "mseloss": 52, "mod2_": 52, "mod2_t": 52, "mseloss_0": 52, "mseloss_1": 52, "kd": [52, 53], "set_student_loss_reduction_fn": 52, "student_loss_reduction_fn": 52, "static": [52, 93, 104, 110, 115, 123, 128, 130, 131, 133, 134, 138, 143, 165], "kd_loss_weight": 52, "kl": 53, "diverg": 53, "arxiv": [53, 104, 105, 123], "1503": 53, "02531": 53, "batchmean": 53, "soften": 53, "logits_t": 53, "logits_": 53, "treat": [53, 168], "mgdloss": 53, "2205": 53, "01529": 53, "num_student_channel": 53, "num_teacher_channel": 53, "alpha_mgd": 53, "lambda_mgd": 53, "65": [53, 102], "out_": 53, "out_t": 53, "bxcxhxw": 53, "exportstudentmodedescriptor": 54, "inspect": [54, 60, 79, 106, 119, 148, 159], "config_class": [54, 79, 106, 119, 148, 159], "entrypoint": [54, 73, 75, 79, 99, 106, 119, 148, 159], "is_export_mod": [54, 79, 119, 148], "knowledgedistillationmodedescriptor": 54, "export_mod": [54, 79, 106, 119, 148], "next_mod": [54, 79, 106, 119, 148], "immedi": [54, 79, 106, 119], "update_for_new_mod": [54, 79, 106, 119, 148], "hold": [56, 87, 168], "nfsworkspac": 58, "workspac": [58, 62], "storag": [58, 138, 139, 140], "nf": [58, 62], "modifit": 58, "commun": [58, 62], "nor": 58, "barrier": [58, 173], "respons": 58, "workspace_path": [58, 62, 64], "cross": [58, 62, 168], "sharedmemori": 58, "clean": [58, 134, 177], "is_initi": [58, 173], "read_configs_and_weights_from_rank": 58, "target_rank": 58, "write_configs_and_weight": 58, "config_json": 58, "get_configs_parallel": 58, "nullabl": 58, "sync": 58, "yield": [58, 62, 72, 93, 94, 100, 108, 115, 121, 134, 153, 168], "destroi": [58, 153], "consumpt": 58, "get_tensors_parallel": 58, "model_config": [60, 62, 63, 64, 67], "empir": [60, 67], "build_attention_config": 60, "model_metadata_config": 60, "ext_config": 60, "tp_size": [60, 63, 67], "decoderlayerconfig": [60, 61, 67], "attentionconfig": [60, 61], "build_conv_config": 60, "convconfig": [60, 61], "build_decoder_config": 60, "build_embedding_config": 60, "normalization_const": 60, "embed": [60, 61, 64, 113], "embeddingconfig": [60, 61], "build_layernorm_config": 60, "layernormconfig": [60, 61], "build_linear_config": 60, "linear_typ": [60, 61], "linearconfig": [60, 61, 63], "build_medusa_heads_config": 60, "medusaheadconfig": [60, 61], "num_medusa_head": [60, 61], "medsua_head": 60, "vocab_s": [60, 61], "num_medusa_lay": [60, 61], "linearactconfig": [60, 61], "hidden_act": [60, 61], "silu": [60, 158], "build_mlp_config": 60, "mlpconfig": [60, 61], "build_moe_config": 60, "moe": [60, 115], "moeconfig": [60, 61], "build_qkv": 60, "qkv_modul": 60, "qkv": [60, 61, 63], "qkvconfig": [60, 61, 63], "build_recurrent_config": 60, "build_stacked_expert": 60, "linear_nam": 60, "num_expert": 60, "expert_gett": 60, "experts_weight_1": 60, "experts_weight_2": 60, "check_model_compat": 60, "module_list": 60, "assembl": 60, "dup_kv_weight": 60, "num_head": 60, "num_kv_head": [60, 61], "get_activation_scaling_factor": [60, 141], "get_kv_cache_dtyp": 60, "kv_cach": 60, "union": [60, 95], "get_kv_cache_scaling_factor": 60, "get_prequant_scaling_factor": 60, "prequant": [60, 61], "get_qkv_and_avg_prequant_scal": 60, "averag": [60, 65], "get_quantization_format": 60, "children": 60, "get_scaling_factor": 60, "get_transformer_lay": 60, "get_weight_block_s": 60, "get_weight_scaling_factor": 60, "get_weight_scaling_factor_2": 60, "secondari": 60, "is_attent": 60, "is_decoder_list": 60, "is_embed": 60, "is_layernorm": 60, "is_linear": 60, "is_mlp": 60, "is_mo": 60, "is_quantlinear": 60, "is_recurr": 60, "kv_cache_scaling_factor": 61, "kv_cache_dtyp": 61, "rotary_dim": 61, "inf": 61, "clip_qkv": 61, "rel_attn_t": 61, "input_layernorm": 61, "mlp_layernorm": 61, "post_layernorm": [61, 66], "pre_feedforward_layernorm": 61, "post_feedforward_layernorm": 61, "num_attention_head": [61, 105, 108], "attention_head_s": 61, "max_position_embed": 61, "rotary_pct": 61, "use_alibi": 61, "new_decoder_architectur": 61, "parallel_attent": 61, "apply_residual_connection_post_layernorm": 61, "chatglm_vers": 61, "rope_ratio": 61, "seq_length": 61, "qwen_typ": 61, "rotary_bas": 61, "partial_rotary_factor": 61, "original_max_position_embed": 61, "longrope_scaling_short_factor": 61, "longrope_scaling_long_factor": 61, "mup_attn_multipli": 61, "mup_embedding_multipli": 61, "mup_use_sc": 61, "mup_width_multipli": 61, "blocksparse_block_s": 61, "blocksparse_homo_head_pattern": 61, "blocksparse_num_local_block": 61, "blocksparse_vertical_strid": 61, "dense_attention_every_n_lay": 61, "gegelu_limit": 61, "longrope_short_mscal": 61, "longrope_long_mscal": 61, "moe_num_expert": 61, "moe_top_k": 61, "moe_tp_mod": 61, "moe_renorm_mod": 61, "alibi_bias_max": 61, "residual_layernorm": 61, "residual_mlp": 61, "rnn_hidden_s": 61, "logits_soft_cap": 61, "emb_scale_by_sqrt_dim": 61, "layer_typ": 61, "attn_replacing_linear": 61, "mlp_replacing_linear": 61, "block_config": 61, "final_logit_softcap": 61, "attn_logit_softcap": 61, "query_pre_attn_scalar": 61, "cross_attent": 61, "cross_attention_layernorm": 61, "self_attent": 61, "self_attention_layernorm": 61, "attention_layernorm": 61, "rel_attn_max_dist": 61, "rel_attn_num_bucket": 61, "rope_sc": 61, "recurrentconfig": 61, "ffn_hidden_size_loc": 61, "ffn": 61, "local_vocab_s": 61, "expertconfig": 61, "fc": 61, "proj": 61, "layernorm_typ": 61, "activation_scaling_factor": 61, "weights_scaling_factor": [61, 63], "weights_scaling_factor_2": 61, "prequant_scaling_factor": 61, "awq_block_s": [61, 63], "gate": [61, 115], "merged_fc1_g": 61, "gat": 61, "fc1": 61, "mixtur": 61, "router": [61, 115], "medusa_lay": 61, "modelconfig": [61, 63, 64, 67], "pipeline_parallel": 61, "tensor_parallel": 61, "vocab_embed": 61, "position_embed": 61, "block_embed": 61, "ln_emb": 61, "ln_f": 61, "share_embedding_t": 61, "medusa_head": 61, "enc_dec": [61, 67], "encoder_hidden_s": 61, "encoder_num_head": 61, "encoder_head_s": 61, "num_key_value_head": 61, "vocab_size_pad": 61, "concat": 61, "quanitz": 61, "weight_scaling_factor_2": 61, "recurrentblock": 61, "linear_i": 61, "y_bia": 61, "linear_x": 61, "linear_out": 61, "rg_lru": 61, "rglruconfig": 61, "rg": 61, "lru": 61, "recurrent_param": 61, "input_g": 61, "recurrent_g": 61, "export_npz": 62, "naive_fp8_quant": 62, "use_nfs_workspac": 62, "manual": [62, 165, 168], "old": 62, "naiv": 62, "nest": [62, 63], "pretrainedconfig": 62, "modeling_util": 62, "tensorrt_llm_config": [62, 67], "per_layer_quant": [62, 69], "from_quantized_weight": 63, "torch_dtyp": 63, "merge_fc1_g": 63, "merge_qkv": 63, "model_config_from_dict": 63, "model_config_to_dict": 63, "naive_quant": 63, "pack_linear_weight": 63, "pad_weight": 63, "process_layer_quant_config": 63, "layer_config_dict": 63, "trtllm": 63, "restore_model_config": 63, "recurs": [63, 94, 100, 103, 116, 168, 169, 180], "split_config_and_weight": 63, "auto_qu": 63, "to_quantized_weight": 63, "weights_scaling_factor2": 63, "check_weight_shape_valid": 64, "training_tensor_parallel": 64, "tp": [64, 67], "recurisv": 64, "pad_embedding_lm_head": 64, "padding_factor": 64, "postprocess_model_config": 64, "training_pipeline_parallel": 64, "pp": 64, "postprocess_tensor": 64, "force_cpu": 64, "force_contigu": 64, "force_non_view": 64, "update_lm_head_quant": 64, "quantlinear": [64, 130], "adjust_attn_amax_valu": 65, "convert_state_dict_amax_to_scal": 65, "quantized_state_dict": 65, "maxbound": [65, 134], "layers_quant_config": 65, "_amax": 65, "get_weights_scaling_factor_and_amax": 65, "group_siz": 65, "facotr": 65, "resmooth_and_get_scale_and_amax": 65, "merged_weight": 65, "avg_pre_quant_scal": 65, "resmooth": 65, "weight_scaling_factor": 65, "layernormpositiontyp": 66, "intenum": 66, "__new__": [66, 138], "pre_layernorm": 66, "layernormtyp": 66, "groupnorm": [66, 74, 102], "rmsnorm": 66, "mlptype": 66, "fusedgatedmlp": 66, "gatedmlp": 66, "convert_to_tensorrt_llm_config": 67, "weight_kei": 67, "tp_size_overwrit": 67, "overwrit": [67, 74, 94, 102, 146], "builder": 67, "unshard": 67, "is_tensorrt_llm_0_8_or_9": 67, "prepare_enc_dec_decoder_lay": 67, "layer_config": 67, "t5config": 67, "prepare_enc_dec_export_dir": 67, "export_root": 67, "weights_to_npz": 67, "convert_to_transformer_engin": 68, "transformers_engin": 68, "export_hf": 69, "quant_config": 69, "hf_quant_cfg": 69, "post_state_dict": 69, "export_to_vllm": 70, "export_path": 70, "strict": [72, 74, 75, 90, 94, 134, 163], "use_centroid": 72, "convent": [72, 99, 108, 143], "kw_only_arg": [72, 108, 177], "z": [72, 108, 177], "interpret": [72, 108, 143, 177], "arg_nam": [72, 108], "constraintsfunc": [72, 73], "0e6": 72, "5e8": 72, "median": [72, 179], "determinist": [72, 179], "is_all_sat": 72, "prunabl": [72, 99, 104], "carefulli": [72, 108, 153], "significantli": [72, 108, 153], "run_forward_loop": [72, 108, 153, 177], "max_iter_data_load": [72, 99, 108], "histori": [72, 73, 93, 99, 108, 121], "autonaspatchmanag": [73, 103], "patchmanag": 73, "monkei": [73, 75, 165], "automod": 73, "sample_during_train": [73, 103], "evolvesearch": 73, "iterativesearch": [73, 103], "evolutionari": 73, "after_step": [73, 103], "before_search": [73, 99, 103, 104, 105, 110, 152], "before_step": [73, 103], "default_search_config": [73, 99, 104, 105, 110, 151, 152], "default_state_dict": [73, 99, 103, 105, 110, 151], "mutat": 73, "crossov": 73, "basesearch": [73, 79, 99, 105, 106, 110, 148, 151], "abc": [73, 99], "after_search": [73, 99, 152], "best_histori": 73, "constraints_func": 73, "early_stop": [73, 103], "earli": [73, 103], "iter_num": 73, "run_search": [73, 99, 105, 110, 151], "run_step": 73, "routin": 73, "sanitize_search_config": [73, 99, 104, 105, 110, 151], "sanit": [73, 99, 104, 105, 110, 151], "randomsearch": 73, "steo": 73, "convert_autonas_searchspac": 73, "convert_searchspac": 73, "patch_manager_typ": 73, "export_searchspac": 73, "exportconfig": [73, 74], "restore_autonas_searchspac": 73, "restore_export": 73, "restore_searchspac": 73, "patch_manag": 73, "update_autonas_metadata": 73, "modeloptbaseruleconfig": [74, 92, 102, 146], "channels_ratio": [74, 88, 102], "features_ratio": [74, 102], "batchnorm1d": [74, 102], "batchnorm3d": [74, 102], "syncbatchnorm": [74, 88, 102], "instancenorm1d": [74, 102, 129], "instancenorm2d": [74, 102, 129], "instancenorm3d": [74, 102, 129], "min_depth": [74, 88, 166], "dynamicbatchnorm1dconfig": [74, 102], "deactiv": [74, 102, 142, 146, 177], "glob": [74, 75, 102, 146], "unnest": [74, 102, 146], "dynamicbatchnorm2dconfig": [74, 102], "dynamicbatchnorm3dconfig": [74, 102], "dynamicconv1dconfig": [74, 102], "dynamicconv2dconfig": [74, 102], "dynamicconv3dconfig": [74, 102], "dynamicconvtranspose1dconfig": [74, 102], "dynamicconvtranspose2dconfig": [74, 102], "dynamicconvtranspose3dconfig": [74, 102], "dynamicgroupnormconfig": [74, 102], "dynamicinstancenorm1dconfig": [74, 102], "dynamicinstancenorm2dconfig": [74, 102], "dynamicinstancenorm3dconfig": [74, 102], "dynamiclayernormconfig": [74, 102], "dynamiclinearconfig": [74, 102], "dynamicsequentialconfig": 74, "dynamicsyncbatchnormconfig": [74, 102], "calib": [74, 75], "exactli": [74, 104, 177], "augment": [75, 165, 182], "render": [75, 182], "incompat": [75, 182], "inherit": [75, 94], "qualifi": 75, "appear": [75, 177], "spatial_conv": [75, 88], "334": [75, 88], "667": [75, 88], "entri": [75, 115, 116, 144], "concattracedhp": 77, "tracedhp": [77, 78, 89], "stitch": 77, "active_slic": [77, 95], "slice": [77, 85, 95], "longtensor": [77, 85, 95], "hp1": 77, "hp2": 77, "hp": [77, 89, 90, 94], "depthhparam": 78, "autonasmodedescriptor": 79, "search_algorithm": [79, 106, 148], "update_for_sav": [79, 106, 119, 148], "exportmodedescriptor": 79, "equival": [80, 95, 115, 116], "get_sliced_tensor": 85, "mod": [85, 168], "hp_name": 85, "get_sliced_tensor_by_slic": 85, "dynamicspac": [88, 94], "searchspac": [88, 90], "stub": 88, "sym_map": 88, "symbol": [88, 89, 94, 95, 143, 163, 164, 165, 166], "symmap": [88, 163, 168], "dm_registri": [88, 94], "_dmregistrycl": [88, 94], "print_summari": 88, "skipped_hparam": [88, 90], "sample_func": [88, 90], "unix": 88, "shell": 88, "preced": 88, "wilcard": 88, "parameter_nam": [88, 90, 94], "sort_paramet": 88, "hps_to_sort": 88, "propag": 88, "generate_search_spac": 88, "det_block": 88, "outlin": 88, "analyz": 88, "analysi": [88, 162], "classmethod": [89, 92, 93, 94, 110, 138, 139, 140, 141, 168, 169], "initialize_from": 89, "resolve_depend": 89, "sym": [89, 165], "get_hp": 89, "parent": [89, 94, 116, 168, 169], "tracedhpregistri": 89, "sym_cl": 89, "mysymbol": 89, "myhparam": 89, "unregist": [89, 92, 116, 168, 169], "previous": [89, 93, 148, 157, 168], "throw": [89, 119, 135, 142, 168], "keyerror": [89, 168], "enable_modelopt_patch": 90, "_decoratorcontextmanag": 90, "decor": [90, 168, 178], "parenthesi": 90, "no_modelopt": 90, "enable_modelopt": 90, "get_subnet_config": 90, "inference_flop": 90, "data_shap": 90, "1000000": [90, 177], "return_str": 90, "1e6": [90, 177], "million": [90, 177], "is_modelopt_patches_en": 90, "no_modelopt_patch": 90, "print_search_space_summari": 90, "replace_forward": 90, "new_forward": 90, "forward_origin": 90, "fake_forward": 90, "out_origin": 90, "set_modelopt_patches_en": 90, "thread": 90, "set_modelopt_en": 90, "ingest": 91, "wihin": 91, "pydant": 92, "basemodel": 92, "easier": [92, 113], "manipul": 92, "alia": [92, 95, 128, 130, 132, 168], "get_field_name_from_kei": 92, "alias": 92, "itemsview": 92, "keysview": 92, "model_dump_json": 92, "valuesview": 92, "modeloptbaserul": 92, "customize_rul": 92, "construct": [92, 94, 133, 134], "get_rule_typ": 92, "wrapped_onli": 92, "typealia": 92, "validate_rul": 92, "made": 92, "register_default": 92, "extra_default": 92, "unregister_default": 92, "modeloptfield": 92, "pydanticundefin": 92, "get_kwargs_for_create_model_with_rul": 92, "default_rul": 92, "create_model": 92, "rule_field": 92, "docstr": 92, "pertain": 92, "myruleconfig": 92, "get_create_model_kwargs_for_rule_model": 92, "sparsemagnitudeconfig": [92, 146, 153], "autodoc": 92, "workaround": 92, "burden": 92, "modeloptstatemanag": 93, "correspondig": 93, "init_st": 93, "add_mod": 93, "_state": 93, "recal": 93, "check_mod": 93, "get_config_class": 93, "has_stat": 93, "trivial": 93, "is_convert": 93, "is_root": 93, "last_mod": 93, "modes_with_st": 93, "transfer_state_dict": 93, "model_from": 93, "model_to": [93, 177], "update_last_state_before_new_mod": 93, "update_last_state_before_sav": 93, "apply_mod": 93, "quantizemodedescriptor": [93, 119], "_moderegistrycl": 93, "retriev": [93, 177], "bias": 93, "model_weight": 93, "pathlik": 93, "binaryio": 93, "locat": [93, 116], "famili": 94, "dynamicconv2d": 94, "callback": [94, 95], "temporari": [94, 134], "expos": 94, "outermost": 94, "child": [94, 113, 158], "dynamiclinear": 94, "__class__": 94, "inject": 94, "rigoruo": 94, "fashion": 94, "mutual": [94, 168], "exlus": 94, "dyanmic": 94, "kept": [94, 115, 177], "until": [94, 177], "extra_repr": [94, 134], "__dict__": 94, "heavili": 94, "force_assign": 94, "forc": 94, "overwritt": 94, "buffer": [94, 134], "circumst": 94, "freez": 94, "orgin": 94, "get_hparam": [94, 100], "get_paramet": 94, "scalabl": 94, "overriden": 94, "out_features_ratio": 94, "fly": [94, 133], "leav": 94, "intact": 94, "some_dynamic_modul": 94, "named_hparam": [94, 100], "reset_dynamic_attribut": 94, "interf": 94, "setattr": 94, "delattr": 94, "exit": [94, 116], "convert_to_dynam": 94, "is_configur": [94, 95, 100], "is_dynam": [94, 100, 168], "named_dynamic_modul": [94, 100], "exact": 94, "ident": 95, "activeslic": 95, "importanceestim": 95, "customhptyp": [95, 110], "enforce_ord": 95, "_order": 95, "todo": 95, "ever": [95, 119], "cycl": 95, "detector": 95, "1d": [95, 128, 147], "notion": 95, "is_sort": [95, 168], "sortabl": [95, 168], "register_import": 95, "importance_estim": 95, "arbitrari": 96, "save_directori": 98, "pretrained_model_name_or_path": 98, "whenev": [99, 165], "construct_forward_loop": 99, "silent": 99, "progress_bar_msg": 99, "post_process_fn": [99, 120], "runnabl": 99, "eval_scor": 99, "has_scor": 99, "load_search_checkpoint": [99, 103], "reset_search": 99, "reset": [99, 113, 114, 116, 134, 165], "save_search_checkpoint": 99, "search_space_s": 100, "accommod": 101, "natur": [101, 143, 168], "15000000000000002": 102, "30000000000000004": 102, "35000000000000003": 102, "45": 102, "55": 102, "6000000000000001": 102, "7000000000000001": 102, "8500000000000001": 102, "9500000000000001": 102, "gradnasconfig": [102, 108], "mcoregptminitronconfig": [102, 108], "fasna": 103, "binarysearch": [103, 104], "boundari": 103, "interv": 103, "middl": 103, "enough": 103, "hparam_names_for_search": [103, 104], "hparam_types_for_search": 103, "original_scor": 103, "max_degrad": 103, "middle_valu": 103, "min_degrad": 103, "sensitivity_map": 103, "fastnaspatchmanag": 103, "convert_fastnas_searchspac": 103, "restore_fastnas_searchspac": 103, "l1": 104, "abstractli": 104, "pdf": [104, 105], "1905": 104, "10650": 104, "gradientbinarysearch": 104, "setup_gradient_func": 104, "gradientdatamanag": 104, "removablehandl": 104, "gradnas_score_func": 104, "neuron": [104, 105, 113], "l": 104, "validation_scor": 104, "reduce_func": 104, "process_gradi": 104, "2407": 105, "14679": 105, "mcoregptminitronsearch": 105, "supported_hparam": 105, "ffn_hidden_s": [105, 108], "num_query_group": [105, 108], "fastnasmodedescriptor": 106, "gradnasmodedescriptor": 106, "mcoregptminitronmodedescriptor": 106, "export_config": 108, "5e6": 108, "autoquantizesearch": [110, 121], "autoquant": [110, 121], "solver": 110, "taylor": 110, "expans": 110, "fisher": 110, "hessian": [110, 152, 153], "mathemat": 110, "likelihood": 110, "proxi": [110, 169], "resnet": 110, "candidate_stat": 110, "gradient_checkpointing_enable_context": 110, "_is_supported_hf_model": 110, "setup_model_for_gradient_checkpoint": 110, "insert_hparams_after_merge_rul": 110, "quant_recip": 110, "register_gradient_checkpointing_enable_context": 110, "is_supported_check": 110, "q_proj": [110, 121], "k_proj": [110, 121], "v_proj": [110, 121], "gate_proj": 110, "up_proj": 110, "w1": 110, "w2": 110, "w3": 110, "w1_linear": 110, "w2_linear": 110, "w3_linear": 110, "quantrecip": 110, "quantizeconfig": [110, 115, 121], "disable_folding_pqs_to_weight": 110, "fold_pqs_to_weight": 110, "quantrecipehparam": 110, "nn_modul": 110, "histogramcalibr": 113, "_calibr": [113, 114, 115], "compute_amax": [113, 114, 134], "percentil": 113, "axi": [113, 114, 115, 128, 130, 131, 133, 134, 144], "num_bin": 113, "grow_method": 113, "skip_zero": 113, "torch_hist": 113, "histc": 113, "start_bin": 113, "calibrate_weight": 113, "perchannel": 113, "collector": 113, "But": 113, "haven": 113, "decoupl": 113, "maxcalibr": 114, "calib_desc": 114, "maxcalibdescriptor": 114, "readonli": 114, "plot": 114, "track_amax": 114, "runtimeerror": 114, "cnn": 115, "int4_awq_cfg": 115, "miss": 115, "sequentialquant": [115, 116, 131, 133, 134], "quantmoduleregistri": 115, "class_nam": 115, "get_kei": 115, "my_quant_cfg": 115, "leakyrelu": 115, "block_sparse_mo": 115, "int4_blockwise_weight_only_cfg": 115, "max_co_batch_s": [115, 120], "custom_int4_awq_cfg": 115, "deepcopi": [115, 165], "awqclipcalibconfig": [115, 120], "quantizealgorithmconfig": 115, "oom": 115, "out_featur": [115, 168], "max_tokens_per_batch": 115, "min_clip_ratio": 115, "shrink_step": 115, "gt": 115, "le": 115, "awqfullcalibconfig": [115, 120], "awqlitecalibconfig": [115, 120], "maxcalibconfig": [115, 120], "smoothquantcalibconfig": [115, 120], "realquantizeconfig": [115, 120], "fake_qu": [115, 128, 130, 131, 133, 134], "narrow_rang": [115, 117, 128, 130, 131, 133, 134, 143], "learn_amax": [115, 128, 130, 131, 133], "trt_high_precision_dtyp": [115, 117, 128, 130, 131, 133, 134, 143], "ax": 115, "kcr": 115, "quant_axi": 115, "scale_bit": [115, 143], "scale_block_s": [115, 140], "histogram": 115, "standardize_constructor_arg": [115, 177], "narrow": 115, "emul": 115, "fpx": 115, "e4m3": 115, "e5m2": 115, "fp6": 115, "e3m2": 115, "e2m3": 115, "fp4": 115, "e2m1": 115, "half": 115, "bfloat16": [115, 134], "additional_algorithm": [115, 120], "smooth": 115, "outlier": 115, "hyper": 115, "migrat": 115, "strength": 115, "difficulti": 115, "ge": 115, "un": 116, "replace_quant_modul": 116, "set_quantizer_attribut": 116, "quant_model": 116, "wildcard_or_filter_func": [116, 121], "parent_class": 116, "finegrain": 116, "set_quantizer_by_cfg": 116, "set_quantizer_by_cfg_context": 116, "caution": 116, "unexpect": 116, "export_fp8": 117, "graphcontext": 117, "export_int8": 117, "get_cuda_ext": 118, "extent": 118, "tensor_qu": [118, 134], "get_cuda_ext_fp8": 118, "tensor_quant_fp8": 118, "get_cuda_ext_mx": 118, "tensor_quant_mx": 118, "descriptor": [119, 148, 159], "quantizeexportmodedescriptor": 119, "placehold": [119, 135, 142], "properli": 119, "4096": 120, "real_quant": 120, "postprocess_amax": 120, "num_calib_step": 121, "num_score_step": 121, "w4a8_awq": 121, "my_loss_func": 121, "run_custom_backward": 121, "taken": [121, 177], "belong": 121, "regex": 121, "r": 121, "readili": 121, "disable_quant": 121, "enable_quant": 121, "clipfunct": 123, "univers": [123, 143], "clamp": [123, 125], "doesn": [123, 133, 144, 169], "broadcast": [123, 143], "genar": 123, "ibm": 123, "pact": 123, "1805": 123, "06085": 123, "tensorflow": [123, 143, 177], "clip_by_valu": 123, "ctx": [123, 143], "grad_output": [123, 143], "clip_value_min": [123, 125], "clip_value_max": [123, 125], "learn_min": 125, "learn_max": 125, "quantconv1d": 128, "quantconv2d": 128, "quantconv3d": 128, "quantconvtranspose1d": 128, "quantconvtranspose2d": 128, "quantconvtranspose3d": 128, "_legacyquantlinearconvbasemixin": [128, 130], "default_quant_desc_weight": [128, 130, 131, 133], "transpos": 128, "quantinstancenorm1d": 129, "_legacyquantinputbasemixin": [129, 132], "quantinstancenorm2d": 129, "4d": 129, "quantinstancenorm3d": 129, "5d": 129, "quantinputbas": 131, "default_quant_desc_input": [131, 133], "default_quant_desc_output": 131, "quantlinearconvbas": 131, "initialize_quantizer_with_dummy_st": 131, "initialize_real_qtensor_with_dummy_weight": 131, "qunat": 131, "quantize_weight": [131, 133], "sanitize_dummy_weight": 131, "nan": 131, "adaptiveavgpool1d": 132, "quantadaptiveavgpool1d": 132, "quantadaptiveavgpool2d": 132, "adaptiveavgpool3d": 132, "quantadaptiveavgpool3d": 132, "avgpool1d": 132, "quantavgpool1d": 132, "avgpool2d": 132, "quantavgpool2d": 132, "avgpool3d": 132, "quantavgpool3d": 132, "maxpool1d": 132, "quantmaxpool1d": 132, "maxpool2d": 132, "quantmaxpool2d": 132, "maxpool3d": 132, "quantmaxpool3d": 132, "quantrnnbas": 133, "all_input_quantizers_dis": 133, "functionals_to_replac": 133, "quantrnnfullbas": 133, "rnnlayerforward": 133, "cell": 133, "variable_len": 133, "vfrnnforward": 133, "reimplement": 133, "_vf": 133, "oringin": 133, "bidirect": 133, "has_proj": 133, "has_bia": 133, "proj_input_quant": 133, "batch_first": 133, "vf": 133, "layer_forward": 133, "flat_weight": 133, "dropout": 133, "get_quantized_rnn_layer_forward": 133, "signatur": [133, 177], "get_quantized_rnn_layer_variable_len_forward": 133, "get_quantized_rnn_layer_variable_len_reverse_forward": 133, "lstm_cell_with_proj": 133, "lstm_cell": 133, "project": 133, "h_n": 133, "c_n": 133, "quantized_cell_forward": 133, "container": 134, "get_modelopt_st": 134, "replace_sequential_quantizer_with_single_quant": 134, "indx": 134, "reset_amax": 134, "attribute_dict": 134, "tensor_quantizer_iter": 134, "quant_attribute_cfg": 134, "if_quant": 134, "if_clip": 134, "_learn_amax": 134, "if_calib": 134, "clean_up_after_set_from_modelopt_st": 134, "set_from_modelopt_st": 134, "qtensor": [134, 138], "de": 134, "basequantizedtensor": [134, 138, 139, 140, 141], "bypass": 134, "neither": 134, "disable_calib": 134, "disable_clip": 134, "disable_qu": 134, "enable_calib": 134, "enable_clip": 134, "enable_qu": 134, "export_amax": 134, "output_dtyp": [134, 143], "properties_onli": 134, "init_learn_amax": 134, "is_en": 134, "is_mx_format": 134, "mx": 134, "load_calib_amax": 134, "symmetr": [134, 143], "attribute_cfg": 134, "step_siz": 134, "sync_amax_across_distributed_group": 134, "parallel_group": 134, "distributedprocessgroup": 134, "freeze_paramet": 135, "group_paramet": 135, "match_paramet": 135, "quant_weight_inplac": 135, "apex": 136, "peft": 136, "original_meta_tensor": 138, "quantized_data": [138, 139, 140], "quantizedtensor": 138, "original_shap": 138, "original_dtyp": 138, "fake_quant_tensor": 138, "qtensorwrapp": 138, "meta_tensor": 138, "get_qtensor": 138, "pack_real_quantize_weight": 138, "force_quant": 138, "proper": 138, "int4qtensor": 139, "uint8": [139, 140], "dequantz": [139, 140], "nf4qtensor": 140, "double_quant": 140, "num_scale_bit": 140, "unlik": [140, 165, 169], "Not": 141, "nvfp4qtensor": 141, "get_weights_scaling_factor": 141, "get_weights_scaling_factor_2": 141, "resmooth_weights_and_get_scal": 141, "enable_onnx_export": 142, "dynamicblockquantizationfunct": 143, "fakeaffinetensorquantfunct": 143, "affin": 143, "gemmlowp": 143, "shift": 143, "cancel": 143, "penalti": 143, "grad_input": 143, "min_rang": 143, "max_rang": 143, "granular": [143, 144], "faketensorquantfunct": 143, "tensorquantfunct": 143, "legacyfaketensorquantfunct": 143, "comment": 143, "scalede4m3funct": 143, "e4m3fi": 143, "127": 143, "grad_scal": 143, "int32": 143, "255": 143, "fake_quant_impl": 143, "quantize_op_abstract": 143, "exponent_bit": 143, "scaled_e4m3_impl": 143, "disable_fused_kernel": 143, "export_torch_mod": 144, "get_parallel_st": 144, "parallelst": 144, "is_quant": 144, "is_quantized_column_parallel_linear": 144, "is_quantized_layer_with_weight": 144, "is_quantized_row_parallel_linear": 144, "row": 144, "is_torch_library_support": 144, "exce": 144, "reduce_amax": 144, "keepdim": 144, "never": [144, 165], "meant": 144, "deprect": 144, "sens": 144, "unknown": 144, "replace_funct": 144, "new_func": 144, "exportsparseconfig": [146, 148], "export_spars": [146, 148], "sparsegptconfig": [146, 153], "sparse_gpt": 146, "sparseconv2dconfig": 146, "sparselinearconfig": 146, "inspir": 147, "magnitudesearch": 147, "basesparsesearch": [147, 151, 152], "compute_valid_1d_pattern": 147, "vector": 147, "permut": 147, "create_asp_mask": 147, "m4n2_1d": 147, "booltensor": [147, 149], "get_nmprune_info": 147, "mat": 147, "mn_1d_best": 147, "reshape_1d": 147, "dimension": 147, "hw": 147, "exportsparsemodedescriptor": 148, "sparsegptmodedescriptor": 148, "sparsemagnitudemodedescriptor": 148, "convert_sparse_model": 148, "restore_export_spars": 148, "restore_sparse_model": 148, "update_sparse_metadata": 148, "sparsemodul": 149, "set_mask": 149, "sparsegptsearch": 152, "artifcat": 152, "hook": [152, 177], "create_sgpt_mask": 152, "invert": 152, "hessian_damp": 152, "invers": 152, "finish": 153, "medusaconfig": [155, 157, 161], "resblock": [155, 158], "convert_to_medusa_model": 157, "restore_medusa_model": 157, "medusamodedescriptor": 159, "analyze_symbol": 163, "concrete_arg": [163, 169], "_strict": 163, "happen": 163, "concret": [163, 169], "_only_": 165, "truli": 165, "cat": 165, "x1": 165, "x2": 165, "y1": 165, "y2": 165, "concatnodeprocessor": 165, "nodeprocessor": 165, "is_special_nod": 165, "post_process": [165, 177], "input_nod": 165, "concatsymbol": 165, "concat_sym": 165, "symbl": 165, "orig_sym": 165, "cat_dim": 165, "create_linked_copi": 165, "link_to": [165, 166, 168], "cl_type": [165, 168], "cltype": [165, 168], "elastic_dim": [165, 168], "_memo": [165, 166, 168], "anywai": 165, "input_sym": 165, "is_const": [165, 168], "is_search": [165, 168], "symdepth": 166, "max_depth": 166, "is_skipp": 166, "skippabl": 166, "sp_parent": [166, 168], "set_skipp": 166, "skippable_idx": 166, "syminfo": 168, "symdict": 168, "is_shape_preserv": 168, "symregisterfunc": 168, "add_sym_info": 168, "sym_info": 168, "get_symbol": 168, "named_modul": 168, "_mod_to_nam": 168, "named_sym_dict": 168, "named_symbol": 168, "nn_cl": 168, "is_explicit_leaf": 168, "leaf": [168, 169], "get_linear_sym_info": 168, "in_featur": 168, "incom": 168, "outgo": 168, "set_symbol": 168, "symmodul": 168, "compound": 168, "is_cross_lay": 168, "is_dangl": 168, "cross_lay": 168, "df": 168, "nchw": 168, "elast": 168, "notat": 168, "is_fre": 168, "is_incom": 168, "is_outgo": 168, "graphcollect": 169, "failure_msg": 169, "is_fail": 169, "is_unvisit": 169, "unvisit": 169, "recursive_trac": 169, "coverag": 169, "robusttrac": 169, "robust": 169, "is_leaf_modul": 169, "module_qualified_nam": 169, "is_registered_leaf": 169, "record_call_modul": 169, "call_modul": 169, "register_leaf": 169, "unregister_leaf": 169, "cpp": 171, "load_cpp_extens": 171, "cuda_version_specifi": 171, "fail_msg": 171, "load_kwarg": 171, "create_forward_loop": 172, "dataset_nam": 172, "cnn_dailymail": 172, "max_sample_length": 172, "include_label": 172, "tailor": 172, "feed": [172, 177], "pretrainedtokenizerfast": 172, "tokniz": 172, "instancn": 172, "hugginfac": 172, "get_data_parallel_group": 173, "get_tensor_parallel_group": 173, "is_avail": 173, "is_mast": 173, "list_closest_to_median": 175, "avg": 175, "val2list": 175, "repeat_tim": 175, "val2tupl": 175, "min_len": 175, "idx_repeat": 175, "deprecatederror": 176, "notimplementederror": 176, "no_stdout": 176, "silenc": 176, "stdout": 176, "num2hrb": 176, "big": 176, "human": 176, "readabl": 176, "print_rank_0": 176, "silence_matched_warn": 176, "compare_dict": 177, "dict1": 177, "dict2": 177, "unmatch": 177, "create_param_grad_clear_hook": 177, "fire": 177, "accum_grad": 177, "aliv": 177, "get_model_attribut": 177, "get_module_devic": 177, "get_same_pad": 177, "get_unwrapped_nam": 177, "is_channels_last": 177, "is_parallel": 177, "make_divis": 177, "divisor": 177, "min_val": 177, "repo": 177, "divis": 177, "slim": 177, "mobilenet": 177, "target_model": 177, "layout": 177, "param_num": 177, "trainable_onli": 177, "count": 177, "trainabl": 177, "param_num_from_forward": 177, "circumv": 177, "remove_bn": 177, "max_it": 177, "infiinit": 177, "exhaust": 177, "set_submodul": 177, "target_submodul": 177, "complement": 177, "get_submodul": 177, "constructor_arg": 177, "standardize_model_arg": 177, "model_or_fw_or_sig": 177, "use_kwarg": 177, "matter": 177, "standardize_model_like_tupl": 177, "standardize_named_model_arg": 177, "args_norm": 177, "args_with_default": 177, "unwrap_model": 177, "raise_error": 177, "msg": 177, "force_unwrap": 177, "timer": 178, "contextdecor": 178, "clear_cuda_cach": 178, "get_cuda_memory_stat": 178, "report_memori": 178, "seq": 179, "prod": 179, "aim": 179, "cheapli": 179, "recogn": 179, "mutablesequ": 179, "numpy_to_torch": 180, "np_output": 180, "torch_detach": 180, "torch_to": 180, "torch_to_numpi": 180, "submit": 181, "methodtyp": 182, "nas_forward_func": 182, "nas_train_func": 182}, "objects": {"modelopt": [[24, 0, 0, "-", "deploy"], [28, 0, 0, "-", "onnx"], [47, 0, 0, "-", "torch"]], "modelopt.deploy": [[25, 0, 0, "-", "llm"]], "modelopt.deploy.llm": [[26, 0, 0, "-", "generate"], [27, 0, 0, "-", "nemo_utils"]], "modelopt.deploy.llm.generate": [[26, 1, 1, "", "LLM"]], "modelopt.deploy.llm.generate.LLM": [[26, 2, 1, "", "__init__"], [26, 2, 1, "", "generate_context_logits"], [26, 2, 1, "", "generate_text"], [26, 2, 1, "", "generate_tokens"], [26, 3, 1, "", "max_beam_width"], [26, 3, 1, "", "max_input_len"]], "modelopt.deploy.llm.nemo_utils": [[27, 1, 1, "", "CustomSentencePieceTokenizer"], [27, 4, 1, "", "get_nemo_tokenizer"], [27, 4, 1, "", "get_tokenzier"]], "modelopt.deploy.llm.nemo_utils.CustomSentencePieceTokenizer": [[27, 2, 1, "", "__init__"], [27, 2, 1, "", "batch_decode"], [27, 2, 1, "", "batch_encode_plus"], [27, 2, 1, "", "decode"], [27, 2, 1, "", "encode"], [27, 3, 1, "", "eos_token"], [27, 3, 1, "", "eos_token_id"], [27, 3, 1, "", "pad_token"], [27, 3, 1, "", "pad_token_id"]], "modelopt.onnx": [[29, 0, 0, "-", "op_types"], [30, 0, 0, "-", "quantization"], [46, 0, 0, "-", "utils"]], "modelopt.onnx.op_types": [[29, 4, 1, "", "is_binary_op"], [29, 4, 1, "", "is_control_flow_op"], [29, 4, 1, "", "is_conversion_op"], [29, 4, 1, "", "is_copy_op"], [29, 4, 1, "", "is_default_quantizable_op_by_ort"], [29, 4, 1, "", "is_fusible_reduction_op"], [29, 4, 1, "", "is_generator_op"], [29, 4, 1, "", "is_irregular_mem_access_op"], [29, 4, 1, "", "is_linear_op"], [29, 4, 1, "", "is_modifier_op"], [29, 4, 1, "", "is_multiclass_op"], [29, 4, 1, "", "is_non_reshape_copy_op"], [29, 4, 1, "", "is_normalization_op"], [29, 4, 1, "", "is_pointwise_or_elementwise_op"], [29, 4, 1, "", "is_pooling_or_window_op"], [29, 4, 1, "", "is_recurrent_op"], [29, 4, 1, "", "is_selection_op"], [29, 4, 1, "", "is_sequence_op"], [29, 4, 1, "", "is_shape_op"], [29, 4, 1, "", "is_unary_op"]], "modelopt.onnx.quantization": [[31, 0, 0, "-", "calib_utils"], [32, 0, 0, "-", "extensions"], [33, 0, 0, "-", "fp8"], [34, 0, 0, "-", "graph_utils"], [35, 0, 0, "-", "gs_patching"], [36, 0, 0, "-", "int4"], [37, 0, 0, "-", "int8"], [38, 0, 0, "-", "operators"], [39, 0, 0, "-", "ort_patching"], [40, 0, 0, "-", "ort_utils"], [41, 0, 0, "-", "partitioning"], [42, 0, 0, "-", "qdq_utils"], [43, 0, 0, "-", "quant_utils"], [44, 4, 1, "", "quantize"], [45, 0, 0, "-", "trt_utils"]], "modelopt.onnx.quantization.calib_utils": [[31, 1, 1, "", "CalibrationDataProvider"], [31, 1, 1, "", "RandomDataProvider"], [31, 4, 1, "", "import_scales_from_calib_cache"]], "modelopt.onnx.quantization.calib_utils.CalibrationDataProvider": [[31, 2, 1, "", "__init__"], [31, 2, 1, "", "get_next"]], "modelopt.onnx.quantization.calib_utils.RandomDataProvider": [[31, 2, 1, "", "__init__"], [31, 2, 1, "", "get_next"]], "modelopt.onnx.quantization.fp8": [[33, 4, 1, "", "int8_to_fp8"], [33, 4, 1, "", "quantize"]], "modelopt.onnx.quantization.graph_utils": [[34, 4, 1, "", "add_fp16_fp32_cast"], [34, 4, 1, "", "build_non_residual_input_map"], [34, 4, 1, "", "classify_partition_nodes"], [34, 4, 1, "", "convert_fp16_io"], [34, 4, 1, "", "expand_node_names_from_patterns"], [34, 4, 1, "", "filter_quantizable_kgen_heads"], [34, 4, 1, "", "find_fp8_mha_partitions"], [34, 4, 1, "", "find_mha_partitions"], [34, 4, 1, "", "find_nodes_from_matmul_to_exclude"], [34, 4, 1, "", "find_nodes_from_mha_to_exclude"], [34, 4, 1, "", "find_nodes_to_exclude"], [34, 4, 1, "", "get_fusible_backbone"], [34, 4, 1, "", "get_tensor_consumer_nodes"], [34, 4, 1, "", "get_tensor_producer_nodes"], [34, 4, 1, "", "has_const_input"], [34, 4, 1, "", "has_path_type"], [34, 4, 1, "", "insert_fp8_mha_casts"], [34, 4, 1, "", "insert_matmul_casts"], [34, 4, 1, "", "is_const_input"], [34, 4, 1, "", "print_stat"], [34, 4, 1, "", "remove_partial_input_qdq"]], "modelopt.onnx.quantization.gs_patching": [[35, 4, 1, "", "patch_gs_modules"]], "modelopt.onnx.quantization.int4": [[36, 1, 1, "", "AWQClipHelper"], [36, 1, 1, "", "AWQLiteHelper"], [36, 4, 1, "", "dq_tensor"], [36, 4, 1, "", "find_scales"], [36, 4, 1, "", "get_act_scale"], [36, 4, 1, "", "get_act_to_weight_map_and_act_to_wa_pack_map"], [36, 4, 1, "", "get_scale"], [36, 4, 1, "", "get_weight_scale"], [36, 4, 1, "", "get_x_w_mean_for_subgraph"], [36, 4, 1, "", "quant_tensor"], [36, 4, 1, "", "quantize"], [36, 4, 1, "", "quantize_rtn"], [36, 4, 1, "", "rtn"], [36, 4, 1, "", "run_awq_scale_search_per_node"], [36, 4, 1, "", "run_awq_scale_search_per_subgraph"]], "modelopt.onnx.quantization.int4.AWQClipHelper": [[36, 2, 1, "", "__init__"], [36, 5, 1, "", "alpha_step"], [36, 5, 1, "", "min_alpha"], [36, 2, 1, "", "update_best_params"]], "modelopt.onnx.quantization.int4.AWQLiteHelper": [[36, 2, 1, "", "__init__"], [36, 5, 1, "", "alpha_step"], [36, 2, 1, "", "update_best_params"]], "modelopt.onnx.quantization.int8": [[37, 4, 1, "", "quantize"]], "modelopt.onnx.quantization.operators": [[38, 1, 1, "", "QDQConvTranspose"], [38, 1, 1, "", "QDQNormalization"]], "modelopt.onnx.quantization.operators.QDQConvTranspose": [[38, 2, 1, "", "__init__"], [38, 2, 1, "", "quantize"]], "modelopt.onnx.quantization.operators.QDQNormalization": [[38, 2, 1, "", "__init__"], [38, 2, 1, "", "quantize"]], "modelopt.onnx.quantization.ort_patching": [[39, 4, 1, "", "patch_ort_modules"]], "modelopt.onnx.quantization.ort_utils": [[40, 4, 1, "", "configure_ort"], [40, 4, 1, "", "create_inference_session"], [40, 4, 1, "", "get_quantizable_op_types"]], "modelopt.onnx.quantization.partitioning": [[41, 4, 1, "", "find_fusible_partitions"], [41, 4, 1, "", "find_hardcoded_patterns"], [41, 4, 1, "", "find_layer_norm_partitions"], [41, 4, 1, "", "find_mha_partitions"], [41, 4, 1, "", "find_non_quantizable_partitions_from_patterns"], [41, 4, 1, "", "find_quantizable_nodes"], [41, 4, 1, "", "get_skiped_output_layers"]], "modelopt.onnx.quantization.qdq_utils": [[42, 4, 1, "", "insert_dq_nodes"], [42, 4, 1, "", "insert_pre_quant_scale_nodes"], [42, 4, 1, "", "insert_qdq_nodes"], [42, 4, 1, "", "make_gs_awq_scale"], [42, 4, 1, "", "make_gs_dequantize_node"], [42, 4, 1, "", "make_gs_dequantize_output"], [42, 4, 1, "", "make_gs_pre_quant_scale_node"], [42, 4, 1, "", "make_gs_pre_quant_scale_output"], [42, 4, 1, "", "make_gs_quantize_node"], [42, 4, 1, "", "make_gs_quantize_output"], [42, 4, 1, "", "make_gs_quantized_weight"], [42, 4, 1, "", "make_gs_scale"], [42, 4, 1, "", "make_gs_zp"], [42, 4, 1, "", "qdq_to_dq"], [42, 4, 1, "", "replace_scale_values"], [42, 4, 1, "", "use_trt_qdq_ops"]], "modelopt.onnx.quantization.quant_utils": [[43, 4, 1, "", "pack_float32_to_4bit_cpp_based"], [43, 4, 1, "", "pack_float32_to_4bit_optimized"]], "modelopt.onnx.quantization.trt_utils": [[45, 4, 1, "", "get_custom_layers"], [45, 4, 1, "", "load_onnx_model"]], "modelopt.onnx.utils": [[46, 4, 1, "", "duplicate_shared_constants"], [46, 4, 1, "", "find_lowest_common_ancestor"], [46, 4, 1, "", "gen_random_inputs"], [46, 4, 1, "", "get_all_input_names"], [46, 4, 1, "", "get_batch_size"], [46, 4, 1, "", "get_batch_size_from_bytes"], [46, 4, 1, "", "get_child_nodes"], [46, 4, 1, "", "get_input_names"], [46, 4, 1, "", "get_input_names_from_bytes"], [46, 4, 1, "", "get_input_shapes"], [46, 4, 1, "", "get_input_shapes_from_bytes"], [46, 4, 1, "", "get_node_names"], [46, 4, 1, "", "get_node_names_from_bytes"], [46, 4, 1, "", "get_output_names"], [46, 4, 1, "", "get_output_names_from_bytes"], [46, 4, 1, "", "get_output_shapes"], [46, 4, 1, "", "get_parent_nodes"], [46, 4, 1, "", "get_variable_inputs"], [46, 4, 1, "", "is_valid_onnx_model"], [46, 4, 1, "", "name_onnx_nodes"], [46, 4, 1, "", "parse_shapes_spec"], [46, 4, 1, "", "randomize_weights"], [46, 4, 1, "", "randomize_weights_onnx_bytes"], [46, 4, 1, "", "remove_weights_data"], [46, 4, 1, "", "save_onnx"], [46, 4, 1, "", "save_onnx_bytes_to_dir"], [46, 4, 1, "", "udpate_domain"], [46, 4, 1, "", "validate_batch_size"], [46, 4, 1, "", "validate_onnx"]], "modelopt.torch": [[48, 0, 0, "-", "distill"], [57, 0, 0, "-", "export"], [71, 0, 0, "-", "nas"], [91, 0, 0, "-", "opt"], [101, 0, 0, "-", "prune"], [109, 0, 0, "-", "quantization"], [145, 0, 0, "-", "sparsity"], [154, 0, 0, "-", "speculative"], [162, 0, 0, "-", "trace"], [170, 0, 0, "-", "utils"]], "modelopt.torch.distill": [[49, 0, 0, "-", "config"], [50, 0, 0, "-", "distillation"], [51, 0, 0, "-", "distillation_model"], [52, 0, 0, "-", "loss_balancers"], [53, 0, 0, "-", "losses"], [54, 0, 0, "-", "mode"], [55, 0, 0, "-", "plugins"], [56, 0, 0, "-", "registry"]], "modelopt.torch.distill.config": [[49, 6, 1, "", "KDLossConfig"]], "modelopt.torch.distill.config.KDLossConfig": [[49, 7, 1, "", "criterion"], [49, 7, 1, "", "expose_minimal_state_dict"], [49, 7, 1, "", "loss_balancer"], [49, 2, 1, "", "model_dump"], [49, 7, 1, "", "teacher_model"]], "modelopt.torch.distill.distillation": [[50, 4, 1, "", "convert"], [50, 4, 1, "", "export"]], "modelopt.torch.distill.distillation_model": [[51, 1, 1, "", "DistillationModel"]], "modelopt.torch.distill.distillation_model.DistillationModel": [[51, 2, 1, "", "compute_kd_loss"], [51, 2, 1, "", "forward"], [51, 2, 1, "", "hide_loss_modules"], [51, 2, 1, "", "hide_teacher_model"], [51, 2, 1, "", "load_state_dict"], [51, 3, 1, "", "loss_balancer"], [51, 3, 1, "", "loss_modules"], [51, 2, 1, "", "modify"], [51, 2, 1, "", "state_dict"], [51, 3, 1, "", "teacher_model"]], "modelopt.torch.distill.loss_balancers": [[52, 1, 1, "", "DistillationLossBalancer"], [52, 1, 1, "", "StaticLossBalancer"]], "modelopt.torch.distill.loss_balancers.DistillationLossBalancer": [[52, 2, 1, "", "__init__"], [52, 2, 1, "", "forward"], [52, 2, 1, "", "set_student_loss_reduction_fn"]], "modelopt.torch.distill.loss_balancers.StaticLossBalancer": [[52, 2, 1, "", "__init__"], [52, 2, 1, "", "forward"]], "modelopt.torch.distill.losses": [[53, 1, 1, "", "LogitsDistillationLoss"], [53, 1, 1, "", "MGDLoss"]], "modelopt.torch.distill.losses.LogitsDistillationLoss": [[53, 2, 1, "", "__init__"], [53, 2, 1, "", "forward"]], "modelopt.torch.distill.losses.MGDLoss": [[53, 2, 1, "", "__init__"], [53, 2, 1, "", "forward"]], "modelopt.torch.distill.mode": [[54, 1, 1, "", "ExportStudentModeDescriptor"], [54, 1, 1, "", "KnowledgeDistillationModeDescriptor"]], "modelopt.torch.distill.mode.ExportStudentModeDescriptor": [[54, 3, 1, "", "config_class"], [54, 3, 1, "", "convert"], [54, 3, 1, "", "is_export_mode"], [54, 3, 1, "", "name"], [54, 3, 1, "", "restore"]], "modelopt.torch.distill.mode.KnowledgeDistillationModeDescriptor": [[54, 3, 1, "", "config_class"], [54, 3, 1, "", "convert"], [54, 3, 1, "", "export_mode"], [54, 3, 1, "", "name"], [54, 3, 1, "", "next_modes"], [54, 3, 1, "", "restore"], [54, 3, 1, "", "update_for_new_mode"]], "modelopt.torch.export": [[58, 0, 0, "-", "distribute"], [59, 0, 0, "-", "hf_config_map"], [60, 0, 0, "-", "layer_utils"], [61, 0, 0, "-", "model_config"], [62, 0, 0, "-", "model_config_export"], [63, 0, 0, "-", "model_config_utils"], [64, 0, 0, "-", "postprocess"], [65, 0, 0, "-", "scaling_factor_utils"], [66, 0, 0, "-", "tensorrt_llm_type"], [67, 0, 0, "-", "tensorrt_llm_utils"], [68, 0, 0, "-", "transformer_engine"], [69, 0, 0, "-", "unified_export_hf"], [70, 0, 0, "-", "vllm"]], "modelopt.torch.export.distribute": [[58, 1, 1, "", "NFSWorkspace"], [58, 4, 1, "", "get_configs_parallel"], [58, 4, 1, "", "get_tensors_parallel"]], "modelopt.torch.export.distribute.NFSWorkspace": [[58, 2, 1, "", "__init__"], [58, 3, 1, "", "is_initialized"], [58, 2, 1, "", "read_configs_and_weights_from_rank"], [58, 2, 1, "", "write_configs_and_weights"]], "modelopt.torch.export.layer_utils": [[60, 4, 1, "", "build_attention_config"], [60, 4, 1, "", "build_conv_config"], [60, 4, 1, "", "build_decoder_config"], [60, 4, 1, "", "build_embedding_config"], [60, 4, 1, "", "build_layernorm_config"], [60, 4, 1, "", "build_linear_config"], [60, 4, 1, "", "build_medusa_heads_config"], [60, 4, 1, "", "build_mlp_config"], [60, 4, 1, "", "build_moe_config"], [60, 4, 1, "", "build_qkv"], [60, 4, 1, "", "build_recurrent_config"], [60, 4, 1, "", "build_stacked_experts"], [60, 4, 1, "", "check_model_compatibility"], [60, 4, 1, "", "dup_kv_weight"], [60, 4, 1, "", "get_activation_scaling_factor"], [60, 4, 1, "", "get_kv_cache_dtype"], [60, 4, 1, "", "get_kv_cache_scaling_factor"], [60, 4, 1, "", "get_prequant_scaling_factor"], [60, 4, 1, "", "get_qkv_and_avg_prequant_scale"], [60, 4, 1, "", "get_quantization_format"], [60, 4, 1, "", "get_scaling_factor"], [60, 4, 1, "", "get_transformer_layers"], [60, 4, 1, "", "get_weight_block_size"], [60, 4, 1, "", "get_weight_scaling_factor"], [60, 4, 1, "", "get_weight_scaling_factor_2"], [60, 4, 1, "", "is_attention"], [60, 4, 1, "", "is_decoder_list"], [60, 4, 1, "", "is_embedding"], [60, 4, 1, "", "is_layernorm"], [60, 4, 1, "", "is_linear"], [60, 4, 1, "", "is_mlp"], [60, 4, 1, "", "is_moe"], [60, 4, 1, "", "is_quantlinear"], [60, 4, 1, "", "is_recurrent"]], "modelopt.torch.export.model_config": [[61, 1, 1, "", "AttentionConfig"], [61, 1, 1, "", "ConvConfig"], [61, 1, 1, "", "DecoderLayerConfig"], [61, 1, 1, "", "EmbeddingConfig"], [61, 1, 1, "", "ExpertConfig"], [61, 1, 1, "", "LayernormConfig"], [61, 1, 1, "", "LinearActConfig"], [61, 1, 1, "", "LinearConfig"], [61, 1, 1, "", "MLPConfig"], [61, 1, 1, "", "MOEConfig"], [61, 1, 1, "", "MedusaHeadConfig"], [61, 1, 1, "", "ModelConfig"], [61, 1, 1, "", "QKVConfig"], [61, 1, 1, "", "RecurrentConfig"], [61, 1, 1, "", "RgLruConfig"]], "modelopt.torch.export.model_config.AttentionConfig": [[61, 2, 1, "", "__init__"], [61, 5, 1, "", "clip_qkv"], [61, 5, 1, "", "dense"], [61, 5, 1, "", "kv_cache_dtype"], [61, 5, 1, "", "kv_cache_scaling_factor"], [61, 5, 1, "", "qkv"], [61, 5, 1, "", "rel_attn_table"], [61, 5, 1, "", "rotary_dim"]], "modelopt.torch.export.model_config.ConvConfig": [[61, 2, 1, "", "__init__"], [61, 5, 1, "", "bias"], [61, 5, 1, "", "quantization"], [61, 5, 1, "", "weight"]], "modelopt.torch.export.model_config.DecoderLayerConfig": [[61, 2, 1, "", "__init__"], [61, 5, 1, "", "alibi_bias_max"], [61, 5, 1, "", "apply_residual_connection_post_layernorm"], [61, 5, 1, "", "attention"], [61, 5, 1, "", "attention_head_size"], [61, 5, 1, "", "attention_layernorm"], [61, 5, 1, "", "attn_logit_softcapping"], [61, 5, 1, "", "attn_replacing_linear"], [61, 5, 1, "", "block_config"], [61, 5, 1, "", "blocksparse_block_size"], [61, 5, 1, "", "blocksparse_homo_head_pattern"], [61, 5, 1, "", "blocksparse_num_local_blocks"], [61, 5, 1, "", "blocksparse_vertical_stride"], [61, 5, 1, "", "chatglm_version"], [61, 5, 1, "", "clip_qkv"], [61, 5, 1, "", "cross_attention"], [61, 5, 1, "", "cross_attention_layernorm"], [61, 5, 1, "", "decoder_type"], [61, 5, 1, "", "dense_attention_every_n_layers"], [61, 5, 1, "", "emb_scale_by_sqrt_dim"], [61, 3, 1, "", "ffn_hidden_size_local"], [61, 5, 1, "", "final_logit_softcapping"], [61, 5, 1, "", "gegelu_limit"], [61, 3, 1, "", "hidden_size"], [61, 5, 1, "", "input_layernorm"], [61, 5, 1, "", "layer_types"], [61, 5, 1, "", "logits_soft_cap"], [61, 5, 1, "", "longrope_long_mscale"], [61, 5, 1, "", "longrope_scaling_long_factors"], [61, 5, 1, "", "longrope_scaling_short_factors"], [61, 5, 1, "", "longrope_short_mscale"], [61, 5, 1, "", "max_position_embeddings"], [61, 5, 1, "", "mlp"], [61, 5, 1, "", "mlp_layernorm"], [61, 5, 1, "", "mlp_replacing_linear"], [61, 5, 1, "", "moe_num_experts"], [61, 5, 1, "", "moe_renorm_mode"], [61, 5, 1, "", "moe_top_k"], [61, 5, 1, "", "moe_tp_mode"], [61, 5, 1, "", "mup_attn_multiplier"], [61, 5, 1, "", "mup_embedding_multiplier"], [61, 5, 1, "", "mup_use_scaling"], [61, 5, 1, "", "mup_width_multiplier"], [61, 5, 1, "", "new_decoder_architecture"], [61, 5, 1, "", "num_attention_heads"], [61, 5, 1, "", "num_kv_heads"], [61, 5, 1, "", "original_max_position_embeddings"], [61, 5, 1, "", "parallel_attention"], [61, 5, 1, "", "partial_rotary_factor"], [61, 5, 1, "", "post_feedforward_layernorm"], [61, 5, 1, "", "post_layernorm"], [61, 5, 1, "", "pre_feedforward_layernorm"], [61, 5, 1, "", "quantization"], [61, 5, 1, "", "query_pre_attn_scalar"], [61, 5, 1, "", "qwen_type"], [61, 5, 1, "", "recurrent"], [61, 5, 1, "", "rel_attn_max_distance"], [61, 5, 1, "", "rel_attn_num_buckets"], [61, 5, 1, "", "residual_layernorm"], [61, 5, 1, "", "residual_mlp"], [61, 5, 1, "", "rnn_hidden_size"], [61, 5, 1, "", "rope_ratio"], [61, 5, 1, "", "rope_scaling"], [61, 5, 1, "", "rotary_base"], [61, 5, 1, "", "rotary_pct"], [61, 5, 1, "", "self_attention"], [61, 5, 1, "", "self_attention_layernorm"], [61, 5, 1, "", "seq_length"], [61, 5, 1, "", "use_alibi"], [61, 5, 1, "", "use_cache"]], "modelopt.torch.export.model_config.EmbeddingConfig": [[61, 2, 1, "", "__init__"], [61, 3, 1, "", "hidden_size"], [61, 3, 1, "", "local_vocab_size"], [61, 5, 1, "", "quantization"], [61, 5, 1, "", "weight"]], "modelopt.torch.export.model_config.ExpertConfig": [[61, 2, 1, "", "__init__"], [61, 5, 1, "", "fc"], [61, 5, 1, "", "proj"]], "modelopt.torch.export.model_config.LayernormConfig": [[61, 2, 1, "", "__init__"], [61, 5, 1, "", "bias"], [61, 5, 1, "", "eps"], [61, 5, 1, "", "layernorm_type"], [61, 5, 1, "", "quantization"], [61, 5, 1, "", "weight"]], "modelopt.torch.export.model_config.LinearActConfig": [[61, 2, 1, "", "__init__"], [61, 5, 1, "", "hidden_act"], [61, 5, 1, "", "linear"]], "modelopt.torch.export.model_config.LinearConfig": [[61, 2, 1, "", "__init__"], [61, 5, 1, "", "activation_scaling_factor"], [61, 5, 1, "", "awq_block_size"], [61, 5, 1, "", "bias"], [61, 5, 1, "", "linear_type"], [61, 5, 1, "", "prequant_scaling_factor"], [61, 5, 1, "", "quantization"], [61, 5, 1, "", "weight"], [61, 5, 1, "", "weights_scaling_factor"], [61, 5, 1, "", "weights_scaling_factor_2"]], "modelopt.torch.export.model_config.MLPConfig": [[61, 2, 1, "", "__init__"], [61, 5, 1, "", "fc"], [61, 5, 1, "", "gate"], [61, 5, 1, "", "hidden_act"], [61, 5, 1, "", "merged_fc1_gate"], [61, 5, 1, "", "proj"], [61, 3, 1, "", "quantization"]], "modelopt.torch.export.model_config.MOEConfig": [[61, 2, 1, "", "__init__"], [61, 5, 1, "", "experts"], [61, 3, 1, "", "fc"], [61, 5, 1, "", "hidden_act"], [61, 5, 1, "", "router"]], "modelopt.torch.export.model_config.MedusaHeadConfig": [[61, 2, 1, "", "__init__"], [61, 5, 1, "", "lm_head"], [61, 5, 1, "", "medusa_layers"]], "modelopt.torch.export.model_config.ModelConfig": [[61, 2, 1, "", "__init__"], [61, 5, 1, "", "block_embedding"], [61, 5, 1, "", "dtype"], [61, 5, 1, "", "enc_dec"], [61, 5, 1, "", "encoder_head_size"], [61, 5, 1, "", "encoder_hidden_size"], [61, 5, 1, "", "encoder_num_heads"], [61, 3, 1, "", "hidden_act"], [61, 3, 1, "", "hidden_size"], [61, 5, 1, "", "layers"], [61, 5, 1, "", "lm_head"], [61, 5, 1, "", "ln_embed"], [61, 5, 1, "", "ln_f"], [61, 3, 1, "", "max_position_embeddings"], [61, 5, 1, "", "medusa_heads"], [61, 3, 1, "", "num_attention_heads"], [61, 3, 1, "", "num_kv_heads"], [61, 5, 1, "", "num_medusa_heads"], [61, 5, 1, "", "num_medusa_layers"], [61, 5, 1, "", "pipeline_parallel"], [61, 5, 1, "", "position_embedding"], [61, 5, 1, "", "quantization"], [61, 5, 1, "", "rank"], [61, 5, 1, "", "share_embedding_table"], [61, 5, 1, "", "tensor_parallel"], [61, 5, 1, "", "version"], [61, 5, 1, "", "vocab_embedding"], [61, 5, 1, "", "vocab_size"], [61, 3, 1, "", "vocab_size_padded"]], "modelopt.torch.export.model_config.QKVConfig": [[61, 2, 1, "", "__init__"], [61, 3, 1, "", "activation_scaling_factor"], [61, 3, 1, "", "awq_block_size"], [61, 3, 1, "", "bias"], [61, 5, 1, "", "k"], [61, 3, 1, "", "prequant_scaling_factor"], [61, 5, 1, "", "q"], [61, 3, 1, "", "quantization"], [61, 5, 1, "", "v"], [61, 3, 1, "", "weight"], [61, 3, 1, "", "weights_scaling_factor"], [61, 3, 1, "", "weights_scaling_factor_2"]], "modelopt.torch.export.model_config.RecurrentConfig": [[61, 2, 1, "", "__init__"], [61, 5, 1, "", "conv1d"], [61, 5, 1, "", "linear_out"], [61, 5, 1, "", "linear_x"], [61, 5, 1, "", "linear_y"], [61, 5, 1, "", "rg_lru"], [61, 5, 1, "", "y_bias"]], "modelopt.torch.export.model_config.RgLruConfig": [[61, 2, 1, "", "__init__"], [61, 5, 1, "", "input_gate"], [61, 5, 1, "", "recurrent_gate"], [61, 5, 1, "", "recurrent_param"]], "modelopt.torch.export.model_config_export": [[62, 4, 1, "", "export_tensorrt_llm_checkpoint"], [62, 4, 1, "", "torch_to_tensorrt_llm_checkpoint"]], "modelopt.torch.export.model_config_utils": [[63, 4, 1, "", "from_quantized_weight"], [63, 4, 1, "", "merge_fc1_gate"], [63, 4, 1, "", "merge_qkv"], [63, 4, 1, "", "model_config_from_dict"], [63, 4, 1, "", "model_config_to_dict"], [63, 4, 1, "", "naive_quantization"], [63, 4, 1, "", "pack_linear_weights"], [63, 4, 1, "", "pad_weights"], [63, 4, 1, "", "process_layer_quant_config"], [63, 4, 1, "", "restore_model_config"], [63, 4, 1, "", "split_config_and_weights"], [63, 4, 1, "", "to_quantized_weight"]], "modelopt.torch.export.postprocess": [[64, 4, 1, "", "check_weight_shape_valid"], [64, 4, 1, "", "pad_embedding_lm_head"], [64, 4, 1, "", "postprocess_model_config"], [64, 4, 1, "", "postprocess_tensors"], [64, 4, 1, "", "update_lm_head_quantization"]], "modelopt.torch.export.scaling_factor_utils": [[65, 4, 1, "", "adjust_attn_amax_values"], [65, 4, 1, "", "convert_state_dict_amax_to_scales"], [65, 4, 1, "", "get_weights_scaling_factor_and_amax"], [65, 4, 1, "", "resmooth_and_get_scale_and_amax"]], "modelopt.torch.export.tensorrt_llm_type": [[66, 1, 1, "", "LayerNormPositionType"], [66, 1, 1, "", "LayerNormType"], [66, 1, 1, "", "MLPType"]], "modelopt.torch.export.tensorrt_llm_type.LayerNormPositionType": [[66, 2, 1, "", "__new__"], [66, 5, 1, "", "post_layernorm"], [66, 5, 1, "", "pre_layernorm"]], "modelopt.torch.export.tensorrt_llm_type.LayerNormType": [[66, 5, 1, "", "GroupNorm"], [66, 5, 1, "", "LayerNorm"], [66, 5, 1, "", "RmsNorm"], [66, 2, 1, "", "__new__"]], "modelopt.torch.export.tensorrt_llm_type.MLPType": [[66, 5, 1, "", "FusedGatedMLP"], [66, 5, 1, "", "GatedMLP"], [66, 5, 1, "", "MLP"], [66, 2, 1, "", "__new__"]], "modelopt.torch.export.tensorrt_llm_utils": [[67, 4, 1, "", "convert_to_tensorrt_llm_config"], [67, 4, 1, "", "is_tensorrt_llm_0_8_or_9"], [67, 4, 1, "", "prepare_enc_dec_decoder_layer"], [67, 4, 1, "", "prepare_enc_dec_export_dir"], [67, 4, 1, "", "weights_to_npz"]], "modelopt.torch.export.transformer_engine": [[68, 4, 1, "", "convert_to_transformer_engine"]], "modelopt.torch.export.unified_export_hf": [[69, 4, 1, "", "export_hf"], [69, 4, 1, "", "export_hf_checkpoint"]], "modelopt.torch.export.vllm": [[70, 4, 1, "", "export_to_vllm"]], "modelopt.torch.nas": [[72, 0, 0, "-", "algorithms"], [73, 0, 0, "-", "autonas"], [74, 0, 0, "-", "config"], [75, 0, 0, "-", "conversion"], [76, 0, 0, "-", "hparams"], [79, 0, 0, "-", "mode"], [80, 0, 0, "-", "modules"], [86, 0, 0, "-", "plugins"], [87, 0, 0, "-", "registry"], [88, 0, 0, "-", "search_space"], [89, 0, 0, "-", "traced_hp"], [90, 0, 0, "-", "utils"]], "modelopt.torch.nas.algorithms": [[72, 4, 1, "", "profile"], [72, 4, 1, "", "search"]], "modelopt.torch.nas.autonas": [[73, 1, 1, "", "AutoNASPatchManager"], [73, 1, 1, "", "EvolveSearcher"], [73, 1, 1, "", "IterativeSearcher"], [73, 1, 1, "", "RandomSearcher"], [73, 4, 1, "", "convert_autonas_searchspace"], [73, 4, 1, "", "convert_searchspace"], [73, 4, 1, "", "export_searchspace"], [73, 4, 1, "", "restore_autonas_searchspace"], [73, 4, 1, "", "restore_export"], [73, 4, 1, "", "restore_searchspace"], [73, 4, 1, "", "update_autonas_metadata"]], "modelopt.torch.nas.autonas.AutoNASPatchManager": [[73, 3, 1, "", "sample_during_training"]], "modelopt.torch.nas.autonas.EvolveSearcher": [[73, 2, 1, "", "after_step"], [73, 2, 1, "", "before_search"], [73, 2, 1, "", "before_step"], [73, 5, 1, "", "candidates"], [73, 3, 1, "", "default_search_config"], [73, 3, 1, "", "default_state_dict"], [73, 5, 1, "", "population"], [73, 2, 1, "", "sample"]], "modelopt.torch.nas.autonas.IterativeSearcher": [[73, 2, 1, "", "after_search"], [73, 2, 1, "", "after_step"], [73, 2, 1, "", "before_search"], [73, 2, 1, "", "before_step"], [73, 5, 1, "", "best"], [73, 5, 1, "", "best_history"], [73, 5, 1, "", "candidate"], [73, 5, 1, "", "constraints_func"], [73, 3, 1, "", "default_search_config"], [73, 3, 1, "", "default_state_dict"], [73, 2, 1, "", "early_stop"], [73, 5, 1, "", "history"], [73, 5, 1, "", "iter_num"], [73, 5, 1, "", "num_satisfied"], [73, 2, 1, "", "run_search"], [73, 2, 1, "", "run_step"], [73, 2, 1, "", "sample"], [73, 5, 1, "", "samples"], [73, 2, 1, "", "sanitize_search_config"]], "modelopt.torch.nas.autonas.RandomSearcher": [[73, 2, 1, "", "sample"]], "modelopt.torch.nas.config": [[74, 6, 1, "", "AutoNASConfig"], [74, 6, 1, "", "ExportConfig"]], "modelopt.torch.nas.config.AutoNASConfig": [[74, 7, 1, "", "nn_batchnorm1d"], [74, 7, 1, "", "nn_batchnorm2d"], [74, 7, 1, "", "nn_batchnorm3d"], [74, 7, 1, "", "nn_conv1d"], [74, 7, 1, "", "nn_conv2d"], [74, 7, 1, "", "nn_conv3d"], [74, 7, 1, "", "nn_convtranspose1d"], [74, 7, 1, "", "nn_convtranspose2d"], [74, 7, 1, "", "nn_convtranspose3d"], [74, 7, 1, "", "nn_groupnorm"], [74, 7, 1, "", "nn_instancenorm1d"], [74, 7, 1, "", "nn_instancenorm2d"], [74, 7, 1, "", "nn_instancenorm3d"], [74, 7, 1, "", "nn_layernorm"], [74, 7, 1, "", "nn_linear"], [74, 7, 1, "", "nn_sequential"], [74, 7, 1, "", "nn_syncbatchnorm"]], "modelopt.torch.nas.config.ExportConfig": [[74, 7, 1, "", "calib"], [74, 7, 1, "", "strict"]], "modelopt.torch.nas.conversion": [[75, 4, 1, "", "convert"], [75, 4, 1, "", "export"]], "modelopt.torch.nas.hparams": [[77, 0, 0, "-", "concat"], [78, 0, 0, "-", "container"]], "modelopt.torch.nas.hparams.concat": [[77, 1, 1, "", "ConcatTracedHp"]], "modelopt.torch.nas.hparams.concat.ConcatTracedHp": [[77, 3, 1, "", "active"], [77, 3, 1, "", "active_slice"]], "modelopt.torch.nas.hparams.container": [[78, 1, 1, "", "DepthHparam"]], "modelopt.torch.nas.mode": [[79, 1, 1, "", "AutoNASModeDescriptor"], [79, 1, 1, "", "ExportModeDescriptor"]], "modelopt.torch.nas.mode.AutoNASModeDescriptor": [[79, 3, 1, "", "config_class"], [79, 3, 1, "", "convert"], [79, 3, 1, "", "export_mode"], [79, 3, 1, "", "name"], [79, 3, 1, "", "next_modes"], [79, 3, 1, "", "restore"], [79, 3, 1, "", "search_algorithm"], [79, 3, 1, "", "update_for_new_mode"], [79, 3, 1, "", "update_for_save"]], "modelopt.torch.nas.mode.ExportModeDescriptor": [[79, 3, 1, "", "config_class"], [79, 3, 1, "", "convert"], [79, 3, 1, "", "is_export_mode"], [79, 3, 1, "", "name"], [79, 3, 1, "", "restore"]], "modelopt.torch.nas.modules": [[81, 0, 0, "-", "container"], [82, 0, 0, "-", "conv"], [83, 0, 0, "-", "linear"], [84, 0, 0, "-", "norm"], [85, 0, 0, "-", "utils"]], "modelopt.torch.nas.modules.utils": [[85, 4, 1, "", "get_sliced_tensor"], [85, 4, 1, "", "get_sliced_tensor_by_slices"]], "modelopt.torch.nas.search_space": [[88, 1, 1, "", "SearchSpace"], [88, 4, 1, "", "generate_search_space"]], "modelopt.torch.nas.search_space.SearchSpace": [[88, 2, 1, "", "__init__"], [88, 2, 1, "", "export"], [88, 2, 1, "", "generate"], [88, 2, 1, "", "print_summary"], [88, 2, 1, "", "sample"], [88, 2, 1, "", "sort_parameters"]], "modelopt.torch.nas.traced_hp": [[89, 1, 1, "", "TracedHp"], [89, 1, 1, "", "TracedHpRegistry"]], "modelopt.torch.nas.traced_hp.TracedHp": [[89, 2, 1, "", "initialize_from"], [89, 2, 1, "", "resolve_dependencies"]], "modelopt.torch.nas.traced_hp.TracedHpRegistry": [[89, 2, 1, "", "get"], [89, 2, 1, "", "initialize_from"], [89, 2, 1, "", "register"], [89, 2, 1, "", "unregister"]], "modelopt.torch.nas.utils": [[90, 1, 1, "", "enable_modelopt_patches"], [90, 4, 1, "", "get_subnet_config"], [90, 4, 1, "", "inference_flops"], [90, 4, 1, "", "is_modelopt_patches_enabled"], [90, 1, 1, "", "no_modelopt_patches"], [90, 4, 1, "", "print_search_space_summary"], [90, 4, 1, "", "replace_forward"], [90, 4, 1, "", "sample"], [90, 4, 1, "", "select"], [90, 1, 1, "", "set_modelopt_patches_enabled"]], "modelopt.torch.nas.utils.enable_modelopt_patches": [[90, 2, 1, "", "__init__"]], "modelopt.torch.nas.utils.no_modelopt_patches": [[90, 2, 1, "", "__init__"]], "modelopt.torch.nas.utils.set_modelopt_patches_enabled": [[90, 2, 1, "", "__init__"], [90, 2, 1, "", "clone"]], "modelopt.torch.opt": [[92, 0, 0, "-", "config"], [93, 0, 0, "-", "conversion"], [94, 0, 0, "-", "dynamic"], [95, 0, 0, "-", "hparam"], [96, 0, 0, "-", "mode"], [97, 0, 0, "-", "plugins"], [99, 0, 0, "-", "searcher"], [100, 0, 0, "-", "utils"]], "modelopt.torch.opt.config": [[92, 6, 1, "", "ModeloptBaseConfig"], [92, 6, 1, "", "ModeloptBaseRule"], [92, 6, 1, "", "ModeloptBaseRuleConfig"], [92, 4, 1, "", "ModeloptField"], [92, 4, 1, "", "get_kwargs_for_create_model_with_rules"]], "modelopt.torch.opt.config.ModeloptBaseConfig": [[92, 2, 1, "", "get"], [92, 2, 1, "", "get_field_name_from_key"], [92, 2, 1, "", "items"], [92, 2, 1, "", "keys"], [92, 2, 1, "", "model_dump"], [92, 2, 1, "", "model_dump_json"], [92, 2, 1, "", "update"], [92, 2, 1, "", "values"]], "modelopt.torch.opt.config.ModeloptBaseRule": [[92, 2, 1, "", "customize_rule"], [92, 2, 1, "", "get_rule_type"], [92, 2, 1, "", "validate_rule"]], "modelopt.torch.opt.config.ModeloptBaseRuleConfig": [[92, 2, 1, "", "register_default"], [92, 2, 1, "", "unregister_default"]], "modelopt.torch.opt.conversion": [[93, 1, 1, "", "ModeloptStateManager"], [93, 4, 1, "", "apply_mode"], [93, 4, 1, "", "modelopt_state"], [93, 4, 1, "", "restore"], [93, 4, 1, "", "restore_from_modelopt_state"], [93, 4, 1, "", "save"]], "modelopt.torch.opt.conversion.ModeloptStateManager": [[93, 2, 1, "", "__init__"], [93, 2, 1, "", "add_mode"], [93, 2, 1, "", "check_mode"], [93, 2, 1, "", "get_config_class"], [93, 3, 1, "", "has_state"], [93, 2, 1, "", "is_converted"], [93, 3, 1, "", "last_mode"], [93, 2, 1, "", "load_state_dict"], [93, 2, 1, "", "modes_with_states"], [93, 2, 1, "", "state_dict"], [93, 2, 1, "", "transfer_state_dict"], [93, 2, 1, "", "update_last_state_before_new_mode"], [93, 2, 1, "", "update_last_state_before_save"]], "modelopt.torch.opt.dynamic": [[94, 1, 1, "", "DynamicModule"], [94, 1, 1, "", "DynamicSpace"]], "modelopt.torch.opt.dynamic.DynamicModule": [[94, 2, 1, "", "__init__"], [94, 2, 1, "", "convert"], [94, 2, 1, "", "export"], [94, 2, 1, "", "extra_repr"], [94, 2, 1, "", "force_assign"], [94, 2, 1, "", "freeze"], [94, 2, 1, "", "get_hparam"], [94, 2, 1, "", "modify"], [94, 2, 1, "", "named_hparams"], [94, 3, 1, "", "original_cls"], [94, 2, 1, "", "reset_dynamic_attributes"]], "modelopt.torch.opt.dynamic.DynamicSpace": [[94, 2, 1, "", "__init__"], [94, 2, 1, "", "config"], [94, 2, 1, "", "convert_to_dynamic"], [94, 2, 1, "", "export"], [94, 2, 1, "", "get_hparam"], [94, 2, 1, "", "is_configurable"], [94, 2, 1, "", "is_dynamic"], [94, 2, 1, "", "named_dynamic_modules"], [94, 2, 1, "", "named_hparams"], [94, 2, 1, "", "select"], [94, 2, 1, "", "size"]], "modelopt.torch.opt.hparam": [[95, 1, 1, "", "Hparam"]], "modelopt.torch.opt.hparam.Hparam": [[95, 5, 1, "", "ActiveSlice"], [95, 5, 1, "", "Importance"], [95, 5, 1, "", "ImportanceEstimator"], [95, 2, 1, "", "__init__"], [95, 3, 1, "", "active"], [95, 3, 1, "", "active_slice"], [95, 3, 1, "", "choices"], [95, 2, 1, "", "enforce_order"], [95, 3, 1, "", "importance"], [95, 3, 1, "", "is_configurable"], [95, 3, 1, "", "is_sortable"], [95, 3, 1, "", "max"], [95, 3, 1, "", "min"], [95, 3, 1, "", "original"], [95, 2, 1, "", "register_importance"]], "modelopt.torch.opt.plugins": [[98, 0, 0, "-", "huggingface"]], "modelopt.torch.opt.plugins.huggingface": [[98, 4, 1, "", "enable_huggingface_checkpointing"]], "modelopt.torch.opt.searcher": [[99, 1, 1, "", "BaseSearcher"]], "modelopt.torch.opt.searcher.BaseSearcher": [[99, 2, 1, "", "__init__"], [99, 2, 1, "", "after_search"], [99, 2, 1, "", "before_search"], [99, 5, 1, "", "config"], [99, 5, 1, "", "constraints"], [99, 2, 1, "", "construct_forward_loop"], [99, 3, 1, "", "default_search_config"], [99, 3, 1, "", "default_state_dict"], [99, 5, 1, "", "deployment"], [99, 5, 1, "", "dummy_input"], [99, 2, 1, "", "eval_score"], [99, 5, 1, "", "forward_loop"], [99, 3, 1, "", "has_score"], [99, 2, 1, "", "load_search_checkpoint"], [99, 5, 1, "", "model"], [99, 2, 1, "", "reset_search"], [99, 2, 1, "", "run_search"], [99, 2, 1, "", "sanitize_search_config"], [99, 2, 1, "", "save_search_checkpoint"], [99, 2, 1, "", "search"], [99, 2, 1, "", "state_dict"]], "modelopt.torch.opt.utils": [[100, 4, 1, "", "get_hparam"], [100, 4, 1, "", "is_configurable"], [100, 4, 1, "", "is_dynamic"], [100, 4, 1, "", "named_dynamic_modules"], [100, 4, 1, "", "named_hparams"], [100, 4, 1, "", "search_space_size"]], "modelopt.torch.prune": [[102, 0, 0, "-", "config"], [103, 0, 0, "-", "fastnas"], [104, 0, 0, "-", "gradnas"], [105, 0, 0, "-", "mcore_gpt_minitron"], [106, 0, 0, "-", "mode"], [107, 0, 0, "-", "plugins"], [108, 0, 0, "-", "pruning"]], "modelopt.torch.prune.config": [[102, 6, 1, "", "FastNASConfig"], [102, 6, 1, "", "GradNASConfig"], [102, 6, 1, "", "MCoreGPTMinitronConfig"]], "modelopt.torch.prune.config.FastNASConfig": [[102, 7, 1, "", "nn_batchnorm1d"], [102, 7, 1, "", "nn_batchnorm2d"], [102, 7, 1, "", "nn_batchnorm3d"], [102, 7, 1, "", "nn_conv1d"], [102, 7, 1, "", "nn_conv2d"], [102, 7, 1, "", "nn_conv3d"], [102, 7, 1, "", "nn_convtranspose1d"], [102, 7, 1, "", "nn_convtranspose2d"], [102, 7, 1, "", "nn_convtranspose3d"], [102, 7, 1, "", "nn_groupnorm"], [102, 7, 1, "", "nn_instancenorm1d"], [102, 7, 1, "", "nn_instancenorm2d"], [102, 7, 1, "", "nn_instancenorm3d"], [102, 7, 1, "", "nn_layernorm"], [102, 7, 1, "", "nn_linear"], [102, 7, 1, "", "nn_syncbatchnorm"]], "modelopt.torch.prune.config.GradNASConfig": [[102, 7, 1, "", "nn_batchnorm1d"], [102, 7, 1, "", "nn_batchnorm2d"], [102, 7, 1, "", "nn_batchnorm3d"], [102, 7, 1, "", "nn_conv1d"], [102, 7, 1, "", "nn_conv2d"], [102, 7, 1, "", "nn_conv3d"], [102, 7, 1, "", "nn_convtranspose1d"], [102, 7, 1, "", "nn_convtranspose2d"], [102, 7, 1, "", "nn_convtranspose3d"], [102, 7, 1, "", "nn_groupnorm"], [102, 7, 1, "", "nn_instancenorm1d"], [102, 7, 1, "", "nn_instancenorm2d"], [102, 7, 1, "", "nn_instancenorm3d"], [102, 7, 1, "", "nn_layernorm"], [102, 7, 1, "", "nn_linear"], [102, 7, 1, "", "nn_syncbatchnorm"]], "modelopt.torch.prune.fastnas": [[103, 1, 1, "", "BinarySearcher"], [103, 1, 1, "", "FastNASPatchManager"], [103, 4, 1, "", "convert_fastnas_searchspace"], [103, 4, 1, "", "restore_fastnas_searchspace"]], "modelopt.torch.prune.fastnas.BinarySearcher": [[103, 2, 1, "", "after_step"], [103, 2, 1, "", "before_search"], [103, 2, 1, "", "before_step"], [103, 3, 1, "", "default_state_dict"], [103, 2, 1, "", "early_stop"], [103, 3, 1, "", "hparam_names_for_search"], [103, 3, 1, "", "hparam_types_for_search"], [103, 2, 1, "", "load_search_checkpoint"], [103, 5, 1, "", "max_degrade"], [103, 5, 1, "", "middle_value"], [103, 5, 1, "", "min_degrade"], [103, 5, 1, "", "original_score"], [103, 2, 1, "", "sample"], [103, 5, 1, "", "sensitivity_map"]], "modelopt.torch.prune.fastnas.FastNASPatchManager": [[103, 3, 1, "", "sample_during_training"]], "modelopt.torch.prune.gradnas": [[104, 1, 1, "", "GradientBinarySearcher"], [104, 1, 1, "", "GradientDataManager"]], "modelopt.torch.prune.gradnas.GradientBinarySearcher": [[104, 5, 1, "", "SETUP_GRADIENT_FUNC"], [104, 2, 1, "", "before_search"], [104, 3, 1, "", "default_search_config"], [104, 2, 1, "", "gradnas_score_func"], [104, 3, 1, "", "hparam_names_for_search"], [104, 2, 1, "", "sanitize_search_config"]], "modelopt.torch.prune.gradnas.GradientDataManager": [[104, 2, 1, "", "__init__"], [104, 2, 1, "", "process_gradient"], [104, 3, 1, "", "score"]], "modelopt.torch.prune.mcore_gpt_minitron": [[105, 1, 1, "", "MCoreGPTMinitronSearcher"]], "modelopt.torch.prune.mcore_gpt_minitron.MCoreGPTMinitronSearcher": [[105, 5, 1, "", "SUPPORTED_HPARAMS"], [105, 2, 1, "", "before_search"], [105, 3, 1, "", "default_search_config"], [105, 3, 1, "", "default_state_dict"], [105, 2, 1, "", "run_search"], [105, 2, 1, "", "sanitize_search_config"]], "modelopt.torch.prune.mode": [[106, 1, 1, "", "FastNASModeDescriptor"], [106, 1, 1, "", "GradNASModeDescriptor"], [106, 1, 1, "", "MCoreGPTMinitronModeDescriptor"]], "modelopt.torch.prune.mode.FastNASModeDescriptor": [[106, 3, 1, "", "config_class"], [106, 3, 1, "", "convert"], [106, 3, 1, "", "export_mode"], [106, 3, 1, "", "name"], [106, 3, 1, "", "next_modes"], [106, 3, 1, "", "restore"], [106, 3, 1, "", "search_algorithm"], [106, 3, 1, "", "update_for_new_mode"], [106, 3, 1, "", "update_for_save"]], "modelopt.torch.prune.mode.GradNASModeDescriptor": [[106, 3, 1, "", "config_class"], [106, 3, 1, "", "name"], [106, 3, 1, "", "search_algorithm"]], "modelopt.torch.prune.mode.MCoreGPTMinitronModeDescriptor": [[106, 3, 1, "", "config_class"], [106, 3, 1, "", "name"], [106, 3, 1, "", "search_algorithm"]], "modelopt.torch.prune.pruning": [[108, 4, 1, "", "prune"]], "modelopt.torch.quantization": [[110, 0, 0, "-", "algorithms"], [111, 0, 0, "-", "calib"], [115, 0, 0, "-", "config"], [116, 0, 0, "-", "conversion"], [117, 0, 0, "-", "export_onnx"], [118, 0, 0, "-", "extensions"], [119, 0, 0, "-", "mode"], [120, 0, 0, "-", "model_calib"], [121, 0, 0, "-", "model_quant"], [122, 0, 0, "-", "nn"], [135, 0, 0, "-", "optim"], [136, 0, 0, "-", "plugins"], [137, 0, 0, "-", "qtensor"], [142, 0, 0, "-", "quant_modules"], [143, 0, 0, "-", "tensor_quant"], [144, 0, 0, "-", "utils"]], "modelopt.torch.quantization.algorithms": [[110, 1, 1, "", "AutoQuantizeSearcher"], [110, 1, 1, "", "QuantRecipe"], [110, 1, 1, "", "QuantRecipeHparam"]], "modelopt.torch.quantization.algorithms.AutoQuantizeSearcher": [[110, 2, 1, "", "before_search"], [110, 5, 1, "", "best"], [110, 5, 1, "", "candidate_stats"], [110, 3, 1, "", "default_search_config"], [110, 3, 1, "", "default_state_dict"], [110, 5, 1, "", "gradient_checkpointing_enable_contexts"], [110, 2, 1, "", "insert_hparams_after_merge_rules"], [110, 2, 1, "", "register_gradient_checkpointing_enable_context"], [110, 5, 1, "", "rules"], [110, 2, 1, "", "run_search"], [110, 2, 1, "", "sanitize_search_config"]], "modelopt.torch.quantization.algorithms.QuantRecipe": [[110, 2, 1, "", "__init__"], [110, 3, 1, "", "compression"], [110, 3, 1, "", "config"], [110, 2, 1, "", "disable_folding_pqs_to_weights"], [110, 2, 1, "", "fold_pqs_to_weights"], [110, 3, 1, "", "num_bits"]], "modelopt.torch.quantization.algorithms.QuantRecipeHparam": [[110, 2, 1, "", "__init__"], [110, 3, 1, "", "active"], [110, 3, 1, "", "importance"]], "modelopt.torch.quantization.calib": [[112, 0, 0, "-", "calibrator"], [113, 0, 0, "-", "histogram"], [114, 0, 0, "-", "max"]], "modelopt.torch.quantization.calib.histogram": [[113, 1, 1, "", "HistogramCalibrator"], [113, 4, 1, "", "calibrate_weights"]], "modelopt.torch.quantization.calib.histogram.HistogramCalibrator": [[113, 2, 1, "", "__init__"], [113, 2, 1, "", "collect"], [113, 2, 1, "", "compute_amax"], [113, 2, 1, "", "reset"]], "modelopt.torch.quantization.calib.max": [[114, 1, 1, "", "MaxCalibrator"]], "modelopt.torch.quantization.calib.max.MaxCalibrator": [[114, 2, 1, "", "__init__"], [114, 3, 1, "", "amaxs"], [114, 2, 1, "", "collect"], [114, 2, 1, "", "compute_amax"], [114, 2, 1, "", "reset"]], "modelopt.torch.quantization.config": [[115, 6, 1, "", "AWQClipCalibConfig"], [115, 6, 1, "", "AWQFullCalibConfig"], [115, 6, 1, "", "AWQLiteCalibConfig"], [115, 6, 1, "", "MaxCalibConfig"], [115, 6, 1, "", "QuantizeAlgorithmConfig"], [115, 6, 1, "", "QuantizeConfig"], [115, 6, 1, "", "QuantizerAttributeConfig"], [115, 6, 1, "", "RealQuantizeConfig"], [115, 6, 1, "", "SmoothQuantCalibConfig"]], "modelopt.torch.quantization.config.AWQClipCalibConfig": [[115, 7, 1, "", "debug"], [115, 7, 1, "", "max_co_batch_size"], [115, 7, 1, "", "max_tokens_per_batch"], [115, 7, 1, "", "min_clip_ratio"], [115, 7, 1, "", "shrink_step"]], "modelopt.torch.quantization.config.AWQFullCalibConfig": [[115, 7, 1, "", "debug"]], "modelopt.torch.quantization.config.AWQLiteCalibConfig": [[115, 7, 1, "", "alpha_step"], [115, 7, 1, "", "debug"]], "modelopt.torch.quantization.config.QuantizeAlgorithmConfig": [[115, 7, 1, "", "method"]], "modelopt.torch.quantization.config.QuantizeConfig": [[115, 7, 1, "", "algorithm"], [115, 7, 1, "", "quant_cfg"]], "modelopt.torch.quantization.config.QuantizerAttributeConfig": [[115, 7, 1, "", "axis"], [115, 7, 1, "", "block_sizes"], [115, 7, 1, "", "calibrator"], [115, 7, 1, "", "enable"], [115, 7, 1, "", "fake_quant"], [115, 7, 1, "", "learn_amax"], [115, 7, 1, "", "narrow_range"], [115, 7, 1, "", "num_bits"], [115, 7, 1, "", "trt_high_precision_dtype"], [115, 7, 1, "", "type"], [115, 7, 1, "", "unsigned"]], "modelopt.torch.quantization.config.RealQuantizeConfig": [[115, 7, 1, "", "additional_algorithm"]], "modelopt.torch.quantization.config.SmoothQuantCalibConfig": [[115, 7, 1, "", "alpha"]], "modelopt.torch.quantization.conversion": [[116, 4, 1, "", "register"], [116, 4, 1, "", "replace_quant_module"], [116, 4, 1, "", "set_quantizer_attribute"], [116, 4, 1, "", "set_quantizer_by_cfg"], [116, 4, 1, "", "set_quantizer_by_cfg_context"], [116, 4, 1, "", "unregister"]], "modelopt.torch.quantization.export_onnx": [[117, 4, 1, "", "export_fp8"], [117, 4, 1, "", "export_int8"]], "modelopt.torch.quantization.extensions": [[118, 4, 1, "", "get_cuda_ext"], [118, 4, 1, "", "get_cuda_ext_fp8"], [118, 4, 1, "", "get_cuda_ext_mx"], [118, 4, 1, "", "precompile"]], "modelopt.torch.quantization.mode": [[119, 1, 1, "", "QuantizeExportModeDescriptor"], [119, 1, 1, "", "QuantizeModeDescriptor"]], "modelopt.torch.quantization.mode.QuantizeExportModeDescriptor": [[119, 3, 1, "", "config_class"], [119, 3, 1, "", "convert"], [119, 3, 1, "", "is_export_mode"], [119, 3, 1, "", "name"], [119, 3, 1, "", "restore"]], "modelopt.torch.quantization.mode.QuantizeModeDescriptor": [[119, 3, 1, "", "config_class"], [119, 3, 1, "", "convert"], [119, 3, 1, "", "export_mode"], [119, 3, 1, "", "name"], [119, 3, 1, "", "next_modes"], [119, 3, 1, "", "restore"], [119, 3, 1, "", "update_for_new_mode"], [119, 3, 1, "", "update_for_save"]], "modelopt.torch.quantization.model_calib": [[120, 4, 1, "", "calibrate"], [120, 4, 1, "", "postprocess_amax"]], "modelopt.torch.quantization.model_quant": [[121, 4, 1, "", "auto_quantize"], [121, 4, 1, "", "disable_quantizer"], [121, 4, 1, "", "enable_quantizer"], [121, 4, 1, "", "fold_weight"], [121, 4, 1, "", "print_quant_summary"], [121, 4, 1, "", "quantize"]], "modelopt.torch.quantization.nn": [[123, 0, 0, "-", "functional"], [124, 0, 0, "-", "modules"]], "modelopt.torch.quantization.nn.functional": [[123, 1, 1, "", "ClipFunction"]], "modelopt.torch.quantization.nn.functional.ClipFunction": [[123, 2, 1, "", "backward"], [123, 2, 1, "", "forward"]], "modelopt.torch.quantization.nn.modules": [[125, 0, 0, "-", "clip"], [126, 0, 0, "-", "quant_activations"], [127, 0, 0, "-", "quant_batchnorm"], [128, 0, 0, "-", "quant_conv"], [129, 0, 0, "-", "quant_instancenorm"], [130, 0, 0, "-", "quant_linear"], [131, 0, 0, "-", "quant_module"], [132, 0, 0, "-", "quant_pooling"], [133, 0, 0, "-", "quant_rnn"], [134, 0, 0, "-", "tensor_quantizer"]], "modelopt.torch.quantization.nn.modules.clip": [[125, 1, 1, "", "Clip"]], "modelopt.torch.quantization.nn.modules.clip.Clip": [[125, 2, 1, "", "__init__"], [125, 2, 1, "", "forward"]], "modelopt.torch.quantization.nn.modules.quant_conv": [[128, 5, 1, "", "Conv1d"], [128, 5, 1, "", "Conv2d"], [128, 5, 1, "", "Conv3d"], [128, 5, 1, "", "ConvTranspose1d"], [128, 5, 1, "", "ConvTranspose2d"], [128, 5, 1, "", "ConvTranspose3d"], [128, 1, 1, "", "QuantConv1d"], [128, 1, 1, "", "QuantConv2d"], [128, 1, 1, "", "QuantConv3d"], [128, 1, 1, "", "QuantConvTranspose1d"], [128, 1, 1, "", "QuantConvTranspose2d"], [128, 1, 1, "", "QuantConvTranspose3d"]], "modelopt.torch.quantization.nn.modules.quant_conv.QuantConv1d": [[128, 5, 1, "", "default_quant_desc_weight"]], "modelopt.torch.quantization.nn.modules.quant_conv.QuantConv2d": [[128, 5, 1, "", "default_quant_desc_weight"]], "modelopt.torch.quantization.nn.modules.quant_conv.QuantConv3d": [[128, 5, 1, "", "default_quant_desc_weight"]], "modelopt.torch.quantization.nn.modules.quant_conv.QuantConvTranspose1d": [[128, 5, 1, "", "default_quant_desc_weight"]], "modelopt.torch.quantization.nn.modules.quant_conv.QuantConvTranspose2d": [[128, 5, 1, "", "default_quant_desc_weight"]], "modelopt.torch.quantization.nn.modules.quant_conv.QuantConvTranspose3d": [[128, 5, 1, "", "default_quant_desc_weight"]], "modelopt.torch.quantization.nn.modules.quant_instancenorm": [[129, 1, 1, "", "QuantInstanceNorm1d"], [129, 1, 1, "", "QuantInstanceNorm2d"], [129, 1, 1, "", "QuantInstanceNorm3d"]], "modelopt.torch.quantization.nn.modules.quant_linear": [[130, 5, 1, "", "Linear"], [130, 1, 1, "", "QuantLinear"]], "modelopt.torch.quantization.nn.modules.quant_linear.QuantLinear": [[130, 5, 1, "", "default_quant_desc_weight"]], "modelopt.torch.quantization.nn.modules.quant_module": [[131, 1, 1, "", "QuantInputBase"], [131, 1, 1, "", "QuantLinearConvBase"]], "modelopt.torch.quantization.nn.modules.quant_module.QuantInputBase": [[131, 5, 1, "", "default_quant_desc_input"], [131, 5, 1, "", "default_quant_desc_output"], [131, 2, 1, "", "forward"], [131, 5, 1, "", "input_quantizer"], [131, 5, 1, "", "output_quantizer"]], "modelopt.torch.quantization.nn.modules.quant_module.QuantLinearConvBase": [[131, 5, 1, "", "default_quant_desc_weight"], [131, 2, 1, "", "forward"], [131, 2, 1, "", "initialize_quantizer_with_dummy_states"], [131, 2, 1, "", "initialize_real_qtensor_with_dummy_weight"], [131, 2, 1, "", "quantize_weight"], [131, 2, 1, "", "sanitize_dummy_weight"], [131, 5, 1, "", "weight_quantizer"]], "modelopt.torch.quantization.nn.modules.quant_pooling": [[132, 5, 1, "", "AdaptiveAvgPool1d"], [132, 5, 1, "", "AdaptiveAvgPool2d"], [132, 5, 1, "", "AdaptiveAvgPool3d"], [132, 5, 1, "", "AvgPool1d"], [132, 5, 1, "", "AvgPool2d"], [132, 5, 1, "", "AvgPool3d"], [132, 5, 1, "", "MaxPool1d"], [132, 5, 1, "", "MaxPool2d"], [132, 5, 1, "", "MaxPool3d"], [132, 1, 1, "", "QuantAdaptiveAvgPool1d"], [132, 1, 1, "", "QuantAdaptiveAvgPool2d"], [132, 1, 1, "", "QuantAdaptiveAvgPool3d"], [132, 1, 1, "", "QuantAvgPool1d"], [132, 1, 1, "", "QuantAvgPool2d"], [132, 1, 1, "", "QuantAvgPool3d"], [132, 1, 1, "", "QuantMaxPool1d"], [132, 1, 1, "", "QuantMaxPool2d"], [132, 1, 1, "", "QuantMaxPool3d"]], "modelopt.torch.quantization.nn.modules.quant_rnn": [[133, 1, 1, "", "QuantRNNBase"], [133, 1, 1, "", "QuantRNNFullBase"], [133, 1, 1, "", "RNNLayerForward"], [133, 1, 1, "", "VFRNNForward"], [133, 4, 1, "", "get_quantized_rnn_layer_forward"], [133, 4, 1, "", "get_quantized_rnn_layer_variable_len_forward"], [133, 4, 1, "", "get_quantized_rnn_layer_variable_len_reverse_forward"], [133, 4, 1, "", "lstm_cell_with_proj"], [133, 4, 1, "", "quantized_cell_forward"]], "modelopt.torch.quantization.nn.modules.quant_rnn.QuantRNNBase": [[133, 3, 1, "", "all_input_quantizers_disabled"], [133, 5, 1, "", "default_quant_desc_input"], [133, 5, 1, "", "default_quant_desc_weight"], [133, 2, 1, "", "forward"], [133, 3, 1, "", "functionals_to_replace"], [133, 2, 1, "", "quantize_weight"], [133, 5, 1, "", "weight_quantizer"]], "modelopt.torch.quantization.nn.modules.quant_rnn.RNNLayerForward": [[133, 2, 1, "", "__init__"]], "modelopt.torch.quantization.nn.modules.quant_rnn.VFRNNForward": [[133, 2, 1, "", "__init__"], [133, 2, 1, "", "forward"]], "modelopt.torch.quantization.nn.modules.tensor_quantizer": [[134, 1, 1, "", "SequentialQuantizer"], [134, 1, 1, "", "TensorQuantizer"]], "modelopt.torch.quantization.nn.modules.tensor_quantizer.SequentialQuantizer": [[134, 2, 1, "", "__init__"], [134, 2, 1, "", "disable"], [134, 2, 1, "", "get_modelopt_state"], [134, 2, 1, "", "replace_sequential_quantizer_with_single_quantizer"], [134, 2, 1, "", "reset_amax"], [134, 2, 1, "", "set_from_attribute_config"], [134, 2, 1, "", "tensor_quantizer_iterator"]], "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer": [[134, 2, 1, "", "__init__"], [134, 3, 1, "", "amax"], [134, 3, 1, "", "axis"], [134, 3, 1, "", "block_sizes"], [134, 2, 1, "", "clean_up_after_set_from_modelopt_state"], [134, 2, 1, "", "dequantize"], [134, 2, 1, "", "disable"], [134, 2, 1, "", "disable_calib"], [134, 2, 1, "", "disable_clip"], [134, 2, 1, "", "disable_quant"], [134, 2, 1, "", "enable"], [134, 2, 1, "", "enable_calib"], [134, 2, 1, "", "enable_clip"], [134, 2, 1, "", "enable_quant"], [134, 2, 1, "", "export_amax"], [134, 2, 1, "", "extra_repr"], [134, 3, 1, "", "fake_quant"], [134, 2, 1, "", "forward"], [134, 2, 1, "", "get_modelopt_state"], [134, 2, 1, "", "init_learn_amax"], [134, 3, 1, "", "is_enabled"], [134, 3, 1, "", "is_mx_format"], [134, 2, 1, "", "load_calib_amax"], [134, 3, 1, "", "maxbound"], [134, 3, 1, "", "narrow_range"], [134, 3, 1, "", "num_bits"], [134, 3, 1, "", "pre_quant_scale"], [134, 2, 1, "", "reset_amax"], [134, 2, 1, "", "set_from_attribute_config"], [134, 2, 1, "", "set_from_modelopt_state"], [134, 3, 1, "", "step_size"], [134, 2, 1, "", "sync_amax_across_distributed_group"], [134, 3, 1, "", "trt_high_precision_dtype"], [134, 3, 1, "", "unsigned"]], "modelopt.torch.quantization.optim": [[135, 4, 1, "", "freeze_parameters"], [135, 4, 1, "", "group_parameters"], [135, 4, 1, "", "match_parameters"], [135, 4, 1, "", "quant_weight_inplace"]], "modelopt.torch.quantization.qtensor": [[138, 0, 0, "-", "base_qtensor"], [139, 0, 0, "-", "int4_tensor"], [140, 0, 0, "-", "nf4_tensor"], [141, 0, 0, "-", "nvfp4_tensor"]], "modelopt.torch.quantization.qtensor.base_qtensor": [[138, 1, 1, "", "BaseQuantizedTensor"], [138, 1, 1, "", "QTensorWrapper"], [138, 4, 1, "", "pack_real_quantize_weight"]], "modelopt.torch.quantization.qtensor.base_qtensor.BaseQuantizedTensor": [[138, 2, 1, "", "__init__"], [138, 2, 1, "", "dequantize"], [138, 5, 1, "", "original_meta_tensor"], [138, 2, 1, "", "quantize"], [138, 5, 1, "", "quantized_data"]], "modelopt.torch.quantization.qtensor.base_qtensor.QTensorWrapper": [[138, 2, 1, "", "__new__"], [138, 2, 1, "", "dim"], [138, 2, 1, "", "get_qtensor"], [138, 2, 1, "", "to"]], "modelopt.torch.quantization.qtensor.int4_tensor": [[139, 1, 1, "", "INT4QTensor"]], "modelopt.torch.quantization.qtensor.int4_tensor.INT4QTensor": [[139, 2, 1, "", "dequantize"], [139, 2, 1, "", "quantize"], [139, 5, 1, "", "quantized_data"]], "modelopt.torch.quantization.qtensor.nf4_tensor": [[140, 1, 1, "", "NF4QTensor"]], "modelopt.torch.quantization.qtensor.nf4_tensor.NF4QTensor": [[140, 2, 1, "", "dequantize"], [140, 2, 1, "", "double_quantization"], [140, 2, 1, "", "quantize"], [140, 5, 1, "", "quantized_data"]], "modelopt.torch.quantization.qtensor.nvfp4_tensor": [[141, 1, 1, "", "NVFP4QTensor"]], "modelopt.torch.quantization.qtensor.nvfp4_tensor.NVFP4QTensor": [[141, 2, 1, "", "dequantize"], [141, 2, 1, "", "get_activation_scaling_factor"], [141, 2, 1, "", "get_weights_scaling_factor"], [141, 2, 1, "", "get_weights_scaling_factor_2"], [141, 2, 1, "", "quantize"], [141, 2, 1, "", "resmooth_weights_and_get_scales"]], "modelopt.torch.quantization.quant_modules": [[142, 4, 1, "", "deactivate"], [142, 4, 1, "", "enable_onnx_export"], [142, 4, 1, "", "initialize"]], "modelopt.torch.quantization.tensor_quant": [[143, 1, 1, "", "DynamicBlockQuantizationFunction"], [143, 1, 1, "", "FakeAffineTensorQuantFunction"], [143, 1, 1, "", "FakeTensorQuantFunction"], [143, 1, 1, "", "LegacyFakeTensorQuantFunction"], [143, 1, 1, "", "ScaledE4M3Function"], [143, 1, 1, "", "TensorQuantFunction"], [143, 4, 1, "", "fake_quant_impl"], [143, 4, 1, "", "quantize_op_abstract"], [143, 4, 1, "", "scaled_e4m3_impl"]], "modelopt.torch.quantization.tensor_quant.DynamicBlockQuantizationFunction": [[143, 2, 1, "", "backward"], [143, 2, 1, "", "forward"]], "modelopt.torch.quantization.tensor_quant.FakeAffineTensorQuantFunction": [[143, 2, 1, "", "backward"], [143, 2, 1, "", "forward"]], "modelopt.torch.quantization.tensor_quant.FakeTensorQuantFunction": [[143, 2, 1, "", "backward"], [143, 2, 1, "", "forward"], [143, 2, 1, "", "symbolic"]], "modelopt.torch.quantization.tensor_quant.LegacyFakeTensorQuantFunction": [[143, 2, 1, "", "backward"], [143, 2, 1, "", "forward"]], "modelopt.torch.quantization.tensor_quant.ScaledE4M3Function": [[143, 2, 1, "", "backward"], [143, 2, 1, "", "forward"], [143, 2, 1, "", "symbolic"]], "modelopt.torch.quantization.tensor_quant.TensorQuantFunction": [[143, 2, 1, "", "backward"], [143, 2, 1, "", "forward"], [143, 2, 1, "", "symbolic"]], "modelopt.torch.quantization.utils": [[144, 4, 1, "", "export_torch_mode"], [144, 4, 1, "", "get_parallel_state"], [144, 4, 1, "", "is_quantized"], [144, 4, 1, "", "is_quantized_column_parallel_linear"], [144, 4, 1, "", "is_quantized_layer_with_weight"], [144, 4, 1, "", "is_quantized_row_parallel_linear"], [144, 4, 1, "", "is_torch_library_supported"], [144, 4, 1, "", "reduce_amax"], [144, 4, 1, "", "replace_function"]], "modelopt.torch.sparsity": [[146, 0, 0, "-", "config"], [147, 0, 0, "-", "magnitude"], [148, 0, 0, "-", "mode"], [149, 0, 0, "-", "module"], [150, 0, 0, "-", "plugins"], [151, 0, 0, "-", "searcher"], [152, 0, 0, "-", "sparsegpt"], [153, 0, 0, "-", "sparsification"]], "modelopt.torch.sparsity.config": [[146, 6, 1, "", "ExportSparseConfig"], [146, 6, 1, "", "SparseGPTConfig"], [146, 6, 1, "", "SparseMagnitudeConfig"]], "modelopt.torch.sparsity.config.SparseGPTConfig": [[146, 7, 1, "", "nn_conv2d"], [146, 7, 1, "", "nn_linear"]], "modelopt.torch.sparsity.config.SparseMagnitudeConfig": [[146, 7, 1, "", "nn_conv2d"], [146, 7, 1, "", "nn_linear"]], "modelopt.torch.sparsity.magnitude": [[147, 1, 1, "", "MagnitudeSearcher"], [147, 4, 1, "", "compute_valid_1d_patterns"], [147, 4, 1, "", "create_asp_mask"], [147, 4, 1, "", "fill"], [147, 4, 1, "", "get_nmprune_info"], [147, 4, 1, "", "m4n2_1d"], [147, 4, 1, "", "mn_1d_best"], [147, 4, 1, "", "reshape_1d"]], "modelopt.torch.sparsity.mode": [[148, 1, 1, "", "ExportSparseModeDescriptor"], [148, 1, 1, "", "SparseGPTModeDescriptor"], [148, 1, 1, "", "SparseMagnitudeModeDescriptor"], [148, 4, 1, "", "convert_sparse_model"], [148, 4, 1, "", "export_sparse"], [148, 4, 1, "", "restore_export_sparse"], [148, 4, 1, "", "restore_sparse_model"], [148, 4, 1, "", "update_sparse_metadata"]], "modelopt.torch.sparsity.mode.ExportSparseModeDescriptor": [[148, 3, 1, "", "config_class"], [148, 3, 1, "", "convert"], [148, 3, 1, "", "is_export_mode"], [148, 3, 1, "", "name"], [148, 3, 1, "", "restore"]], "modelopt.torch.sparsity.mode.SparseGPTModeDescriptor": [[148, 3, 1, "", "config_class"], [148, 3, 1, "", "name"], [148, 3, 1, "", "search_algorithm"]], "modelopt.torch.sparsity.mode.SparseMagnitudeModeDescriptor": [[148, 3, 1, "", "config_class"], [148, 3, 1, "", "convert"], [148, 3, 1, "", "export_mode"], [148, 3, 1, "", "name"], [148, 3, 1, "", "next_modes"], [148, 3, 1, "", "restore"], [148, 3, 1, "", "search_algorithm"], [148, 3, 1, "", "update_for_new_mode"], [148, 3, 1, "", "update_for_save"]], "modelopt.torch.sparsity.module": [[149, 1, 1, "", "SparseModule"]], "modelopt.torch.sparsity.module.SparseModule": [[149, 2, 1, "", "modify"], [149, 2, 1, "", "set_mask"]], "modelopt.torch.sparsity.searcher": [[151, 1, 1, "", "BaseSparseSearcher"]], "modelopt.torch.sparsity.searcher.BaseSparseSearcher": [[151, 3, 1, "", "default_search_config"], [151, 3, 1, "", "default_state_dict"], [151, 2, 1, "", "run_search"], [151, 2, 1, "", "sanitize_search_config"]], "modelopt.torch.sparsity.sparsegpt": [[152, 1, 1, "", "SparseGPTSearcher"], [152, 4, 1, "", "create_sgpt_mask"], [152, 4, 1, "", "invert"], [152, 4, 1, "", "prepare"]], "modelopt.torch.sparsity.sparsegpt.SparseGPTSearcher": [[152, 2, 1, "", "after_search"], [152, 2, 1, "", "before_search"], [152, 3, 1, "", "default_search_config"]], "modelopt.torch.sparsity.sparsification": [[153, 4, 1, "", "export"], [153, 4, 1, "", "sparsify"]], "modelopt.torch.speculative": [[155, 0, 0, "-", "config"], [156, 0, 0, "-", "medusa"], [159, 0, 0, "-", "mode"], [160, 0, 0, "-", "plugins"], [161, 0, 0, "-", "speculative_decoding"]], "modelopt.torch.speculative.config": [[155, 6, 1, "", "MedusaConfig"]], "modelopt.torch.speculative.config.MedusaConfig": [[155, 7, 1, "", "medusa_num_heads"], [155, 7, 1, "", "medusa_num_layers"]], "modelopt.torch.speculative.medusa": [[157, 0, 0, "-", "conversion"], [158, 0, 0, "-", "medusa_model"]], "modelopt.torch.speculative.medusa.conversion": [[157, 4, 1, "", "convert_to_medusa_model"], [157, 4, 1, "", "restore_medusa_model"]], "modelopt.torch.speculative.medusa.medusa_model": [[158, 1, 1, "", "MedusaModel"], [158, 1, 1, "", "ResBlock"]], "modelopt.torch.speculative.medusa.medusa_model.MedusaModel": [[158, 2, 1, "", "modify"]], "modelopt.torch.speculative.medusa.medusa_model.ResBlock": [[158, 2, 1, "", "__init__"], [158, 2, 1, "", "forward"]], "modelopt.torch.speculative.mode": [[159, 1, 1, "", "MedusaModeDescriptor"]], "modelopt.torch.speculative.mode.MedusaModeDescriptor": [[159, 3, 1, "", "config_class"], [159, 3, 1, "", "convert"], [159, 3, 1, "", "name"], [159, 3, 1, "", "restore"]], "modelopt.torch.speculative.speculative_decoding": [[161, 4, 1, "", "convert"]], "modelopt.torch.trace": [[163, 0, 0, "-", "analyzer"], [164, 0, 0, "-", "modules"], [167, 0, 0, "-", "plugins"], [168, 0, 0, "-", "symbols"], [169, 0, 0, "-", "tracer"]], "modelopt.torch.trace.analyzer": [[163, 4, 1, "", "analyze_symbols"]], "modelopt.torch.trace.modules": [[165, 0, 0, "-", "concat"], [166, 0, 0, "-", "nn"]], "modelopt.torch.trace.modules.concat": [[165, 1, 1, "", "ConcatNodeProcessor"], [165, 1, 1, "", "ConcatSymbol"]], "modelopt.torch.trace.modules.concat.ConcatNodeProcessor": [[165, 2, 1, "", "__init__"], [165, 2, 1, "", "is_special_node"], [165, 2, 1, "", "post_process"], [165, 2, 1, "", "process"], [165, 2, 1, "", "reset"]], "modelopt.torch.trace.modules.concat.ConcatSymbol": [[165, 1, 1, "", "Input"], [165, 2, 1, "", "__init__"], [165, 2, 1, "", "disable"], [165, 3, 1, "", "input_syms"], [165, 3, 1, "", "is_constant"], [165, 3, 1, "", "is_searchable"], [165, 2, 1, "", "link_to"]], "modelopt.torch.trace.modules.concat.ConcatSymbol.Input": [[165, 2, 1, "", "__init__"], [165, 3, 1, "", "concat_sym"], [165, 2, 1, "", "convert"], [165, 2, 1, "", "create_linked_copy"], [165, 2, 1, "", "link_to"]], "modelopt.torch.trace.modules.nn": [[166, 1, 1, "", "SymDepth"]], "modelopt.torch.trace.modules.nn.SymDepth": [[166, 2, 1, "", "__init__"], [166, 2, 1, "", "disable"], [166, 2, 1, "", "is_skippable"], [166, 2, 1, "", "link_to"], [166, 3, 1, "", "max_depth"], [166, 3, 1, "", "min_depth"], [166, 2, 1, "", "set_skippable"], [166, 3, 1, "", "skippable_idxs"]], "modelopt.torch.trace.symbols": [[168, 1, 1, "", "SymInfo"], [168, 1, 1, "", "SymMap"], [168, 1, 1, "", "Symbol"]], "modelopt.torch.trace.symbols.SymInfo": [[168, 5, 1, "", "SymDict"], [168, 2, 1, "", "__init__"], [168, 3, 1, "", "is_shape_preserving"]], "modelopt.torch.trace.symbols.SymMap": [[168, 5, 1, "", "SymRegisterFunc"], [168, 2, 1, "", "__init__"], [168, 2, 1, "", "add_sym_info"], [168, 2, 1, "", "get_symbol"], [168, 2, 1, "", "is_shape_preserving"], [168, 2, 1, "", "items"], [168, 2, 1, "", "named_modules"], [168, 2, 1, "", "named_sym_dicts"], [168, 2, 1, "", "named_symbols"], [168, 2, 1, "", "pop"], [168, 2, 1, "", "prune"], [168, 2, 1, "", "register"], [168, 2, 1, "", "set_symbol"], [168, 2, 1, "", "unregister"]], "modelopt.torch.trace.symbols.Symbol": [[168, 1, 1, "", "CLType"], [168, 2, 1, "", "__init__"], [168, 3, 1, "", "cl_type"], [168, 2, 1, "", "disable"], [168, 3, 1, "", "elastic_dims"], [168, 3, 1, "", "is_constant"], [168, 3, 1, "", "is_cross_layer"], [168, 3, 1, "", "is_dangling"], [168, 3, 1, "", "is_dynamic"], [168, 3, 1, "", "is_free"], [168, 3, 1, "", "is_incoming"], [168, 3, 1, "", "is_outgoing"], [168, 3, 1, "", "is_searchable"], [168, 3, 1, "", "is_sortable"], [168, 2, 1, "", "link_to"], [168, 3, 1, "", "parent"]], "modelopt.torch.trace.symbols.Symbol.CLType": [[168, 5, 1, "", "INCOMING"], [168, 5, 1, "", "NONE"], [168, 5, 1, "", "OUTGOING"]], "modelopt.torch.trace.tracer": [[169, 1, 1, "", "GraphCollection"], [169, 1, 1, "", "RobustTracer"], [169, 4, 1, "", "recursive_trace"]], "modelopt.torch.trace.tracer.GraphCollection": [[169, 2, 1, "", "__init__"], [169, 2, 1, "", "failure_msg"], [169, 2, 1, "", "is_failed"], [169, 2, 1, "", "is_unvisited"], [169, 2, 1, "", "recursive_trace"]], "modelopt.torch.trace.tracer.RobustTracer": [[169, 2, 1, "", "__init__"], [169, 2, 1, "", "failure_msg"], [169, 2, 1, "", "is_failed"], [169, 2, 1, "", "is_leaf_module"], [169, 2, 1, "", "is_registered_leaf"], [169, 2, 1, "", "is_unvisited"], [169, 2, 1, "", "record_call_module"], [169, 2, 1, "", "register_leaf"], [169, 2, 1, "", "trace"], [169, 2, 1, "", "unregister_leaf"]], "modelopt.torch.utils": [[171, 0, 0, "-", "cpp_extension"], [172, 0, 0, "-", "dataset_utils"], [173, 0, 0, "-", "distributed"], [174, 0, 0, "-", "graph"], [175, 0, 0, "-", "list"], [176, 0, 0, "-", "logging"], [177, 0, 0, "-", "network"], [178, 0, 0, "-", "perf"], [179, 0, 0, "-", "random"], [180, 0, 0, "-", "tensor"]], "modelopt.torch.utils.cpp_extension": [[171, 4, 1, "", "load_cpp_extension"]], "modelopt.torch.utils.dataset_utils": [[172, 4, 1, "", "create_forward_loop"], [172, 4, 1, "", "get_dataset_dataloader"]], "modelopt.torch.utils.distributed": [[173, 4, 1, "", "backend"], [173, 4, 1, "", "barrier"], [173, 4, 1, "", "get_data_parallel_group"], [173, 4, 1, "", "get_tensor_parallel_group"], [173, 4, 1, "", "is_available"], [173, 4, 1, "", "is_initialized"], [173, 4, 1, "", "is_master"], [173, 4, 1, "", "rank"], [173, 4, 1, "", "set_data_parallel_group"], [173, 4, 1, "", "set_tensor_parallel_group"], [173, 4, 1, "", "size"]], "modelopt.torch.utils.graph": [[174, 4, 1, "", "match"]], "modelopt.torch.utils.list": [[175, 4, 1, "", "list_closest_to_median"], [175, 4, 1, "", "stats"], [175, 4, 1, "", "val2list"], [175, 4, 1, "", "val2tuple"]], "modelopt.torch.utils.logging": [[176, 8, 1, "", "DeprecatedError"], [176, 4, 1, "", "no_stdout"], [176, 4, 1, "", "num2hrb"], [176, 4, 1, "", "print_rank_0"], [176, 4, 1, "", "silence_matched_warnings"]], "modelopt.torch.utils.network": [[177, 4, 1, "", "compare_dict"], [177, 4, 1, "", "create_param_grad_clear_hook"], [177, 4, 1, "", "get_model_attributes"], [177, 4, 1, "", "get_module_device"], [177, 4, 1, "", "get_same_padding"], [177, 4, 1, "", "get_unwrapped_name"], [177, 4, 1, "", "init_model_from_model_like"], [177, 4, 1, "", "is_channels_last"], [177, 4, 1, "", "is_parallel"], [177, 4, 1, "", "make_divisible"], [177, 4, 1, "", "model_to"], [177, 4, 1, "", "param_num"], [177, 4, 1, "", "param_num_from_forward"], [177, 4, 1, "", "remove_bn"], [177, 4, 1, "", "run_forward_loop"], [177, 4, 1, "", "set_submodule"], [177, 4, 1, "", "standardize_constructor_args"], [177, 4, 1, "", "standardize_model_args"], [177, 4, 1, "", "standardize_model_like_tuple"], [177, 4, 1, "", "standardize_named_model_args"], [177, 4, 1, "", "unwrap_model"], [177, 4, 1, "", "zero_grad"]], "modelopt.torch.utils.perf": [[178, 1, 1, "", "Timer"], [178, 4, 1, "", "clear_cuda_cache"], [178, 4, 1, "", "get_cuda_memory_stats"], [178, 4, 1, "", "report_memory"]], "modelopt.torch.utils.perf.Timer": [[178, 2, 1, "", "__init__"], [178, 2, 1, "", "start"], [178, 2, 1, "", "stop"]], "modelopt.torch.utils.random": [[179, 4, 1, "", "centroid"], [179, 4, 1, "", "choice"], [179, 4, 1, "", "original"], [179, 4, 1, "", "random"], [179, 4, 1, "", "sample"], [179, 4, 1, "", "shuffle"]], "modelopt.torch.utils.tensor": [[180, 4, 1, "", "numpy_to_torch"], [180, 4, 1, "", "torch_detach"], [180, 4, 1, "", "torch_to"], [180, 4, 1, "", "torch_to_numpy"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:property", "4": "py:function", "5": "py:attribute", "6": "py:pydantic_model", "7": "py:pydantic_field", "8": "py:exception"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "property", "Python property"], "4": ["py", "function", "Python function"], "5": ["py", "attribute", "Python attribute"], "6": ["py", "pydantic_model", "Python model"], "7": ["py", "pydantic_field", "Python field"], "8": ["py", "exception", "Python exception"]}, "titleterms": {"tensorrt": [0, 4], "llm": [0, 25], "deploy": [0, 6, 21], "export": [0, 8, 57], "quantiz": [0, 3, 4, 6, 10, 17, 18, 19, 20, 30, 44, 109, 115], "model": [0, 2, 4, 5, 6, 7, 8, 9, 11, 12, 14, 15, 16, 19, 20, 21, 22], "support": [0, 12, 21], "matrix": 0, "checkpoint": [0, 15], "convert": [0, 12, 13, 16], "all": 1, "github": 1, "exampl": [1, 21, 115], "resnet20": 2, "cifar": 2, "10": [2, 22], "prune": [2, 3, 4, 7, 11, 12, 101, 108, 182], "dataset": [2, 19], "imag": 2, "classif": 2, "resnet": 2, "set": [2, 7, 8], "up": [2, 7, 8], "train": [2, 8, 9, 11, 12, 14, 17, 19, 20], "baselin": 2, "fastna": [2, 103], "optim": [2, 4, 5, 20, 21, 22, 135], "base": [2, 8, 12], "store": [2, 11, 20], "net": 2, "restor": [2, 12, 14, 15, 20], "subnet": [2, 11, 12], "us": [2, 15, 20], "mto": 2, "fine": [2, 11, 12, 16], "tune": [2, 11, 12, 16], "evalu": [2, 20], "search": [2, 7, 11, 12, 182], "hf": 3, "bert": 3, "distil": [3, 4, 8, 13, 48, 50], "prerequisit": [3, 11, 12], "full": 3, "code": 3, "command": 3, "overview": [4, 12, 13], "nvidia": 4, "techniqu": 4, "sparsiti": [4, 9, 14, 145], "instal": 5, "system": 5, "requir": [5, 19], "environ": 5, "setup": 5, "check": 5, "quick": [6, 7, 8, 9], "start": [6, 7, 8, 9, 21], "ptq": [6, 19, 20], "pytorch": [6, 9, 20], "your": [7, 8, 12], "meta": 8, "dure": 8, "post": [9, 14, 19, 20], "sparsif": [9, 14, 153], "pt": 9, "awar": [9, 17, 20], "sat": 9, "perform": [11, 12, 19], "result": 11, "custom": [11, 20], "config": [11, 20, 49, 74, 92, 102, 115, 146, 155], "profil": [11, 12], "space": [11, 12], "choos": [11, 18], "constraint": 11, "load": 11, "run": 11, "deploi": [11, 19, 24], "concept": [11, 12, 13, 14, 16, 17], "na": [12, 71, 182], "introduct": [12, 13, 14, 16], "save": [12, 14, 15, 16], "architectur": 12, "The": 12, "convers": [12, 75, 93, 116, 157], "process": 12, "layer": 12, "gener": [12, 26], "traceabl": 12, "distributeddataparallel": 12, "auxiliari": 12, "modul": [12, 20, 80, 124, 149, 164], "known": [12, 182], "limit": 12, "glossari": [12, 13], "neural": 12, "hyperparamet": 12, "modelopt": [12, 15, 21, 23, 44], "select": 12, "v": 12, "integr": 13, "knowledg": 13, "student": 13, "teacher": 13, "loss": [13, 53], "balanc": 13, "soft": 13, "label": 13, "spars": 14, "structur": 14, "unstructur": 14, "n": 14, "m": 14, "algorithm": [14, 16, 17, 72, 110], "state": 15, "weight": 15, "togeth": 15, "separ": 15, "huggingfac": [15, 98], "api": [15, 23], "specul": [16, 154], "decod": 16, "medusa": [16, 156], "sepcul": 16, "basic": 17, "precis": 17, "format": [17, 115], "scale": 17, "factor": 17, "block": 17, "calibr": [17, 19, 112], "qat": [17, 20], "more": 17, "read": 17, "best": 18, "practic": 18, "right": 18, "method": 18, "onnx": [19, 28, 44], "beta": 19, "appli": [19, 20], "prepar": 19, "call": 19, "function": [19, 123, 182], "compar": 19, "partial": 20, "autoquant": 20, "auto_quant": 20, "advanc": 20, "topic": 20, "tensorquant": 20, "placement": 20, "fast": 20, "migrat": 20, "from": 20, "pytorch_quant": 20, "welcom": 21, "document": 21, "get": 21, "guid": 21, "refer": 21, "changelog": 22, "0": 22, "19": 22, "2024": 22, "23": 22, "17": 22, "09": 22, "11": 22, "15": 22, "07": 22, "25": 22, "13": 22, "06": 22, "14": 22, "05": 22, "nemo_util": 27, "op_typ": 29, "calib_util": 31, "extens": [32, 118], "fp8": 33, "graph_util": 34, "gs_patch": 35, "int4": 36, "int8": 37, "oper": 38, "ort_patch": 39, "ort_util": 40, "partit": 41, "qdq_util": 42, "quant_util": 43, "trt_util": 45, "util": [46, 85, 90, 100, 144, 170], "torch": 47, "distillation_model": 51, "loss_balanc": 52, "mode": [54, 79, 96, 106, 119, 148, 159], "plugin": [55, 86, 97, 107, 136, 150, 160, 167], "registri": [56, 87], "distribut": [58, 173], "hf_config_map": 59, "layer_util": 60, "model_config": 61, "model_config_export": 62, "model_config_util": 63, "postprocess": 64, "scaling_factor_util": 65, "tensorrt_llm_typ": 66, "tensorrt_llm_util": 67, "transformer_engin": 68, "unified_export_hf": 69, "vllm": 70, "autona": 73, "hparam": [76, 95], "concat": [77, 165], "contain": [78, 81], "conv": 82, "linear": 83, "norm": 84, "search_spac": 88, "traced_hp": 89, "opt": 91, "dynam": 94, "searcher": [99, 151], "gradna": 104, "summari": 104, "detail": 104, "mcore_gpt_minitron": 105, "calib": 111, "histogram": 113, "max": 114, "configur": 115, "export_onnx": 117, "model_calib": 120, "model_qu": 121, "nn": [122, 166], "clip": 125, "quant_activ": 126, "quant_batchnorm": 127, "quant_conv": 128, "quant_instancenorm": 129, "quant_linear": 130, "quant_modul": [131, 142], "quant_pool": 132, "quant_rnn": 133, "tensor_quant": 134, "qtensor": 137, "base_qtensor": 138, "int4_tensor": 139, "nf4_tensor": 140, "nvfp4_tensor": 141, "tensor_qu": 143, "magnitud": 147, "sparsegpt": 152, "medusa_model": 158, "speculative_decod": 161, "trace": 162, "analyz": 163, "symbol": 168, "tracer": 169, "cpp_extens": 171, "dataset_util": 172, "graph": 174, "list": 175, "log": 176, "network": 177, "perf": 178, "random": 179, "tensor": 180, "contact": 181, "u": 181, "faq": 182, "parallel": 182, "monkei": 182, "patch": 182, "issu": 182, "1": 182, "potenti": 182, "memori": 182, "leak": 182, "fsdp": 182, "use_orig_param": 182, "true": 182}, "envversion": {"sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "nbsphinx": 4, "sphinx": 60}, "alltitles": {"TensorRT-LLM Deployment": [[0, "tensorrt-llm-deployment"]], "Export Quantized Model": [[0, "export-quantized-model"]], "Model support matrix for the TensorRT-LLM checkpoint export": [[0, "id1"]], "Convert to TensorRT-LLM": [[0, "convert-to-tensorrt-llm"]], "All GitHub Examples": [[1, "all-github-examples"]], "ResNet20 on CIFAR-10: Pruning": [[2, "ResNet20-on-CIFAR-10:-Pruning"]], "CIFAR-10 Dataset for Image Classification": [[2, "CIFAR-10-Dataset-for-Image-Classification"]], "ResNet for CIFAR dataset": [[2, "ResNet-for-CIFAR-dataset"]], "Setting up the model": [[2, "Setting-up-the-model"]], "Training a baseline model": [[2, "Training-a-baseline-model"]], "FastNAS Pruning with Model Optimizer": [[2, "FastNAS-Pruning-with-Model-Optimizer"]], "Prune base model and store pruned net": [[2, "Prune-base-model-and-store-pruned-net"]], "Restore the pruned subnet using mto.restore": [[2, "Restore-the-pruned-subnet-using-mto.restore"]], "Fine-tuning": [[2, "Fine-tuning"], [11, "fine-tuning"], [12, "fine-tuning"]], "Evaluate the searched subnet": [[2, "Evaluate-the-searched-subnet"]], "HF BERT: Prune, Distill & Quantize": [[3, "hf-bert-prune-distill-quantize"]], "Prerequisites": [[3, "prerequisites"], [11, "prerequisites"], [11, "id1"], [12, "prerequisites"], [12, "id1"], [12, "id2"]], "Full code": [[3, "full-code"]], "Commands": [[3, "commands"]], "Overview": [[4, "overview"], [12, "overview"], [13, "overview"]], "NVIDIA TensorRT Model Optimizer": [[4, "nvidia-tensorrt-model-optimizer"]], "Techniques": [[4, "techniques"]], "Quantization": [[4, "quantization"], [6, "quantization"], [10, "quantization"]], "Sparsity": [[4, "sparsity"], [9, "sparsity"], [14, "sparsity"]], "Distillation": [[4, "distillation"], [13, "distillation"]], "Pruning": [[4, "pruning"], [11, "pruning"]], "Installation": [[5, "installation"]], "System requirements": [[5, "system-requirements"]], "Environment setup": [[5, "environment-setup"]], "Install Model Optimizer": [[5, "install-model-optimizer"]], "Check installation": [[5, "check-installation"]], "Quick Start: Quantization": [[6, "quick-start-quantization"]], "PTQ for PyTorch models": [[6, "ptq-for-pytorch-models"]], "Deployment": [[6, "deployment"], [21, null]], "Quick Start: Pruning": [[7, "quick-start-pruning"]], "Set up your model": [[7, "set-up-your-model"]], "Set up the search": [[7, "set-up-the-search"]], "Prune the model": [[7, "prune-the-model"]], "Quick Start: Distillation": [[8, "quick-start-distillation"]], "Set up your base models": [[8, "set-up-your-base-models"]], "Set up the meta model": [[8, "set-up-the-meta-model"]], "Distill during training": [[8, "distill-during-training"]], "Export trained model": [[8, "export-trained-model"]], "Quick Start: Sparsity": [[9, "quick-start-sparsity"]], "Post-Training Sparsification (PTS) for PyTorch models": [[9, "post-training-sparsification-pts-for-pytorch-models"]], "Sparsity-aware Training (SAT) for PyTorch models": [[9, "sparsity-aware-training-sat-for-pytorch-models"]], "Training": [[11, "training"], [12, "training"]], "Pruning and subnet search": [[11, "pruning-and-subnet-search"]], "Perform pruning": [[11, "perform-pruning"]], "Storing the prune results": [[11, "storing-the-prune-results"]], "Customizing pruning config": [[11, "customizing-pruning-config"]], "Profiling the search space and choosing constraints": [[11, "profiling-the-search-space-and-choosing-constraints"]], "Load the pruned model": [[11, "load-the-pruned-model"]], "Run fine-tuning": [[11, "run-fine-tuning"]], "Deploy": [[11, "deploy"]], "Pruning Concepts": [[11, "pruning-concepts"]], "NAS": [[12, "nas"]], "Introduction": [[12, "introduction"], [13, "introduction"], [14, "introduction"], [16, "introduction"]], "Convert and save": [[12, "convert-and-save"]], "Profiling a search space": [[12, "profiling-a-search-space"]], "NAS training": [[12, "nas-training"]], "Restore the search space": [[12, "restore-the-search-space"]], "Subnet architecture search": [[12, "subnet-architecture-search"]], "Performing search": [[12, "performing-search"]], "NAS Model Prerequisites": [[12, "nas-model-prerequisites"]], "Convert your model": [[12, "convert-your-model"]], "The conversion process": [[12, "the-conversion-process"]], "Layer support": [[12, "layer-support"]], "Generating a search space": [[12, "generating-a-search-space"]], "Traceability": [[12, "traceability"]], "DistributedDataParallel": [[12, "distributeddataparallel"]], "Auxiliary modules": [[12, "auxiliary-modules"]], "Known limitations": [[12, "known-limitations"]], "NAS Concepts": [[12, "nas-concepts"]], "Glossary": [[12, "id4"], [13, "id3"]], "Concepts": [[12, "concepts"], [13, "concepts"]], "Neural Architecture Search (NAS)": [[12, "neural-architecture-search-nas"]], "Search space": [[12, "search-space"]], "Architecture hyperparameters": [[12, "architecture-hyperparameters"]], "Subnet": [[12, "subnet"]], "ModelOpt-converted model": [[12, "modelopt-converted-model"]], "NAS-based training": [[12, "nas-based-training"]], "Architecture search & selection": [[12, "architecture-search-selection"]], "Subnet fine-tuning": [[12, "subnet-fine-tuning"]], "NAS vs. Pruning": [[12, "nas-vs-pruning"]], "Convert and integrate": [[13, "convert-and-integrate"]], "Distillation Concepts": [[13, "distillation-concepts"]], "Knowledge Distillation": [[13, "knowledge-distillation"]], "Student": [[13, "student"]], "Teacher": [[13, "teacher"]], "Distillation loss": [[13, "distillation-loss"]], "Loss Balancer": [[13, "loss-balancer"]], "Soft-label Distillation": [[13, "soft-label-distillation"]], "Post-Training Sparsification": [[14, "post-training-sparsification"]], "Save and restore the sparse model": [[14, "save-and-restore-the-sparse-model"]], "Sparsity Concepts": [[14, "sparsity-concepts"]], "Structured and Unstructured Sparsity": [[14, "structured-and-unstructured-sparsity"]], "N:M Sparsity": [[14, "n-m-sparsity"]], "Sparsification algorithm": [[14, "sparsification-algorithm"]], "Saving & Restoring": [[15, "saving-restoring"]], "Saving ModelOpt Models": [[15, "saving-modelopt-models"]], "Saving ModelOpt state & model weights together": [[15, "saving-modelopt-state-model-weights-together"]], "Saving ModelOpt state and model weights separately": [[15, "saving-modelopt-state-and-model-weights-separately"]], "Restoring ModelOpt Models": [[15, "restoring-modelopt-models"]], "Restoring ModelOpt state & model weights together": [[15, "restoring-modelopt-state-model-weights-together"]], "Restoring ModelOpt state and model weights separately": [[15, "restoring-modelopt-state-and-model-weights-separately"]], "ModelOpt Save/Restore Using Huggingface Checkpointing APIs": [[15, "modelopt-save-restore-using-huggingface-checkpointing-apis"]], "Speculative Decoding": [[16, "speculative-decoding"]], "Convert": [[16, "convert"]], "Fine-tune Medusa model and save": [[16, "fine-tune-medusa-model-and-save"]], "Speculative Decoding Concepts": [[16, "speculative-decoding-concepts"]], "Sepculative decoding": [[16, "sepculative-decoding"]], "Medusa algorithm": [[16, "medusa-algorithm"]], "Basic Concepts": [[17, "basic-concepts"]], "Precision format": [[17, "precision-format"]], "Scaling factor": [[17, "scaling-factor"]], "Block format": [[17, "block-format"]], "Calibration algorithm": [[17, "calibration-algorithm"]], "Quantization-aware training (QAT)": [[17, "quantization-aware-training-qat"]], "More Readings": [[17, "more-readings"]], "Best practices to choose the right quantization methods": [[18, "best-practices-to-choose-the-right-quantization-methods"]], "ONNX Quantization (Beta)": [[19, "onnx-quantization-beta"]], "Requirements": [[19, "requirements"]], "Apply Post Training Quantization (PTQ)": [[19, "apply-post-training-quantization-ptq"], [20, "apply-post-training-quantization-ptq"]], "Prepare calibration dataset": [[19, "prepare-calibration-dataset"]], "Call PTQ function": [[19, "call-ptq-function"]], "Deploy Quantized ONNX Model": [[19, "deploy-quantized-onnx-model"]], "Compare the performance": [[19, "compare-the-performance"]], "PyTorch Quantization": [[20, "pytorch-quantization"]], "Quantization-aware Training (QAT)": [[20, "quantization-aware-training-qat"]], "Storing and restoring quantized model": [[20, "storing-and-restoring-quantized-model"]], "Optimal Partial Quantization using AutoQuantize(auto_quantize)": [[20, "optimal-partial-quantization-using-autoquantize-auto-quantize"]], "Advanced Topics": [[20, "advanced-topics"]], "TensorQuantizer": [[20, "tensorquantizer"]], "Customize quantizer config": [[20, "customize-quantizer-config"]], "Custom quantized module and quantizer placement": [[20, "custom-quantized-module-and-quantizer-placement"]], "Fast evaluation": [[20, "fast-evaluation"]], "Migrate from pytorch_quantization": [[20, "migrate-from-pytorch-quantization"]], "Welcome to Model Optimizer (ModelOpt) documentation!": [[21, "welcome-to-model-optimizer-modelopt-documentation"]], "Getting Started": [[21, null]], "Guides": [[21, null]], "Examples": [[21, null]], "Reference": [[21, null]], "Support": [[21, null]], "Model Optimizer Changelog": [[22, "model-optimizer-changelog"]], "0.19 (2024-10-23)": [[22, "id1"]], "0.17 (2024-09-11)": [[22, "id2"]], "0.15 (2024-07-25)": [[22, "id3"]], "0.13 (2024-06-14)": [[22, "id4"]], "0.11 (2024-05-07)": [[22, "id6"]], "modelopt API": [[23, "modelopt-api"]], "deploy": [[24, "deploy"]], "llm": [[25, "llm"]], "generate": [[26, "generate"]], "nemo_utils": [[27, "nemo-utils"]], "onnx": [[28, "onnx"]], "op_types": [[29, "op-types"]], "quantization": [[30, "quantization"], [109, "quantization"]], "calib_utils": [[31, "calib-utils"]], "extensions": [[32, "extensions"], [118, "extensions"]], "fp8": [[33, "fp8"]], "graph_utils": [[34, "graph-utils"]], "gs_patching": [[35, "gs-patching"]], "int4": [[36, "int4"]], "int8": [[37, "int8"]], "operators": [[38, "operators"]], "ort_patching": [[39, "ort-patching"]], "ort_utils": [[40, "ort-utils"]], "partitioning": [[41, "partitioning"]], "qdq_utils": [[42, "qdq-utils"]], "quant_utils": [[43, "quant-utils"]], "modelopt.onnx.quantization.quantize": [[44, "modelopt-onnx-quantization-quantize"]], "trt_utils": [[45, "trt-utils"]], "utils": [[46, "utils"], [85, "utils"], [90, "utils"], [100, "utils"], [144, "utils"], [170, "utils"]], "torch": [[47, "torch"]], "distill": [[48, "distill"]], "config": [[49, "config"], [74, "config"], [92, "config"], [102, "config"], [115, "config"], [146, "config"], [155, "config"]], "distillation": [[50, "distillation"]], "distillation_model": [[51, "distillation-model"]], "loss_balancers": [[52, "loss-balancers"]], "losses": [[53, "losses"]], "mode": [[54, "mode"], [79, "mode"], [96, "mode"], [106, "mode"], [119, "mode"], [148, "mode"], [159, "mode"]], "plugins": [[55, "plugins"], [86, "plugins"], [97, "plugins"], [107, "plugins"], [136, "plugins"], [150, "plugins"], [160, "plugins"], [167, "plugins"]], "registry": [[56, "registry"], [87, "registry"]], "export": [[57, "export"]], "distribute": [[58, "distribute"]], "hf_config_map": [[59, "hf-config-map"]], "layer_utils": [[60, "layer-utils"]], "model_config": [[61, "model-config"]], "model_config_export": [[62, "model-config-export"]], "model_config_utils": [[63, "model-config-utils"]], "postprocess": [[64, "postprocess"]], "scaling_factor_utils": [[65, "scaling-factor-utils"]], "tensorrt_llm_type": [[66, "tensorrt-llm-type"]], "tensorrt_llm_utils": [[67, "tensorrt-llm-utils"]], "transformer_engine": [[68, "transformer-engine"]], "unified_export_hf": [[69, "unified-export-hf"]], "vllm": [[70, "vllm"]], "nas": [[71, "nas"]], "algorithms": [[72, "algorithms"], [110, "algorithms"]], "autonas": [[73, "autonas"]], "conversion": [[75, "conversion"], [93, "conversion"], [116, "conversion"], [157, "conversion"]], "hparams": [[76, "hparams"]], "concat": [[77, "concat"], [165, "concat"]], "container": [[78, "container"], [81, "container"]], "modules": [[80, "modules"], [124, "modules"], [164, "modules"]], "conv": [[82, "conv"]], "linear": [[83, "linear"]], "norm": [[84, "norm"]], "search_space": [[88, "search-space"]], "traced_hp": [[89, "traced-hp"]], "opt": [[91, "opt"]], "dynamic": [[94, "dynamic"]], "hparam": [[95, "hparam"]], "huggingface": [[98, "huggingface"]], "searcher": [[99, "searcher"], [151, "searcher"]], "prune": [[101, "prune"]], "fastnas": [[103, "fastnas"]], "gradnas": [[104, "gradnas"]], "Summary:": [[104, "summary"]], "Details:": [[104, "details"]], "mcore_gpt_minitron": [[105, "mcore-gpt-minitron"]], "pruning": [[108, "pruning"]], "calib": [[111, "calib"]], "calibrator": [[112, "calibrator"]], "histogram": [[113, "histogram"]], "max": [[114, "max"]], "Quantization Formats": [[115, "quantization-formats"]], "Quantization Configs": [[115, "quantization-configs"]], "Example Quantization Configurations": [[115, "example-quantization-configurations"]], "export_onnx": [[117, "export-onnx"]], "model_calib": [[120, "model-calib"]], "model_quant": [[121, "model-quant"]], "nn": [[122, "nn"], [166, "nn"]], "functional": [[123, "functional"]], "clip": [[125, "clip"]], "quant_activations": [[126, "quant-activations"]], "quant_batchnorm": [[127, "quant-batchnorm"]], "quant_conv": [[128, "quant-conv"]], "quant_instancenorm": [[129, "quant-instancenorm"]], "quant_linear": [[130, "quant-linear"]], "quant_module": [[131, "quant-module"]], "quant_pooling": [[132, "quant-pooling"]], "quant_rnn": [[133, "quant-rnn"]], "tensor_quantizer": [[134, "tensor-quantizer"]], "optim": [[135, "optim"]], "qtensor": [[137, "qtensor"]], "base_qtensor": [[138, "base-qtensor"]], "int4_tensor": [[139, "int4-tensor"]], "nf4_tensor": [[140, "nf4-tensor"]], "nvfp4_tensor": [[141, "nvfp4-tensor"]], "quant_modules": [[142, "quant-modules"]], "tensor_quant": [[143, "tensor-quant"]], "sparsity": [[145, "sparsity"]], "magnitude": [[147, "magnitude"]], "module": [[149, "module"]], "sparsegpt": [[152, "sparsegpt"]], "sparsification": [[153, "sparsification"]], "speculative": [[154, "speculative"]], "medusa": [[156, "medusa"]], "medusa_model": [[158, "medusa-model"]], "speculative_decoding": [[161, "speculative-decoding"]], "trace": [[162, "trace"]], "analyzer": [[163, "analyzer"]], "symbols": [[168, "symbols"]], "tracer": [[169, "tracer"]], "cpp_extension": [[171, "cpp-extension"]], "dataset_utils": [[172, "dataset-utils"]], "distributed": [[173, "distributed"]], "graph": [[174, "graph"]], "list": [[175, "list"]], "logging": [[176, "logging"]], "network": [[177, "network"]], "perf": [[178, "perf"]], "random": [[179, "random"]], "tensor": [[180, "tensor"]], "Contact us": [[181, "contact-us"]], "FAQs": [[182, "faqs"]], "NAS/Pruning": [[182, "nas-pruning"]], "Parallel search": [[182, "parallel-search"]], "Monkey-patched functions": [[182, "monkey-patched-functions"]], "Known Issues": [[182, "known-issues"]], "1. Potential memory leak for FSDP with use_orig_params=True": [[182, "potential-memory-leak-for-fsdp-with-use-orig-params-true"]]}, "indexentries": {"modelopt.deploy": [[24, "module-modelopt.deploy"]], "module": [[24, "module-modelopt.deploy"], [25, "module-modelopt.deploy.llm"], [26, "module-modelopt.deploy.llm.generate"], [27, "module-modelopt.deploy.llm.nemo_utils"], [28, "module-modelopt.onnx"], [29, "module-modelopt.onnx.op_types"], [30, "module-modelopt.onnx.quantization"], [31, "module-modelopt.onnx.quantization.calib_utils"], [32, "module-modelopt.onnx.quantization.extensions"], [33, "module-modelopt.onnx.quantization.fp8"], [34, "module-modelopt.onnx.quantization.graph_utils"], [35, "module-modelopt.onnx.quantization.gs_patching"], [36, "module-modelopt.onnx.quantization.int4"], [37, "module-modelopt.onnx.quantization.int8"], [38, "module-modelopt.onnx.quantization.operators"], [39, "module-modelopt.onnx.quantization.ort_patching"], [40, "module-modelopt.onnx.quantization.ort_utils"], [41, "module-modelopt.onnx.quantization.partitioning"], [42, "module-modelopt.onnx.quantization.qdq_utils"], [43, "module-modelopt.onnx.quantization.quant_utils"], [45, "module-modelopt.onnx.quantization.trt_utils"], [46, "module-modelopt.onnx.utils"], [47, "module-modelopt.torch"], [48, "module-modelopt.torch.distill"], [49, "module-modelopt.torch.distill.config"], [50, "module-modelopt.torch.distill.distillation"], [51, "module-modelopt.torch.distill.distillation_model"], [52, "module-modelopt.torch.distill.loss_balancers"], [53, "module-modelopt.torch.distill.losses"], [54, "module-modelopt.torch.distill.mode"], [55, "module-modelopt.torch.distill.plugins"], [56, "module-modelopt.torch.distill.registry"], [57, "module-modelopt.torch.export"], [58, "module-modelopt.torch.export.distribute"], [59, "module-modelopt.torch.export.hf_config_map"], [60, "module-modelopt.torch.export.layer_utils"], [61, "module-modelopt.torch.export.model_config"], [62, "module-modelopt.torch.export.model_config_export"], [63, "module-modelopt.torch.export.model_config_utils"], [64, "module-modelopt.torch.export.postprocess"], [65, "module-modelopt.torch.export.scaling_factor_utils"], [66, "module-modelopt.torch.export.tensorrt_llm_type"], [67, "module-modelopt.torch.export.tensorrt_llm_utils"], [68, "module-modelopt.torch.export.transformer_engine"], [69, "module-modelopt.torch.export.unified_export_hf"], [70, "module-modelopt.torch.export.vllm"], [71, "module-modelopt.torch.nas"], [72, "module-modelopt.torch.nas.algorithms"], [73, "module-modelopt.torch.nas.autonas"], [74, "module-modelopt.torch.nas.config"], [75, "module-modelopt.torch.nas.conversion"], [76, "module-modelopt.torch.nas.hparams"], [77, "module-modelopt.torch.nas.hparams.concat"], [78, "module-modelopt.torch.nas.hparams.container"], [79, "module-modelopt.torch.nas.mode"], [80, "module-modelopt.torch.nas.modules"], [81, "module-modelopt.torch.nas.modules.container"], [82, "module-modelopt.torch.nas.modules.conv"], [83, "module-modelopt.torch.nas.modules.linear"], [84, "module-modelopt.torch.nas.modules.norm"], [85, "module-modelopt.torch.nas.modules.utils"], [86, "module-modelopt.torch.nas.plugins"], [87, "module-modelopt.torch.nas.registry"], [88, "module-modelopt.torch.nas.search_space"], [89, "module-modelopt.torch.nas.traced_hp"], [90, "module-modelopt.torch.nas.utils"], [91, "module-modelopt.torch.opt"], [92, "module-modelopt.torch.opt.config"], [93, "module-modelopt.torch.opt.conversion"], [94, "module-modelopt.torch.opt.dynamic"], [95, "module-modelopt.torch.opt.hparam"], [96, "module-modelopt.torch.opt.mode"], [97, "module-modelopt.torch.opt.plugins"], [98, "module-modelopt.torch.opt.plugins.huggingface"], [99, "module-modelopt.torch.opt.searcher"], [100, "module-modelopt.torch.opt.utils"], [101, "module-modelopt.torch.prune"], [102, "module-modelopt.torch.prune.config"], [103, "module-modelopt.torch.prune.fastnas"], [104, "module-modelopt.torch.prune.gradnas"], [105, "module-modelopt.torch.prune.mcore_gpt_minitron"], [106, "module-modelopt.torch.prune.mode"], [107, "module-modelopt.torch.prune.plugins"], [108, "module-modelopt.torch.prune.pruning"], [109, "module-modelopt.torch.quantization"], [110, "module-modelopt.torch.quantization.algorithms"], [111, "module-modelopt.torch.quantization.calib"], [112, "module-modelopt.torch.quantization.calib.calibrator"], [113, "module-modelopt.torch.quantization.calib.histogram"], [114, "module-modelopt.torch.quantization.calib.max"], [115, "module-modelopt.torch.quantization.config"], [116, "module-modelopt.torch.quantization.conversion"], [117, "module-modelopt.torch.quantization.export_onnx"], [118, "module-modelopt.torch.quantization.extensions"], [119, "module-modelopt.torch.quantization.mode"], [120, "module-modelopt.torch.quantization.model_calib"], [121, "module-modelopt.torch.quantization.model_quant"], [122, "module-modelopt.torch.quantization.nn"], [123, "module-modelopt.torch.quantization.nn.functional"], [124, "module-modelopt.torch.quantization.nn.modules"], [125, "module-modelopt.torch.quantization.nn.modules.clip"], [126, "module-modelopt.torch.quantization.nn.modules.quant_activations"], [127, "module-modelopt.torch.quantization.nn.modules.quant_batchnorm"], [128, "module-modelopt.torch.quantization.nn.modules.quant_conv"], [129, "module-modelopt.torch.quantization.nn.modules.quant_instancenorm"], [130, "module-modelopt.torch.quantization.nn.modules.quant_linear"], [131, "module-modelopt.torch.quantization.nn.modules.quant_module"], [132, "module-modelopt.torch.quantization.nn.modules.quant_pooling"], [133, "module-modelopt.torch.quantization.nn.modules.quant_rnn"], [134, "module-modelopt.torch.quantization.nn.modules.tensor_quantizer"], [135, "module-modelopt.torch.quantization.optim"], [136, "module-modelopt.torch.quantization.plugins"], [137, "module-modelopt.torch.quantization.qtensor"], [138, "module-modelopt.torch.quantization.qtensor.base_qtensor"], [139, "module-modelopt.torch.quantization.qtensor.int4_tensor"], [140, "module-modelopt.torch.quantization.qtensor.nf4_tensor"], [141, "module-modelopt.torch.quantization.qtensor.nvfp4_tensor"], [142, "module-modelopt.torch.quantization.quant_modules"], [143, "module-modelopt.torch.quantization.tensor_quant"], [144, "module-modelopt.torch.quantization.utils"], [145, "module-modelopt.torch.sparsity"], [146, "module-modelopt.torch.sparsity.config"], [147, "module-modelopt.torch.sparsity.magnitude"], [148, "module-modelopt.torch.sparsity.mode"], [149, "module-modelopt.torch.sparsity.module"], [150, "module-modelopt.torch.sparsity.plugins"], [151, "module-modelopt.torch.sparsity.searcher"], [152, "module-modelopt.torch.sparsity.sparsegpt"], [153, "module-modelopt.torch.sparsity.sparsification"], [154, "module-modelopt.torch.speculative"], [155, "module-modelopt.torch.speculative.config"], [156, "module-modelopt.torch.speculative.medusa"], [157, "module-modelopt.torch.speculative.medusa.conversion"], [158, "module-modelopt.torch.speculative.medusa.medusa_model"], [159, "module-modelopt.torch.speculative.mode"], [160, "module-modelopt.torch.speculative.plugins"], [161, "module-modelopt.torch.speculative.speculative_decoding"], [162, "module-modelopt.torch.trace"], [163, "module-modelopt.torch.trace.analyzer"], [164, "module-modelopt.torch.trace.modules"], [165, "module-modelopt.torch.trace.modules.concat"], [166, "module-modelopt.torch.trace.modules.nn"], [167, "module-modelopt.torch.trace.plugins"], [168, "module-modelopt.torch.trace.symbols"], [169, "module-modelopt.torch.trace.tracer"], [170, "module-modelopt.torch.utils"], [171, "module-modelopt.torch.utils.cpp_extension"], [172, "module-modelopt.torch.utils.dataset_utils"], [173, "module-modelopt.torch.utils.distributed"], [174, "module-modelopt.torch.utils.graph"], [175, "module-modelopt.torch.utils.list"], [176, "module-modelopt.torch.utils.logging"], [177, "module-modelopt.torch.utils.network"], [178, "module-modelopt.torch.utils.perf"], [179, "module-modelopt.torch.utils.random"], [180, "module-modelopt.torch.utils.tensor"]], "modelopt.deploy.llm": [[25, "module-modelopt.deploy.llm"]], "llm (class in modelopt.deploy.llm.generate)": [[26, "modelopt.deploy.llm.generate.LLM"]], "__init__() (llm method)": [[26, "modelopt.deploy.llm.generate.LLM.__init__"]], "generate_context_logits() (llm method)": [[26, "modelopt.deploy.llm.generate.LLM.generate_context_logits"]], "generate_text() (llm method)": [[26, "modelopt.deploy.llm.generate.LLM.generate_text"]], "generate_tokens() (llm method)": [[26, "modelopt.deploy.llm.generate.LLM.generate_tokens"]], "max_beam_width (llm property)": [[26, "modelopt.deploy.llm.generate.LLM.max_beam_width"]], "max_input_len (llm property)": [[26, "modelopt.deploy.llm.generate.LLM.max_input_len"]], "modelopt.deploy.llm.generate": [[26, "module-modelopt.deploy.llm.generate"]], "customsentencepiecetokenizer (class in modelopt.deploy.llm.nemo_utils)": [[27, "modelopt.deploy.llm.nemo_utils.CustomSentencePieceTokenizer"]], "__init__() (customsentencepiecetokenizer method)": [[27, "modelopt.deploy.llm.nemo_utils.CustomSentencePieceTokenizer.__init__"]], "batch_decode() (customsentencepiecetokenizer method)": [[27, "modelopt.deploy.llm.nemo_utils.CustomSentencePieceTokenizer.batch_decode"]], "batch_encode_plus() (customsentencepiecetokenizer method)": [[27, "modelopt.deploy.llm.nemo_utils.CustomSentencePieceTokenizer.batch_encode_plus"]], "decode() (customsentencepiecetokenizer method)": [[27, "modelopt.deploy.llm.nemo_utils.CustomSentencePieceTokenizer.decode"]], "encode() (customsentencepiecetokenizer method)": [[27, "modelopt.deploy.llm.nemo_utils.CustomSentencePieceTokenizer.encode"]], "eos_token (customsentencepiecetokenizer property)": [[27, "modelopt.deploy.llm.nemo_utils.CustomSentencePieceTokenizer.eos_token"]], "eos_token_id (customsentencepiecetokenizer property)": [[27, "modelopt.deploy.llm.nemo_utils.CustomSentencePieceTokenizer.eos_token_id"]], "get_nemo_tokenizer() (in module modelopt.deploy.llm.nemo_utils)": [[27, "modelopt.deploy.llm.nemo_utils.get_nemo_tokenizer"]], "get_tokenzier() (in module modelopt.deploy.llm.nemo_utils)": [[27, "modelopt.deploy.llm.nemo_utils.get_tokenzier"]], "modelopt.deploy.llm.nemo_utils": [[27, "module-modelopt.deploy.llm.nemo_utils"]], "pad_token (customsentencepiecetokenizer property)": [[27, "modelopt.deploy.llm.nemo_utils.CustomSentencePieceTokenizer.pad_token"]], "pad_token_id (customsentencepiecetokenizer property)": [[27, "modelopt.deploy.llm.nemo_utils.CustomSentencePieceTokenizer.pad_token_id"]], "modelopt.onnx": [[28, "module-modelopt.onnx"]], "is_binary_op() (in module modelopt.onnx.op_types)": [[29, "modelopt.onnx.op_types.is_binary_op"]], "is_control_flow_op() (in module modelopt.onnx.op_types)": [[29, "modelopt.onnx.op_types.is_control_flow_op"]], "is_conversion_op() (in module modelopt.onnx.op_types)": [[29, "modelopt.onnx.op_types.is_conversion_op"]], "is_copy_op() (in module modelopt.onnx.op_types)": [[29, "modelopt.onnx.op_types.is_copy_op"]], "is_default_quantizable_op_by_ort() (in module modelopt.onnx.op_types)": [[29, "modelopt.onnx.op_types.is_default_quantizable_op_by_ort"]], "is_fusible_reduction_op() (in module modelopt.onnx.op_types)": [[29, "modelopt.onnx.op_types.is_fusible_reduction_op"]], "is_generator_op() (in module modelopt.onnx.op_types)": [[29, "modelopt.onnx.op_types.is_generator_op"]], "is_irregular_mem_access_op() (in module modelopt.onnx.op_types)": [[29, "modelopt.onnx.op_types.is_irregular_mem_access_op"]], "is_linear_op() (in module modelopt.onnx.op_types)": [[29, "modelopt.onnx.op_types.is_linear_op"]], "is_modifier_op() (in module modelopt.onnx.op_types)": [[29, "modelopt.onnx.op_types.is_modifier_op"]], "is_multiclass_op() (in module modelopt.onnx.op_types)": [[29, "modelopt.onnx.op_types.is_multiclass_op"]], "is_non_reshape_copy_op() (in module modelopt.onnx.op_types)": [[29, "modelopt.onnx.op_types.is_non_reshape_copy_op"]], "is_normalization_op() (in module modelopt.onnx.op_types)": [[29, "modelopt.onnx.op_types.is_normalization_op"]], "is_pointwise_or_elementwise_op() (in module modelopt.onnx.op_types)": [[29, "modelopt.onnx.op_types.is_pointwise_or_elementwise_op"]], "is_pooling_or_window_op() (in module modelopt.onnx.op_types)": [[29, "modelopt.onnx.op_types.is_pooling_or_window_op"]], "is_recurrent_op() (in module modelopt.onnx.op_types)": [[29, "modelopt.onnx.op_types.is_recurrent_op"]], "is_selection_op() (in module modelopt.onnx.op_types)": [[29, "modelopt.onnx.op_types.is_selection_op"]], "is_sequence_op() (in module modelopt.onnx.op_types)": [[29, "modelopt.onnx.op_types.is_sequence_op"]], "is_shape_op() (in module modelopt.onnx.op_types)": [[29, "modelopt.onnx.op_types.is_shape_op"]], "is_unary_op() (in module modelopt.onnx.op_types)": [[29, "modelopt.onnx.op_types.is_unary_op"]], "modelopt.onnx.op_types": [[29, "module-modelopt.onnx.op_types"]], "modelopt.onnx.quantization": [[30, "module-modelopt.onnx.quantization"]], "calibrationdataprovider (class in modelopt.onnx.quantization.calib_utils)": [[31, "modelopt.onnx.quantization.calib_utils.CalibrationDataProvider"]], "randomdataprovider (class in modelopt.onnx.quantization.calib_utils)": [[31, "modelopt.onnx.quantization.calib_utils.RandomDataProvider"]], "__init__() (calibrationdataprovider method)": [[31, "modelopt.onnx.quantization.calib_utils.CalibrationDataProvider.__init__"]], "__init__() (randomdataprovider method)": [[31, "modelopt.onnx.quantization.calib_utils.RandomDataProvider.__init__"]], "get_next() (calibrationdataprovider method)": [[31, "modelopt.onnx.quantization.calib_utils.CalibrationDataProvider.get_next"]], "get_next() (randomdataprovider method)": [[31, "modelopt.onnx.quantization.calib_utils.RandomDataProvider.get_next"]], "import_scales_from_calib_cache() (in module modelopt.onnx.quantization.calib_utils)": [[31, "modelopt.onnx.quantization.calib_utils.import_scales_from_calib_cache"]], "modelopt.onnx.quantization.calib_utils": [[31, "module-modelopt.onnx.quantization.calib_utils"]], "modelopt.onnx.quantization.extensions": [[32, "module-modelopt.onnx.quantization.extensions"]], "int8_to_fp8() (in module modelopt.onnx.quantization.fp8)": [[33, "modelopt.onnx.quantization.fp8.int8_to_fp8"]], "modelopt.onnx.quantization.fp8": [[33, "module-modelopt.onnx.quantization.fp8"]], "quantize() (in module modelopt.onnx.quantization.fp8)": [[33, "modelopt.onnx.quantization.fp8.quantize"]], "add_fp16_fp32_cast() (in module modelopt.onnx.quantization.graph_utils)": [[34, "modelopt.onnx.quantization.graph_utils.add_fp16_fp32_cast"]], "build_non_residual_input_map() (in module modelopt.onnx.quantization.graph_utils)": [[34, "modelopt.onnx.quantization.graph_utils.build_non_residual_input_map"]], "classify_partition_nodes() (in module modelopt.onnx.quantization.graph_utils)": [[34, "modelopt.onnx.quantization.graph_utils.classify_partition_nodes"]], "convert_fp16_io() (in module modelopt.onnx.quantization.graph_utils)": [[34, "modelopt.onnx.quantization.graph_utils.convert_fp16_io"]], "expand_node_names_from_patterns() (in module modelopt.onnx.quantization.graph_utils)": [[34, "modelopt.onnx.quantization.graph_utils.expand_node_names_from_patterns"]], "filter_quantizable_kgen_heads() (in module modelopt.onnx.quantization.graph_utils)": [[34, "modelopt.onnx.quantization.graph_utils.filter_quantizable_kgen_heads"]], "find_fp8_mha_partitions() (in module modelopt.onnx.quantization.graph_utils)": [[34, "modelopt.onnx.quantization.graph_utils.find_fp8_mha_partitions"]], "find_mha_partitions() (in module modelopt.onnx.quantization.graph_utils)": [[34, "modelopt.onnx.quantization.graph_utils.find_mha_partitions"]], "find_nodes_from_matmul_to_exclude() (in module modelopt.onnx.quantization.graph_utils)": [[34, "modelopt.onnx.quantization.graph_utils.find_nodes_from_matmul_to_exclude"]], "find_nodes_from_mha_to_exclude() (in module modelopt.onnx.quantization.graph_utils)": [[34, "modelopt.onnx.quantization.graph_utils.find_nodes_from_mha_to_exclude"]], "find_nodes_to_exclude() (in module modelopt.onnx.quantization.graph_utils)": [[34, "modelopt.onnx.quantization.graph_utils.find_nodes_to_exclude"]], "get_fusible_backbone() (in module modelopt.onnx.quantization.graph_utils)": [[34, "modelopt.onnx.quantization.graph_utils.get_fusible_backbone"]], "get_tensor_consumer_nodes() (in module modelopt.onnx.quantization.graph_utils)": [[34, "modelopt.onnx.quantization.graph_utils.get_tensor_consumer_nodes"]], "get_tensor_producer_nodes() (in module modelopt.onnx.quantization.graph_utils)": [[34, "modelopt.onnx.quantization.graph_utils.get_tensor_producer_nodes"]], "has_const_input() (in module modelopt.onnx.quantization.graph_utils)": [[34, "modelopt.onnx.quantization.graph_utils.has_const_input"]], "has_path_type() (in module modelopt.onnx.quantization.graph_utils)": [[34, "modelopt.onnx.quantization.graph_utils.has_path_type"]], "insert_fp8_mha_casts() (in module modelopt.onnx.quantization.graph_utils)": [[34, "modelopt.onnx.quantization.graph_utils.insert_fp8_mha_casts"]], "insert_matmul_casts() (in module modelopt.onnx.quantization.graph_utils)": [[34, "modelopt.onnx.quantization.graph_utils.insert_matmul_casts"]], "is_const_input() (in module modelopt.onnx.quantization.graph_utils)": [[34, "modelopt.onnx.quantization.graph_utils.is_const_input"]], "modelopt.onnx.quantization.graph_utils": [[34, "module-modelopt.onnx.quantization.graph_utils"]], "print_stat() (in module modelopt.onnx.quantization.graph_utils)": [[34, "modelopt.onnx.quantization.graph_utils.print_stat"]], "remove_partial_input_qdq() (in module modelopt.onnx.quantization.graph_utils)": [[34, "modelopt.onnx.quantization.graph_utils.remove_partial_input_qdq"]], "modelopt.onnx.quantization.gs_patching": [[35, "module-modelopt.onnx.quantization.gs_patching"]], "patch_gs_modules() (in module modelopt.onnx.quantization.gs_patching)": [[35, "modelopt.onnx.quantization.gs_patching.patch_gs_modules"]], "awqcliphelper (class in modelopt.onnx.quantization.int4)": [[36, "modelopt.onnx.quantization.int4.AWQClipHelper"]], "awqlitehelper (class in modelopt.onnx.quantization.int4)": [[36, "modelopt.onnx.quantization.int4.AWQLiteHelper"]], "__init__() (awqcliphelper method)": [[36, "modelopt.onnx.quantization.int4.AWQClipHelper.__init__"]], "__init__() (awqlitehelper method)": [[36, "modelopt.onnx.quantization.int4.AWQLiteHelper.__init__"]], "alpha_step (awqcliphelper attribute)": [[36, "modelopt.onnx.quantization.int4.AWQClipHelper.alpha_step"]], "alpha_step (awqlitehelper attribute)": [[36, "modelopt.onnx.quantization.int4.AWQLiteHelper.alpha_step"]], "dq_tensor() (in module modelopt.onnx.quantization.int4)": [[36, "modelopt.onnx.quantization.int4.dq_tensor"]], "find_scales() (in module modelopt.onnx.quantization.int4)": [[36, "modelopt.onnx.quantization.int4.find_scales"]], "get_act_scale() (in module modelopt.onnx.quantization.int4)": [[36, "modelopt.onnx.quantization.int4.get_act_scale"]], "get_act_to_weight_map_and_act_to_wa_pack_map() (in module modelopt.onnx.quantization.int4)": [[36, "modelopt.onnx.quantization.int4.get_act_to_weight_map_and_act_to_wa_pack_map"]], "get_scale() (in module modelopt.onnx.quantization.int4)": [[36, "modelopt.onnx.quantization.int4.get_scale"]], "get_weight_scale() (in module modelopt.onnx.quantization.int4)": [[36, "modelopt.onnx.quantization.int4.get_weight_scale"]], "get_x_w_mean_for_subgraph() (in module modelopt.onnx.quantization.int4)": [[36, "modelopt.onnx.quantization.int4.get_x_w_mean_for_subgraph"]], "min_alpha (awqcliphelper attribute)": [[36, "modelopt.onnx.quantization.int4.AWQClipHelper.min_alpha"]], "modelopt.onnx.quantization.int4": [[36, "module-modelopt.onnx.quantization.int4"]], "quant_tensor() (in module modelopt.onnx.quantization.int4)": [[36, "modelopt.onnx.quantization.int4.quant_tensor"]], "quantize() (in module modelopt.onnx.quantization.int4)": [[36, "modelopt.onnx.quantization.int4.quantize"]], "quantize_rtn() (in module modelopt.onnx.quantization.int4)": [[36, "modelopt.onnx.quantization.int4.quantize_rtn"]], "rtn() (in module modelopt.onnx.quantization.int4)": [[36, "modelopt.onnx.quantization.int4.rtn"]], "run_awq_scale_search_per_node() (in module modelopt.onnx.quantization.int4)": [[36, "modelopt.onnx.quantization.int4.run_awq_scale_search_per_node"]], "run_awq_scale_search_per_subgraph() (in module modelopt.onnx.quantization.int4)": [[36, "modelopt.onnx.quantization.int4.run_awq_scale_search_per_subgraph"]], "update_best_params() (awqcliphelper method)": [[36, "modelopt.onnx.quantization.int4.AWQClipHelper.update_best_params"]], "update_best_params() (awqlitehelper method)": [[36, "modelopt.onnx.quantization.int4.AWQLiteHelper.update_best_params"]], "modelopt.onnx.quantization.int8": [[37, "module-modelopt.onnx.quantization.int8"]], "quantize() (in module modelopt.onnx.quantization.int8)": [[37, "modelopt.onnx.quantization.int8.quantize"]], "qdqconvtranspose (class in modelopt.onnx.quantization.operators)": [[38, "modelopt.onnx.quantization.operators.QDQConvTranspose"]], "qdqnormalization (class in modelopt.onnx.quantization.operators)": [[38, "modelopt.onnx.quantization.operators.QDQNormalization"]], "__init__() (qdqconvtranspose method)": [[38, "modelopt.onnx.quantization.operators.QDQConvTranspose.__init__"]], "__init__() (qdqnormalization method)": [[38, "modelopt.onnx.quantization.operators.QDQNormalization.__init__"]], "modelopt.onnx.quantization.operators": [[38, "module-modelopt.onnx.quantization.operators"]], "quantize() (qdqconvtranspose method)": [[38, "modelopt.onnx.quantization.operators.QDQConvTranspose.quantize"]], "quantize() (qdqnormalization method)": [[38, "modelopt.onnx.quantization.operators.QDQNormalization.quantize"]], "modelopt.onnx.quantization.ort_patching": [[39, "module-modelopt.onnx.quantization.ort_patching"]], "patch_ort_modules() (in module modelopt.onnx.quantization.ort_patching)": [[39, "modelopt.onnx.quantization.ort_patching.patch_ort_modules"]], "configure_ort() (in module modelopt.onnx.quantization.ort_utils)": [[40, "modelopt.onnx.quantization.ort_utils.configure_ort"]], "create_inference_session() (in module modelopt.onnx.quantization.ort_utils)": [[40, "modelopt.onnx.quantization.ort_utils.create_inference_session"]], "get_quantizable_op_types() (in module modelopt.onnx.quantization.ort_utils)": [[40, "modelopt.onnx.quantization.ort_utils.get_quantizable_op_types"]], "modelopt.onnx.quantization.ort_utils": [[40, "module-modelopt.onnx.quantization.ort_utils"]], "find_fusible_partitions() (in module modelopt.onnx.quantization.partitioning)": [[41, "modelopt.onnx.quantization.partitioning.find_fusible_partitions"]], "find_hardcoded_patterns() (in module modelopt.onnx.quantization.partitioning)": [[41, "modelopt.onnx.quantization.partitioning.find_hardcoded_patterns"]], "find_layer_norm_partitions() (in module modelopt.onnx.quantization.partitioning)": [[41, "modelopt.onnx.quantization.partitioning.find_layer_norm_partitions"]], "find_mha_partitions() (in module modelopt.onnx.quantization.partitioning)": [[41, "modelopt.onnx.quantization.partitioning.find_mha_partitions"]], "find_non_quantizable_partitions_from_patterns() (in module modelopt.onnx.quantization.partitioning)": [[41, "modelopt.onnx.quantization.partitioning.find_non_quantizable_partitions_from_patterns"]], "find_quantizable_nodes() (in module modelopt.onnx.quantization.partitioning)": [[41, "modelopt.onnx.quantization.partitioning.find_quantizable_nodes"]], "get_skiped_output_layers() (in module modelopt.onnx.quantization.partitioning)": [[41, "modelopt.onnx.quantization.partitioning.get_skiped_output_layers"]], "modelopt.onnx.quantization.partitioning": [[41, "module-modelopt.onnx.quantization.partitioning"]], "insert_dq_nodes() (in module modelopt.onnx.quantization.qdq_utils)": [[42, "modelopt.onnx.quantization.qdq_utils.insert_dq_nodes"]], "insert_pre_quant_scale_nodes() (in module modelopt.onnx.quantization.qdq_utils)": [[42, "modelopt.onnx.quantization.qdq_utils.insert_pre_quant_scale_nodes"]], "insert_qdq_nodes() (in module modelopt.onnx.quantization.qdq_utils)": [[42, "modelopt.onnx.quantization.qdq_utils.insert_qdq_nodes"]], "make_gs_awq_scale() (in module modelopt.onnx.quantization.qdq_utils)": [[42, "modelopt.onnx.quantization.qdq_utils.make_gs_awq_scale"]], "make_gs_dequantize_node() (in module modelopt.onnx.quantization.qdq_utils)": [[42, "modelopt.onnx.quantization.qdq_utils.make_gs_dequantize_node"]], "make_gs_dequantize_output() (in module modelopt.onnx.quantization.qdq_utils)": [[42, "modelopt.onnx.quantization.qdq_utils.make_gs_dequantize_output"]], "make_gs_pre_quant_scale_node() (in module modelopt.onnx.quantization.qdq_utils)": [[42, "modelopt.onnx.quantization.qdq_utils.make_gs_pre_quant_scale_node"]], "make_gs_pre_quant_scale_output() (in module modelopt.onnx.quantization.qdq_utils)": [[42, "modelopt.onnx.quantization.qdq_utils.make_gs_pre_quant_scale_output"]], "make_gs_quantize_node() (in module modelopt.onnx.quantization.qdq_utils)": [[42, "modelopt.onnx.quantization.qdq_utils.make_gs_quantize_node"]], "make_gs_quantize_output() (in module modelopt.onnx.quantization.qdq_utils)": [[42, "modelopt.onnx.quantization.qdq_utils.make_gs_quantize_output"]], "make_gs_quantized_weight() (in module modelopt.onnx.quantization.qdq_utils)": [[42, "modelopt.onnx.quantization.qdq_utils.make_gs_quantized_weight"]], "make_gs_scale() (in module modelopt.onnx.quantization.qdq_utils)": [[42, "modelopt.onnx.quantization.qdq_utils.make_gs_scale"]], "make_gs_zp() (in module modelopt.onnx.quantization.qdq_utils)": [[42, "modelopt.onnx.quantization.qdq_utils.make_gs_zp"]], "modelopt.onnx.quantization.qdq_utils": [[42, "module-modelopt.onnx.quantization.qdq_utils"]], "qdq_to_dq() (in module modelopt.onnx.quantization.qdq_utils)": [[42, "modelopt.onnx.quantization.qdq_utils.qdq_to_dq"]], "replace_scale_values() (in module modelopt.onnx.quantization.qdq_utils)": [[42, "modelopt.onnx.quantization.qdq_utils.replace_scale_values"]], "use_trt_qdq_ops() (in module modelopt.onnx.quantization.qdq_utils)": [[42, "modelopt.onnx.quantization.qdq_utils.use_trt_qdq_ops"]], "modelopt.onnx.quantization.quant_utils": [[43, "module-modelopt.onnx.quantization.quant_utils"]], "pack_float32_to_4bit_cpp_based() (in module modelopt.onnx.quantization.quant_utils)": [[43, "modelopt.onnx.quantization.quant_utils.pack_float32_to_4bit_cpp_based"]], "pack_float32_to_4bit_optimized() (in module modelopt.onnx.quantization.quant_utils)": [[43, "modelopt.onnx.quantization.quant_utils.pack_float32_to_4bit_optimized"]], "quantize() (in module modelopt.onnx.quantization)": [[44, "modelopt.onnx.quantization.quantize"]], "get_custom_layers() (in module modelopt.onnx.quantization.trt_utils)": [[45, "modelopt.onnx.quantization.trt_utils.get_custom_layers"]], "load_onnx_model() (in module modelopt.onnx.quantization.trt_utils)": [[45, "modelopt.onnx.quantization.trt_utils.load_onnx_model"]], "modelopt.onnx.quantization.trt_utils": [[45, "module-modelopt.onnx.quantization.trt_utils"]], "duplicate_shared_constants() (in module modelopt.onnx.utils)": [[46, "modelopt.onnx.utils.duplicate_shared_constants"]], "find_lowest_common_ancestor() (in module modelopt.onnx.utils)": [[46, "modelopt.onnx.utils.find_lowest_common_ancestor"]], "gen_random_inputs() (in module modelopt.onnx.utils)": [[46, "modelopt.onnx.utils.gen_random_inputs"]], "get_all_input_names() (in module modelopt.onnx.utils)": [[46, "modelopt.onnx.utils.get_all_input_names"]], "get_batch_size() (in module modelopt.onnx.utils)": [[46, "modelopt.onnx.utils.get_batch_size"]], "get_batch_size_from_bytes() (in module modelopt.onnx.utils)": [[46, "modelopt.onnx.utils.get_batch_size_from_bytes"]], "get_child_nodes() (in module modelopt.onnx.utils)": [[46, "modelopt.onnx.utils.get_child_nodes"]], "get_input_names() (in module modelopt.onnx.utils)": [[46, "modelopt.onnx.utils.get_input_names"]], "get_input_names_from_bytes() (in module modelopt.onnx.utils)": [[46, "modelopt.onnx.utils.get_input_names_from_bytes"]], "get_input_shapes() (in module modelopt.onnx.utils)": [[46, "modelopt.onnx.utils.get_input_shapes"]], "get_input_shapes_from_bytes() (in module modelopt.onnx.utils)": [[46, "modelopt.onnx.utils.get_input_shapes_from_bytes"]], "get_node_names() (in module modelopt.onnx.utils)": [[46, "modelopt.onnx.utils.get_node_names"]], "get_node_names_from_bytes() (in module modelopt.onnx.utils)": [[46, "modelopt.onnx.utils.get_node_names_from_bytes"]], "get_output_names() (in module modelopt.onnx.utils)": [[46, "modelopt.onnx.utils.get_output_names"]], "get_output_names_from_bytes() (in module modelopt.onnx.utils)": [[46, "modelopt.onnx.utils.get_output_names_from_bytes"]], "get_output_shapes() (in module modelopt.onnx.utils)": [[46, "modelopt.onnx.utils.get_output_shapes"]], "get_parent_nodes() (in module modelopt.onnx.utils)": [[46, "modelopt.onnx.utils.get_parent_nodes"]], "get_variable_inputs() (in module modelopt.onnx.utils)": [[46, "modelopt.onnx.utils.get_variable_inputs"]], "is_valid_onnx_model() (in module modelopt.onnx.utils)": [[46, "modelopt.onnx.utils.is_valid_onnx_model"]], "modelopt.onnx.utils": [[46, "module-modelopt.onnx.utils"]], "name_onnx_nodes() (in module modelopt.onnx.utils)": [[46, "modelopt.onnx.utils.name_onnx_nodes"]], "parse_shapes_spec() (in module modelopt.onnx.utils)": [[46, "modelopt.onnx.utils.parse_shapes_spec"]], "randomize_weights() (in module modelopt.onnx.utils)": [[46, "modelopt.onnx.utils.randomize_weights"]], "randomize_weights_onnx_bytes() (in module modelopt.onnx.utils)": [[46, "modelopt.onnx.utils.randomize_weights_onnx_bytes"]], "remove_weights_data() (in module modelopt.onnx.utils)": [[46, "modelopt.onnx.utils.remove_weights_data"]], "save_onnx() (in module modelopt.onnx.utils)": [[46, "modelopt.onnx.utils.save_onnx"]], "save_onnx_bytes_to_dir() (in module modelopt.onnx.utils)": [[46, "modelopt.onnx.utils.save_onnx_bytes_to_dir"]], "udpate_domain() (in module modelopt.onnx.utils)": [[46, "modelopt.onnx.utils.udpate_domain"]], "validate_batch_size() (in module modelopt.onnx.utils)": [[46, "modelopt.onnx.utils.validate_batch_size"]], "validate_onnx() (in module modelopt.onnx.utils)": [[46, "modelopt.onnx.utils.validate_onnx"]], "modelopt.torch": [[47, "module-modelopt.torch"]], "modelopt.torch.distill": [[48, "module-modelopt.torch.distill"]], "criterion (kdlossconfig attribute)": [[49, "modelopt.torch.distill.config.KDLossConfig.criterion"]], "expose_minimal_state_dict (kdlossconfig attribute)": [[49, "modelopt.torch.distill.config.KDLossConfig.expose_minimal_state_dict"]], "loss_balancer (kdlossconfig attribute)": [[49, "modelopt.torch.distill.config.KDLossConfig.loss_balancer"]], "model_dump() (kdlossconfig method)": [[49, "modelopt.torch.distill.config.KDLossConfig.model_dump"]], "modelopt.torch.distill.config": [[49, "module-modelopt.torch.distill.config"]], "teacher_model (kdlossconfig attribute)": [[49, "modelopt.torch.distill.config.KDLossConfig.teacher_model"]], "convert() (in module modelopt.torch.distill.distillation)": [[50, "modelopt.torch.distill.distillation.convert"]], "export() (in module modelopt.torch.distill.distillation)": [[50, "modelopt.torch.distill.distillation.export"]], "modelopt.torch.distill.distillation": [[50, "module-modelopt.torch.distill.distillation"]], "distillationmodel (class in modelopt.torch.distill.distillation_model)": [[51, "modelopt.torch.distill.distillation_model.DistillationModel"]], "compute_kd_loss() (distillationmodel method)": [[51, "modelopt.torch.distill.distillation_model.DistillationModel.compute_kd_loss"]], "forward() (distillationmodel method)": [[51, "modelopt.torch.distill.distillation_model.DistillationModel.forward"]], "hide_loss_modules() (distillationmodel method)": [[51, "modelopt.torch.distill.distillation_model.DistillationModel.hide_loss_modules"]], "hide_teacher_model() (distillationmodel method)": [[51, "modelopt.torch.distill.distillation_model.DistillationModel.hide_teacher_model"]], "load_state_dict() (distillationmodel method)": [[51, "modelopt.torch.distill.distillation_model.DistillationModel.load_state_dict"]], "loss_balancer (distillationmodel property)": [[51, "modelopt.torch.distill.distillation_model.DistillationModel.loss_balancer"]], "loss_modules (distillationmodel property)": [[51, "modelopt.torch.distill.distillation_model.DistillationModel.loss_modules"]], "modelopt.torch.distill.distillation_model": [[51, "module-modelopt.torch.distill.distillation_model"]], "modify() (distillationmodel method)": [[51, "modelopt.torch.distill.distillation_model.DistillationModel.modify"]], "state_dict() (distillationmodel method)": [[51, "modelopt.torch.distill.distillation_model.DistillationModel.state_dict"]], "teacher_model (distillationmodel property)": [[51, "modelopt.torch.distill.distillation_model.DistillationModel.teacher_model"]], "distillationlossbalancer (class in modelopt.torch.distill.loss_balancers)": [[52, "modelopt.torch.distill.loss_balancers.DistillationLossBalancer"]], "staticlossbalancer (class in modelopt.torch.distill.loss_balancers)": [[52, "modelopt.torch.distill.loss_balancers.StaticLossBalancer"]], "__init__() (distillationlossbalancer method)": [[52, "modelopt.torch.distill.loss_balancers.DistillationLossBalancer.__init__"]], "__init__() (staticlossbalancer method)": [[52, "modelopt.torch.distill.loss_balancers.StaticLossBalancer.__init__"]], "forward() (distillationlossbalancer method)": [[52, "modelopt.torch.distill.loss_balancers.DistillationLossBalancer.forward"]], "forward() (staticlossbalancer method)": [[52, "modelopt.torch.distill.loss_balancers.StaticLossBalancer.forward"]], "modelopt.torch.distill.loss_balancers": [[52, "module-modelopt.torch.distill.loss_balancers"]], "set_student_loss_reduction_fn() (distillationlossbalancer method)": [[52, "modelopt.torch.distill.loss_balancers.DistillationLossBalancer.set_student_loss_reduction_fn"]], "logitsdistillationloss (class in modelopt.torch.distill.losses)": [[53, "modelopt.torch.distill.losses.LogitsDistillationLoss"]], "mgdloss (class in modelopt.torch.distill.losses)": [[53, "modelopt.torch.distill.losses.MGDLoss"]], "__init__() (logitsdistillationloss method)": [[53, "modelopt.torch.distill.losses.LogitsDistillationLoss.__init__"]], "__init__() (mgdloss method)": [[53, "modelopt.torch.distill.losses.MGDLoss.__init__"]], "forward() (logitsdistillationloss method)": [[53, "modelopt.torch.distill.losses.LogitsDistillationLoss.forward"]], "forward() (mgdloss method)": [[53, "modelopt.torch.distill.losses.MGDLoss.forward"]], "modelopt.torch.distill.losses": [[53, "module-modelopt.torch.distill.losses"]], "exportstudentmodedescriptor (class in modelopt.torch.distill.mode)": [[54, "modelopt.torch.distill.mode.ExportStudentModeDescriptor"]], "knowledgedistillationmodedescriptor (class in modelopt.torch.distill.mode)": [[54, "modelopt.torch.distill.mode.KnowledgeDistillationModeDescriptor"]], "config_class (exportstudentmodedescriptor property)": [[54, "modelopt.torch.distill.mode.ExportStudentModeDescriptor.config_class"]], "config_class (knowledgedistillationmodedescriptor property)": [[54, "modelopt.torch.distill.mode.KnowledgeDistillationModeDescriptor.config_class"]], "convert (exportstudentmodedescriptor property)": [[54, "modelopt.torch.distill.mode.ExportStudentModeDescriptor.convert"]], "convert (knowledgedistillationmodedescriptor property)": [[54, "modelopt.torch.distill.mode.KnowledgeDistillationModeDescriptor.convert"]], "export_mode (knowledgedistillationmodedescriptor property)": [[54, "modelopt.torch.distill.mode.KnowledgeDistillationModeDescriptor.export_mode"]], "is_export_mode (exportstudentmodedescriptor property)": [[54, "modelopt.torch.distill.mode.ExportStudentModeDescriptor.is_export_mode"]], "modelopt.torch.distill.mode": [[54, "module-modelopt.torch.distill.mode"]], "name (exportstudentmodedescriptor property)": [[54, "modelopt.torch.distill.mode.ExportStudentModeDescriptor.name"]], "name (knowledgedistillationmodedescriptor property)": [[54, "modelopt.torch.distill.mode.KnowledgeDistillationModeDescriptor.name"]], "next_modes (knowledgedistillationmodedescriptor property)": [[54, "modelopt.torch.distill.mode.KnowledgeDistillationModeDescriptor.next_modes"]], "restore (exportstudentmodedescriptor property)": [[54, "modelopt.torch.distill.mode.ExportStudentModeDescriptor.restore"]], "restore (knowledgedistillationmodedescriptor property)": [[54, "modelopt.torch.distill.mode.KnowledgeDistillationModeDescriptor.restore"]], "update_for_new_mode (knowledgedistillationmodedescriptor property)": [[54, "modelopt.torch.distill.mode.KnowledgeDistillationModeDescriptor.update_for_new_mode"]], "modelopt.torch.distill.plugins": [[55, "module-modelopt.torch.distill.plugins"]], "modelopt.torch.distill.registry": [[56, "module-modelopt.torch.distill.registry"]], "modelopt.torch.export": [[57, "module-modelopt.torch.export"]], "nfsworkspace (class in modelopt.torch.export.distribute)": [[58, "modelopt.torch.export.distribute.NFSWorkspace"]], "__init__() (nfsworkspace method)": [[58, "modelopt.torch.export.distribute.NFSWorkspace.__init__"]], "get_configs_parallel() (in module modelopt.torch.export.distribute)": [[58, "modelopt.torch.export.distribute.get_configs_parallel"]], "get_tensors_parallel() (in module modelopt.torch.export.distribute)": [[58, "modelopt.torch.export.distribute.get_tensors_parallel"]], "is_initialized (nfsworkspace property)": [[58, "modelopt.torch.export.distribute.NFSWorkspace.is_initialized"]], "modelopt.torch.export.distribute": [[58, "module-modelopt.torch.export.distribute"]], "read_configs_and_weights_from_rank() (nfsworkspace method)": [[58, "modelopt.torch.export.distribute.NFSWorkspace.read_configs_and_weights_from_rank"]], "write_configs_and_weights() (nfsworkspace method)": [[58, "modelopt.torch.export.distribute.NFSWorkspace.write_configs_and_weights"]], "modelopt.torch.export.hf_config_map": [[59, "module-modelopt.torch.export.hf_config_map"]], "build_attention_config() (in module modelopt.torch.export.layer_utils)": [[60, "modelopt.torch.export.layer_utils.build_attention_config"]], "build_conv_config() (in module modelopt.torch.export.layer_utils)": [[60, "modelopt.torch.export.layer_utils.build_conv_config"]], "build_decoder_config() (in module modelopt.torch.export.layer_utils)": [[60, "modelopt.torch.export.layer_utils.build_decoder_config"]], "build_embedding_config() (in module modelopt.torch.export.layer_utils)": [[60, "modelopt.torch.export.layer_utils.build_embedding_config"]], "build_layernorm_config() (in module modelopt.torch.export.layer_utils)": [[60, "modelopt.torch.export.layer_utils.build_layernorm_config"]], "build_linear_config() (in module modelopt.torch.export.layer_utils)": [[60, "modelopt.torch.export.layer_utils.build_linear_config"]], "build_medusa_heads_config() (in module modelopt.torch.export.layer_utils)": [[60, "modelopt.torch.export.layer_utils.build_medusa_heads_config"]], "build_mlp_config() (in module modelopt.torch.export.layer_utils)": [[60, "modelopt.torch.export.layer_utils.build_mlp_config"]], "build_moe_config() (in module modelopt.torch.export.layer_utils)": [[60, "modelopt.torch.export.layer_utils.build_moe_config"]], "build_qkv() (in module modelopt.torch.export.layer_utils)": [[60, "modelopt.torch.export.layer_utils.build_qkv"]], "build_recurrent_config() (in module modelopt.torch.export.layer_utils)": [[60, "modelopt.torch.export.layer_utils.build_recurrent_config"]], "build_stacked_experts() (in module modelopt.torch.export.layer_utils)": [[60, "modelopt.torch.export.layer_utils.build_stacked_experts"]], "check_model_compatibility() (in module modelopt.torch.export.layer_utils)": [[60, "modelopt.torch.export.layer_utils.check_model_compatibility"]], "dup_kv_weight() (in module modelopt.torch.export.layer_utils)": [[60, "modelopt.torch.export.layer_utils.dup_kv_weight"]], "get_activation_scaling_factor() (in module modelopt.torch.export.layer_utils)": [[60, "modelopt.torch.export.layer_utils.get_activation_scaling_factor"]], "get_kv_cache_dtype() (in module modelopt.torch.export.layer_utils)": [[60, "modelopt.torch.export.layer_utils.get_kv_cache_dtype"]], "get_kv_cache_scaling_factor() (in module modelopt.torch.export.layer_utils)": [[60, "modelopt.torch.export.layer_utils.get_kv_cache_scaling_factor"]], "get_prequant_scaling_factor() (in module modelopt.torch.export.layer_utils)": [[60, "modelopt.torch.export.layer_utils.get_prequant_scaling_factor"]], "get_qkv_and_avg_prequant_scale() (in module modelopt.torch.export.layer_utils)": [[60, "modelopt.torch.export.layer_utils.get_qkv_and_avg_prequant_scale"]], "get_quantization_format() (in module modelopt.torch.export.layer_utils)": [[60, "modelopt.torch.export.layer_utils.get_quantization_format"]], "get_scaling_factor() (in module modelopt.torch.export.layer_utils)": [[60, "modelopt.torch.export.layer_utils.get_scaling_factor"]], "get_transformer_layers() (in module modelopt.torch.export.layer_utils)": [[60, "modelopt.torch.export.layer_utils.get_transformer_layers"]], "get_weight_block_size() (in module modelopt.torch.export.layer_utils)": [[60, "modelopt.torch.export.layer_utils.get_weight_block_size"]], "get_weight_scaling_factor() (in module modelopt.torch.export.layer_utils)": [[60, "modelopt.torch.export.layer_utils.get_weight_scaling_factor"]], "get_weight_scaling_factor_2() (in module modelopt.torch.export.layer_utils)": [[60, "modelopt.torch.export.layer_utils.get_weight_scaling_factor_2"]], "is_attention() (in module modelopt.torch.export.layer_utils)": [[60, "modelopt.torch.export.layer_utils.is_attention"]], "is_decoder_list() (in module modelopt.torch.export.layer_utils)": [[60, "modelopt.torch.export.layer_utils.is_decoder_list"]], "is_embedding() (in module modelopt.torch.export.layer_utils)": [[60, "modelopt.torch.export.layer_utils.is_embedding"]], "is_layernorm() (in module modelopt.torch.export.layer_utils)": [[60, "modelopt.torch.export.layer_utils.is_layernorm"]], "is_linear() (in module modelopt.torch.export.layer_utils)": [[60, "modelopt.torch.export.layer_utils.is_linear"]], "is_mlp() (in module modelopt.torch.export.layer_utils)": [[60, "modelopt.torch.export.layer_utils.is_mlp"]], "is_moe() (in module modelopt.torch.export.layer_utils)": [[60, "modelopt.torch.export.layer_utils.is_moe"]], "is_quantlinear() (in module modelopt.torch.export.layer_utils)": [[60, "modelopt.torch.export.layer_utils.is_quantlinear"]], "is_recurrent() (in module modelopt.torch.export.layer_utils)": [[60, "modelopt.torch.export.layer_utils.is_recurrent"]], "modelopt.torch.export.layer_utils": [[60, "module-modelopt.torch.export.layer_utils"]], "attentionconfig (class in modelopt.torch.export.model_config)": [[61, "modelopt.torch.export.model_config.AttentionConfig"]], "convconfig (class in modelopt.torch.export.model_config)": [[61, "modelopt.torch.export.model_config.ConvConfig"]], "decoderlayerconfig (class in modelopt.torch.export.model_config)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig"]], "embeddingconfig (class in modelopt.torch.export.model_config)": [[61, "modelopt.torch.export.model_config.EmbeddingConfig"]], "expertconfig (class in modelopt.torch.export.model_config)": [[61, "modelopt.torch.export.model_config.ExpertConfig"]], "layernormconfig (class in modelopt.torch.export.model_config)": [[61, "modelopt.torch.export.model_config.LayernormConfig"]], "linearactconfig (class in modelopt.torch.export.model_config)": [[61, "modelopt.torch.export.model_config.LinearActConfig"]], "linearconfig (class in modelopt.torch.export.model_config)": [[61, "modelopt.torch.export.model_config.LinearConfig"]], "mlpconfig (class in modelopt.torch.export.model_config)": [[61, "modelopt.torch.export.model_config.MLPConfig"]], "moeconfig (class in modelopt.torch.export.model_config)": [[61, "modelopt.torch.export.model_config.MOEConfig"]], "medusaheadconfig (class in modelopt.torch.export.model_config)": [[61, "modelopt.torch.export.model_config.MedusaHeadConfig"]], "modelconfig (class in modelopt.torch.export.model_config)": [[61, "modelopt.torch.export.model_config.ModelConfig"]], "qkvconfig (class in modelopt.torch.export.model_config)": [[61, "modelopt.torch.export.model_config.QKVConfig"]], "recurrentconfig (class in modelopt.torch.export.model_config)": [[61, "modelopt.torch.export.model_config.RecurrentConfig"]], "rglruconfig (class in modelopt.torch.export.model_config)": [[61, "modelopt.torch.export.model_config.RgLruConfig"]], "__init__() (attentionconfig method)": [[61, "modelopt.torch.export.model_config.AttentionConfig.__init__"]], "__init__() (convconfig method)": [[61, "modelopt.torch.export.model_config.ConvConfig.__init__"]], "__init__() (decoderlayerconfig method)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.__init__"]], "__init__() (embeddingconfig method)": [[61, "modelopt.torch.export.model_config.EmbeddingConfig.__init__"]], "__init__() (expertconfig method)": [[61, "modelopt.torch.export.model_config.ExpertConfig.__init__"]], "__init__() (layernormconfig method)": [[61, "modelopt.torch.export.model_config.LayernormConfig.__init__"]], "__init__() (linearactconfig method)": [[61, "modelopt.torch.export.model_config.LinearActConfig.__init__"]], "__init__() (linearconfig method)": [[61, "modelopt.torch.export.model_config.LinearConfig.__init__"]], "__init__() (mlpconfig method)": [[61, "modelopt.torch.export.model_config.MLPConfig.__init__"]], "__init__() (moeconfig method)": [[61, "modelopt.torch.export.model_config.MOEConfig.__init__"]], "__init__() (medusaheadconfig method)": [[61, "modelopt.torch.export.model_config.MedusaHeadConfig.__init__"]], "__init__() (modelconfig method)": [[61, "modelopt.torch.export.model_config.ModelConfig.__init__"]], "__init__() (qkvconfig method)": [[61, "modelopt.torch.export.model_config.QKVConfig.__init__"]], "__init__() (recurrentconfig method)": [[61, "modelopt.torch.export.model_config.RecurrentConfig.__init__"]], "__init__() (rglruconfig method)": [[61, "modelopt.torch.export.model_config.RgLruConfig.__init__"]], "activation_scaling_factor (linearconfig attribute)": [[61, "modelopt.torch.export.model_config.LinearConfig.activation_scaling_factor"]], "activation_scaling_factor (qkvconfig property)": [[61, "modelopt.torch.export.model_config.QKVConfig.activation_scaling_factor"]], "alibi_bias_max (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.alibi_bias_max"]], "apply_residual_connection_post_layernorm (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.apply_residual_connection_post_layernorm"]], "attention (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.attention"]], "attention_head_size (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.attention_head_size"]], "attention_layernorm (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.attention_layernorm"]], "attn_logit_softcapping (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.attn_logit_softcapping"]], "attn_replacing_linear (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.attn_replacing_linear"]], "awq_block_size (linearconfig attribute)": [[61, "modelopt.torch.export.model_config.LinearConfig.awq_block_size"]], "awq_block_size (qkvconfig property)": [[61, "modelopt.torch.export.model_config.QKVConfig.awq_block_size"]], "bias (convconfig attribute)": [[61, "modelopt.torch.export.model_config.ConvConfig.bias"]], "bias (layernormconfig attribute)": [[61, "modelopt.torch.export.model_config.LayernormConfig.bias"]], "bias (linearconfig attribute)": [[61, "modelopt.torch.export.model_config.LinearConfig.bias"]], "bias (qkvconfig property)": [[61, "modelopt.torch.export.model_config.QKVConfig.bias"]], "block_config (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.block_config"]], "block_embedding (modelconfig attribute)": [[61, "modelopt.torch.export.model_config.ModelConfig.block_embedding"]], "blocksparse_block_size (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.blocksparse_block_size"]], "blocksparse_homo_head_pattern (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.blocksparse_homo_head_pattern"]], "blocksparse_num_local_blocks (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.blocksparse_num_local_blocks"]], "blocksparse_vertical_stride (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.blocksparse_vertical_stride"]], "chatglm_version (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.chatglm_version"]], "clip_qkv (attentionconfig attribute)": [[61, "modelopt.torch.export.model_config.AttentionConfig.clip_qkv"]], "clip_qkv (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.clip_qkv"]], "conv1d (recurrentconfig attribute)": [[61, "modelopt.torch.export.model_config.RecurrentConfig.conv1d"]], "cross_attention (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.cross_attention"]], "cross_attention_layernorm (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.cross_attention_layernorm"]], "decoder_type (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.decoder_type"]], "dense (attentionconfig attribute)": [[61, "modelopt.torch.export.model_config.AttentionConfig.dense"]], "dense_attention_every_n_layers (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.dense_attention_every_n_layers"]], "dtype (modelconfig attribute)": [[61, "modelopt.torch.export.model_config.ModelConfig.dtype"]], "emb_scale_by_sqrt_dim (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.emb_scale_by_sqrt_dim"]], "enc_dec (modelconfig attribute)": [[61, "modelopt.torch.export.model_config.ModelConfig.enc_dec"]], "encoder_head_size (modelconfig attribute)": [[61, "modelopt.torch.export.model_config.ModelConfig.encoder_head_size"]], "encoder_hidden_size (modelconfig attribute)": [[61, "modelopt.torch.export.model_config.ModelConfig.encoder_hidden_size"]], "encoder_num_heads (modelconfig attribute)": [[61, "modelopt.torch.export.model_config.ModelConfig.encoder_num_heads"]], "eps (layernormconfig attribute)": [[61, "modelopt.torch.export.model_config.LayernormConfig.eps"]], "experts (moeconfig attribute)": [[61, "modelopt.torch.export.model_config.MOEConfig.experts"]], "fc (expertconfig attribute)": [[61, "modelopt.torch.export.model_config.ExpertConfig.fc"]], "fc (mlpconfig attribute)": [[61, "modelopt.torch.export.model_config.MLPConfig.fc"]], "fc (moeconfig property)": [[61, "modelopt.torch.export.model_config.MOEConfig.fc"]], "ffn_hidden_size_local (decoderlayerconfig property)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.ffn_hidden_size_local"]], "final_logit_softcapping (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.final_logit_softcapping"]], "gate (mlpconfig attribute)": [[61, "modelopt.torch.export.model_config.MLPConfig.gate"]], "gegelu_limit (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.gegelu_limit"]], "hidden_act (linearactconfig attribute)": [[61, "modelopt.torch.export.model_config.LinearActConfig.hidden_act"]], "hidden_act (mlpconfig attribute)": [[61, "modelopt.torch.export.model_config.MLPConfig.hidden_act"]], "hidden_act (moeconfig attribute)": [[61, "modelopt.torch.export.model_config.MOEConfig.hidden_act"]], "hidden_act (modelconfig property)": [[61, "modelopt.torch.export.model_config.ModelConfig.hidden_act"]], "hidden_size (decoderlayerconfig property)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.hidden_size"]], "hidden_size (embeddingconfig property)": [[61, "modelopt.torch.export.model_config.EmbeddingConfig.hidden_size"]], "hidden_size (modelconfig property)": [[61, "modelopt.torch.export.model_config.ModelConfig.hidden_size"]], "input_gate (rglruconfig attribute)": [[61, "modelopt.torch.export.model_config.RgLruConfig.input_gate"]], "input_layernorm (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.input_layernorm"]], "k (qkvconfig attribute)": [[61, "modelopt.torch.export.model_config.QKVConfig.k"]], "kv_cache_dtype (attentionconfig attribute)": [[61, "modelopt.torch.export.model_config.AttentionConfig.kv_cache_dtype"]], "kv_cache_scaling_factor (attentionconfig attribute)": [[61, "modelopt.torch.export.model_config.AttentionConfig.kv_cache_scaling_factor"]], "layer_types (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.layer_types"]], "layernorm_type (layernormconfig attribute)": [[61, "modelopt.torch.export.model_config.LayernormConfig.layernorm_type"]], "layers (modelconfig attribute)": [[61, "modelopt.torch.export.model_config.ModelConfig.layers"]], "linear (linearactconfig attribute)": [[61, "modelopt.torch.export.model_config.LinearActConfig.linear"]], "linear_out (recurrentconfig attribute)": [[61, "modelopt.torch.export.model_config.RecurrentConfig.linear_out"]], "linear_type (linearconfig attribute)": [[61, "modelopt.torch.export.model_config.LinearConfig.linear_type"]], "linear_x (recurrentconfig attribute)": [[61, "modelopt.torch.export.model_config.RecurrentConfig.linear_x"]], "linear_y (recurrentconfig attribute)": [[61, "modelopt.torch.export.model_config.RecurrentConfig.linear_y"]], "lm_head (medusaheadconfig attribute)": [[61, "modelopt.torch.export.model_config.MedusaHeadConfig.lm_head"]], "lm_head (modelconfig attribute)": [[61, "modelopt.torch.export.model_config.ModelConfig.lm_head"]], "ln_embed (modelconfig attribute)": [[61, "modelopt.torch.export.model_config.ModelConfig.ln_embed"]], "ln_f (modelconfig attribute)": [[61, "modelopt.torch.export.model_config.ModelConfig.ln_f"]], "local_vocab_size (embeddingconfig property)": [[61, "modelopt.torch.export.model_config.EmbeddingConfig.local_vocab_size"]], "logits_soft_cap (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.logits_soft_cap"]], "longrope_long_mscale (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.longrope_long_mscale"]], "longrope_scaling_long_factors (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.longrope_scaling_long_factors"]], "longrope_scaling_short_factors (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.longrope_scaling_short_factors"]], "longrope_short_mscale (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.longrope_short_mscale"]], "max_position_embeddings (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.max_position_embeddings"]], "max_position_embeddings (modelconfig property)": [[61, "modelopt.torch.export.model_config.ModelConfig.max_position_embeddings"]], "medusa_heads (modelconfig attribute)": [[61, "modelopt.torch.export.model_config.ModelConfig.medusa_heads"]], "medusa_layers (medusaheadconfig attribute)": [[61, "modelopt.torch.export.model_config.MedusaHeadConfig.medusa_layers"]], "merged_fc1_gate (mlpconfig attribute)": [[61, "modelopt.torch.export.model_config.MLPConfig.merged_fc1_gate"]], "mlp (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.mlp"]], "mlp_layernorm (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.mlp_layernorm"]], "mlp_replacing_linear (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.mlp_replacing_linear"]], "modelopt.torch.export.model_config": [[61, "module-modelopt.torch.export.model_config"]], "moe_num_experts (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.moe_num_experts"]], "moe_renorm_mode (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.moe_renorm_mode"]], "moe_top_k (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.moe_top_k"]], "moe_tp_mode (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.moe_tp_mode"]], "mup_attn_multiplier (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.mup_attn_multiplier"]], "mup_embedding_multiplier (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.mup_embedding_multiplier"]], "mup_use_scaling (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.mup_use_scaling"]], "mup_width_multiplier (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.mup_width_multiplier"]], "new_decoder_architecture (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.new_decoder_architecture"]], "num_attention_heads (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.num_attention_heads"]], "num_attention_heads (modelconfig property)": [[61, "modelopt.torch.export.model_config.ModelConfig.num_attention_heads"]], "num_kv_heads (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.num_kv_heads"]], "num_kv_heads (modelconfig property)": [[61, "modelopt.torch.export.model_config.ModelConfig.num_kv_heads"]], "num_medusa_heads (modelconfig attribute)": [[61, "modelopt.torch.export.model_config.ModelConfig.num_medusa_heads"]], "num_medusa_layers (modelconfig attribute)": [[61, "modelopt.torch.export.model_config.ModelConfig.num_medusa_layers"]], "original_max_position_embeddings (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.original_max_position_embeddings"]], "parallel_attention (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.parallel_attention"]], "partial_rotary_factor (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.partial_rotary_factor"]], "pipeline_parallel (modelconfig attribute)": [[61, "modelopt.torch.export.model_config.ModelConfig.pipeline_parallel"]], "position_embedding (modelconfig attribute)": [[61, "modelopt.torch.export.model_config.ModelConfig.position_embedding"]], "post_feedforward_layernorm (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.post_feedforward_layernorm"]], "post_layernorm (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.post_layernorm"]], "pre_feedforward_layernorm (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.pre_feedforward_layernorm"]], "prequant_scaling_factor (linearconfig attribute)": [[61, "modelopt.torch.export.model_config.LinearConfig.prequant_scaling_factor"]], "prequant_scaling_factor (qkvconfig property)": [[61, "modelopt.torch.export.model_config.QKVConfig.prequant_scaling_factor"]], "proj (expertconfig attribute)": [[61, "modelopt.torch.export.model_config.ExpertConfig.proj"]], "proj (mlpconfig attribute)": [[61, "modelopt.torch.export.model_config.MLPConfig.proj"]], "q (qkvconfig attribute)": [[61, "modelopt.torch.export.model_config.QKVConfig.q"]], "qkv (attentionconfig attribute)": [[61, "modelopt.torch.export.model_config.AttentionConfig.qkv"]], "quantization (convconfig attribute)": [[61, "modelopt.torch.export.model_config.ConvConfig.quantization"]], "quantization (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.quantization"]], "quantization (embeddingconfig attribute)": [[61, "modelopt.torch.export.model_config.EmbeddingConfig.quantization"]], "quantization (layernormconfig attribute)": [[61, "modelopt.torch.export.model_config.LayernormConfig.quantization"]], "quantization (linearconfig attribute)": [[61, "modelopt.torch.export.model_config.LinearConfig.quantization"]], "quantization (mlpconfig property)": [[61, "modelopt.torch.export.model_config.MLPConfig.quantization"]], "quantization (modelconfig attribute)": [[61, "modelopt.torch.export.model_config.ModelConfig.quantization"]], "quantization (qkvconfig property)": [[61, "modelopt.torch.export.model_config.QKVConfig.quantization"]], "query_pre_attn_scalar (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.query_pre_attn_scalar"]], "qwen_type (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.qwen_type"]], "rank (modelconfig attribute)": [[61, "modelopt.torch.export.model_config.ModelConfig.rank"]], "recurrent (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.recurrent"]], "recurrent_gate (rglruconfig attribute)": [[61, "modelopt.torch.export.model_config.RgLruConfig.recurrent_gate"]], "recurrent_param (rglruconfig attribute)": [[61, "modelopt.torch.export.model_config.RgLruConfig.recurrent_param"]], "rel_attn_max_distance (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.rel_attn_max_distance"]], "rel_attn_num_buckets (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.rel_attn_num_buckets"]], "rel_attn_table (attentionconfig attribute)": [[61, "modelopt.torch.export.model_config.AttentionConfig.rel_attn_table"]], "residual_layernorm (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.residual_layernorm"]], "residual_mlp (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.residual_mlp"]], "rg_lru (recurrentconfig attribute)": [[61, "modelopt.torch.export.model_config.RecurrentConfig.rg_lru"]], "rnn_hidden_size (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.rnn_hidden_size"]], "rope_ratio (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.rope_ratio"]], "rope_scaling (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.rope_scaling"]], "rotary_base (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.rotary_base"]], "rotary_dim (attentionconfig attribute)": [[61, "modelopt.torch.export.model_config.AttentionConfig.rotary_dim"]], "rotary_pct (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.rotary_pct"]], "router (moeconfig attribute)": [[61, "modelopt.torch.export.model_config.MOEConfig.router"]], "self_attention (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.self_attention"]], "self_attention_layernorm (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.self_attention_layernorm"]], "seq_length (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.seq_length"]], "share_embedding_table (modelconfig attribute)": [[61, "modelopt.torch.export.model_config.ModelConfig.share_embedding_table"]], "tensor_parallel (modelconfig attribute)": [[61, "modelopt.torch.export.model_config.ModelConfig.tensor_parallel"]], "use_alibi (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.use_alibi"]], "use_cache (decoderlayerconfig attribute)": [[61, "modelopt.torch.export.model_config.DecoderLayerConfig.use_cache"]], "v (qkvconfig attribute)": [[61, "modelopt.torch.export.model_config.QKVConfig.v"]], "version (modelconfig attribute)": [[61, "modelopt.torch.export.model_config.ModelConfig.version"]], "vocab_embedding (modelconfig attribute)": [[61, "modelopt.torch.export.model_config.ModelConfig.vocab_embedding"]], "vocab_size (modelconfig attribute)": [[61, "modelopt.torch.export.model_config.ModelConfig.vocab_size"]], "vocab_size_padded (modelconfig property)": [[61, "modelopt.torch.export.model_config.ModelConfig.vocab_size_padded"]], "weight (convconfig attribute)": [[61, "modelopt.torch.export.model_config.ConvConfig.weight"]], "weight (embeddingconfig attribute)": [[61, "modelopt.torch.export.model_config.EmbeddingConfig.weight"]], "weight (layernormconfig attribute)": [[61, "modelopt.torch.export.model_config.LayernormConfig.weight"]], "weight (linearconfig attribute)": [[61, "modelopt.torch.export.model_config.LinearConfig.weight"]], "weight (qkvconfig property)": [[61, "modelopt.torch.export.model_config.QKVConfig.weight"]], "weights_scaling_factor (linearconfig attribute)": [[61, "modelopt.torch.export.model_config.LinearConfig.weights_scaling_factor"]], "weights_scaling_factor (qkvconfig property)": [[61, "modelopt.torch.export.model_config.QKVConfig.weights_scaling_factor"]], "weights_scaling_factor_2 (linearconfig attribute)": [[61, "modelopt.torch.export.model_config.LinearConfig.weights_scaling_factor_2"]], "weights_scaling_factor_2 (qkvconfig property)": [[61, "modelopt.torch.export.model_config.QKVConfig.weights_scaling_factor_2"]], "y_bias (recurrentconfig attribute)": [[61, "modelopt.torch.export.model_config.RecurrentConfig.y_bias"]], "export_tensorrt_llm_checkpoint() (in module modelopt.torch.export.model_config_export)": [[62, "modelopt.torch.export.model_config_export.export_tensorrt_llm_checkpoint"]], "modelopt.torch.export.model_config_export": [[62, "module-modelopt.torch.export.model_config_export"]], "torch_to_tensorrt_llm_checkpoint() (in module modelopt.torch.export.model_config_export)": [[62, "modelopt.torch.export.model_config_export.torch_to_tensorrt_llm_checkpoint"]], "from_quantized_weight() (in module modelopt.torch.export.model_config_utils)": [[63, "modelopt.torch.export.model_config_utils.from_quantized_weight"]], "merge_fc1_gate() (in module modelopt.torch.export.model_config_utils)": [[63, "modelopt.torch.export.model_config_utils.merge_fc1_gate"]], "merge_qkv() (in module modelopt.torch.export.model_config_utils)": [[63, "modelopt.torch.export.model_config_utils.merge_qkv"]], "model_config_from_dict() (in module modelopt.torch.export.model_config_utils)": [[63, "modelopt.torch.export.model_config_utils.model_config_from_dict"]], "model_config_to_dict() (in module modelopt.torch.export.model_config_utils)": [[63, "modelopt.torch.export.model_config_utils.model_config_to_dict"]], "modelopt.torch.export.model_config_utils": [[63, "module-modelopt.torch.export.model_config_utils"]], "naive_quantization() (in module modelopt.torch.export.model_config_utils)": [[63, "modelopt.torch.export.model_config_utils.naive_quantization"]], "pack_linear_weights() (in module modelopt.torch.export.model_config_utils)": [[63, "modelopt.torch.export.model_config_utils.pack_linear_weights"]], "pad_weights() (in module modelopt.torch.export.model_config_utils)": [[63, "modelopt.torch.export.model_config_utils.pad_weights"]], "process_layer_quant_config() (in module modelopt.torch.export.model_config_utils)": [[63, "modelopt.torch.export.model_config_utils.process_layer_quant_config"]], "restore_model_config() (in module modelopt.torch.export.model_config_utils)": [[63, "modelopt.torch.export.model_config_utils.restore_model_config"]], "split_config_and_weights() (in module modelopt.torch.export.model_config_utils)": [[63, "modelopt.torch.export.model_config_utils.split_config_and_weights"]], "to_quantized_weight() (in module modelopt.torch.export.model_config_utils)": [[63, "modelopt.torch.export.model_config_utils.to_quantized_weight"]], "check_weight_shape_valid() (in module modelopt.torch.export.postprocess)": [[64, "modelopt.torch.export.postprocess.check_weight_shape_valid"]], "modelopt.torch.export.postprocess": [[64, "module-modelopt.torch.export.postprocess"]], "pad_embedding_lm_head() (in module modelopt.torch.export.postprocess)": [[64, "modelopt.torch.export.postprocess.pad_embedding_lm_head"]], "postprocess_model_config() (in module modelopt.torch.export.postprocess)": [[64, "modelopt.torch.export.postprocess.postprocess_model_config"]], "postprocess_tensors() (in module modelopt.torch.export.postprocess)": [[64, "modelopt.torch.export.postprocess.postprocess_tensors"]], "update_lm_head_quantization() (in module modelopt.torch.export.postprocess)": [[64, "modelopt.torch.export.postprocess.update_lm_head_quantization"]], "adjust_attn_amax_values() (in module modelopt.torch.export.scaling_factor_utils)": [[65, "modelopt.torch.export.scaling_factor_utils.adjust_attn_amax_values"]], "convert_state_dict_amax_to_scales() (in module modelopt.torch.export.scaling_factor_utils)": [[65, "modelopt.torch.export.scaling_factor_utils.convert_state_dict_amax_to_scales"]], "get_weights_scaling_factor_and_amax() (in module modelopt.torch.export.scaling_factor_utils)": [[65, "modelopt.torch.export.scaling_factor_utils.get_weights_scaling_factor_and_amax"]], "modelopt.torch.export.scaling_factor_utils": [[65, "module-modelopt.torch.export.scaling_factor_utils"]], "resmooth_and_get_scale_and_amax() (in module modelopt.torch.export.scaling_factor_utils)": [[65, "modelopt.torch.export.scaling_factor_utils.resmooth_and_get_scale_and_amax"]], "fusedgatedmlp (mlptype attribute)": [[66, "modelopt.torch.export.tensorrt_llm_type.MLPType.FusedGatedMLP"]], "gatedmlp (mlptype attribute)": [[66, "modelopt.torch.export.tensorrt_llm_type.MLPType.GatedMLP"]], "groupnorm (layernormtype attribute)": [[66, "modelopt.torch.export.tensorrt_llm_type.LayerNormType.GroupNorm"]], "layernorm (layernormtype attribute)": [[66, "modelopt.torch.export.tensorrt_llm_type.LayerNormType.LayerNorm"]], "layernormpositiontype (class in modelopt.torch.export.tensorrt_llm_type)": [[66, "modelopt.torch.export.tensorrt_llm_type.LayerNormPositionType"]], "layernormtype (class in modelopt.torch.export.tensorrt_llm_type)": [[66, "modelopt.torch.export.tensorrt_llm_type.LayerNormType"]], "mlp (mlptype attribute)": [[66, "modelopt.torch.export.tensorrt_llm_type.MLPType.MLP"]], "mlptype (class in modelopt.torch.export.tensorrt_llm_type)": [[66, "modelopt.torch.export.tensorrt_llm_type.MLPType"]], "rmsnorm (layernormtype attribute)": [[66, "modelopt.torch.export.tensorrt_llm_type.LayerNormType.RmsNorm"]], "__new__() (layernormpositiontype method)": [[66, "modelopt.torch.export.tensorrt_llm_type.LayerNormPositionType.__new__"]], "__new__() (layernormtype method)": [[66, "modelopt.torch.export.tensorrt_llm_type.LayerNormType.__new__"]], "__new__() (mlptype method)": [[66, "modelopt.torch.export.tensorrt_llm_type.MLPType.__new__"]], "modelopt.torch.export.tensorrt_llm_type": [[66, "module-modelopt.torch.export.tensorrt_llm_type"]], "post_layernorm (layernormpositiontype attribute)": [[66, "modelopt.torch.export.tensorrt_llm_type.LayerNormPositionType.post_layernorm"]], "pre_layernorm (layernormpositiontype attribute)": [[66, "modelopt.torch.export.tensorrt_llm_type.LayerNormPositionType.pre_layernorm"]], "convert_to_tensorrt_llm_config() (in module modelopt.torch.export.tensorrt_llm_utils)": [[67, "modelopt.torch.export.tensorrt_llm_utils.convert_to_tensorrt_llm_config"]], "is_tensorrt_llm_0_8_or_9() (in module modelopt.torch.export.tensorrt_llm_utils)": [[67, "modelopt.torch.export.tensorrt_llm_utils.is_tensorrt_llm_0_8_or_9"]], "modelopt.torch.export.tensorrt_llm_utils": [[67, "module-modelopt.torch.export.tensorrt_llm_utils"]], "prepare_enc_dec_decoder_layer() (in module modelopt.torch.export.tensorrt_llm_utils)": [[67, "modelopt.torch.export.tensorrt_llm_utils.prepare_enc_dec_decoder_layer"]], "prepare_enc_dec_export_dir() (in module modelopt.torch.export.tensorrt_llm_utils)": [[67, "modelopt.torch.export.tensorrt_llm_utils.prepare_enc_dec_export_dir"]], "weights_to_npz() (in module modelopt.torch.export.tensorrt_llm_utils)": [[67, "modelopt.torch.export.tensorrt_llm_utils.weights_to_npz"]], "convert_to_transformer_engine() (in module modelopt.torch.export.transformer_engine)": [[68, "modelopt.torch.export.transformer_engine.convert_to_transformer_engine"]], "modelopt.torch.export.transformer_engine": [[68, "module-modelopt.torch.export.transformer_engine"]], "export_hf() (in module modelopt.torch.export.unified_export_hf)": [[69, "modelopt.torch.export.unified_export_hf.export_hf"]], "export_hf_checkpoint() (in module modelopt.torch.export.unified_export_hf)": [[69, "modelopt.torch.export.unified_export_hf.export_hf_checkpoint"]], "modelopt.torch.export.unified_export_hf": [[69, "module-modelopt.torch.export.unified_export_hf"]], "export_to_vllm() (in module modelopt.torch.export.vllm)": [[70, "modelopt.torch.export.vllm.export_to_vllm"]], "modelopt.torch.export.vllm": [[70, "module-modelopt.torch.export.vllm"]], "modelopt.torch.nas": [[71, "module-modelopt.torch.nas"]], "modelopt.torch.nas.algorithms": [[72, "module-modelopt.torch.nas.algorithms"]], "profile() (in module modelopt.torch.nas.algorithms)": [[72, "modelopt.torch.nas.algorithms.profile"]], "search() (in module modelopt.torch.nas.algorithms)": [[72, "modelopt.torch.nas.algorithms.search"]], "autonaspatchmanager (class in modelopt.torch.nas.autonas)": [[73, "modelopt.torch.nas.autonas.AutoNASPatchManager"]], "evolvesearcher (class in modelopt.torch.nas.autonas)": [[73, "modelopt.torch.nas.autonas.EvolveSearcher"]], "iterativesearcher (class in modelopt.torch.nas.autonas)": [[73, "modelopt.torch.nas.autonas.IterativeSearcher"]], "randomsearcher (class in modelopt.torch.nas.autonas)": [[73, "modelopt.torch.nas.autonas.RandomSearcher"]], "after_search() (iterativesearcher method)": [[73, "modelopt.torch.nas.autonas.IterativeSearcher.after_search"]], "after_step() (evolvesearcher method)": [[73, "modelopt.torch.nas.autonas.EvolveSearcher.after_step"]], "after_step() (iterativesearcher method)": [[73, "modelopt.torch.nas.autonas.IterativeSearcher.after_step"]], "before_search() (evolvesearcher method)": [[73, "modelopt.torch.nas.autonas.EvolveSearcher.before_search"]], "before_search() (iterativesearcher method)": [[73, "modelopt.torch.nas.autonas.IterativeSearcher.before_search"]], "before_step() (evolvesearcher method)": [[73, "modelopt.torch.nas.autonas.EvolveSearcher.before_step"]], "before_step() (iterativesearcher method)": [[73, "modelopt.torch.nas.autonas.IterativeSearcher.before_step"]], "best (iterativesearcher attribute)": [[73, "modelopt.torch.nas.autonas.IterativeSearcher.best"]], "best_history (iterativesearcher attribute)": [[73, "modelopt.torch.nas.autonas.IterativeSearcher.best_history"]], "candidate (iterativesearcher attribute)": [[73, "modelopt.torch.nas.autonas.IterativeSearcher.candidate"]], "candidates (evolvesearcher attribute)": [[73, "modelopt.torch.nas.autonas.EvolveSearcher.candidates"]], "constraints_func (iterativesearcher attribute)": [[73, "modelopt.torch.nas.autonas.IterativeSearcher.constraints_func"]], "convert_autonas_searchspace() (in module modelopt.torch.nas.autonas)": [[73, "modelopt.torch.nas.autonas.convert_autonas_searchspace"]], "convert_searchspace() (in module modelopt.torch.nas.autonas)": [[73, "modelopt.torch.nas.autonas.convert_searchspace"]], "default_search_config (evolvesearcher property)": [[73, "modelopt.torch.nas.autonas.EvolveSearcher.default_search_config"]], "default_search_config (iterativesearcher property)": [[73, "modelopt.torch.nas.autonas.IterativeSearcher.default_search_config"]], "default_state_dict (evolvesearcher property)": [[73, "modelopt.torch.nas.autonas.EvolveSearcher.default_state_dict"]], "default_state_dict (iterativesearcher property)": [[73, "modelopt.torch.nas.autonas.IterativeSearcher.default_state_dict"]], "early_stop() (iterativesearcher method)": [[73, "modelopt.torch.nas.autonas.IterativeSearcher.early_stop"]], "export_searchspace() (in module modelopt.torch.nas.autonas)": [[73, "modelopt.torch.nas.autonas.export_searchspace"]], "history (iterativesearcher attribute)": [[73, "modelopt.torch.nas.autonas.IterativeSearcher.history"]], "iter_num (iterativesearcher attribute)": [[73, "modelopt.torch.nas.autonas.IterativeSearcher.iter_num"]], "modelopt.torch.nas.autonas": [[73, "module-modelopt.torch.nas.autonas"]], "num_satisfied (iterativesearcher attribute)": [[73, "modelopt.torch.nas.autonas.IterativeSearcher.num_satisfied"]], "population (evolvesearcher attribute)": [[73, "modelopt.torch.nas.autonas.EvolveSearcher.population"]], "restore_autonas_searchspace() (in module modelopt.torch.nas.autonas)": [[73, "modelopt.torch.nas.autonas.restore_autonas_searchspace"]], "restore_export() (in module modelopt.torch.nas.autonas)": [[73, "modelopt.torch.nas.autonas.restore_export"]], "restore_searchspace() (in module modelopt.torch.nas.autonas)": [[73, "modelopt.torch.nas.autonas.restore_searchspace"]], "run_search() (iterativesearcher method)": [[73, "modelopt.torch.nas.autonas.IterativeSearcher.run_search"]], "run_step() (iterativesearcher method)": [[73, "modelopt.torch.nas.autonas.IterativeSearcher.run_step"]], "sample() (evolvesearcher method)": [[73, "modelopt.torch.nas.autonas.EvolveSearcher.sample"]], "sample() (iterativesearcher method)": [[73, "modelopt.torch.nas.autonas.IterativeSearcher.sample"]], "sample() (randomsearcher method)": [[73, "modelopt.torch.nas.autonas.RandomSearcher.sample"]], "sample_during_training (autonaspatchmanager property)": [[73, "modelopt.torch.nas.autonas.AutoNASPatchManager.sample_during_training"]], "samples (iterativesearcher attribute)": [[73, "modelopt.torch.nas.autonas.IterativeSearcher.samples"]], "sanitize_search_config() (iterativesearcher method)": [[73, "modelopt.torch.nas.autonas.IterativeSearcher.sanitize_search_config"]], "update_autonas_metadata() (in module modelopt.torch.nas.autonas)": [[73, "modelopt.torch.nas.autonas.update_autonas_metadata"]], "calib (exportconfig attribute)": [[74, "modelopt.torch.nas.config.ExportConfig.calib"]], "modelopt.torch.nas.config": [[74, "module-modelopt.torch.nas.config"]], "nn_batchnorm1d (autonasconfig attribute)": [[74, "modelopt.torch.nas.config.AutoNASConfig.nn_batchnorm1d"]], "nn_batchnorm2d (autonasconfig attribute)": [[74, "modelopt.torch.nas.config.AutoNASConfig.nn_batchnorm2d"]], "nn_batchnorm3d (autonasconfig attribute)": [[74, "modelopt.torch.nas.config.AutoNASConfig.nn_batchnorm3d"]], "nn_conv1d (autonasconfig attribute)": [[74, "modelopt.torch.nas.config.AutoNASConfig.nn_conv1d"]], "nn_conv2d (autonasconfig attribute)": [[74, "modelopt.torch.nas.config.AutoNASConfig.nn_conv2d"]], "nn_conv3d (autonasconfig attribute)": [[74, "modelopt.torch.nas.config.AutoNASConfig.nn_conv3d"]], "nn_convtranspose1d (autonasconfig attribute)": [[74, "modelopt.torch.nas.config.AutoNASConfig.nn_convtranspose1d"]], "nn_convtranspose2d (autonasconfig attribute)": [[74, "modelopt.torch.nas.config.AutoNASConfig.nn_convtranspose2d"]], "nn_convtranspose3d (autonasconfig attribute)": [[74, "modelopt.torch.nas.config.AutoNASConfig.nn_convtranspose3d"]], "nn_groupnorm (autonasconfig attribute)": [[74, "modelopt.torch.nas.config.AutoNASConfig.nn_groupnorm"]], "nn_instancenorm1d (autonasconfig attribute)": [[74, "modelopt.torch.nas.config.AutoNASConfig.nn_instancenorm1d"]], "nn_instancenorm2d (autonasconfig attribute)": [[74, "modelopt.torch.nas.config.AutoNASConfig.nn_instancenorm2d"]], "nn_instancenorm3d (autonasconfig attribute)": [[74, "modelopt.torch.nas.config.AutoNASConfig.nn_instancenorm3d"]], "nn_layernorm (autonasconfig attribute)": [[74, "modelopt.torch.nas.config.AutoNASConfig.nn_layernorm"]], "nn_linear (autonasconfig attribute)": [[74, "modelopt.torch.nas.config.AutoNASConfig.nn_linear"]], "nn_sequential (autonasconfig attribute)": [[74, "modelopt.torch.nas.config.AutoNASConfig.nn_sequential"]], "nn_syncbatchnorm (autonasconfig attribute)": [[74, "modelopt.torch.nas.config.AutoNASConfig.nn_syncbatchnorm"]], "strict (exportconfig attribute)": [[74, "modelopt.torch.nas.config.ExportConfig.strict"]], "convert() (in module modelopt.torch.nas.conversion)": [[75, "modelopt.torch.nas.conversion.convert"]], "export() (in module modelopt.torch.nas.conversion)": [[75, "modelopt.torch.nas.conversion.export"]], "modelopt.torch.nas.conversion": [[75, "module-modelopt.torch.nas.conversion"]], "modelopt.torch.nas.hparams": [[76, "module-modelopt.torch.nas.hparams"]], "concattracedhp (class in modelopt.torch.nas.hparams.concat)": [[77, "modelopt.torch.nas.hparams.concat.ConcatTracedHp"]], "active (concattracedhp property)": [[77, "modelopt.torch.nas.hparams.concat.ConcatTracedHp.active"]], "active_slice (concattracedhp property)": [[77, "modelopt.torch.nas.hparams.concat.ConcatTracedHp.active_slice"]], "modelopt.torch.nas.hparams.concat": [[77, "module-modelopt.torch.nas.hparams.concat"]], "depthhparam (class in modelopt.torch.nas.hparams.container)": [[78, "modelopt.torch.nas.hparams.container.DepthHparam"]], "modelopt.torch.nas.hparams.container": [[78, "module-modelopt.torch.nas.hparams.container"]], "autonasmodedescriptor (class in modelopt.torch.nas.mode)": [[79, "modelopt.torch.nas.mode.AutoNASModeDescriptor"]], "exportmodedescriptor (class in modelopt.torch.nas.mode)": [[79, "modelopt.torch.nas.mode.ExportModeDescriptor"]], "config_class (autonasmodedescriptor property)": [[79, "modelopt.torch.nas.mode.AutoNASModeDescriptor.config_class"]], "config_class (exportmodedescriptor property)": [[79, "modelopt.torch.nas.mode.ExportModeDescriptor.config_class"]], "convert (autonasmodedescriptor property)": [[79, "modelopt.torch.nas.mode.AutoNASModeDescriptor.convert"]], "convert (exportmodedescriptor property)": [[79, "modelopt.torch.nas.mode.ExportModeDescriptor.convert"]], "export_mode (autonasmodedescriptor property)": [[79, "modelopt.torch.nas.mode.AutoNASModeDescriptor.export_mode"]], "is_export_mode (exportmodedescriptor property)": [[79, "modelopt.torch.nas.mode.ExportModeDescriptor.is_export_mode"]], "modelopt.torch.nas.mode": [[79, "module-modelopt.torch.nas.mode"]], "name (autonasmodedescriptor property)": [[79, "modelopt.torch.nas.mode.AutoNASModeDescriptor.name"]], "name (exportmodedescriptor property)": [[79, "modelopt.torch.nas.mode.ExportModeDescriptor.name"]], "next_modes (autonasmodedescriptor property)": [[79, "modelopt.torch.nas.mode.AutoNASModeDescriptor.next_modes"]], "restore (autonasmodedescriptor property)": [[79, "modelopt.torch.nas.mode.AutoNASModeDescriptor.restore"]], "restore (exportmodedescriptor property)": [[79, "modelopt.torch.nas.mode.ExportModeDescriptor.restore"]], "search_algorithm (autonasmodedescriptor property)": [[79, "modelopt.torch.nas.mode.AutoNASModeDescriptor.search_algorithm"]], "update_for_new_mode (autonasmodedescriptor property)": [[79, "modelopt.torch.nas.mode.AutoNASModeDescriptor.update_for_new_mode"]], "update_for_save (autonasmodedescriptor property)": [[79, "modelopt.torch.nas.mode.AutoNASModeDescriptor.update_for_save"]], "modelopt.torch.nas.modules": [[80, "module-modelopt.torch.nas.modules"]], "modelopt.torch.nas.modules.container": [[81, "module-modelopt.torch.nas.modules.container"]], "modelopt.torch.nas.modules.conv": [[82, "module-modelopt.torch.nas.modules.conv"]], "modelopt.torch.nas.modules.linear": [[83, "module-modelopt.torch.nas.modules.linear"]], "modelopt.torch.nas.modules.norm": [[84, "module-modelopt.torch.nas.modules.norm"]], "get_sliced_tensor() (in module modelopt.torch.nas.modules.utils)": [[85, "modelopt.torch.nas.modules.utils.get_sliced_tensor"]], "get_sliced_tensor_by_slices() (in module modelopt.torch.nas.modules.utils)": [[85, "modelopt.torch.nas.modules.utils.get_sliced_tensor_by_slices"]], "modelopt.torch.nas.modules.utils": [[85, "module-modelopt.torch.nas.modules.utils"]], "modelopt.torch.nas.plugins": [[86, "module-modelopt.torch.nas.plugins"]], "modelopt.torch.nas.registry": [[87, "module-modelopt.torch.nas.registry"]], "searchspace (class in modelopt.torch.nas.search_space)": [[88, "modelopt.torch.nas.search_space.SearchSpace"]], "__init__() (searchspace method)": [[88, "modelopt.torch.nas.search_space.SearchSpace.__init__"]], "export() (searchspace method)": [[88, "modelopt.torch.nas.search_space.SearchSpace.export"]], "generate() (searchspace method)": [[88, "modelopt.torch.nas.search_space.SearchSpace.generate"]], "generate_search_space() (in module modelopt.torch.nas.search_space)": [[88, "modelopt.torch.nas.search_space.generate_search_space"]], "modelopt.torch.nas.search_space": [[88, "module-modelopt.torch.nas.search_space"]], "print_summary() (searchspace method)": [[88, "modelopt.torch.nas.search_space.SearchSpace.print_summary"]], "sample() (searchspace method)": [[88, "modelopt.torch.nas.search_space.SearchSpace.sample"]], "sort_parameters() (searchspace method)": [[88, "modelopt.torch.nas.search_space.SearchSpace.sort_parameters"]], "tracedhp (class in modelopt.torch.nas.traced_hp)": [[89, "modelopt.torch.nas.traced_hp.TracedHp"]], "tracedhpregistry (class in modelopt.torch.nas.traced_hp)": [[89, "modelopt.torch.nas.traced_hp.TracedHpRegistry"]], "get() (tracedhpregistry class method)": [[89, "modelopt.torch.nas.traced_hp.TracedHpRegistry.get"]], "initialize_from() (tracedhp class method)": [[89, "modelopt.torch.nas.traced_hp.TracedHp.initialize_from"]], "initialize_from() (tracedhpregistry class method)": [[89, "modelopt.torch.nas.traced_hp.TracedHpRegistry.initialize_from"]], "modelopt.torch.nas.traced_hp": [[89, "module-modelopt.torch.nas.traced_hp"]], "register() (tracedhpregistry class method)": [[89, "modelopt.torch.nas.traced_hp.TracedHpRegistry.register"]], "resolve_dependencies() (tracedhp method)": [[89, "modelopt.torch.nas.traced_hp.TracedHp.resolve_dependencies"]], "unregister() (tracedhpregistry class method)": [[89, "modelopt.torch.nas.traced_hp.TracedHpRegistry.unregister"]], "__init__() (enable_modelopt_patches method)": [[90, "modelopt.torch.nas.utils.enable_modelopt_patches.__init__"]], "__init__() (no_modelopt_patches method)": [[90, "modelopt.torch.nas.utils.no_modelopt_patches.__init__"]], "__init__() (set_modelopt_patches_enabled method)": [[90, "modelopt.torch.nas.utils.set_modelopt_patches_enabled.__init__"]], "clone() (set_modelopt_patches_enabled method)": [[90, "modelopt.torch.nas.utils.set_modelopt_patches_enabled.clone"]], "enable_modelopt_patches (class in modelopt.torch.nas.utils)": [[90, "modelopt.torch.nas.utils.enable_modelopt_patches"]], "get_subnet_config() (in module modelopt.torch.nas.utils)": [[90, "modelopt.torch.nas.utils.get_subnet_config"]], "inference_flops() (in module modelopt.torch.nas.utils)": [[90, "modelopt.torch.nas.utils.inference_flops"]], "is_modelopt_patches_enabled() (in module modelopt.torch.nas.utils)": [[90, "modelopt.torch.nas.utils.is_modelopt_patches_enabled"]], "modelopt.torch.nas.utils": [[90, "module-modelopt.torch.nas.utils"]], "no_modelopt_patches (class in modelopt.torch.nas.utils)": [[90, "modelopt.torch.nas.utils.no_modelopt_patches"]], "print_search_space_summary() (in module modelopt.torch.nas.utils)": [[90, "modelopt.torch.nas.utils.print_search_space_summary"]], "replace_forward() (in module modelopt.torch.nas.utils)": [[90, "modelopt.torch.nas.utils.replace_forward"]], "sample() (in module modelopt.torch.nas.utils)": [[90, "modelopt.torch.nas.utils.sample"]], "select() (in module modelopt.torch.nas.utils)": [[90, "modelopt.torch.nas.utils.select"]], "set_modelopt_patches_enabled (class in modelopt.torch.nas.utils)": [[90, "modelopt.torch.nas.utils.set_modelopt_patches_enabled"]], "modelopt.torch.opt": [[91, "module-modelopt.torch.opt"]], "modeloptfield() (in module modelopt.torch.opt.config)": [[92, "modelopt.torch.opt.config.ModeloptField"]], "customize_rule() (modeloptbaserule class method)": [[92, "modelopt.torch.opt.config.ModeloptBaseRule.customize_rule"]], "get() (modeloptbaseconfig method)": [[92, "modelopt.torch.opt.config.ModeloptBaseConfig.get"]], "get_field_name_from_key() (modeloptbaseconfig method)": [[92, "modelopt.torch.opt.config.ModeloptBaseConfig.get_field_name_from_key"]], "get_kwargs_for_create_model_with_rules() (in module modelopt.torch.opt.config)": [[92, "modelopt.torch.opt.config.get_kwargs_for_create_model_with_rules"]], "get_rule_type() (modeloptbaserule class method)": [[92, "modelopt.torch.opt.config.ModeloptBaseRule.get_rule_type"]], "items() (modeloptbaseconfig method)": [[92, "modelopt.torch.opt.config.ModeloptBaseConfig.items"]], "keys() (modeloptbaseconfig method)": [[92, "modelopt.torch.opt.config.ModeloptBaseConfig.keys"]], "model_dump() (modeloptbaseconfig method)": [[92, "modelopt.torch.opt.config.ModeloptBaseConfig.model_dump"]], "model_dump_json() (modeloptbaseconfig method)": [[92, "modelopt.torch.opt.config.ModeloptBaseConfig.model_dump_json"]], "modelopt.torch.opt.config": [[92, "module-modelopt.torch.opt.config"]], "register_default() (modeloptbaseruleconfig class method)": [[92, "modelopt.torch.opt.config.ModeloptBaseRuleConfig.register_default"]], "unregister_default() (modeloptbaseruleconfig class method)": [[92, "modelopt.torch.opt.config.ModeloptBaseRuleConfig.unregister_default"]], "update() (modeloptbaseconfig method)": [[92, "modelopt.torch.opt.config.ModeloptBaseConfig.update"]], "validate_rule() (modeloptbaserule class method)": [[92, "modelopt.torch.opt.config.ModeloptBaseRule.validate_rule"]], "values() (modeloptbaseconfig method)": [[92, "modelopt.torch.opt.config.ModeloptBaseConfig.values"]], "modeloptstatemanager (class in modelopt.torch.opt.conversion)": [[93, "modelopt.torch.opt.conversion.ModeloptStateManager"]], "__init__() (modeloptstatemanager method)": [[93, "modelopt.torch.opt.conversion.ModeloptStateManager.__init__"]], "add_mode() (modeloptstatemanager method)": [[93, "modelopt.torch.opt.conversion.ModeloptStateManager.add_mode"]], "apply_mode() (in module modelopt.torch.opt.conversion)": [[93, "modelopt.torch.opt.conversion.apply_mode"]], "check_mode() (modeloptstatemanager method)": [[93, "modelopt.torch.opt.conversion.ModeloptStateManager.check_mode"]], "get_config_class() (modeloptstatemanager static method)": [[93, "modelopt.torch.opt.conversion.ModeloptStateManager.get_config_class"]], "has_state (modeloptstatemanager property)": [[93, "modelopt.torch.opt.conversion.ModeloptStateManager.has_state"]], "is_converted() (modeloptstatemanager class method)": [[93, "modelopt.torch.opt.conversion.ModeloptStateManager.is_converted"]], "last_mode (modeloptstatemanager property)": [[93, "modelopt.torch.opt.conversion.ModeloptStateManager.last_mode"]], "load_state_dict() (modeloptstatemanager method)": [[93, "modelopt.torch.opt.conversion.ModeloptStateManager.load_state_dict"]], "modelopt.torch.opt.conversion": [[93, "module-modelopt.torch.opt.conversion"]], "modelopt_state() (in module modelopt.torch.opt.conversion)": [[93, "modelopt.torch.opt.conversion.modelopt_state"]], "modes_with_states() (modeloptstatemanager method)": [[93, "modelopt.torch.opt.conversion.ModeloptStateManager.modes_with_states"]], "restore() (in module modelopt.torch.opt.conversion)": [[93, "modelopt.torch.opt.conversion.restore"]], "restore_from_modelopt_state() (in module modelopt.torch.opt.conversion)": [[93, "modelopt.torch.opt.conversion.restore_from_modelopt_state"]], "save() (in module modelopt.torch.opt.conversion)": [[93, "modelopt.torch.opt.conversion.save"]], "state_dict() (modeloptstatemanager method)": [[93, "modelopt.torch.opt.conversion.ModeloptStateManager.state_dict"]], "transfer_state_dict() (modeloptstatemanager class method)": [[93, "modelopt.torch.opt.conversion.ModeloptStateManager.transfer_state_dict"]], "update_last_state_before_new_mode() (modeloptstatemanager method)": [[93, "modelopt.torch.opt.conversion.ModeloptStateManager.update_last_state_before_new_mode"]], "update_last_state_before_save() (modeloptstatemanager method)": [[93, "modelopt.torch.opt.conversion.ModeloptStateManager.update_last_state_before_save"]], "dynamicmodule (class in modelopt.torch.opt.dynamic)": [[94, "modelopt.torch.opt.dynamic.DynamicModule"]], "dynamicspace (class in modelopt.torch.opt.dynamic)": [[94, "modelopt.torch.opt.dynamic.DynamicSpace"]], "__init__() (dynamicmodule method)": [[94, "modelopt.torch.opt.dynamic.DynamicModule.__init__"]], "__init__() (dynamicspace method)": [[94, "modelopt.torch.opt.dynamic.DynamicSpace.__init__"]], "config() (dynamicspace method)": [[94, "modelopt.torch.opt.dynamic.DynamicSpace.config"]], "convert() (dynamicmodule class method)": [[94, "modelopt.torch.opt.dynamic.DynamicModule.convert"]], "convert_to_dynamic() (dynamicspace method)": [[94, "modelopt.torch.opt.dynamic.DynamicSpace.convert_to_dynamic"]], "export() (dynamicmodule method)": [[94, "modelopt.torch.opt.dynamic.DynamicModule.export"]], "export() (dynamicspace method)": [[94, "modelopt.torch.opt.dynamic.DynamicSpace.export"]], "extra_repr() (dynamicmodule method)": [[94, "modelopt.torch.opt.dynamic.DynamicModule.extra_repr"]], "force_assign() (dynamicmodule method)": [[94, "modelopt.torch.opt.dynamic.DynamicModule.force_assign"]], "freeze() (dynamicmodule method)": [[94, "modelopt.torch.opt.dynamic.DynamicModule.freeze"]], "get_hparam() (dynamicmodule method)": [[94, "modelopt.torch.opt.dynamic.DynamicModule.get_hparam"]], "get_hparam() (dynamicspace method)": [[94, "modelopt.torch.opt.dynamic.DynamicSpace.get_hparam"]], "is_configurable() (dynamicspace method)": [[94, "modelopt.torch.opt.dynamic.DynamicSpace.is_configurable"]], "is_dynamic() (dynamicspace method)": [[94, "modelopt.torch.opt.dynamic.DynamicSpace.is_dynamic"]], "modelopt.torch.opt.dynamic": [[94, "module-modelopt.torch.opt.dynamic"]], "modify() (dynamicmodule method)": [[94, "modelopt.torch.opt.dynamic.DynamicModule.modify"]], "named_dynamic_modules() (dynamicspace method)": [[94, "modelopt.torch.opt.dynamic.DynamicSpace.named_dynamic_modules"]], "named_hparams() (dynamicmodule method)": [[94, "modelopt.torch.opt.dynamic.DynamicModule.named_hparams"]], "named_hparams() (dynamicspace method)": [[94, "modelopt.torch.opt.dynamic.DynamicSpace.named_hparams"]], "original_cls (dynamicmodule property)": [[94, "modelopt.torch.opt.dynamic.DynamicModule.original_cls"]], "reset_dynamic_attributes() (dynamicmodule method)": [[94, "modelopt.torch.opt.dynamic.DynamicModule.reset_dynamic_attributes"]], "select() (dynamicspace method)": [[94, "modelopt.torch.opt.dynamic.DynamicSpace.select"]], "size() (dynamicspace method)": [[94, "modelopt.torch.opt.dynamic.DynamicSpace.size"]], "activeslice (hparam attribute)": [[95, "modelopt.torch.opt.hparam.Hparam.ActiveSlice"]], "hparam (class in modelopt.torch.opt.hparam)": [[95, "modelopt.torch.opt.hparam.Hparam"]], "importance (hparam attribute)": [[95, "modelopt.torch.opt.hparam.Hparam.Importance"]], "importanceestimator (hparam attribute)": [[95, "modelopt.torch.opt.hparam.Hparam.ImportanceEstimator"]], "__init__() (hparam method)": [[95, "modelopt.torch.opt.hparam.Hparam.__init__"]], "active (hparam property)": [[95, "modelopt.torch.opt.hparam.Hparam.active"]], "active_slice (hparam property)": [[95, "modelopt.torch.opt.hparam.Hparam.active_slice"]], "choices (hparam property)": [[95, "modelopt.torch.opt.hparam.Hparam.choices"]], "enforce_order() (hparam method)": [[95, "modelopt.torch.opt.hparam.Hparam.enforce_order"]], "importance (hparam property)": [[95, "modelopt.torch.opt.hparam.Hparam.importance"]], "is_configurable (hparam property)": [[95, "modelopt.torch.opt.hparam.Hparam.is_configurable"]], "is_sortable (hparam property)": [[95, "modelopt.torch.opt.hparam.Hparam.is_sortable"]], "max (hparam property)": [[95, "modelopt.torch.opt.hparam.Hparam.max"]], "min (hparam property)": [[95, "modelopt.torch.opt.hparam.Hparam.min"]], "modelopt.torch.opt.hparam": [[95, "module-modelopt.torch.opt.hparam"]], "original (hparam property)": [[95, "modelopt.torch.opt.hparam.Hparam.original"]], "register_importance() (hparam method)": [[95, "modelopt.torch.opt.hparam.Hparam.register_importance"]], "modelopt.torch.opt.mode": [[96, "module-modelopt.torch.opt.mode"]], "modelopt.torch.opt.plugins": [[97, "module-modelopt.torch.opt.plugins"]], "enable_huggingface_checkpointing() (in module modelopt.torch.opt.plugins.huggingface)": [[98, "modelopt.torch.opt.plugins.huggingface.enable_huggingface_checkpointing"]], "modelopt.torch.opt.plugins.huggingface": [[98, "module-modelopt.torch.opt.plugins.huggingface"]], "basesearcher (class in modelopt.torch.opt.searcher)": [[99, "modelopt.torch.opt.searcher.BaseSearcher"]], "__init__() (basesearcher method)": [[99, "modelopt.torch.opt.searcher.BaseSearcher.__init__"]], "after_search() (basesearcher method)": [[99, "modelopt.torch.opt.searcher.BaseSearcher.after_search"]], "before_search() (basesearcher method)": [[99, "modelopt.torch.opt.searcher.BaseSearcher.before_search"]], "config (basesearcher attribute)": [[99, "modelopt.torch.opt.searcher.BaseSearcher.config"]], "constraints (basesearcher attribute)": [[99, "modelopt.torch.opt.searcher.BaseSearcher.constraints"]], "construct_forward_loop() (basesearcher method)": [[99, "modelopt.torch.opt.searcher.BaseSearcher.construct_forward_loop"]], "default_search_config (basesearcher property)": [[99, "modelopt.torch.opt.searcher.BaseSearcher.default_search_config"]], "default_state_dict (basesearcher property)": [[99, "modelopt.torch.opt.searcher.BaseSearcher.default_state_dict"]], "deployment (basesearcher attribute)": [[99, "modelopt.torch.opt.searcher.BaseSearcher.deployment"]], "dummy_input (basesearcher attribute)": [[99, "modelopt.torch.opt.searcher.BaseSearcher.dummy_input"]], "eval_score() (basesearcher method)": [[99, "modelopt.torch.opt.searcher.BaseSearcher.eval_score"]], "forward_loop (basesearcher attribute)": [[99, "modelopt.torch.opt.searcher.BaseSearcher.forward_loop"]], "has_score (basesearcher property)": [[99, "modelopt.torch.opt.searcher.BaseSearcher.has_score"]], "load_search_checkpoint() (basesearcher method)": [[99, "modelopt.torch.opt.searcher.BaseSearcher.load_search_checkpoint"]], "model (basesearcher attribute)": [[99, "modelopt.torch.opt.searcher.BaseSearcher.model"]], "modelopt.torch.opt.searcher": [[99, "module-modelopt.torch.opt.searcher"]], "reset_search() (basesearcher method)": [[99, "modelopt.torch.opt.searcher.BaseSearcher.reset_search"]], "run_search() (basesearcher method)": [[99, "modelopt.torch.opt.searcher.BaseSearcher.run_search"]], "sanitize_search_config() (basesearcher method)": [[99, "modelopt.torch.opt.searcher.BaseSearcher.sanitize_search_config"]], "save_search_checkpoint() (basesearcher method)": [[99, "modelopt.torch.opt.searcher.BaseSearcher.save_search_checkpoint"]], "search() (basesearcher method)": [[99, "modelopt.torch.opt.searcher.BaseSearcher.search"]], "state_dict() (basesearcher method)": [[99, "modelopt.torch.opt.searcher.BaseSearcher.state_dict"]], "get_hparam() (in module modelopt.torch.opt.utils)": [[100, "modelopt.torch.opt.utils.get_hparam"]], "is_configurable() (in module modelopt.torch.opt.utils)": [[100, "modelopt.torch.opt.utils.is_configurable"]], "is_dynamic() (in module modelopt.torch.opt.utils)": [[100, "modelopt.torch.opt.utils.is_dynamic"]], "modelopt.torch.opt.utils": [[100, "module-modelopt.torch.opt.utils"]], "named_dynamic_modules() (in module modelopt.torch.opt.utils)": [[100, "modelopt.torch.opt.utils.named_dynamic_modules"]], "named_hparams() (in module modelopt.torch.opt.utils)": [[100, "modelopt.torch.opt.utils.named_hparams"]], "search_space_size() (in module modelopt.torch.opt.utils)": [[100, "modelopt.torch.opt.utils.search_space_size"]], "modelopt.torch.prune": [[101, "module-modelopt.torch.prune"]], "modelopt.torch.prune.config": [[102, "module-modelopt.torch.prune.config"]], "nn_batchnorm1d (fastnasconfig attribute)": [[102, "modelopt.torch.prune.config.FastNASConfig.nn_batchnorm1d"]], "nn_batchnorm1d (gradnasconfig attribute)": [[102, "modelopt.torch.prune.config.GradNASConfig.nn_batchnorm1d"]], "nn_batchnorm2d (fastnasconfig attribute)": [[102, "modelopt.torch.prune.config.FastNASConfig.nn_batchnorm2d"]], "nn_batchnorm2d (gradnasconfig attribute)": [[102, "modelopt.torch.prune.config.GradNASConfig.nn_batchnorm2d"]], "nn_batchnorm3d (fastnasconfig attribute)": [[102, "modelopt.torch.prune.config.FastNASConfig.nn_batchnorm3d"]], "nn_batchnorm3d (gradnasconfig attribute)": [[102, "modelopt.torch.prune.config.GradNASConfig.nn_batchnorm3d"]], "nn_conv1d (fastnasconfig attribute)": [[102, "modelopt.torch.prune.config.FastNASConfig.nn_conv1d"]], "nn_conv1d (gradnasconfig attribute)": [[102, "modelopt.torch.prune.config.GradNASConfig.nn_conv1d"]], "nn_conv2d (fastnasconfig attribute)": [[102, "modelopt.torch.prune.config.FastNASConfig.nn_conv2d"]], "nn_conv2d (gradnasconfig attribute)": [[102, "modelopt.torch.prune.config.GradNASConfig.nn_conv2d"]], "nn_conv3d (fastnasconfig attribute)": [[102, "modelopt.torch.prune.config.FastNASConfig.nn_conv3d"]], "nn_conv3d (gradnasconfig attribute)": [[102, "modelopt.torch.prune.config.GradNASConfig.nn_conv3d"]], "nn_convtranspose1d (fastnasconfig attribute)": [[102, "modelopt.torch.prune.config.FastNASConfig.nn_convtranspose1d"]], "nn_convtranspose1d (gradnasconfig attribute)": [[102, "modelopt.torch.prune.config.GradNASConfig.nn_convtranspose1d"]], "nn_convtranspose2d (fastnasconfig attribute)": [[102, "modelopt.torch.prune.config.FastNASConfig.nn_convtranspose2d"]], "nn_convtranspose2d (gradnasconfig attribute)": [[102, "modelopt.torch.prune.config.GradNASConfig.nn_convtranspose2d"]], "nn_convtranspose3d (fastnasconfig attribute)": [[102, "modelopt.torch.prune.config.FastNASConfig.nn_convtranspose3d"]], "nn_convtranspose3d (gradnasconfig attribute)": [[102, "modelopt.torch.prune.config.GradNASConfig.nn_convtranspose3d"]], "nn_groupnorm (fastnasconfig attribute)": [[102, "modelopt.torch.prune.config.FastNASConfig.nn_groupnorm"]], "nn_groupnorm (gradnasconfig attribute)": [[102, "modelopt.torch.prune.config.GradNASConfig.nn_groupnorm"]], "nn_instancenorm1d (fastnasconfig attribute)": [[102, "modelopt.torch.prune.config.FastNASConfig.nn_instancenorm1d"]], "nn_instancenorm1d (gradnasconfig attribute)": [[102, "modelopt.torch.prune.config.GradNASConfig.nn_instancenorm1d"]], "nn_instancenorm2d (fastnasconfig attribute)": [[102, "modelopt.torch.prune.config.FastNASConfig.nn_instancenorm2d"]], "nn_instancenorm2d (gradnasconfig attribute)": [[102, "modelopt.torch.prune.config.GradNASConfig.nn_instancenorm2d"]], "nn_instancenorm3d (fastnasconfig attribute)": [[102, "modelopt.torch.prune.config.FastNASConfig.nn_instancenorm3d"]], "nn_instancenorm3d (gradnasconfig attribute)": [[102, "modelopt.torch.prune.config.GradNASConfig.nn_instancenorm3d"]], "nn_layernorm (fastnasconfig attribute)": [[102, "modelopt.torch.prune.config.FastNASConfig.nn_layernorm"]], "nn_layernorm (gradnasconfig attribute)": [[102, "modelopt.torch.prune.config.GradNASConfig.nn_layernorm"]], "nn_linear (fastnasconfig attribute)": [[102, "modelopt.torch.prune.config.FastNASConfig.nn_linear"]], "nn_linear (gradnasconfig attribute)": [[102, "modelopt.torch.prune.config.GradNASConfig.nn_linear"]], "nn_syncbatchnorm (fastnasconfig attribute)": [[102, "modelopt.torch.prune.config.FastNASConfig.nn_syncbatchnorm"]], "nn_syncbatchnorm (gradnasconfig attribute)": [[102, "modelopt.torch.prune.config.GradNASConfig.nn_syncbatchnorm"]], "binarysearcher (class in modelopt.torch.prune.fastnas)": [[103, "modelopt.torch.prune.fastnas.BinarySearcher"]], "fastnaspatchmanager (class in modelopt.torch.prune.fastnas)": [[103, "modelopt.torch.prune.fastnas.FastNASPatchManager"]], "after_step() (binarysearcher method)": [[103, "modelopt.torch.prune.fastnas.BinarySearcher.after_step"]], "before_search() (binarysearcher method)": [[103, "modelopt.torch.prune.fastnas.BinarySearcher.before_search"]], "before_step() (binarysearcher method)": [[103, "modelopt.torch.prune.fastnas.BinarySearcher.before_step"]], "convert_fastnas_searchspace() (in module modelopt.torch.prune.fastnas)": [[103, "modelopt.torch.prune.fastnas.convert_fastnas_searchspace"]], "default_state_dict (binarysearcher property)": [[103, "modelopt.torch.prune.fastnas.BinarySearcher.default_state_dict"]], "early_stop() (binarysearcher method)": [[103, "modelopt.torch.prune.fastnas.BinarySearcher.early_stop"]], "hparam_names_for_search (binarysearcher property)": [[103, "modelopt.torch.prune.fastnas.BinarySearcher.hparam_names_for_search"]], "hparam_types_for_search (binarysearcher property)": [[103, "modelopt.torch.prune.fastnas.BinarySearcher.hparam_types_for_search"]], "load_search_checkpoint() (binarysearcher method)": [[103, "modelopt.torch.prune.fastnas.BinarySearcher.load_search_checkpoint"]], "max_degrade (binarysearcher attribute)": [[103, "modelopt.torch.prune.fastnas.BinarySearcher.max_degrade"]], "middle_value (binarysearcher attribute)": [[103, "modelopt.torch.prune.fastnas.BinarySearcher.middle_value"]], "min_degrade (binarysearcher attribute)": [[103, "modelopt.torch.prune.fastnas.BinarySearcher.min_degrade"]], "modelopt.torch.prune.fastnas": [[103, "module-modelopt.torch.prune.fastnas"]], "original_score (binarysearcher attribute)": [[103, "modelopt.torch.prune.fastnas.BinarySearcher.original_score"]], "restore_fastnas_searchspace() (in module modelopt.torch.prune.fastnas)": [[103, "modelopt.torch.prune.fastnas.restore_fastnas_searchspace"]], "sample() (binarysearcher method)": [[103, "modelopt.torch.prune.fastnas.BinarySearcher.sample"]], "sample_during_training (fastnaspatchmanager property)": [[103, "modelopt.torch.prune.fastnas.FastNASPatchManager.sample_during_training"]], "sensitivity_map (binarysearcher attribute)": [[103, "modelopt.torch.prune.fastnas.BinarySearcher.sensitivity_map"]], "gradientbinarysearcher (class in modelopt.torch.prune.gradnas)": [[104, "modelopt.torch.prune.gradnas.GradientBinarySearcher"]], "gradientdatamanager (class in modelopt.torch.prune.gradnas)": [[104, "modelopt.torch.prune.gradnas.GradientDataManager"]], "setup_gradient_func (gradientbinarysearcher attribute)": [[104, "modelopt.torch.prune.gradnas.GradientBinarySearcher.SETUP_GRADIENT_FUNC"]], "__init__() (gradientdatamanager method)": [[104, "modelopt.torch.prune.gradnas.GradientDataManager.__init__"]], "before_search() (gradientbinarysearcher method)": [[104, "modelopt.torch.prune.gradnas.GradientBinarySearcher.before_search"]], "default_search_config (gradientbinarysearcher property)": [[104, "modelopt.torch.prune.gradnas.GradientBinarySearcher.default_search_config"]], "gradnas_score_func() (gradientbinarysearcher static method)": [[104, "modelopt.torch.prune.gradnas.GradientBinarySearcher.gradnas_score_func"]], "hparam_names_for_search (gradientbinarysearcher property)": [[104, "modelopt.torch.prune.gradnas.GradientBinarySearcher.hparam_names_for_search"]], "modelopt.torch.prune.gradnas": [[104, "module-modelopt.torch.prune.gradnas"]], "process_gradient() (gradientdatamanager method)": [[104, "modelopt.torch.prune.gradnas.GradientDataManager.process_gradient"]], "sanitize_search_config() (gradientbinarysearcher method)": [[104, "modelopt.torch.prune.gradnas.GradientBinarySearcher.sanitize_search_config"]], "score (gradientdatamanager property)": [[104, "modelopt.torch.prune.gradnas.GradientDataManager.score"]], "mcoregptminitronsearcher (class in modelopt.torch.prune.mcore_gpt_minitron)": [[105, "modelopt.torch.prune.mcore_gpt_minitron.MCoreGPTMinitronSearcher"]], "supported_hparams (mcoregptminitronsearcher attribute)": [[105, "modelopt.torch.prune.mcore_gpt_minitron.MCoreGPTMinitronSearcher.SUPPORTED_HPARAMS"]], "before_search() (mcoregptminitronsearcher method)": [[105, "modelopt.torch.prune.mcore_gpt_minitron.MCoreGPTMinitronSearcher.before_search"]], "default_search_config (mcoregptminitronsearcher property)": [[105, "modelopt.torch.prune.mcore_gpt_minitron.MCoreGPTMinitronSearcher.default_search_config"]], "default_state_dict (mcoregptminitronsearcher property)": [[105, "modelopt.torch.prune.mcore_gpt_minitron.MCoreGPTMinitronSearcher.default_state_dict"]], "modelopt.torch.prune.mcore_gpt_minitron": [[105, "module-modelopt.torch.prune.mcore_gpt_minitron"]], "run_search() (mcoregptminitronsearcher method)": [[105, "modelopt.torch.prune.mcore_gpt_minitron.MCoreGPTMinitronSearcher.run_search"]], "sanitize_search_config() (mcoregptminitronsearcher method)": [[105, "modelopt.torch.prune.mcore_gpt_minitron.MCoreGPTMinitronSearcher.sanitize_search_config"]], "fastnasmodedescriptor (class in modelopt.torch.prune.mode)": [[106, "modelopt.torch.prune.mode.FastNASModeDescriptor"]], "gradnasmodedescriptor (class in modelopt.torch.prune.mode)": [[106, "modelopt.torch.prune.mode.GradNASModeDescriptor"]], "mcoregptminitronmodedescriptor (class in modelopt.torch.prune.mode)": [[106, "modelopt.torch.prune.mode.MCoreGPTMinitronModeDescriptor"]], "config_class (fastnasmodedescriptor property)": [[106, "modelopt.torch.prune.mode.FastNASModeDescriptor.config_class"]], "config_class (gradnasmodedescriptor property)": [[106, "modelopt.torch.prune.mode.GradNASModeDescriptor.config_class"]], "config_class (mcoregptminitronmodedescriptor property)": [[106, "modelopt.torch.prune.mode.MCoreGPTMinitronModeDescriptor.config_class"]], "convert (fastnasmodedescriptor property)": [[106, "modelopt.torch.prune.mode.FastNASModeDescriptor.convert"]], "export_mode (fastnasmodedescriptor property)": [[106, "modelopt.torch.prune.mode.FastNASModeDescriptor.export_mode"]], "modelopt.torch.prune.mode": [[106, "module-modelopt.torch.prune.mode"]], "name (fastnasmodedescriptor property)": [[106, "modelopt.torch.prune.mode.FastNASModeDescriptor.name"]], "name (gradnasmodedescriptor property)": [[106, "modelopt.torch.prune.mode.GradNASModeDescriptor.name"]], "name (mcoregptminitronmodedescriptor property)": [[106, "modelopt.torch.prune.mode.MCoreGPTMinitronModeDescriptor.name"]], "next_modes (fastnasmodedescriptor property)": [[106, "modelopt.torch.prune.mode.FastNASModeDescriptor.next_modes"]], "restore (fastnasmodedescriptor property)": [[106, "modelopt.torch.prune.mode.FastNASModeDescriptor.restore"]], "search_algorithm (fastnasmodedescriptor property)": [[106, "modelopt.torch.prune.mode.FastNASModeDescriptor.search_algorithm"]], "search_algorithm (gradnasmodedescriptor property)": [[106, "modelopt.torch.prune.mode.GradNASModeDescriptor.search_algorithm"]], "search_algorithm (mcoregptminitronmodedescriptor property)": [[106, "modelopt.torch.prune.mode.MCoreGPTMinitronModeDescriptor.search_algorithm"]], "update_for_new_mode (fastnasmodedescriptor property)": [[106, "modelopt.torch.prune.mode.FastNASModeDescriptor.update_for_new_mode"]], "update_for_save (fastnasmodedescriptor property)": [[106, "modelopt.torch.prune.mode.FastNASModeDescriptor.update_for_save"]], "modelopt.torch.prune.plugins": [[107, "module-modelopt.torch.prune.plugins"]], "modelopt.torch.prune.pruning": [[108, "module-modelopt.torch.prune.pruning"]], "prune() (in module modelopt.torch.prune.pruning)": [[108, "modelopt.torch.prune.pruning.prune"]], "modelopt.torch.quantization": [[109, "module-modelopt.torch.quantization"]], "autoquantizesearcher (class in modelopt.torch.quantization.algorithms)": [[110, "modelopt.torch.quantization.algorithms.AutoQuantizeSearcher"]], "quantrecipe (class in modelopt.torch.quantization.algorithms)": [[110, "modelopt.torch.quantization.algorithms.QuantRecipe"]], "quantrecipehparam (class in modelopt.torch.quantization.algorithms)": [[110, "modelopt.torch.quantization.algorithms.QuantRecipeHparam"]], "__init__() (quantrecipe method)": [[110, "modelopt.torch.quantization.algorithms.QuantRecipe.__init__"]], "__init__() (quantrecipehparam method)": [[110, "modelopt.torch.quantization.algorithms.QuantRecipeHparam.__init__"]], "active (quantrecipehparam property)": [[110, "modelopt.torch.quantization.algorithms.QuantRecipeHparam.active"]], "before_search() (autoquantizesearcher method)": [[110, "modelopt.torch.quantization.algorithms.AutoQuantizeSearcher.before_search"]], "best (autoquantizesearcher attribute)": [[110, "modelopt.torch.quantization.algorithms.AutoQuantizeSearcher.best"]], "candidate_stats (autoquantizesearcher attribute)": [[110, "modelopt.torch.quantization.algorithms.AutoQuantizeSearcher.candidate_stats"]], "compression (quantrecipe property)": [[110, "modelopt.torch.quantization.algorithms.QuantRecipe.compression"]], "config (quantrecipe property)": [[110, "modelopt.torch.quantization.algorithms.QuantRecipe.config"]], "default_search_config (autoquantizesearcher property)": [[110, "modelopt.torch.quantization.algorithms.AutoQuantizeSearcher.default_search_config"]], "default_state_dict (autoquantizesearcher property)": [[110, "modelopt.torch.quantization.algorithms.AutoQuantizeSearcher.default_state_dict"]], "disable_folding_pqs_to_weights() (quantrecipe static method)": [[110, "modelopt.torch.quantization.algorithms.QuantRecipe.disable_folding_pqs_to_weights"]], "fold_pqs_to_weights() (quantrecipe static method)": [[110, "modelopt.torch.quantization.algorithms.QuantRecipe.fold_pqs_to_weights"]], "gradient_checkpointing_enable_contexts (autoquantizesearcher attribute)": [[110, "modelopt.torch.quantization.algorithms.AutoQuantizeSearcher.gradient_checkpointing_enable_contexts"]], "importance (quantrecipehparam property)": [[110, "modelopt.torch.quantization.algorithms.QuantRecipeHparam.importance"]], "insert_hparams_after_merge_rules() (autoquantizesearcher class method)": [[110, "modelopt.torch.quantization.algorithms.AutoQuantizeSearcher.insert_hparams_after_merge_rules"]], "modelopt.torch.quantization.algorithms": [[110, "module-modelopt.torch.quantization.algorithms"]], "num_bits (quantrecipe property)": [[110, "modelopt.torch.quantization.algorithms.QuantRecipe.num_bits"]], "register_gradient_checkpointing_enable_context() (autoquantizesearcher class method)": [[110, "modelopt.torch.quantization.algorithms.AutoQuantizeSearcher.register_gradient_checkpointing_enable_context"]], "rules (autoquantizesearcher attribute)": [[110, "modelopt.torch.quantization.algorithms.AutoQuantizeSearcher.rules"]], "run_search() (autoquantizesearcher method)": [[110, "modelopt.torch.quantization.algorithms.AutoQuantizeSearcher.run_search"]], "sanitize_search_config() (autoquantizesearcher method)": [[110, "modelopt.torch.quantization.algorithms.AutoQuantizeSearcher.sanitize_search_config"]], "modelopt.torch.quantization.calib": [[111, "module-modelopt.torch.quantization.calib"]], "modelopt.torch.quantization.calib.calibrator": [[112, "module-modelopt.torch.quantization.calib.calibrator"]], "histogramcalibrator (class in modelopt.torch.quantization.calib.histogram)": [[113, "modelopt.torch.quantization.calib.histogram.HistogramCalibrator"]], "__init__() (histogramcalibrator method)": [[113, "modelopt.torch.quantization.calib.histogram.HistogramCalibrator.__init__"]], "calibrate_weights() (in module modelopt.torch.quantization.calib.histogram)": [[113, "modelopt.torch.quantization.calib.histogram.calibrate_weights"]], "collect() (histogramcalibrator method)": [[113, "modelopt.torch.quantization.calib.histogram.HistogramCalibrator.collect"]], "compute_amax() (histogramcalibrator method)": [[113, "modelopt.torch.quantization.calib.histogram.HistogramCalibrator.compute_amax"]], "modelopt.torch.quantization.calib.histogram": [[113, "module-modelopt.torch.quantization.calib.histogram"]], "reset() (histogramcalibrator method)": [[113, "modelopt.torch.quantization.calib.histogram.HistogramCalibrator.reset"]], "maxcalibrator (class in modelopt.torch.quantization.calib.max)": [[114, "modelopt.torch.quantization.calib.max.MaxCalibrator"]], "__init__() (maxcalibrator method)": [[114, "modelopt.torch.quantization.calib.max.MaxCalibrator.__init__"]], "amaxs (maxcalibrator property)": [[114, "modelopt.torch.quantization.calib.max.MaxCalibrator.amaxs"]], "collect() (maxcalibrator method)": [[114, "modelopt.torch.quantization.calib.max.MaxCalibrator.collect"]], "compute_amax() (maxcalibrator method)": [[114, "modelopt.torch.quantization.calib.max.MaxCalibrator.compute_amax"]], "modelopt.torch.quantization.calib.max": [[114, "module-modelopt.torch.quantization.calib.max"]], "reset() (maxcalibrator method)": [[114, "modelopt.torch.quantization.calib.max.MaxCalibrator.reset"]], "additional_algorithm (realquantizeconfig attribute)": [[115, "modelopt.torch.quantization.config.RealQuantizeConfig.additional_algorithm"]], "algorithm (quantizeconfig attribute)": [[115, "modelopt.torch.quantization.config.QuantizeConfig.algorithm"]], "alpha (smoothquantcalibconfig attribute)": [[115, "modelopt.torch.quantization.config.SmoothQuantCalibConfig.alpha"]], "alpha_step (awqlitecalibconfig attribute)": [[115, "modelopt.torch.quantization.config.AWQLiteCalibConfig.alpha_step"]], "axis (quantizerattributeconfig attribute)": [[115, "modelopt.torch.quantization.config.QuantizerAttributeConfig.axis"]], "block_sizes (quantizerattributeconfig attribute)": [[115, "modelopt.torch.quantization.config.QuantizerAttributeConfig.block_sizes"]], "calibrator (quantizerattributeconfig attribute)": [[115, "modelopt.torch.quantization.config.QuantizerAttributeConfig.calibrator"]], "debug (awqclipcalibconfig attribute)": [[115, "modelopt.torch.quantization.config.AWQClipCalibConfig.debug"]], "debug (awqfullcalibconfig attribute)": [[115, "modelopt.torch.quantization.config.AWQFullCalibConfig.debug"]], "debug (awqlitecalibconfig attribute)": [[115, "modelopt.torch.quantization.config.AWQLiteCalibConfig.debug"]], "enable (quantizerattributeconfig attribute)": [[115, "modelopt.torch.quantization.config.QuantizerAttributeConfig.enable"]], "fake_quant (quantizerattributeconfig attribute)": [[115, "modelopt.torch.quantization.config.QuantizerAttributeConfig.fake_quant"]], "learn_amax (quantizerattributeconfig attribute)": [[115, "modelopt.torch.quantization.config.QuantizerAttributeConfig.learn_amax"]], "max_co_batch_size (awqclipcalibconfig attribute)": [[115, "modelopt.torch.quantization.config.AWQClipCalibConfig.max_co_batch_size"]], "max_tokens_per_batch (awqclipcalibconfig attribute)": [[115, "modelopt.torch.quantization.config.AWQClipCalibConfig.max_tokens_per_batch"]], "method (quantizealgorithmconfig attribute)": [[115, "modelopt.torch.quantization.config.QuantizeAlgorithmConfig.method"]], "min_clip_ratio (awqclipcalibconfig attribute)": [[115, "modelopt.torch.quantization.config.AWQClipCalibConfig.min_clip_ratio"]], "modelopt.torch.quantization.config": [[115, "module-modelopt.torch.quantization.config"]], "narrow_range (quantizerattributeconfig attribute)": [[115, "modelopt.torch.quantization.config.QuantizerAttributeConfig.narrow_range"]], "num_bits (quantizerattributeconfig attribute)": [[115, "modelopt.torch.quantization.config.QuantizerAttributeConfig.num_bits"]], "quant_cfg (quantizeconfig attribute)": [[115, "modelopt.torch.quantization.config.QuantizeConfig.quant_cfg"]], "shrink_step (awqclipcalibconfig attribute)": [[115, "modelopt.torch.quantization.config.AWQClipCalibConfig.shrink_step"]], "trt_high_precision_dtype (quantizerattributeconfig attribute)": [[115, "modelopt.torch.quantization.config.QuantizerAttributeConfig.trt_high_precision_dtype"]], "type (quantizerattributeconfig attribute)": [[115, "modelopt.torch.quantization.config.QuantizerAttributeConfig.type"]], "unsigned (quantizerattributeconfig attribute)": [[115, "modelopt.torch.quantization.config.QuantizerAttributeConfig.unsigned"]], "modelopt.torch.quantization.conversion": [[116, "module-modelopt.torch.quantization.conversion"]], "register() (in module modelopt.torch.quantization.conversion)": [[116, "modelopt.torch.quantization.conversion.register"]], "replace_quant_module() (in module modelopt.torch.quantization.conversion)": [[116, "modelopt.torch.quantization.conversion.replace_quant_module"]], "set_quantizer_attribute() (in module modelopt.torch.quantization.conversion)": [[116, "modelopt.torch.quantization.conversion.set_quantizer_attribute"]], "set_quantizer_by_cfg() (in module modelopt.torch.quantization.conversion)": [[116, "modelopt.torch.quantization.conversion.set_quantizer_by_cfg"]], "set_quantizer_by_cfg_context() (in module modelopt.torch.quantization.conversion)": [[116, "modelopt.torch.quantization.conversion.set_quantizer_by_cfg_context"]], "unregister() (in module modelopt.torch.quantization.conversion)": [[116, "modelopt.torch.quantization.conversion.unregister"]], "export_fp8() (in module modelopt.torch.quantization.export_onnx)": [[117, "modelopt.torch.quantization.export_onnx.export_fp8"]], "export_int8() (in module modelopt.torch.quantization.export_onnx)": [[117, "modelopt.torch.quantization.export_onnx.export_int8"]], "modelopt.torch.quantization.export_onnx": [[117, "module-modelopt.torch.quantization.export_onnx"]], "get_cuda_ext() (in module modelopt.torch.quantization.extensions)": [[118, "modelopt.torch.quantization.extensions.get_cuda_ext"]], "get_cuda_ext_fp8() (in module modelopt.torch.quantization.extensions)": [[118, "modelopt.torch.quantization.extensions.get_cuda_ext_fp8"]], "get_cuda_ext_mx() (in module modelopt.torch.quantization.extensions)": [[118, "modelopt.torch.quantization.extensions.get_cuda_ext_mx"]], "modelopt.torch.quantization.extensions": [[118, "module-modelopt.torch.quantization.extensions"]], "precompile() (in module modelopt.torch.quantization.extensions)": [[118, "modelopt.torch.quantization.extensions.precompile"]], "quantizeexportmodedescriptor (class in modelopt.torch.quantization.mode)": [[119, "modelopt.torch.quantization.mode.QuantizeExportModeDescriptor"]], "quantizemodedescriptor (class in modelopt.torch.quantization.mode)": [[119, "modelopt.torch.quantization.mode.QuantizeModeDescriptor"]], "config_class (quantizeexportmodedescriptor property)": [[119, "modelopt.torch.quantization.mode.QuantizeExportModeDescriptor.config_class"]], "config_class (quantizemodedescriptor property)": [[119, "modelopt.torch.quantization.mode.QuantizeModeDescriptor.config_class"]], "convert (quantizeexportmodedescriptor property)": [[119, "modelopt.torch.quantization.mode.QuantizeExportModeDescriptor.convert"]], "convert (quantizemodedescriptor property)": [[119, "modelopt.torch.quantization.mode.QuantizeModeDescriptor.convert"]], "export_mode (quantizemodedescriptor property)": [[119, "modelopt.torch.quantization.mode.QuantizeModeDescriptor.export_mode"]], "is_export_mode (quantizeexportmodedescriptor property)": [[119, "modelopt.torch.quantization.mode.QuantizeExportModeDescriptor.is_export_mode"]], "modelopt.torch.quantization.mode": [[119, "module-modelopt.torch.quantization.mode"]], "name (quantizeexportmodedescriptor property)": [[119, "modelopt.torch.quantization.mode.QuantizeExportModeDescriptor.name"]], "name (quantizemodedescriptor property)": [[119, "modelopt.torch.quantization.mode.QuantizeModeDescriptor.name"]], "next_modes (quantizemodedescriptor property)": [[119, "modelopt.torch.quantization.mode.QuantizeModeDescriptor.next_modes"]], "restore (quantizeexportmodedescriptor property)": [[119, "modelopt.torch.quantization.mode.QuantizeExportModeDescriptor.restore"]], "restore (quantizemodedescriptor property)": [[119, "modelopt.torch.quantization.mode.QuantizeModeDescriptor.restore"]], "update_for_new_mode (quantizemodedescriptor property)": [[119, "modelopt.torch.quantization.mode.QuantizeModeDescriptor.update_for_new_mode"]], "update_for_save (quantizemodedescriptor property)": [[119, "modelopt.torch.quantization.mode.QuantizeModeDescriptor.update_for_save"]], "calibrate() (in module modelopt.torch.quantization.model_calib)": [[120, "modelopt.torch.quantization.model_calib.calibrate"]], "modelopt.torch.quantization.model_calib": [[120, "module-modelopt.torch.quantization.model_calib"]], "postprocess_amax() (in module modelopt.torch.quantization.model_calib)": [[120, "modelopt.torch.quantization.model_calib.postprocess_amax"]], "auto_quantize() (in module modelopt.torch.quantization.model_quant)": [[121, "modelopt.torch.quantization.model_quant.auto_quantize"]], "disable_quantizer() (in module modelopt.torch.quantization.model_quant)": [[121, "modelopt.torch.quantization.model_quant.disable_quantizer"]], "enable_quantizer() (in module modelopt.torch.quantization.model_quant)": [[121, "modelopt.torch.quantization.model_quant.enable_quantizer"]], "fold_weight() (in module modelopt.torch.quantization.model_quant)": [[121, "modelopt.torch.quantization.model_quant.fold_weight"]], "modelopt.torch.quantization.model_quant": [[121, "module-modelopt.torch.quantization.model_quant"]], "print_quant_summary() (in module modelopt.torch.quantization.model_quant)": [[121, "modelopt.torch.quantization.model_quant.print_quant_summary"]], "quantize() (in module modelopt.torch.quantization.model_quant)": [[121, "modelopt.torch.quantization.model_quant.quantize"]], "modelopt.torch.quantization.nn": [[122, "module-modelopt.torch.quantization.nn"]], "clipfunction (class in modelopt.torch.quantization.nn.functional)": [[123, "modelopt.torch.quantization.nn.functional.ClipFunction"]], "backward() (clipfunction static method)": [[123, "modelopt.torch.quantization.nn.functional.ClipFunction.backward"]], "forward() (clipfunction static method)": [[123, "modelopt.torch.quantization.nn.functional.ClipFunction.forward"]], "modelopt.torch.quantization.nn.functional": [[123, "module-modelopt.torch.quantization.nn.functional"]], "modelopt.torch.quantization.nn.modules": [[124, "module-modelopt.torch.quantization.nn.modules"]], "clip (class in modelopt.torch.quantization.nn.modules.clip)": [[125, "modelopt.torch.quantization.nn.modules.clip.Clip"]], "__init__() (clip method)": [[125, "modelopt.torch.quantization.nn.modules.clip.Clip.__init__"]], "forward() (clip method)": [[125, "modelopt.torch.quantization.nn.modules.clip.Clip.forward"]], "modelopt.torch.quantization.nn.modules.clip": [[125, "module-modelopt.torch.quantization.nn.modules.clip"]], "modelopt.torch.quantization.nn.modules.quant_activations": [[126, "module-modelopt.torch.quantization.nn.modules.quant_activations"]], "modelopt.torch.quantization.nn.modules.quant_batchnorm": [[127, "module-modelopt.torch.quantization.nn.modules.quant_batchnorm"]], "conv1d (in module modelopt.torch.quantization.nn.modules.quant_conv)": [[128, "modelopt.torch.quantization.nn.modules.quant_conv.Conv1d"]], "conv2d (in module modelopt.torch.quantization.nn.modules.quant_conv)": [[128, "modelopt.torch.quantization.nn.modules.quant_conv.Conv2d"]], "conv3d (in module modelopt.torch.quantization.nn.modules.quant_conv)": [[128, "modelopt.torch.quantization.nn.modules.quant_conv.Conv3d"]], "convtranspose1d (in module modelopt.torch.quantization.nn.modules.quant_conv)": [[128, "modelopt.torch.quantization.nn.modules.quant_conv.ConvTranspose1d"]], "convtranspose2d (in module modelopt.torch.quantization.nn.modules.quant_conv)": [[128, "modelopt.torch.quantization.nn.modules.quant_conv.ConvTranspose2d"]], "convtranspose3d (in module modelopt.torch.quantization.nn.modules.quant_conv)": [[128, "modelopt.torch.quantization.nn.modules.quant_conv.ConvTranspose3d"]], "quantconv1d (class in modelopt.torch.quantization.nn.modules.quant_conv)": [[128, "modelopt.torch.quantization.nn.modules.quant_conv.QuantConv1d"]], "quantconv2d (class in modelopt.torch.quantization.nn.modules.quant_conv)": [[128, "modelopt.torch.quantization.nn.modules.quant_conv.QuantConv2d"]], "quantconv3d (class in modelopt.torch.quantization.nn.modules.quant_conv)": [[128, "modelopt.torch.quantization.nn.modules.quant_conv.QuantConv3d"]], "quantconvtranspose1d (class in modelopt.torch.quantization.nn.modules.quant_conv)": [[128, "modelopt.torch.quantization.nn.modules.quant_conv.QuantConvTranspose1d"]], "quantconvtranspose2d (class in modelopt.torch.quantization.nn.modules.quant_conv)": [[128, "modelopt.torch.quantization.nn.modules.quant_conv.QuantConvTranspose2d"]], "quantconvtranspose3d (class in modelopt.torch.quantization.nn.modules.quant_conv)": [[128, "modelopt.torch.quantization.nn.modules.quant_conv.QuantConvTranspose3d"]], "default_quant_desc_weight (quantconv1d attribute)": [[128, "modelopt.torch.quantization.nn.modules.quant_conv.QuantConv1d.default_quant_desc_weight"]], "default_quant_desc_weight (quantconv2d attribute)": [[128, "modelopt.torch.quantization.nn.modules.quant_conv.QuantConv2d.default_quant_desc_weight"]], "default_quant_desc_weight (quantconv3d attribute)": [[128, "modelopt.torch.quantization.nn.modules.quant_conv.QuantConv3d.default_quant_desc_weight"]], "default_quant_desc_weight (quantconvtranspose1d attribute)": [[128, "modelopt.torch.quantization.nn.modules.quant_conv.QuantConvTranspose1d.default_quant_desc_weight"]], "default_quant_desc_weight (quantconvtranspose2d attribute)": [[128, "modelopt.torch.quantization.nn.modules.quant_conv.QuantConvTranspose2d.default_quant_desc_weight"]], "default_quant_desc_weight (quantconvtranspose3d attribute)": [[128, "modelopt.torch.quantization.nn.modules.quant_conv.QuantConvTranspose3d.default_quant_desc_weight"]], "modelopt.torch.quantization.nn.modules.quant_conv": [[128, "module-modelopt.torch.quantization.nn.modules.quant_conv"]], "quantinstancenorm1d (class in modelopt.torch.quantization.nn.modules.quant_instancenorm)": [[129, "modelopt.torch.quantization.nn.modules.quant_instancenorm.QuantInstanceNorm1d"]], "quantinstancenorm2d (class in modelopt.torch.quantization.nn.modules.quant_instancenorm)": [[129, "modelopt.torch.quantization.nn.modules.quant_instancenorm.QuantInstanceNorm2d"]], "quantinstancenorm3d (class in modelopt.torch.quantization.nn.modules.quant_instancenorm)": [[129, "modelopt.torch.quantization.nn.modules.quant_instancenorm.QuantInstanceNorm3d"]], "modelopt.torch.quantization.nn.modules.quant_instancenorm": [[129, "module-modelopt.torch.quantization.nn.modules.quant_instancenorm"]], "linear (in module modelopt.torch.quantization.nn.modules.quant_linear)": [[130, "modelopt.torch.quantization.nn.modules.quant_linear.Linear"]], "quantlinear (class in modelopt.torch.quantization.nn.modules.quant_linear)": [[130, "modelopt.torch.quantization.nn.modules.quant_linear.QuantLinear"]], "default_quant_desc_weight (quantlinear attribute)": [[130, "modelopt.torch.quantization.nn.modules.quant_linear.QuantLinear.default_quant_desc_weight"]], "modelopt.torch.quantization.nn.modules.quant_linear": [[130, "module-modelopt.torch.quantization.nn.modules.quant_linear"]], "quantinputbase (class in modelopt.torch.quantization.nn.modules.quant_module)": [[131, "modelopt.torch.quantization.nn.modules.quant_module.QuantInputBase"]], "quantlinearconvbase (class in modelopt.torch.quantization.nn.modules.quant_module)": [[131, "modelopt.torch.quantization.nn.modules.quant_module.QuantLinearConvBase"]], "default_quant_desc_input (quantinputbase attribute)": [[131, "modelopt.torch.quantization.nn.modules.quant_module.QuantInputBase.default_quant_desc_input"]], "default_quant_desc_output (quantinputbase attribute)": [[131, "modelopt.torch.quantization.nn.modules.quant_module.QuantInputBase.default_quant_desc_output"]], "default_quant_desc_weight (quantlinearconvbase attribute)": [[131, "modelopt.torch.quantization.nn.modules.quant_module.QuantLinearConvBase.default_quant_desc_weight"]], "forward() (quantinputbase method)": [[131, "modelopt.torch.quantization.nn.modules.quant_module.QuantInputBase.forward"]], "forward() (quantlinearconvbase method)": [[131, "modelopt.torch.quantization.nn.modules.quant_module.QuantLinearConvBase.forward"]], "initialize_quantizer_with_dummy_states() (quantlinearconvbase static method)": [[131, "modelopt.torch.quantization.nn.modules.quant_module.QuantLinearConvBase.initialize_quantizer_with_dummy_states"]], "initialize_real_qtensor_with_dummy_weight() (quantlinearconvbase static method)": [[131, "modelopt.torch.quantization.nn.modules.quant_module.QuantLinearConvBase.initialize_real_qtensor_with_dummy_weight"]], "input_quantizer (quantinputbase attribute)": [[131, "modelopt.torch.quantization.nn.modules.quant_module.QuantInputBase.input_quantizer"]], "modelopt.torch.quantization.nn.modules.quant_module": [[131, "module-modelopt.torch.quantization.nn.modules.quant_module"]], "output_quantizer (quantinputbase attribute)": [[131, "modelopt.torch.quantization.nn.modules.quant_module.QuantInputBase.output_quantizer"]], "quantize_weight() (quantlinearconvbase method)": [[131, "modelopt.torch.quantization.nn.modules.quant_module.QuantLinearConvBase.quantize_weight"]], "sanitize_dummy_weight() (quantlinearconvbase static method)": [[131, "modelopt.torch.quantization.nn.modules.quant_module.QuantLinearConvBase.sanitize_dummy_weight"]], "weight_quantizer (quantlinearconvbase attribute)": [[131, "modelopt.torch.quantization.nn.modules.quant_module.QuantLinearConvBase.weight_quantizer"]], "adaptiveavgpool1d (in module modelopt.torch.quantization.nn.modules.quant_pooling)": [[132, "modelopt.torch.quantization.nn.modules.quant_pooling.AdaptiveAvgPool1d"]], "adaptiveavgpool2d (in module modelopt.torch.quantization.nn.modules.quant_pooling)": [[132, "modelopt.torch.quantization.nn.modules.quant_pooling.AdaptiveAvgPool2d"]], "adaptiveavgpool3d (in module modelopt.torch.quantization.nn.modules.quant_pooling)": [[132, "modelopt.torch.quantization.nn.modules.quant_pooling.AdaptiveAvgPool3d"]], "avgpool1d (in module modelopt.torch.quantization.nn.modules.quant_pooling)": [[132, "modelopt.torch.quantization.nn.modules.quant_pooling.AvgPool1d"]], "avgpool2d (in module modelopt.torch.quantization.nn.modules.quant_pooling)": [[132, "modelopt.torch.quantization.nn.modules.quant_pooling.AvgPool2d"]], "avgpool3d (in module modelopt.torch.quantization.nn.modules.quant_pooling)": [[132, "modelopt.torch.quantization.nn.modules.quant_pooling.AvgPool3d"]], "maxpool1d (in module modelopt.torch.quantization.nn.modules.quant_pooling)": [[132, "modelopt.torch.quantization.nn.modules.quant_pooling.MaxPool1d"]], "maxpool2d (in module modelopt.torch.quantization.nn.modules.quant_pooling)": [[132, "modelopt.torch.quantization.nn.modules.quant_pooling.MaxPool2d"]], "maxpool3d (in module modelopt.torch.quantization.nn.modules.quant_pooling)": [[132, "modelopt.torch.quantization.nn.modules.quant_pooling.MaxPool3d"]], "quantadaptiveavgpool1d (class in modelopt.torch.quantization.nn.modules.quant_pooling)": [[132, "modelopt.torch.quantization.nn.modules.quant_pooling.QuantAdaptiveAvgPool1d"]], "quantadaptiveavgpool2d (class in modelopt.torch.quantization.nn.modules.quant_pooling)": [[132, "modelopt.torch.quantization.nn.modules.quant_pooling.QuantAdaptiveAvgPool2d"]], "quantadaptiveavgpool3d (class in modelopt.torch.quantization.nn.modules.quant_pooling)": [[132, "modelopt.torch.quantization.nn.modules.quant_pooling.QuantAdaptiveAvgPool3d"]], "quantavgpool1d (class in modelopt.torch.quantization.nn.modules.quant_pooling)": [[132, "modelopt.torch.quantization.nn.modules.quant_pooling.QuantAvgPool1d"]], "quantavgpool2d (class in modelopt.torch.quantization.nn.modules.quant_pooling)": [[132, "modelopt.torch.quantization.nn.modules.quant_pooling.QuantAvgPool2d"]], "quantavgpool3d (class in modelopt.torch.quantization.nn.modules.quant_pooling)": [[132, "modelopt.torch.quantization.nn.modules.quant_pooling.QuantAvgPool3d"]], "quantmaxpool1d (class in modelopt.torch.quantization.nn.modules.quant_pooling)": [[132, "modelopt.torch.quantization.nn.modules.quant_pooling.QuantMaxPool1d"]], "quantmaxpool2d (class in modelopt.torch.quantization.nn.modules.quant_pooling)": [[132, "modelopt.torch.quantization.nn.modules.quant_pooling.QuantMaxPool2d"]], "quantmaxpool3d (class in modelopt.torch.quantization.nn.modules.quant_pooling)": [[132, "modelopt.torch.quantization.nn.modules.quant_pooling.QuantMaxPool3d"]], "modelopt.torch.quantization.nn.modules.quant_pooling": [[132, "module-modelopt.torch.quantization.nn.modules.quant_pooling"]], "quantrnnbase (class in modelopt.torch.quantization.nn.modules.quant_rnn)": [[133, "modelopt.torch.quantization.nn.modules.quant_rnn.QuantRNNBase"]], "quantrnnfullbase (class in modelopt.torch.quantization.nn.modules.quant_rnn)": [[133, "modelopt.torch.quantization.nn.modules.quant_rnn.QuantRNNFullBase"]], "rnnlayerforward (class in modelopt.torch.quantization.nn.modules.quant_rnn)": [[133, "modelopt.torch.quantization.nn.modules.quant_rnn.RNNLayerForward"]], "vfrnnforward (class in modelopt.torch.quantization.nn.modules.quant_rnn)": [[133, "modelopt.torch.quantization.nn.modules.quant_rnn.VFRNNForward"]], "__init__() (rnnlayerforward method)": [[133, "modelopt.torch.quantization.nn.modules.quant_rnn.RNNLayerForward.__init__"]], "__init__() (vfrnnforward method)": [[133, "modelopt.torch.quantization.nn.modules.quant_rnn.VFRNNForward.__init__"]], "all_input_quantizers_disabled (quantrnnbase property)": [[133, "modelopt.torch.quantization.nn.modules.quant_rnn.QuantRNNBase.all_input_quantizers_disabled"]], "default_quant_desc_input (quantrnnbase attribute)": [[133, "modelopt.torch.quantization.nn.modules.quant_rnn.QuantRNNBase.default_quant_desc_input"]], "default_quant_desc_weight (quantrnnbase attribute)": [[133, "modelopt.torch.quantization.nn.modules.quant_rnn.QuantRNNBase.default_quant_desc_weight"]], "forward() (quantrnnbase method)": [[133, "modelopt.torch.quantization.nn.modules.quant_rnn.QuantRNNBase.forward"]], "forward() (vfrnnforward method)": [[133, "modelopt.torch.quantization.nn.modules.quant_rnn.VFRNNForward.forward"]], "functionals_to_replace (quantrnnbase property)": [[133, "modelopt.torch.quantization.nn.modules.quant_rnn.QuantRNNBase.functionals_to_replace"]], "get_quantized_rnn_layer_forward() (in module modelopt.torch.quantization.nn.modules.quant_rnn)": [[133, "modelopt.torch.quantization.nn.modules.quant_rnn.get_quantized_rnn_layer_forward"]], "get_quantized_rnn_layer_variable_len_forward() (in module modelopt.torch.quantization.nn.modules.quant_rnn)": [[133, "modelopt.torch.quantization.nn.modules.quant_rnn.get_quantized_rnn_layer_variable_len_forward"]], "get_quantized_rnn_layer_variable_len_reverse_forward() (in module modelopt.torch.quantization.nn.modules.quant_rnn)": [[133, "modelopt.torch.quantization.nn.modules.quant_rnn.get_quantized_rnn_layer_variable_len_reverse_forward"]], "lstm_cell_with_proj() (in module modelopt.torch.quantization.nn.modules.quant_rnn)": [[133, "modelopt.torch.quantization.nn.modules.quant_rnn.lstm_cell_with_proj"]], "modelopt.torch.quantization.nn.modules.quant_rnn": [[133, "module-modelopt.torch.quantization.nn.modules.quant_rnn"]], "quantize_weight() (quantrnnbase method)": [[133, "modelopt.torch.quantization.nn.modules.quant_rnn.QuantRNNBase.quantize_weight"]], "quantized_cell_forward() (in module modelopt.torch.quantization.nn.modules.quant_rnn)": [[133, "modelopt.torch.quantization.nn.modules.quant_rnn.quantized_cell_forward"]], "weight_quantizer (quantrnnbase attribute)": [[133, "modelopt.torch.quantization.nn.modules.quant_rnn.QuantRNNBase.weight_quantizer"]], "sequentialquantizer (class in modelopt.torch.quantization.nn.modules.tensor_quantizer)": [[134, "modelopt.torch.quantization.nn.modules.tensor_quantizer.SequentialQuantizer"]], "tensorquantizer (class in modelopt.torch.quantization.nn.modules.tensor_quantizer)": [[134, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer"]], "__init__() (sequentialquantizer method)": [[134, "modelopt.torch.quantization.nn.modules.tensor_quantizer.SequentialQuantizer.__init__"]], "__init__() (tensorquantizer method)": [[134, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.__init__"]], "amax (tensorquantizer property)": [[134, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.amax"]], "axis (tensorquantizer property)": [[134, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.axis"]], "block_sizes (tensorquantizer property)": [[134, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.block_sizes"]], "clean_up_after_set_from_modelopt_state() (tensorquantizer method)": [[134, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.clean_up_after_set_from_modelopt_state"]], "dequantize() (tensorquantizer method)": [[134, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.dequantize"]], "disable() (sequentialquantizer method)": [[134, "modelopt.torch.quantization.nn.modules.tensor_quantizer.SequentialQuantizer.disable"]], "disable() (tensorquantizer method)": [[134, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.disable"]], "disable_calib() (tensorquantizer method)": [[134, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.disable_calib"]], "disable_clip() (tensorquantizer method)": [[134, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.disable_clip"]], "disable_quant() (tensorquantizer method)": [[134, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.disable_quant"]], "enable() (tensorquantizer method)": [[134, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.enable"]], "enable_calib() (tensorquantizer method)": [[134, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.enable_calib"]], "enable_clip() (tensorquantizer method)": [[134, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.enable_clip"]], "enable_quant() (tensorquantizer method)": [[134, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.enable_quant"]], "export_amax() (tensorquantizer method)": [[134, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.export_amax"]], "extra_repr() (tensorquantizer method)": [[134, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.extra_repr"]], "fake_quant (tensorquantizer property)": [[134, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.fake_quant"]], "forward() (tensorquantizer method)": [[134, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.forward"]], "get_modelopt_state() (sequentialquantizer method)": [[134, "modelopt.torch.quantization.nn.modules.tensor_quantizer.SequentialQuantizer.get_modelopt_state"]], "get_modelopt_state() (tensorquantizer method)": [[134, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.get_modelopt_state"]], "init_learn_amax() (tensorquantizer method)": [[134, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.init_learn_amax"]], "is_enabled (tensorquantizer property)": [[134, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.is_enabled"]], "is_mx_format (tensorquantizer property)": [[134, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.is_mx_format"]], "load_calib_amax() (tensorquantizer method)": [[134, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.load_calib_amax"]], "maxbound (tensorquantizer property)": [[134, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.maxbound"]], "modelopt.torch.quantization.nn.modules.tensor_quantizer": [[134, "module-modelopt.torch.quantization.nn.modules.tensor_quantizer"]], "narrow_range (tensorquantizer property)": [[134, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.narrow_range"]], "num_bits (tensorquantizer property)": [[134, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.num_bits"]], "pre_quant_scale (tensorquantizer property)": [[134, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.pre_quant_scale"]], "replace_sequential_quantizer_with_single_quantizer() (sequentialquantizer static method)": [[134, "modelopt.torch.quantization.nn.modules.tensor_quantizer.SequentialQuantizer.replace_sequential_quantizer_with_single_quantizer"]], "reset_amax() (sequentialquantizer method)": [[134, "modelopt.torch.quantization.nn.modules.tensor_quantizer.SequentialQuantizer.reset_amax"]], "reset_amax() (tensorquantizer method)": [[134, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.reset_amax"]], "set_from_attribute_config() (sequentialquantizer method)": [[134, "modelopt.torch.quantization.nn.modules.tensor_quantizer.SequentialQuantizer.set_from_attribute_config"]], "set_from_attribute_config() (tensorquantizer method)": [[134, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.set_from_attribute_config"]], "set_from_modelopt_state() (tensorquantizer method)": [[134, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.set_from_modelopt_state"]], "step_size (tensorquantizer property)": [[134, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.step_size"]], "sync_amax_across_distributed_group() (tensorquantizer method)": [[134, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.sync_amax_across_distributed_group"]], "tensor_quantizer_iterator() (sequentialquantizer static method)": [[134, "modelopt.torch.quantization.nn.modules.tensor_quantizer.SequentialQuantizer.tensor_quantizer_iterator"]], "trt_high_precision_dtype (tensorquantizer property)": [[134, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.trt_high_precision_dtype"]], "unsigned (tensorquantizer property)": [[134, "modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer.unsigned"]], "freeze_parameters() (in module modelopt.torch.quantization.optim)": [[135, "modelopt.torch.quantization.optim.freeze_parameters"]], "group_parameters() (in module modelopt.torch.quantization.optim)": [[135, "modelopt.torch.quantization.optim.group_parameters"]], "match_parameters() (in module modelopt.torch.quantization.optim)": [[135, "modelopt.torch.quantization.optim.match_parameters"]], "modelopt.torch.quantization.optim": [[135, "module-modelopt.torch.quantization.optim"]], "quant_weight_inplace() (in module modelopt.torch.quantization.optim)": [[135, "modelopt.torch.quantization.optim.quant_weight_inplace"]], "modelopt.torch.quantization.plugins": [[136, "module-modelopt.torch.quantization.plugins"]], "modelopt.torch.quantization.qtensor": [[137, "module-modelopt.torch.quantization.qtensor"]], "basequantizedtensor (class in modelopt.torch.quantization.qtensor.base_qtensor)": [[138, "modelopt.torch.quantization.qtensor.base_qtensor.BaseQuantizedTensor"]], "qtensorwrapper (class in modelopt.torch.quantization.qtensor.base_qtensor)": [[138, "modelopt.torch.quantization.qtensor.base_qtensor.QTensorWrapper"]], "__init__() (basequantizedtensor method)": [[138, "modelopt.torch.quantization.qtensor.base_qtensor.BaseQuantizedTensor.__init__"]], "__new__() (qtensorwrapper static method)": [[138, "modelopt.torch.quantization.qtensor.base_qtensor.QTensorWrapper.__new__"]], "dequantize() (basequantizedtensor method)": [[138, "modelopt.torch.quantization.qtensor.base_qtensor.BaseQuantizedTensor.dequantize"]], "dim() (qtensorwrapper method)": [[138, "modelopt.torch.quantization.qtensor.base_qtensor.QTensorWrapper.dim"]], "get_qtensor() (qtensorwrapper method)": [[138, "modelopt.torch.quantization.qtensor.base_qtensor.QTensorWrapper.get_qtensor"]], "modelopt.torch.quantization.qtensor.base_qtensor": [[138, "module-modelopt.torch.quantization.qtensor.base_qtensor"]], "original_meta_tensor (basequantizedtensor attribute)": [[138, "modelopt.torch.quantization.qtensor.base_qtensor.BaseQuantizedTensor.original_meta_tensor"]], "pack_real_quantize_weight() (in module modelopt.torch.quantization.qtensor.base_qtensor)": [[138, "modelopt.torch.quantization.qtensor.base_qtensor.pack_real_quantize_weight"]], "quantize() (basequantizedtensor class method)": [[138, "modelopt.torch.quantization.qtensor.base_qtensor.BaseQuantizedTensor.quantize"]], "quantized_data (basequantizedtensor attribute)": [[138, "modelopt.torch.quantization.qtensor.base_qtensor.BaseQuantizedTensor.quantized_data"]], "to() (qtensorwrapper method)": [[138, "modelopt.torch.quantization.qtensor.base_qtensor.QTensorWrapper.to"]], "int4qtensor (class in modelopt.torch.quantization.qtensor.int4_tensor)": [[139, "modelopt.torch.quantization.qtensor.int4_tensor.INT4QTensor"]], "dequantize() (int4qtensor method)": [[139, "modelopt.torch.quantization.qtensor.int4_tensor.INT4QTensor.dequantize"]], "modelopt.torch.quantization.qtensor.int4_tensor": [[139, "module-modelopt.torch.quantization.qtensor.int4_tensor"]], "quantize() (int4qtensor class method)": [[139, "modelopt.torch.quantization.qtensor.int4_tensor.INT4QTensor.quantize"]], "quantized_data (int4qtensor attribute)": [[139, "modelopt.torch.quantization.qtensor.int4_tensor.INT4QTensor.quantized_data"]], "nf4qtensor (class in modelopt.torch.quantization.qtensor.nf4_tensor)": [[140, "modelopt.torch.quantization.qtensor.nf4_tensor.NF4QTensor"]], "dequantize() (nf4qtensor method)": [[140, "modelopt.torch.quantization.qtensor.nf4_tensor.NF4QTensor.dequantize"]], "double_quantization() (nf4qtensor class method)": [[140, "modelopt.torch.quantization.qtensor.nf4_tensor.NF4QTensor.double_quantization"]], "modelopt.torch.quantization.qtensor.nf4_tensor": [[140, "module-modelopt.torch.quantization.qtensor.nf4_tensor"]], "quantize() (nf4qtensor class method)": [[140, "modelopt.torch.quantization.qtensor.nf4_tensor.NF4QTensor.quantize"]], "quantized_data (nf4qtensor attribute)": [[140, "modelopt.torch.quantization.qtensor.nf4_tensor.NF4QTensor.quantized_data"]], "nvfp4qtensor (class in modelopt.torch.quantization.qtensor.nvfp4_tensor)": [[141, "modelopt.torch.quantization.qtensor.nvfp4_tensor.NVFP4QTensor"]], "dequantize() (nvfp4qtensor method)": [[141, "modelopt.torch.quantization.qtensor.nvfp4_tensor.NVFP4QTensor.dequantize"]], "get_activation_scaling_factor() (nvfp4qtensor class method)": [[141, "modelopt.torch.quantization.qtensor.nvfp4_tensor.NVFP4QTensor.get_activation_scaling_factor"]], "get_weights_scaling_factor() (nvfp4qtensor class method)": [[141, "modelopt.torch.quantization.qtensor.nvfp4_tensor.NVFP4QTensor.get_weights_scaling_factor"]], "get_weights_scaling_factor_2() (nvfp4qtensor class method)": [[141, "modelopt.torch.quantization.qtensor.nvfp4_tensor.NVFP4QTensor.get_weights_scaling_factor_2"]], "modelopt.torch.quantization.qtensor.nvfp4_tensor": [[141, "module-modelopt.torch.quantization.qtensor.nvfp4_tensor"]], "quantize() (nvfp4qtensor class method)": [[141, "modelopt.torch.quantization.qtensor.nvfp4_tensor.NVFP4QTensor.quantize"]], "resmooth_weights_and_get_scales() (nvfp4qtensor class method)": [[141, "modelopt.torch.quantization.qtensor.nvfp4_tensor.NVFP4QTensor.resmooth_weights_and_get_scales"]], "deactivate() (in module modelopt.torch.quantization.quant_modules)": [[142, "modelopt.torch.quantization.quant_modules.deactivate"]], "enable_onnx_export() (in module modelopt.torch.quantization.quant_modules)": [[142, "modelopt.torch.quantization.quant_modules.enable_onnx_export"]], "initialize() (in module modelopt.torch.quantization.quant_modules)": [[142, "modelopt.torch.quantization.quant_modules.initialize"]], "modelopt.torch.quantization.quant_modules": [[142, "module-modelopt.torch.quantization.quant_modules"]], "dynamicblockquantizationfunction (class in modelopt.torch.quantization.tensor_quant)": [[143, "modelopt.torch.quantization.tensor_quant.DynamicBlockQuantizationFunction"]], "fakeaffinetensorquantfunction (class in modelopt.torch.quantization.tensor_quant)": [[143, "modelopt.torch.quantization.tensor_quant.FakeAffineTensorQuantFunction"]], "faketensorquantfunction (class in modelopt.torch.quantization.tensor_quant)": [[143, "modelopt.torch.quantization.tensor_quant.FakeTensorQuantFunction"]], "legacyfaketensorquantfunction (class in modelopt.torch.quantization.tensor_quant)": [[143, "modelopt.torch.quantization.tensor_quant.LegacyFakeTensorQuantFunction"]], "scalede4m3function (class in modelopt.torch.quantization.tensor_quant)": [[143, "modelopt.torch.quantization.tensor_quant.ScaledE4M3Function"]], "tensorquantfunction (class in modelopt.torch.quantization.tensor_quant)": [[143, "modelopt.torch.quantization.tensor_quant.TensorQuantFunction"]], "backward() (dynamicblockquantizationfunction static method)": [[143, "modelopt.torch.quantization.tensor_quant.DynamicBlockQuantizationFunction.backward"]], "backward() (fakeaffinetensorquantfunction static method)": [[143, "modelopt.torch.quantization.tensor_quant.FakeAffineTensorQuantFunction.backward"]], "backward() (faketensorquantfunction static method)": [[143, "modelopt.torch.quantization.tensor_quant.FakeTensorQuantFunction.backward"]], "backward() (legacyfaketensorquantfunction static method)": [[143, "modelopt.torch.quantization.tensor_quant.LegacyFakeTensorQuantFunction.backward"]], "backward() (scalede4m3function static method)": [[143, "modelopt.torch.quantization.tensor_quant.ScaledE4M3Function.backward"]], "backward() (tensorquantfunction static method)": [[143, "modelopt.torch.quantization.tensor_quant.TensorQuantFunction.backward"]], "fake_quant_impl() (in module modelopt.torch.quantization.tensor_quant)": [[143, "modelopt.torch.quantization.tensor_quant.fake_quant_impl"]], "forward() (dynamicblockquantizationfunction static method)": [[143, "modelopt.torch.quantization.tensor_quant.DynamicBlockQuantizationFunction.forward"]], "forward() (fakeaffinetensorquantfunction static method)": [[143, "modelopt.torch.quantization.tensor_quant.FakeAffineTensorQuantFunction.forward"]], "forward() (faketensorquantfunction static method)": [[143, "modelopt.torch.quantization.tensor_quant.FakeTensorQuantFunction.forward"]], "forward() (legacyfaketensorquantfunction static method)": [[143, "modelopt.torch.quantization.tensor_quant.LegacyFakeTensorQuantFunction.forward"]], "forward() (scalede4m3function static method)": [[143, "modelopt.torch.quantization.tensor_quant.ScaledE4M3Function.forward"]], "forward() (tensorquantfunction static method)": [[143, "modelopt.torch.quantization.tensor_quant.TensorQuantFunction.forward"]], "modelopt.torch.quantization.tensor_quant": [[143, "module-modelopt.torch.quantization.tensor_quant"]], "quantize_op_abstract() (in module modelopt.torch.quantization.tensor_quant)": [[143, "modelopt.torch.quantization.tensor_quant.quantize_op_abstract"]], "scaled_e4m3_impl() (in module modelopt.torch.quantization.tensor_quant)": [[143, "modelopt.torch.quantization.tensor_quant.scaled_e4m3_impl"]], "symbolic() (faketensorquantfunction static method)": [[143, "modelopt.torch.quantization.tensor_quant.FakeTensorQuantFunction.symbolic"]], "symbolic() (scalede4m3function static method)": [[143, "modelopt.torch.quantization.tensor_quant.ScaledE4M3Function.symbolic"]], "symbolic() (tensorquantfunction static method)": [[143, "modelopt.torch.quantization.tensor_quant.TensorQuantFunction.symbolic"]], "export_torch_mode() (in module modelopt.torch.quantization.utils)": [[144, "modelopt.torch.quantization.utils.export_torch_mode"]], "get_parallel_state() (in module modelopt.torch.quantization.utils)": [[144, "modelopt.torch.quantization.utils.get_parallel_state"]], "is_quantized() (in module modelopt.torch.quantization.utils)": [[144, "modelopt.torch.quantization.utils.is_quantized"]], "is_quantized_column_parallel_linear() (in module modelopt.torch.quantization.utils)": [[144, "modelopt.torch.quantization.utils.is_quantized_column_parallel_linear"]], "is_quantized_layer_with_weight() (in module modelopt.torch.quantization.utils)": [[144, "modelopt.torch.quantization.utils.is_quantized_layer_with_weight"]], "is_quantized_row_parallel_linear() (in module modelopt.torch.quantization.utils)": [[144, "modelopt.torch.quantization.utils.is_quantized_row_parallel_linear"]], "is_torch_library_supported() (in module modelopt.torch.quantization.utils)": [[144, "modelopt.torch.quantization.utils.is_torch_library_supported"]], "modelopt.torch.quantization.utils": [[144, "module-modelopt.torch.quantization.utils"]], "reduce_amax() (in module modelopt.torch.quantization.utils)": [[144, "modelopt.torch.quantization.utils.reduce_amax"]], "replace_function() (in module modelopt.torch.quantization.utils)": [[144, "modelopt.torch.quantization.utils.replace_function"]], "modelopt.torch.sparsity": [[145, "module-modelopt.torch.sparsity"]], "modelopt.torch.sparsity.config": [[146, "module-modelopt.torch.sparsity.config"]], "nn_conv2d (sparsegptconfig attribute)": [[146, "modelopt.torch.sparsity.config.SparseGPTConfig.nn_conv2d"]], "nn_conv2d (sparsemagnitudeconfig attribute)": [[146, "modelopt.torch.sparsity.config.SparseMagnitudeConfig.nn_conv2d"]], "nn_linear (sparsegptconfig attribute)": [[146, "modelopt.torch.sparsity.config.SparseGPTConfig.nn_linear"]], "nn_linear (sparsemagnitudeconfig attribute)": [[146, "modelopt.torch.sparsity.config.SparseMagnitudeConfig.nn_linear"]], "magnitudesearcher (class in modelopt.torch.sparsity.magnitude)": [[147, "modelopt.torch.sparsity.magnitude.MagnitudeSearcher"]], "compute_valid_1d_patterns() (in module modelopt.torch.sparsity.magnitude)": [[147, "modelopt.torch.sparsity.magnitude.compute_valid_1d_patterns"]], "create_asp_mask() (in module modelopt.torch.sparsity.magnitude)": [[147, "modelopt.torch.sparsity.magnitude.create_asp_mask"]], "fill() (in module modelopt.torch.sparsity.magnitude)": [[147, "modelopt.torch.sparsity.magnitude.fill"]], "get_nmprune_info() (in module modelopt.torch.sparsity.magnitude)": [[147, "modelopt.torch.sparsity.magnitude.get_nmprune_info"]], "m4n2_1d() (in module modelopt.torch.sparsity.magnitude)": [[147, "modelopt.torch.sparsity.magnitude.m4n2_1d"]], "mn_1d_best() (in module modelopt.torch.sparsity.magnitude)": [[147, "modelopt.torch.sparsity.magnitude.mn_1d_best"]], "modelopt.torch.sparsity.magnitude": [[147, "module-modelopt.torch.sparsity.magnitude"]], "reshape_1d() (in module modelopt.torch.sparsity.magnitude)": [[147, "modelopt.torch.sparsity.magnitude.reshape_1d"]], "exportsparsemodedescriptor (class in modelopt.torch.sparsity.mode)": [[148, "modelopt.torch.sparsity.mode.ExportSparseModeDescriptor"]], "sparsegptmodedescriptor (class in modelopt.torch.sparsity.mode)": [[148, "modelopt.torch.sparsity.mode.SparseGPTModeDescriptor"]], "sparsemagnitudemodedescriptor (class in modelopt.torch.sparsity.mode)": [[148, "modelopt.torch.sparsity.mode.SparseMagnitudeModeDescriptor"]], "config_class (exportsparsemodedescriptor property)": [[148, "modelopt.torch.sparsity.mode.ExportSparseModeDescriptor.config_class"]], "config_class (sparsegptmodedescriptor property)": [[148, "modelopt.torch.sparsity.mode.SparseGPTModeDescriptor.config_class"]], "config_class (sparsemagnitudemodedescriptor property)": [[148, "modelopt.torch.sparsity.mode.SparseMagnitudeModeDescriptor.config_class"]], "convert (exportsparsemodedescriptor property)": [[148, "modelopt.torch.sparsity.mode.ExportSparseModeDescriptor.convert"]], "convert (sparsemagnitudemodedescriptor property)": [[148, "modelopt.torch.sparsity.mode.SparseMagnitudeModeDescriptor.convert"]], "convert_sparse_model() (in module modelopt.torch.sparsity.mode)": [[148, "modelopt.torch.sparsity.mode.convert_sparse_model"]], "export_mode (sparsemagnitudemodedescriptor property)": [[148, "modelopt.torch.sparsity.mode.SparseMagnitudeModeDescriptor.export_mode"]], "export_sparse() (in module modelopt.torch.sparsity.mode)": [[148, "modelopt.torch.sparsity.mode.export_sparse"]], "is_export_mode (exportsparsemodedescriptor property)": [[148, "modelopt.torch.sparsity.mode.ExportSparseModeDescriptor.is_export_mode"]], "modelopt.torch.sparsity.mode": [[148, "module-modelopt.torch.sparsity.mode"]], "name (exportsparsemodedescriptor property)": [[148, "modelopt.torch.sparsity.mode.ExportSparseModeDescriptor.name"]], "name (sparsegptmodedescriptor property)": [[148, "modelopt.torch.sparsity.mode.SparseGPTModeDescriptor.name"]], "name (sparsemagnitudemodedescriptor property)": [[148, "modelopt.torch.sparsity.mode.SparseMagnitudeModeDescriptor.name"]], "next_modes (sparsemagnitudemodedescriptor property)": [[148, "modelopt.torch.sparsity.mode.SparseMagnitudeModeDescriptor.next_modes"]], "restore (exportsparsemodedescriptor property)": [[148, "modelopt.torch.sparsity.mode.ExportSparseModeDescriptor.restore"]], "restore (sparsemagnitudemodedescriptor property)": [[148, "modelopt.torch.sparsity.mode.SparseMagnitudeModeDescriptor.restore"]], "restore_export_sparse() (in module modelopt.torch.sparsity.mode)": [[148, "modelopt.torch.sparsity.mode.restore_export_sparse"]], "restore_sparse_model() (in module modelopt.torch.sparsity.mode)": [[148, "modelopt.torch.sparsity.mode.restore_sparse_model"]], "search_algorithm (sparsegptmodedescriptor property)": [[148, "modelopt.torch.sparsity.mode.SparseGPTModeDescriptor.search_algorithm"]], "search_algorithm (sparsemagnitudemodedescriptor property)": [[148, "modelopt.torch.sparsity.mode.SparseMagnitudeModeDescriptor.search_algorithm"]], "update_for_new_mode (sparsemagnitudemodedescriptor property)": [[148, "modelopt.torch.sparsity.mode.SparseMagnitudeModeDescriptor.update_for_new_mode"]], "update_for_save (sparsemagnitudemodedescriptor property)": [[148, "modelopt.torch.sparsity.mode.SparseMagnitudeModeDescriptor.update_for_save"]], "update_sparse_metadata() (in module modelopt.torch.sparsity.mode)": [[148, "modelopt.torch.sparsity.mode.update_sparse_metadata"]], "sparsemodule (class in modelopt.torch.sparsity.module)": [[149, "modelopt.torch.sparsity.module.SparseModule"]], "modelopt.torch.sparsity.module": [[149, "module-modelopt.torch.sparsity.module"]], "modify() (sparsemodule method)": [[149, "modelopt.torch.sparsity.module.SparseModule.modify"]], "set_mask() (sparsemodule method)": [[149, "modelopt.torch.sparsity.module.SparseModule.set_mask"]], "modelopt.torch.sparsity.plugins": [[150, "module-modelopt.torch.sparsity.plugins"]], "basesparsesearcher (class in modelopt.torch.sparsity.searcher)": [[151, "modelopt.torch.sparsity.searcher.BaseSparseSearcher"]], "default_search_config (basesparsesearcher property)": [[151, "modelopt.torch.sparsity.searcher.BaseSparseSearcher.default_search_config"]], "default_state_dict (basesparsesearcher property)": [[151, "modelopt.torch.sparsity.searcher.BaseSparseSearcher.default_state_dict"]], "modelopt.torch.sparsity.searcher": [[151, "module-modelopt.torch.sparsity.searcher"]], "run_search() (basesparsesearcher method)": [[151, "modelopt.torch.sparsity.searcher.BaseSparseSearcher.run_search"]], "sanitize_search_config() (basesparsesearcher method)": [[151, "modelopt.torch.sparsity.searcher.BaseSparseSearcher.sanitize_search_config"]], "sparsegptsearcher (class in modelopt.torch.sparsity.sparsegpt)": [[152, "modelopt.torch.sparsity.sparsegpt.SparseGPTSearcher"]], "after_search() (sparsegptsearcher method)": [[152, "modelopt.torch.sparsity.sparsegpt.SparseGPTSearcher.after_search"]], "before_search() (sparsegptsearcher method)": [[152, "modelopt.torch.sparsity.sparsegpt.SparseGPTSearcher.before_search"]], "create_sgpt_mask() (in module modelopt.torch.sparsity.sparsegpt)": [[152, "modelopt.torch.sparsity.sparsegpt.create_sgpt_mask"]], "default_search_config (sparsegptsearcher property)": [[152, "modelopt.torch.sparsity.sparsegpt.SparseGPTSearcher.default_search_config"]], "invert() (in module modelopt.torch.sparsity.sparsegpt)": [[152, "modelopt.torch.sparsity.sparsegpt.invert"]], "modelopt.torch.sparsity.sparsegpt": [[152, "module-modelopt.torch.sparsity.sparsegpt"]], "prepare() (in module modelopt.torch.sparsity.sparsegpt)": [[152, "modelopt.torch.sparsity.sparsegpt.prepare"]], "export() (in module modelopt.torch.sparsity.sparsification)": [[153, "modelopt.torch.sparsity.sparsification.export"]], "modelopt.torch.sparsity.sparsification": [[153, "module-modelopt.torch.sparsity.sparsification"]], "sparsify() (in module modelopt.torch.sparsity.sparsification)": [[153, "modelopt.torch.sparsity.sparsification.sparsify"]], "modelopt.torch.speculative": [[154, "module-modelopt.torch.speculative"]], "medusa_num_heads (medusaconfig attribute)": [[155, "modelopt.torch.speculative.config.MedusaConfig.medusa_num_heads"]], "medusa_num_layers (medusaconfig attribute)": [[155, "modelopt.torch.speculative.config.MedusaConfig.medusa_num_layers"]], "modelopt.torch.speculative.config": [[155, "module-modelopt.torch.speculative.config"]], "modelopt.torch.speculative.medusa": [[156, "module-modelopt.torch.speculative.medusa"]], "convert_to_medusa_model() (in module modelopt.torch.speculative.medusa.conversion)": [[157, "modelopt.torch.speculative.medusa.conversion.convert_to_medusa_model"]], "modelopt.torch.speculative.medusa.conversion": [[157, "module-modelopt.torch.speculative.medusa.conversion"]], "restore_medusa_model() (in module modelopt.torch.speculative.medusa.conversion)": [[157, "modelopt.torch.speculative.medusa.conversion.restore_medusa_model"]], "medusamodel (class in modelopt.torch.speculative.medusa.medusa_model)": [[158, "modelopt.torch.speculative.medusa.medusa_model.MedusaModel"]], "resblock (class in modelopt.torch.speculative.medusa.medusa_model)": [[158, "modelopt.torch.speculative.medusa.medusa_model.ResBlock"]], "__init__() (resblock method)": [[158, "modelopt.torch.speculative.medusa.medusa_model.ResBlock.__init__"]], "forward() (resblock method)": [[158, "modelopt.torch.speculative.medusa.medusa_model.ResBlock.forward"]], "modelopt.torch.speculative.medusa.medusa_model": [[158, "module-modelopt.torch.speculative.medusa.medusa_model"]], "modify() (medusamodel method)": [[158, "modelopt.torch.speculative.medusa.medusa_model.MedusaModel.modify"]], "medusamodedescriptor (class in modelopt.torch.speculative.mode)": [[159, "modelopt.torch.speculative.mode.MedusaModeDescriptor"]], "config_class (medusamodedescriptor property)": [[159, "modelopt.torch.speculative.mode.MedusaModeDescriptor.config_class"]], "convert (medusamodedescriptor property)": [[159, "modelopt.torch.speculative.mode.MedusaModeDescriptor.convert"]], "modelopt.torch.speculative.mode": [[159, "module-modelopt.torch.speculative.mode"]], "name (medusamodedescriptor property)": [[159, "modelopt.torch.speculative.mode.MedusaModeDescriptor.name"]], "restore (medusamodedescriptor property)": [[159, "modelopt.torch.speculative.mode.MedusaModeDescriptor.restore"]], "modelopt.torch.speculative.plugins": [[160, "module-modelopt.torch.speculative.plugins"]], "convert() (in module modelopt.torch.speculative.speculative_decoding)": [[161, "modelopt.torch.speculative.speculative_decoding.convert"]], "modelopt.torch.speculative.speculative_decoding": [[161, "module-modelopt.torch.speculative.speculative_decoding"]], "modelopt.torch.trace": [[162, "module-modelopt.torch.trace"]], "analyze_symbols() (in module modelopt.torch.trace.analyzer)": [[163, "modelopt.torch.trace.analyzer.analyze_symbols"]], "modelopt.torch.trace.analyzer": [[163, "module-modelopt.torch.trace.analyzer"]], "modelopt.torch.trace.modules": [[164, "module-modelopt.torch.trace.modules"]], "concatnodeprocessor (class in modelopt.torch.trace.modules.concat)": [[165, "modelopt.torch.trace.modules.concat.ConcatNodeProcessor"]], "concatsymbol (class in modelopt.torch.trace.modules.concat)": [[165, "modelopt.torch.trace.modules.concat.ConcatSymbol"]], "concatsymbol.input (class in modelopt.torch.trace.modules.concat)": [[165, "modelopt.torch.trace.modules.concat.ConcatSymbol.Input"]], "__init__() (concatnodeprocessor method)": [[165, "modelopt.torch.trace.modules.concat.ConcatNodeProcessor.__init__"]], "__init__() (concatsymbol method)": [[165, "modelopt.torch.trace.modules.concat.ConcatSymbol.__init__"]], "__init__() (concatsymbol.input method)": [[165, "modelopt.torch.trace.modules.concat.ConcatSymbol.Input.__init__"]], "concat_sym (concatsymbol.input property)": [[165, "modelopt.torch.trace.modules.concat.ConcatSymbol.Input.concat_sym"]], "convert() (concatsymbol.input static method)": [[165, "modelopt.torch.trace.modules.concat.ConcatSymbol.Input.convert"]], "create_linked_copy() (concatsymbol.input method)": [[165, "modelopt.torch.trace.modules.concat.ConcatSymbol.Input.create_linked_copy"]], "disable() (concatsymbol method)": [[165, "modelopt.torch.trace.modules.concat.ConcatSymbol.disable"]], "input_syms (concatsymbol property)": [[165, "modelopt.torch.trace.modules.concat.ConcatSymbol.input_syms"]], "is_constant (concatsymbol property)": [[165, "modelopt.torch.trace.modules.concat.ConcatSymbol.is_constant"]], "is_searchable (concatsymbol property)": [[165, "modelopt.torch.trace.modules.concat.ConcatSymbol.is_searchable"]], "is_special_node() (concatnodeprocessor method)": [[165, "modelopt.torch.trace.modules.concat.ConcatNodeProcessor.is_special_node"]], "link_to() (concatsymbol method)": [[165, "modelopt.torch.trace.modules.concat.ConcatSymbol.link_to"]], "link_to() (concatsymbol.input method)": [[165, "modelopt.torch.trace.modules.concat.ConcatSymbol.Input.link_to"]], "modelopt.torch.trace.modules.concat": [[165, "module-modelopt.torch.trace.modules.concat"]], "post_process() (concatnodeprocessor method)": [[165, "modelopt.torch.trace.modules.concat.ConcatNodeProcessor.post_process"]], "process() (concatnodeprocessor method)": [[165, "modelopt.torch.trace.modules.concat.ConcatNodeProcessor.process"]], "reset() (concatnodeprocessor method)": [[165, "modelopt.torch.trace.modules.concat.ConcatNodeProcessor.reset"]], "symdepth (class in modelopt.torch.trace.modules.nn)": [[166, "modelopt.torch.trace.modules.nn.SymDepth"]], "__init__() (symdepth method)": [[166, "modelopt.torch.trace.modules.nn.SymDepth.__init__"]], "disable() (symdepth method)": [[166, "modelopt.torch.trace.modules.nn.SymDepth.disable"]], "is_skippable() (symdepth method)": [[166, "modelopt.torch.trace.modules.nn.SymDepth.is_skippable"]], "link_to() (symdepth method)": [[166, "modelopt.torch.trace.modules.nn.SymDepth.link_to"]], "max_depth (symdepth property)": [[166, "modelopt.torch.trace.modules.nn.SymDepth.max_depth"]], "min_depth (symdepth property)": [[166, "modelopt.torch.trace.modules.nn.SymDepth.min_depth"]], "modelopt.torch.trace.modules.nn": [[166, "module-modelopt.torch.trace.modules.nn"]], "set_skippable() (symdepth method)": [[166, "modelopt.torch.trace.modules.nn.SymDepth.set_skippable"]], "skippable_idxs (symdepth property)": [[166, "modelopt.torch.trace.modules.nn.SymDepth.skippable_idxs"]], "modelopt.torch.trace.plugins": [[167, "module-modelopt.torch.trace.plugins"]], "incoming (symbol.cltype attribute)": [[168, "modelopt.torch.trace.symbols.Symbol.CLType.INCOMING"]], "none (symbol.cltype attribute)": [[168, "modelopt.torch.trace.symbols.Symbol.CLType.NONE"]], "outgoing (symbol.cltype attribute)": [[168, "modelopt.torch.trace.symbols.Symbol.CLType.OUTGOING"]], "symdict (syminfo attribute)": [[168, "modelopt.torch.trace.symbols.SymInfo.SymDict"]], "syminfo (class in modelopt.torch.trace.symbols)": [[168, "modelopt.torch.trace.symbols.SymInfo"]], "symmap (class in modelopt.torch.trace.symbols)": [[168, "modelopt.torch.trace.symbols.SymMap"]], "symregisterfunc (symmap attribute)": [[168, "modelopt.torch.trace.symbols.SymMap.SymRegisterFunc"]], "symbol (class in modelopt.torch.trace.symbols)": [[168, "modelopt.torch.trace.symbols.Symbol"]], "symbol.cltype (class in modelopt.torch.trace.symbols)": [[168, "modelopt.torch.trace.symbols.Symbol.CLType"]], "__init__() (syminfo method)": [[168, "modelopt.torch.trace.symbols.SymInfo.__init__"]], "__init__() (symmap method)": [[168, "modelopt.torch.trace.symbols.SymMap.__init__"]], "__init__() (symbol method)": [[168, "modelopt.torch.trace.symbols.Symbol.__init__"]], "add_sym_info() (symmap method)": [[168, "modelopt.torch.trace.symbols.SymMap.add_sym_info"]], "cl_type (symbol property)": [[168, "modelopt.torch.trace.symbols.Symbol.cl_type"]], "disable() (symbol method)": [[168, "modelopt.torch.trace.symbols.Symbol.disable"]], "elastic_dims (symbol property)": [[168, "modelopt.torch.trace.symbols.Symbol.elastic_dims"]], "get_symbol() (symmap method)": [[168, "modelopt.torch.trace.symbols.SymMap.get_symbol"]], "is_constant (symbol property)": [[168, "modelopt.torch.trace.symbols.Symbol.is_constant"]], "is_cross_layer (symbol property)": [[168, "modelopt.torch.trace.symbols.Symbol.is_cross_layer"]], "is_dangling (symbol property)": [[168, "modelopt.torch.trace.symbols.Symbol.is_dangling"]], "is_dynamic (symbol property)": [[168, "modelopt.torch.trace.symbols.Symbol.is_dynamic"]], "is_free (symbol property)": [[168, "modelopt.torch.trace.symbols.Symbol.is_free"]], "is_incoming (symbol property)": [[168, "modelopt.torch.trace.symbols.Symbol.is_incoming"]], "is_outgoing (symbol property)": [[168, "modelopt.torch.trace.symbols.Symbol.is_outgoing"]], "is_searchable (symbol property)": [[168, "modelopt.torch.trace.symbols.Symbol.is_searchable"]], "is_shape_preserving (syminfo property)": [[168, "modelopt.torch.trace.symbols.SymInfo.is_shape_preserving"]], "is_shape_preserving() (symmap method)": [[168, "modelopt.torch.trace.symbols.SymMap.is_shape_preserving"]], "is_sortable (symbol property)": [[168, "modelopt.torch.trace.symbols.Symbol.is_sortable"]], "items() (symmap method)": [[168, "modelopt.torch.trace.symbols.SymMap.items"]], "link_to() (symbol method)": [[168, "modelopt.torch.trace.symbols.Symbol.link_to"]], "modelopt.torch.trace.symbols": [[168, "module-modelopt.torch.trace.symbols"]], "named_modules() (symmap method)": [[168, "modelopt.torch.trace.symbols.SymMap.named_modules"]], "named_sym_dicts() (symmap method)": [[168, "modelopt.torch.trace.symbols.SymMap.named_sym_dicts"]], "named_symbols() (symmap method)": [[168, "modelopt.torch.trace.symbols.SymMap.named_symbols"]], "parent (symbol property)": [[168, "modelopt.torch.trace.symbols.Symbol.parent"]], "pop() (symmap method)": [[168, "modelopt.torch.trace.symbols.SymMap.pop"]], "prune() (symmap method)": [[168, "modelopt.torch.trace.symbols.SymMap.prune"]], "register() (symmap class method)": [[168, "modelopt.torch.trace.symbols.SymMap.register"]], "set_symbol() (symmap method)": [[168, "modelopt.torch.trace.symbols.SymMap.set_symbol"]], "unregister() (symmap class method)": [[168, "modelopt.torch.trace.symbols.SymMap.unregister"]], "graphcollection (class in modelopt.torch.trace.tracer)": [[169, "modelopt.torch.trace.tracer.GraphCollection"]], "robusttracer (class in modelopt.torch.trace.tracer)": [[169, "modelopt.torch.trace.tracer.RobustTracer"]], "__init__() (graphcollection method)": [[169, "modelopt.torch.trace.tracer.GraphCollection.__init__"]], "__init__() (robusttracer method)": [[169, "modelopt.torch.trace.tracer.RobustTracer.__init__"]], "failure_msg() (graphcollection method)": [[169, "modelopt.torch.trace.tracer.GraphCollection.failure_msg"]], "failure_msg() (robusttracer method)": [[169, "modelopt.torch.trace.tracer.RobustTracer.failure_msg"]], "is_failed() (graphcollection method)": [[169, "modelopt.torch.trace.tracer.GraphCollection.is_failed"]], "is_failed() (robusttracer method)": [[169, "modelopt.torch.trace.tracer.RobustTracer.is_failed"]], "is_leaf_module() (robusttracer method)": [[169, "modelopt.torch.trace.tracer.RobustTracer.is_leaf_module"]], "is_registered_leaf() (robusttracer class method)": [[169, "modelopt.torch.trace.tracer.RobustTracer.is_registered_leaf"]], "is_unvisited() (graphcollection method)": [[169, "modelopt.torch.trace.tracer.GraphCollection.is_unvisited"]], "is_unvisited() (robusttracer method)": [[169, "modelopt.torch.trace.tracer.RobustTracer.is_unvisited"]], "modelopt.torch.trace.tracer": [[169, "module-modelopt.torch.trace.tracer"]], "record_call_module() (robusttracer method)": [[169, "modelopt.torch.trace.tracer.RobustTracer.record_call_module"]], "recursive_trace() (graphcollection method)": [[169, "modelopt.torch.trace.tracer.GraphCollection.recursive_trace"]], "recursive_trace() (in module modelopt.torch.trace.tracer)": [[169, "modelopt.torch.trace.tracer.recursive_trace"]], "register_leaf() (robusttracer class method)": [[169, "modelopt.torch.trace.tracer.RobustTracer.register_leaf"]], "trace() (robusttracer method)": [[169, "modelopt.torch.trace.tracer.RobustTracer.trace"]], "unregister_leaf() (robusttracer class method)": [[169, "modelopt.torch.trace.tracer.RobustTracer.unregister_leaf"]], "modelopt.torch.utils": [[170, "module-modelopt.torch.utils"]], "load_cpp_extension() (in module modelopt.torch.utils.cpp_extension)": [[171, "modelopt.torch.utils.cpp_extension.load_cpp_extension"]], "modelopt.torch.utils.cpp_extension": [[171, "module-modelopt.torch.utils.cpp_extension"]], "create_forward_loop() (in module modelopt.torch.utils.dataset_utils)": [[172, "modelopt.torch.utils.dataset_utils.create_forward_loop"]], "get_dataset_dataloader() (in module modelopt.torch.utils.dataset_utils)": [[172, "modelopt.torch.utils.dataset_utils.get_dataset_dataloader"]], "modelopt.torch.utils.dataset_utils": [[172, "module-modelopt.torch.utils.dataset_utils"]], "backend() (in module modelopt.torch.utils.distributed)": [[173, "modelopt.torch.utils.distributed.backend"]], "barrier() (in module modelopt.torch.utils.distributed)": [[173, "modelopt.torch.utils.distributed.barrier"]], "get_data_parallel_group() (in module modelopt.torch.utils.distributed)": [[173, "modelopt.torch.utils.distributed.get_data_parallel_group"]], "get_tensor_parallel_group() (in module modelopt.torch.utils.distributed)": [[173, "modelopt.torch.utils.distributed.get_tensor_parallel_group"]], "is_available() (in module modelopt.torch.utils.distributed)": [[173, "modelopt.torch.utils.distributed.is_available"]], "is_initialized() (in module modelopt.torch.utils.distributed)": [[173, "modelopt.torch.utils.distributed.is_initialized"]], "is_master() (in module modelopt.torch.utils.distributed)": [[173, "modelopt.torch.utils.distributed.is_master"]], "modelopt.torch.utils.distributed": [[173, "module-modelopt.torch.utils.distributed"]], "rank() (in module modelopt.torch.utils.distributed)": [[173, "modelopt.torch.utils.distributed.rank"]], "set_data_parallel_group() (in module modelopt.torch.utils.distributed)": [[173, "modelopt.torch.utils.distributed.set_data_parallel_group"]], "set_tensor_parallel_group() (in module modelopt.torch.utils.distributed)": [[173, "modelopt.torch.utils.distributed.set_tensor_parallel_group"]], "size() (in module modelopt.torch.utils.distributed)": [[173, "modelopt.torch.utils.distributed.size"]], "match() (in module modelopt.torch.utils.graph)": [[174, "modelopt.torch.utils.graph.match"]], "modelopt.torch.utils.graph": [[174, "module-modelopt.torch.utils.graph"]], "list_closest_to_median() (in module modelopt.torch.utils.list)": [[175, "modelopt.torch.utils.list.list_closest_to_median"]], "modelopt.torch.utils.list": [[175, "module-modelopt.torch.utils.list"]], "stats() (in module modelopt.torch.utils.list)": [[175, "modelopt.torch.utils.list.stats"]], "val2list() (in module modelopt.torch.utils.list)": [[175, "modelopt.torch.utils.list.val2list"]], "val2tuple() (in module modelopt.torch.utils.list)": [[175, "modelopt.torch.utils.list.val2tuple"]], "deprecatederror": [[176, "modelopt.torch.utils.logging.DeprecatedError"]], "modelopt.torch.utils.logging": [[176, "module-modelopt.torch.utils.logging"]], "no_stdout() (in module modelopt.torch.utils.logging)": [[176, "modelopt.torch.utils.logging.no_stdout"]], "num2hrb() (in module modelopt.torch.utils.logging)": [[176, "modelopt.torch.utils.logging.num2hrb"]], "print_rank_0() (in module modelopt.torch.utils.logging)": [[176, "modelopt.torch.utils.logging.print_rank_0"]], "silence_matched_warnings() (in module modelopt.torch.utils.logging)": [[176, "modelopt.torch.utils.logging.silence_matched_warnings"]], "compare_dict() (in module modelopt.torch.utils.network)": [[177, "modelopt.torch.utils.network.compare_dict"]], "create_param_grad_clear_hook() (in module modelopt.torch.utils.network)": [[177, "modelopt.torch.utils.network.create_param_grad_clear_hook"]], "get_model_attributes() (in module modelopt.torch.utils.network)": [[177, "modelopt.torch.utils.network.get_model_attributes"]], "get_module_device() (in module modelopt.torch.utils.network)": [[177, "modelopt.torch.utils.network.get_module_device"]], "get_same_padding() (in module modelopt.torch.utils.network)": [[177, "modelopt.torch.utils.network.get_same_padding"]], "get_unwrapped_name() (in module modelopt.torch.utils.network)": [[177, "modelopt.torch.utils.network.get_unwrapped_name"]], "init_model_from_model_like() (in module modelopt.torch.utils.network)": [[177, "modelopt.torch.utils.network.init_model_from_model_like"]], "is_channels_last() (in module modelopt.torch.utils.network)": [[177, "modelopt.torch.utils.network.is_channels_last"]], "is_parallel() (in module modelopt.torch.utils.network)": [[177, "modelopt.torch.utils.network.is_parallel"]], "make_divisible() (in module modelopt.torch.utils.network)": [[177, "modelopt.torch.utils.network.make_divisible"]], "model_to() (in module modelopt.torch.utils.network)": [[177, "modelopt.torch.utils.network.model_to"]], "modelopt.torch.utils.network": [[177, "module-modelopt.torch.utils.network"]], "param_num() (in module modelopt.torch.utils.network)": [[177, "modelopt.torch.utils.network.param_num"]], "param_num_from_forward() (in module modelopt.torch.utils.network)": [[177, "modelopt.torch.utils.network.param_num_from_forward"]], "remove_bn() (in module modelopt.torch.utils.network)": [[177, "modelopt.torch.utils.network.remove_bn"]], "run_forward_loop() (in module modelopt.torch.utils.network)": [[177, "modelopt.torch.utils.network.run_forward_loop"]], "set_submodule() (in module modelopt.torch.utils.network)": [[177, "modelopt.torch.utils.network.set_submodule"]], "standardize_constructor_args() (in module modelopt.torch.utils.network)": [[177, "modelopt.torch.utils.network.standardize_constructor_args"]], "standardize_model_args() (in module modelopt.torch.utils.network)": [[177, "modelopt.torch.utils.network.standardize_model_args"]], "standardize_model_like_tuple() (in module modelopt.torch.utils.network)": [[177, "modelopt.torch.utils.network.standardize_model_like_tuple"]], "standardize_named_model_args() (in module modelopt.torch.utils.network)": [[177, "modelopt.torch.utils.network.standardize_named_model_args"]], "unwrap_model() (in module modelopt.torch.utils.network)": [[177, "modelopt.torch.utils.network.unwrap_model"]], "zero_grad() (in module modelopt.torch.utils.network)": [[177, "modelopt.torch.utils.network.zero_grad"]], "timer (class in modelopt.torch.utils.perf)": [[178, "modelopt.torch.utils.perf.Timer"]], "__init__() (timer method)": [[178, "modelopt.torch.utils.perf.Timer.__init__"]], "clear_cuda_cache() (in module modelopt.torch.utils.perf)": [[178, "modelopt.torch.utils.perf.clear_cuda_cache"]], "get_cuda_memory_stats() (in module modelopt.torch.utils.perf)": [[178, "modelopt.torch.utils.perf.get_cuda_memory_stats"]], "modelopt.torch.utils.perf": [[178, "module-modelopt.torch.utils.perf"]], "report_memory() (in module modelopt.torch.utils.perf)": [[178, "modelopt.torch.utils.perf.report_memory"]], "start() (timer method)": [[178, "modelopt.torch.utils.perf.Timer.start"]], "stop() (timer method)": [[178, "modelopt.torch.utils.perf.Timer.stop"]], "centroid() (in module modelopt.torch.utils.random)": [[179, "modelopt.torch.utils.random.centroid"]], "choice() (in module modelopt.torch.utils.random)": [[179, "modelopt.torch.utils.random.choice"]], "modelopt.torch.utils.random": [[179, "module-modelopt.torch.utils.random"]], "original() (in module modelopt.torch.utils.random)": [[179, "modelopt.torch.utils.random.original"]], "random() (in module modelopt.torch.utils.random)": [[179, "modelopt.torch.utils.random.random"]], "sample() (in module modelopt.torch.utils.random)": [[179, "modelopt.torch.utils.random.sample"]], "shuffle() (in module modelopt.torch.utils.random)": [[179, "modelopt.torch.utils.random.shuffle"]], "modelopt.torch.utils.tensor": [[180, "module-modelopt.torch.utils.tensor"]], "numpy_to_torch() (in module modelopt.torch.utils.tensor)": [[180, "modelopt.torch.utils.tensor.numpy_to_torch"]], "torch_detach() (in module modelopt.torch.utils.tensor)": [[180, "modelopt.torch.utils.tensor.torch_detach"]], "torch_to() (in module modelopt.torch.utils.tensor)": [[180, "modelopt.torch.utils.tensor.torch_to"]], "torch_to_numpy() (in module modelopt.torch.utils.tensor)": [[180, "modelopt.torch.utils.tensor.torch_to_numpy"]]}})