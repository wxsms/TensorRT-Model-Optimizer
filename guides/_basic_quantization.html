<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Basic Concepts &mdash; Model Optimizer 0.11.2</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../_static/tabs.css?v=4c969af8" />
      <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
      <link rel="stylesheet" type="text/css" href="../_static/autodoc_pydantic.css" />
      <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=d10054b6" />


  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->

        <script src="../_static/jquery.js?v=5d32c60e"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../_static/documentation_options.js?v=5929fcd5"></script>
        <script src="../_static/doctools.js?v=888ff710"></script>
        <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
        <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
        <script src="../_static/copybutton.js?v=20d3d275"></script>
        <script src="../_static/tabs.js?v=3ee01567"></script>
        <script>let toggleHintShow = 'Click to show';</script>
        <script>let toggleHintHide = 'Click to hide';</script>
        <script>let toggleOpenOnPrint = 'true';</script>
        <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
        <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Best practices to choose the right quantization methods" href="_choosing_quant_methods.html" />
    <link rel="prev" title="Quantization" href="1_quantization.html" />
</head>

<body class="wy-body-for-nav">
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >



          <a href="../index.html" class="icon icon-home">
            TensorRT Model Optimizer
          </a>
              <div class="version">
                0.11.2
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/1_overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/2_installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/3_quantization.html">Quick Start: Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/6_sparsity.html">Quick Start: Sparsity</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Optimization Guides</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="1_quantization.html">Quantization</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">Basic Concepts</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#precision-format">Precision format</a></li>
<li class="toctree-l3"><a class="reference internal" href="#scaling-factor">Scaling factor</a></li>
<li class="toctree-l3"><a class="reference internal" href="#block-format">Block format</a></li>
<li class="toctree-l3"><a class="reference internal" href="#calibration-algorithm">Calibration algorithm</a></li>
<li class="toctree-l3"><a class="reference internal" href="#quantization-aware-training-qat">Quantization-aware training (QAT)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#more-readings">More Readings</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="_choosing_quant_methods.html">Best practices to choose the right quantization methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="_pytorch_quantization.html">PyTorch Quantization</a></li>
<li class="toctree-l2"><a class="reference internal" href="_onnx_quantization.html">ONNX Quantization (Beta)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="5_sparsity.html">Sparsity</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Deployment</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../deployment/1_tensorrt_llm_deployment.html">TensorRT-LLM Deployment</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../examples/0_all_examples.html">All ModelOpt Examples</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../reference/0_versions.html">Model Optimizer Changelog</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reference/1_modelopt_api.html">modelopt API</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Support</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../support/1_contact.html">Contact us</a></li>
<li class="toctree-l1"><a class="reference internal" href="../support/2_faqs.html">FAQs</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">TensorRT Model Optimizer</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="1_quantization.html">Quantization</a></li>
      <li class="breadcrumb-item active">Basic Concepts</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/guides/_basic_quantization.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">

  <section id="basic-concepts">
<h1>Basic Concepts<a class="headerlink" href="#basic-concepts" title="Link to this heading"></a></h1>
<p>A quantization format consists of the precision format, the block format, and the calibration
algorithm.
The detailed list of available quantization formats can be found in <a class="reference internal" href="../reference/generated/modelopt.torch.quantization.config.html#quantization-formats"><span class="std std-ref">Quantization Formats</span></a>.
Below we provide an overview of the important topics:</p>
<section id="precision-format">
<h2>Precision format<a class="headerlink" href="#precision-format" title="Link to this heading"></a></h2>
<p>The precision format defines the bit-width of the quantized values. Generally, there are integer
formats (sign bit + mantissa bits) and floating-point formats (sign bit + exponent bits + mantissa
bits). <a class="reference external" href="https://arxiv.org/pdf/2209.05433" rel="noopener noreferrer" target="_blank">FP8 FORMATS FOR DEEP LEARNING</a> provides a detailed
explanation of the floating-point formats.</p>
</section>
<section id="scaling-factor">
<h2>Scaling factor<a class="headerlink" href="#scaling-factor" title="Link to this heading"></a></h2>
<p>The scaling factor is a floating-point value that is used to scale and unscale the values before and
after the quantized operation, respectively. The scaling factor is used to map the range of the
original values to the range of the quantized values. The scaling factor is shared across the
quantized values in the same block. The scaling factor is calculated during the calibration process.</p>
</section>
<section id="block-format">
<h2>Block format<a class="headerlink" href="#block-format" title="Link to this heading"></a></h2>
<p>The block format defines the way the tensor is divided into blocks for sharing the scaling factors.
The most common block format is per-tensor quantization, where the whole tensor is quantized as a
single block with one global scaling factor. Other block formats include per-channel quantization,
where each channel is quantized separately, and the fine-grained per-block quantization, where the
tensor is divided into fix-size blocks along the channel dimension. For low-bit quantization (e.g.
4-bit), per-block quantization is typically needed to preserve the accuracy.</p>
<p>Weight and activation may share different precision and block formats. For example, in GPTQ and AWQ,
the weight is quantized to 4-bit while activation stays in high precision. Weight-only quantization
is helpful for bandwidth-constrained scenarios, while weight and activation quantization can reduce
both bandwidth and computation cost.</p>
</section>
<section id="calibration-algorithm">
<h2>Calibration algorithm<a class="headerlink" href="#calibration-algorithm" title="Link to this heading"></a></h2>
<p>The calibration algorithm calculate scaling factors and potentially adjust weights to maximize
accuracy post quantization. The simplest calibration algorithm is “max calibration”, in which the
scaling factor is calculated from the global maximum of the tensor and the weights are unchanged and
rounded to the nearest quantized value. An example of a more advanced calibration algorithm is
<a class="reference external" href="https://docs.nvidia.com/deeplearning/tensorrt/api/python_api/infer/Int8/EntropyCalibrator.html" rel="noopener noreferrer" target="_blank">Entropy Calibration</a>,
<a class="reference external" href="https://arxiv.org/abs/2211.10438" rel="noopener noreferrer" target="_blank">SmoothQuant</a>, and <a class="reference external" href="https://arxiv.org/abs/2306.00978" rel="noopener noreferrer" target="_blank">AWQ</a>.</p>
</section>
<section id="quantization-aware-training-qat">
<h2>Quantization-aware training (QAT)<a class="headerlink" href="#quantization-aware-training-qat" title="Link to this heading"></a></h2>
<p>QAT can be viewed as regular PTQ followed by fine-tuning during which the original, unquantized
weights are updated to minimize the loss. Compared to regular fine-tuning, we must model the effect
of quantization on the forward and backward passes. Commonly used QAT techniques like
<a class="reference external" href="https://arxiv.org/abs/1308.3432" rel="noopener noreferrer" target="_blank">Straight-Through Estimator (STE)</a> or STE with clipping have
fixed scaling factors and tune the weights during training to minimize the loss. ModelOpt implements
STE with clipping for QAT.</p>
</section>
<section id="more-readings">
<h2>More Readings<a class="headerlink" href="#more-readings" title="Link to this heading"></a></h2>
<ul class="simple">
<li><p>Math behind quantization: <a class="reference external" href="https://arxiv.org/pdf/2004.09602.pdf" rel="noopener noreferrer" target="_blank">Integer Quantization</a></p></li>
<li><p>Explicit quantization graph representation with QDQ node:
<a class="reference external" href="https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index.html#work-with-qat-networks" rel="noopener noreferrer" target="_blank">work-with-qat-networks</a></p></li>
</ul>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="1_quantization.html" class="btn btn-neutral float-left" title="Quantization" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="_choosing_quant_methods.html" class="btn btn-neutral float-right" title="Best practices to choose the right quantization methods" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023-2024, NVIDIA Corporation.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.


</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

</body>
</html>
