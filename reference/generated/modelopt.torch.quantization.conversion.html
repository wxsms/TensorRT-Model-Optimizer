<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>conversion &mdash; Model Optimizer 0.11.2</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../../_static/tabs.css?v=4c969af8" />
      <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
      <link rel="stylesheet" type="text/css" href="../../_static/autodoc_pydantic.css" />
      <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=d10054b6" />


  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->

        <script src="../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../../_static/documentation_options.js?v=5929fcd5"></script>
        <script src="../../_static/doctools.js?v=888ff710"></script>
        <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
        <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
        <script src="../../_static/copybutton.js?v=20d3d275"></script>
        <script src="../../_static/tabs.js?v=3ee01567"></script>
        <script>let toggleHintShow = 'Click to show';</script>
        <script>let toggleHintHide = 'Click to hide';</script>
        <script>let toggleOpenOnPrint = 'true';</script>
        <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
        <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="extensions" href="modelopt.torch.quantization.extensions.html" />
    <link rel="prev" title="config" href="modelopt.torch.quantization.config.html" />
</head>

<body class="wy-body-for-nav">
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >



          <a href="../../index.html" class="icon icon-home">
            TensorRT Model Optimizer
          </a>
              <div class="version">
                0.11.2
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started/1_overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started/2_installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started/3_quantization.html">Quick Start: Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started/6_sparsity.html">Quick Start: Sparsity</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Optimization Guides</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../guides/1_quantization.html">Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../guides/5_sparsity.html">Sparsity</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Deployment</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../deployment/1_tensorrt_llm_deployment.html">TensorRT-LLM Deployment</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../examples/0_all_examples.html">All ModelOpt Examples</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Reference</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../0_versions.html">Model Optimizer Changelog</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../1_modelopt_api.html">modelopt API</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="modelopt.deploy.html">deploy</a></li>
<li class="toctree-l2"><a class="reference internal" href="modelopt.onnx.html">onnx</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="modelopt.torch.html">torch</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="modelopt.torch.export.html">export</a></li>
<li class="toctree-l3"><a class="reference internal" href="modelopt.torch.opt.html">opt</a></li>
<li class="toctree-l3 current"><a class="reference internal" href="modelopt.torch.quantization.html">quantization</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="modelopt.torch.quantization.calib.html">calib</a></li>
<li class="toctree-l4"><a class="reference internal" href="modelopt.torch.quantization.config.html">config</a></li>
<li class="toctree-l4 current"><a class="current reference internal" href="#">conversion</a></li>
<li class="toctree-l4"><a class="reference internal" href="modelopt.torch.quantization.extensions.html">extensions</a></li>
<li class="toctree-l4"><a class="reference internal" href="modelopt.torch.quantization.mode.html">mode</a></li>
<li class="toctree-l4"><a class="reference internal" href="modelopt.torch.quantization.model_calib.html">model_calib</a></li>
<li class="toctree-l4"><a class="reference internal" href="modelopt.torch.quantization.model_quant.html">model_quant</a></li>
<li class="toctree-l4"><a class="reference internal" href="modelopt.torch.quantization.nn.html">nn</a></li>
<li class="toctree-l4"><a class="reference internal" href="modelopt.torch.quantization.optim.html">optim</a></li>
<li class="toctree-l4"><a class="reference internal" href="modelopt.torch.quantization.plugins.html">plugins</a></li>
<li class="toctree-l4"><a class="reference internal" href="modelopt.torch.quantization.quant_modules.html">quant_modules</a></li>
<li class="toctree-l4"><a class="reference internal" href="modelopt.torch.quantization.tensor_quant.html">tensor_quant</a></li>
<li class="toctree-l4"><a class="reference internal" href="modelopt.torch.quantization.utils.html">utils</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="modelopt.torch.sparsity.html">sparsity</a></li>
<li class="toctree-l3"><a class="reference internal" href="modelopt.torch.utils.html">utils</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Support</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../support/1_contact.html">Contact us</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../support/2_faqs.html">FAQs</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">TensorRT Model Optimizer</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../1_modelopt_api.html">modelopt API</a></li>
          <li class="breadcrumb-item"><a href="modelopt.torch.html">torch</a></li>
          <li class="breadcrumb-item"><a href="modelopt.torch.quantization.html">quantization</a></li>
      <li class="breadcrumb-item active">conversion</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/reference/generated/modelopt.torch.quantization.conversion.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">

  <section id="conversion">
<h1>conversion<a class="headerlink" href="#conversion" title="Link to this heading"></a></h1>
<p id="module-modelopt.torch.quantization.conversion">Quantization conversion/restore utilities.</p>
<p class="rubric">Functions</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#modelopt.torch.quantization.conversion.replace_quant_module" title="modelopt.torch.quantization.conversion.replace_quant_module"><code class="xref py py-obj docutils literal notranslate"><span class="pre">replace_quant_module</span></code></a></p></td>
<td><p>Recursively replace the module with quantized module.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#modelopt.torch.quantization.conversion.set_quantizer_by_cfg" title="modelopt.torch.quantization.conversion.set_quantizer_by_cfg"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_quantizer_by_cfg</span></code></a></p></td>
<td><p>Update the quantizer attributes based on the specified <cite>quant_cfg</cite>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#modelopt.torch.quantization.conversion.set_quantizer_attribute" title="modelopt.torch.quantization.conversion.set_quantizer_attribute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_quantizer_attribute</span></code></a></p></td>
<td><p>Finegrained adjustment of quantizer attribute by wildcard or filter function.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#modelopt.torch.quantization.conversion.register" title="modelopt.torch.quantization.conversion.register"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register</span></code></a></p></td>
<td><p>Register a quantized class for the given un-quantized original class.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#modelopt.torch.quantization.conversion.unregister" title="modelopt.torch.quantization.conversion.unregister"><code class="xref py py-obj docutils literal notranslate"><span class="pre">unregister</span></code></a></p></td>
<td><p>Unregister the quantized class for the given un-quantized original class.</p></td>
</tr>
</tbody>
</table>
<dl class="py function">
<dt class="sig sig-object py" id="modelopt.torch.quantization.conversion.register">
<span class="sig-name descname"><span class="pre">register</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">original_cls</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">quantized_cls</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#modelopt.torch.quantization.conversion.register" title="Link to this definition"></a></dt>
<dd><p>Register a quantized class for the given un-quantized original class.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>original_cls</strong> (<em>Module</em>) – The original un-quantized class.</p></li>
<li><p><strong>quantized_cls</strong> (<em>Module</em>) – The quantized class. This class should have a <cite>_setup</cite> method which initializes
various quantizers called in the forward. The forward function of the quantized class should call the
quantizers at the correct location.</p></li>
</ul>
</dd>
</dl>
<p>Here is an example of defining a quantized class and registering it:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">modelopt.torch.quantization</span> <span class="k">as</span> <span class="nn">mtq</span>
<span class="kn">from</span> <span class="nn">modelopt.torch.quantization.tensor_quant</span> <span class="kn">import</span> <span class="n">TensorQuantizer</span><span class="p">,</span> <span class="n">QuantDescriptor</span>


<span class="k">class</span> <span class="nc">QuantLayerNorm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">normalized_shape</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">normalized_shape</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setup</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_setup</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Method to setup the quantizers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_quantizer</span> <span class="o">=</span> <span class="n">TensorQuantizer</span><span class="p">(</span><span class="n">QuantDescriptor</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight_quantizer</span> <span class="o">=</span> <span class="n">TensorQuantizer</span><span class="p">(</span><span class="n">QuantDescriptor</span><span class="p">())</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
        <span class="nb">input</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_quantizer</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
        <span class="n">weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_quantizer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">layer_norm</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalized_shape</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">)</span>


<span class="c1"># Register the custom quantized module</span>
<span class="n">mtq</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="n">original_cls</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">,</span> <span class="n">quantized_cls</span><span class="o">=</span><span class="n">QuantLayerNorm</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="modelopt.torch.quantization.conversion.replace_quant_module">
<span class="sig-name descname"><span class="pre">replace_quant_module</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#modelopt.torch.quantization.conversion.replace_quant_module" title="Link to this definition"></a></dt>
<dd><p>Recursively replace the module with quantized module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>model</strong> (<em>Module</em>) – </p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="modelopt.torch.quantization.conversion.set_quantizer_attribute">
<span class="sig-name descname"><span class="pre">set_quantizer_attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">quant_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">wildcard_or_filter_func</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attribute</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#modelopt.torch.quantization.conversion.set_quantizer_attribute" title="Link to this definition"></a></dt>
<dd><p>Finegrained adjustment of quantizer attribute by wildcard or filter function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>quant_model</strong> (<em>Module</em>) – A pytorch model</p></li>
<li><p><strong>wildcard_or_filter_func</strong> (<em>str</em><em> | </em><em>Callable</em>) – a wildcard string or a filter function. The wildcard string is matched
against the quantizer module names. The quantizer modules are
instances of
<a class="reference internal" href="modelopt.torch.quantization.nn.modules.tensor_quantizer.html#modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer" title="modelopt.torch.quantization.nn.modules.tensor_quantizer.TensorQuantizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">TensorQuantizer</span></code></a>.
The filter function takes a quantized module name as input and returns <code class="docutils literal notranslate"><span class="pre">True</span></code> if the
quantizer should be adjusted and <code class="docutils literal notranslate"><span class="pre">False</span></code> otherwise.</p></li>
<li><p><strong>attribute</strong> – a dict of quantizer attributes or a list of quantizer attribute dicts.
An example attribute dict is: <code class="docutils literal notranslate"><span class="pre">{&quot;num_bits&quot;:</span> <span class="pre">8,</span> <span class="pre">&quot;axis&quot;:</span> <span class="pre">0,</span> <span class="pre">&quot;enable&quot;:</span> <span class="pre">True}</span></code>.
If <code class="docutils literal notranslate"><span class="pre">attribute</span></code> is a list of dicts, the matched
<code class="xref py py-class docutils literal notranslate"><span class="pre">TensorQuantizer</span></code> modules will be replaced with
<code class="xref py py-class docutils literal notranslate"><span class="pre">SequentialQuantizer</span></code> modules having one quantizer
for each attribute dict from the list.
See <code class="xref py py-meth docutils literal notranslate"><span class="pre">set_from_attribute_dict</span></code>
for more details on the supported attributes and their types.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="modelopt.torch.quantization.conversion.set_quantizer_by_cfg">
<span class="sig-name descname"><span class="pre">set_quantizer_by_cfg</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">quant_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">quant_cfg</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#modelopt.torch.quantization.conversion.set_quantizer_by_cfg" title="Link to this definition"></a></dt>
<dd><p>Update the quantizer attributes based on the specified <cite>quant_cfg</cite>.</p>
<p><cite>quant_cfg</cite> is a dictionary mapping wildcards or filter functions
to its quantizer attributes. The wildcards or filter functions  are matched
against the quantizer module names. The specified quantizer attributes of the
matched quantizer modules are set accordingly.</p>
<p>See <a class="reference internal" href="#modelopt.torch.quantization.conversion.set_quantizer_attribute" title="modelopt.torch.quantization.conversion.set_quantizer_attribute"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_quantizer_attribute</span></code></a>
for more details.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>quant_model</strong> (<em>Module</em>) – </p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="modelopt.torch.quantization.conversion.unregister">
<span class="sig-name descname"><span class="pre">unregister</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">original_cls</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#modelopt.torch.quantization.conversion.unregister" title="Link to this definition"></a></dt>
<dd><p>Unregister the quantized class for the given un-quantized original class.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>original_cls</strong> (<em>Module</em>) – The original un-quantized class.</p>
</dd>
</dl>
</dd></dl>

</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="modelopt.torch.quantization.config.html" class="btn btn-neutral float-left" title="config" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="modelopt.torch.quantization.extensions.html" class="btn btn-neutral float-right" title="extensions" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023-2024, NVIDIA Corporation.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.


</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

</body>
</html>
