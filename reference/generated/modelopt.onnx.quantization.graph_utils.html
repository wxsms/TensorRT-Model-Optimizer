

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>graph_utils &mdash; Model Optimizer 0.19.0</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../../_static/tabs.css?v=4c969af8" />
      <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
      <link rel="stylesheet" type="text/css" href="../../_static/autodoc_pydantic.css" />
      <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=7a224f4b" />

  
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=5929fcd5"></script>
      <script src="../../_static/doctools.js?v=888ff710"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="../../_static/copybutton.js?v=20d3d275"></script>
      <script src="../../_static/tabs.js?v=3ee01567"></script>
      <script>let toggleHintShow = 'Click to show';</script>
      <script>let toggleHintHide = 'Click to hide';</script>
      <script>let toggleOpenOnPrint = 'true';</script>
      <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
      <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
      <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
      <script src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>
      <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="gs_patching" href="modelopt.onnx.quantization.gs_patching.html" />
    <link rel="prev" title="fp8" href="modelopt.onnx.quantization.fp8.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            TensorRT Model Optimizer
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started/1_overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started/2_installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started/3_quantization.html">Quick Start: Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started/4_pruning.html">Quick Start: Pruning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started/5_distillation.html">Quick Start: Distillation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started/6_sparsity.html">Quick Start: Sparsity</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Guides</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../guides/1_quantization.html">Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../guides/2_pruning.html">Pruning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../guides/3_nas.html">NAS</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../guides/4_distillation.html">Distillation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../guides/5_sparsity.html">Sparsity</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../guides/6_save_load.html">Saving &amp; Restoring</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../guides/7_speculative_decoding.html">Speculative Decoding</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Deployment</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../deployment/1_tensorrt_llm_deployment.html">TensorRT-LLM Deployment</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../examples/0_all_examples.html">All GitHub Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../examples/1_cifar_resnet.html">ResNet20 on CIFAR-10: Pruning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../examples/2_bert_prune_distill_quantize.html">HF BERT: Prune, Distill &amp; Quantize</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Reference</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../0_changelog.html">Model Optimizer Changelog</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../1_modelopt_api.html">modelopt API</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="modelopt.deploy.html">deploy</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="modelopt.onnx.html">onnx</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="modelopt.onnx.op_types.html">op_types</a></li>
<li class="toctree-l3 current"><a class="reference internal" href="modelopt.onnx.quantization.html">quantization</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="modelopt.onnx.quantization.calib_utils.html">calib_utils</a></li>
<li class="toctree-l4"><a class="reference internal" href="modelopt.onnx.quantization.extensions.html">extensions</a></li>
<li class="toctree-l4"><a class="reference internal" href="modelopt.onnx.quantization.fp8.html">fp8</a></li>
<li class="toctree-l4 current"><a class="current reference internal" href="#">graph_utils</a></li>
<li class="toctree-l4"><a class="reference internal" href="modelopt.onnx.quantization.gs_patching.html">gs_patching</a></li>
<li class="toctree-l4"><a class="reference internal" href="modelopt.onnx.quantization.int4.html">int4</a></li>
<li class="toctree-l4"><a class="reference internal" href="modelopt.onnx.quantization.int8.html">int8</a></li>
<li class="toctree-l4"><a class="reference internal" href="modelopt.onnx.quantization.operators.html">operators</a></li>
<li class="toctree-l4"><a class="reference internal" href="modelopt.onnx.quantization.ort_patching.html">ort_patching</a></li>
<li class="toctree-l4"><a class="reference internal" href="modelopt.onnx.quantization.ort_utils.html">ort_utils</a></li>
<li class="toctree-l4"><a class="reference internal" href="modelopt.onnx.quantization.partitioning.html">partitioning</a></li>
<li class="toctree-l4"><a class="reference internal" href="modelopt.onnx.quantization.qdq_utils.html">qdq_utils</a></li>
<li class="toctree-l4"><a class="reference internal" href="modelopt.onnx.quantization.quant_utils.html">quant_utils</a></li>
<li class="toctree-l4"><a class="reference internal" href="modelopt.onnx.quantization.quantize.html">modelopt.onnx.quantization.quantize</a></li>
<li class="toctree-l4"><a class="reference internal" href="modelopt.onnx.quantization.trt_utils.html">trt_utils</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="modelopt.onnx.utils.html">utils</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="modelopt.torch.html">torch</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Support</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../support/1_contact.html">Contact us</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../support/2_faqs.html">FAQs</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">TensorRT Model Optimizer</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../1_modelopt_api.html">modelopt API</a></li>
          <li class="breadcrumb-item"><a href="modelopt.onnx.html">onnx</a></li>
          <li class="breadcrumb-item"><a href="modelopt.onnx.quantization.html">quantization</a></li>
      <li class="breadcrumb-item active">graph_utils</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/reference/generated/modelopt.onnx.quantization.graph_utils.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="graph-utils">
<h1>graph_utils<a class="headerlink" href="#graph-utils" title="Link to this heading"></a></h1>
<p id="module-modelopt.onnx.quantization.graph_utils">Provides ONNX graph related utils for QDQ placement.</p>
<p class="rubric">Functions</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#modelopt.onnx.quantization.graph_utils.add_fp16_fp32_cast" title="modelopt.onnx.quantization.graph_utils.add_fp16_fp32_cast"><code class="xref py py-obj docutils literal notranslate"><span class="pre">add_fp16_fp32_cast</span></code></a></p></td>
<td><p>Adds cast_to_fp16 nodes to the inputs of a layer and cast_to_fp32 to the outputs.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#modelopt.onnx.quantization.graph_utils.build_non_residual_input_map" title="modelopt.onnx.quantization.graph_utils.build_non_residual_input_map"><code class="xref py py-obj docutils literal notranslate"><span class="pre">build_non_residual_input_map</span></code></a></p></td>
<td><p>Builds a map of non-residual Add input name to the Add node name from the given graph.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#modelopt.onnx.quantization.graph_utils.classify_partition_nodes" title="modelopt.onnx.quantization.graph_utils.classify_partition_nodes"><code class="xref py py-obj docutils literal notranslate"><span class="pre">classify_partition_nodes</span></code></a></p></td>
<td><p>We should partially quantize the partition nodes with inputs outside of the partition.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#modelopt.onnx.quantization.graph_utils.convert_fp16_io" title="modelopt.onnx.quantization.graph_utils.convert_fp16_io"><code class="xref py py-obj docutils literal notranslate"><span class="pre">convert_fp16_io</span></code></a></p></td>
<td><p>Convert graph I/O to FP16.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#modelopt.onnx.quantization.graph_utils.expand_node_names_from_patterns" title="modelopt.onnx.quantization.graph_utils.expand_node_names_from_patterns"><code class="xref py py-obj docutils literal notranslate"><span class="pre">expand_node_names_from_patterns</span></code></a></p></td>
<td><p>Expand the node names from the given patterns.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#modelopt.onnx.quantization.graph_utils.filter_quantizable_kgen_heads" title="modelopt.onnx.quantization.graph_utils.filter_quantizable_kgen_heads"><code class="xref py py-obj docutils literal notranslate"><span class="pre">filter_quantizable_kgen_heads</span></code></a></p></td>
<td><p>Returns the list of kgen head names if it follows a CASK partition.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#modelopt.onnx.quantization.graph_utils.find_fp8_mha_partitions" title="modelopt.onnx.quantization.graph_utils.find_fp8_mha_partitions"><code class="xref py py-obj docutils literal notranslate"><span class="pre">find_fp8_mha_partitions</span></code></a></p></td>
<td><p>Match FP8 MHA: Q -&gt; DQ -&gt; BMM1 -&gt; (Mul/Div) -&gt; (Add) -&gt; Softmax -&gt; (Cast) -&gt; Q -&gt; DQ -&gt; BMM2 -&gt; Q -&gt; DQ.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#modelopt.onnx.quantization.graph_utils.find_mha_partitions" title="modelopt.onnx.quantization.graph_utils.find_mha_partitions"><code class="xref py py-obj docutils literal notranslate"><span class="pre">find_mha_partitions</span></code></a></p></td>
<td><p>Match MHA: BMM1 -&gt; (Mul/Div) -&gt; (Add) -&gt; Softmax -&gt; (Cast) -&gt; BMM2.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#modelopt.onnx.quantization.graph_utils.find_nodes_from_matmul_to_exclude" title="modelopt.onnx.quantization.graph_utils.find_nodes_from_matmul_to_exclude"><code class="xref py py-obj docutils literal notranslate"><span class="pre">find_nodes_from_matmul_to_exclude</span></code></a></p></td>
<td><p>Find MatMul nodes that meets gemv condition to exclude.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#modelopt.onnx.quantization.graph_utils.find_nodes_from_mha_to_exclude" title="modelopt.onnx.quantization.graph_utils.find_nodes_from_mha_to_exclude"><code class="xref py py-obj docutils literal notranslate"><span class="pre">find_nodes_from_mha_to_exclude</span></code></a></p></td>
<td><p>Find MatMul nodes in MHA pattern to exclude.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#modelopt.onnx.quantization.graph_utils.find_nodes_to_exclude" title="modelopt.onnx.quantization.graph_utils.find_nodes_to_exclude"><code class="xref py py-obj docutils literal notranslate"><span class="pre">find_nodes_to_exclude</span></code></a></p></td>
<td><p>Find the node names from the ONNX graph which matches user's exclusion patterns.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#modelopt.onnx.quantization.graph_utils.get_fusible_backbone" title="modelopt.onnx.quantization.graph_utils.get_fusible_backbone"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_fusible_backbone</span></code></a></p></td>
<td><p>Returns the linear backbone node for a given node if it matches the pattern.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#modelopt.onnx.quantization.graph_utils.get_tensor_consumer_nodes" title="modelopt.onnx.quantization.graph_utils.get_tensor_consumer_nodes"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_tensor_consumer_nodes</span></code></a></p></td>
<td><p>Returns a dictionary of tensor name and their consumer node object mapping.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#modelopt.onnx.quantization.graph_utils.get_tensor_producer_nodes" title="modelopt.onnx.quantization.graph_utils.get_tensor_producer_nodes"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_tensor_producer_nodes</span></code></a></p></td>
<td><p>Returns a dictionary of tensor name and their producer node object mapping.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#modelopt.onnx.quantization.graph_utils.has_const_input" title="modelopt.onnx.quantization.graph_utils.has_const_input"><code class="xref py py-obj docutils literal notranslate"><span class="pre">has_const_input</span></code></a></p></td>
<td><p>Returns whether the given node has any constant input.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#modelopt.onnx.quantization.graph_utils.has_path_type" title="modelopt.onnx.quantization.graph_utils.has_path_type"><code class="xref py py-obj docutils literal notranslate"><span class="pre">has_path_type</span></code></a></p></td>
<td><p>Checks if the given node is start/end of a given forward/backward path type.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#modelopt.onnx.quantization.graph_utils.insert_fp8_mha_casts" title="modelopt.onnx.quantization.graph_utils.insert_fp8_mha_casts"><code class="xref py py-obj docutils literal notranslate"><span class="pre">insert_fp8_mha_casts</span></code></a></p></td>
<td><p>Insert three cast ops.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#modelopt.onnx.quantization.graph_utils.insert_matmul_casts" title="modelopt.onnx.quantization.graph_utils.insert_matmul_casts"><code class="xref py py-obj docutils literal notranslate"><span class="pre">insert_matmul_casts</span></code></a></p></td>
<td><p>Insert three cast nodes for MatMul's two inputs and output.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#modelopt.onnx.quantization.graph_utils.is_const_input" title="modelopt.onnx.quantization.graph_utils.is_const_input"><code class="xref py py-obj docutils literal notranslate"><span class="pre">is_const_input</span></code></a></p></td>
<td><p>Returns whether the given tensor is an initializer or produced by const-foldable nodes.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#modelopt.onnx.quantization.graph_utils.print_stat" title="modelopt.onnx.quantization.graph_utils.print_stat"><code class="xref py py-obj docutils literal notranslate"><span class="pre">print_stat</span></code></a></p></td>
<td><p>Collect and print stats of the quantized model.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#modelopt.onnx.quantization.graph_utils.remove_partial_input_qdq" title="modelopt.onnx.quantization.graph_utils.remove_partial_input_qdq"><code class="xref py py-obj docutils literal notranslate"><span class="pre">remove_partial_input_qdq</span></code></a></p></td>
<td><p>Modifies the onnx model by removing QDQ nodes from the marked inputs, ex.</p></td>
</tr>
</tbody>
</table>
<dl class="py function">
<dt class="sig sig-object py" id="modelopt.onnx.quantization.graph_utils.add_fp16_fp32_cast">
<span class="sig-name descname"><span class="pre">add_fp16_fp32_cast</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">onnx_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">custom_ops_to_cast_to_fp16</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#modelopt.onnx.quantization.graph_utils.add_fp16_fp32_cast" title="Link to this definition"></a></dt>
<dd><p>Adds cast_to_fp16 nodes to the inputs of a layer and cast_to_fp32 to the outputs.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="modelopt.onnx.quantization.graph_utils.build_non_residual_input_map">
<span class="sig-name descname"><span class="pre">build_non_residual_input_map</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">graph</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#modelopt.onnx.quantization.graph_utils.build_non_residual_input_map" title="Link to this definition"></a></dt>
<dd><p>Builds a map of non-residual Add input name to the Add node name from the given graph.</p>
<p>This assumes that the Add layer only has 2 inputs.</p>
<p>We will refer to a subgraph which has a Convolution node with a single output that is summed (element-wise)
with another non-constant input-tensor as a “residual-add” subgraph, because it occurs in modern
convnets that use residual connections.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>graph</strong> (<em>Graph</em>) – Onnx model graph.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Dictionary of Add node names vs their non-residual input name.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Dict</em>[<em>str</em>, <em>str</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="modelopt.onnx.quantization.graph_utils.classify_partition_nodes">
<span class="sig-name descname"><span class="pre">classify_partition_nodes</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">partitions</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#modelopt.onnx.quantization.graph_utils.classify_partition_nodes" title="Link to this definition"></a></dt>
<dd><p>We should partially quantize the partition nodes with inputs outside of the partition.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>partitions</strong> (<em>List</em><em>[</em><em>List</em><em>[</em><em>Node</em><em>]</em><em>]</em>) – Partitions created by modelopt ptq algo.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>List of non-quantizable nodes.
List of quantizable nodes.
List of partially-quantizable inputs with non-quantizable input info as (src, dst, input_name)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tuple</em>[<em>List</em>[<em>Node</em>], <em>List</em>[<em>Node</em>], <em>List</em>[<em>Tuple</em>[<em>Node</em>, <em>Node</em>, <em>str</em>]]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="modelopt.onnx.quantization.graph_utils.convert_fp16_io">
<span class="sig-name descname"><span class="pre">convert_fp16_io</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">graph</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#modelopt.onnx.quantization.graph_utils.convert_fp16_io" title="Link to this definition"></a></dt>
<dd><p>Convert graph I/O to FP16.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="modelopt.onnx.quantization.graph_utils.expand_node_names_from_patterns">
<span class="sig-name descname"><span class="pre">expand_node_names_from_patterns</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">graph</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name_patterns</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#modelopt.onnx.quantization.graph_utils.expand_node_names_from_patterns" title="Link to this definition"></a></dt>
<dd><p>Expand the node names from the given patterns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>graph</strong> (<em>GraphProto</em><em> | </em><em>Graph</em>) – </p></li>
<li><p><strong>name_patterns</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>List</em>[<em>str</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="modelopt.onnx.quantization.graph_utils.filter_quantizable_kgen_heads">
<span class="sig-name descname"><span class="pre">filter_quantizable_kgen_heads</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cask_fusible_partitions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kgen_partitions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">quantizable_op_types</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#modelopt.onnx.quantization.graph_utils.filter_quantizable_kgen_heads" title="Link to this definition"></a></dt>
<dd><p>Returns the list of kgen head names if it follows a CASK partition.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cask_fusible_partitions</strong> (<em>List</em><em>[</em><em>List</em><em>[</em><em>Node</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>kgen_partitions</strong> (<em>List</em><em>[</em><em>List</em><em>[</em><em>Node</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>quantizable_op_types</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tuple</em>[<em>List</em>[<em>Node</em>], <em>List</em>[<em>Tuple</em>[<em>Node</em>, <em>Node</em>, <em>str</em>]]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="modelopt.onnx.quantization.graph_utils.find_fp8_mha_partitions">
<span class="sig-name descname"><span class="pre">find_fp8_mha_partitions</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">graph</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#modelopt.onnx.quantization.graph_utils.find_fp8_mha_partitions" title="Link to this definition"></a></dt>
<dd><p>Match FP8 MHA: Q -&gt; DQ -&gt; BMM1 -&gt; (Mul/Div) -&gt; (Add) -&gt; Softmax -&gt; (Cast) -&gt; Q -&gt; DQ -&gt; BMM2 -&gt; Q -&gt; DQ.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="modelopt.onnx.quantization.graph_utils.find_mha_partitions">
<span class="sig-name descname"><span class="pre">find_mha_partitions</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">graph</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#modelopt.onnx.quantization.graph_utils.find_mha_partitions" title="Link to this definition"></a></dt>
<dd><p>Match MHA: BMM1 -&gt; (Mul/Div) -&gt; (Add) -&gt; Softmax -&gt; (Cast) -&gt; BMM2.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="modelopt.onnx.quantization.graph_utils.find_nodes_from_matmul_to_exclude">
<span class="sig-name descname"><span class="pre">find_nodes_from_matmul_to_exclude</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">onnx_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_external_data_format</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">intermediate_generated_files</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">calibration_shapes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">calibration_eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">['cuda:0',</span> <span class="pre">'cpu',</span> <span class="pre">'trt']</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#modelopt.onnx.quantization.graph_utils.find_nodes_from_matmul_to_exclude" title="Link to this definition"></a></dt>
<dd><p>Find MatMul nodes that meets gemv condition to exclude.</p>
<p>Either of m or n in matmul is 1, this matmul cannot utilize
TensorCores. The perf of adding Q/DQ layers is not good in
TRT. Thus, in this case, do not add Q/DQ layers to this matmul.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>onnx_path</strong> (<em>str</em>) – Path to the onnx model.</p></li>
<li><p><strong>use_external_data_format</strong> (<em>bool</em>) – If not None, this path will be used to store the weights of the quantized model.</p></li>
<li><p><strong>intermediate_generated_files</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – List of intermediate generated files that will be deleted after quantization.</p></li>
<li><p><strong>calibration_shapes</strong> (<em>str</em>) – Model input shapes for inferenece.</p></li>
<li><p><strong>calibration_eps</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – Priority order for the execution providers (EP) to calibrate the model.
Any subset of [‘cuda:x’, ‘cpu’, ‘trt’], where ‘x’ is the device id.</p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) – If True, print the matmul nodes to exclude.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>List of Nodes to exclude from quantization.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>List</em>[<em>str</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="modelopt.onnx.quantization.graph_utils.find_nodes_from_mha_to_exclude">
<span class="sig-name descname"><span class="pre">find_nodes_from_mha_to_exclude</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">onnx_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_external_data_format</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nodes_to_exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disable_mha_qdq</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">quantize_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'int8'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">high_precision_dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">intermediate_generated_files</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">calibration_shapes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">calibration_eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">['cuda:0',</span> <span class="pre">'cpu',</span> <span class="pre">'trt']</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#modelopt.onnx.quantization.graph_utils.find_nodes_from_mha_to_exclude" title="Link to this definition"></a></dt>
<dd><p>Find MatMul nodes in MHA pattern to exclude.</p>
<p>If disable_mha_qdq is set, don’t add Q/DQ layers to MatMuls in MHA pattern.
else when quantize_mode == “fp8” and high_precision_dtype == “fp16”,
if head_size is not the multiple of 16 or there is maskadd in MHA pattern,
don’t add Q/DQ layers to MatMuls in MHA pattern.
else when quantize_mode == “int8”, if seq_len &gt; 512, don’t add Q/DQ layers
to MatMuls in MHA pattern.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>onnx_path</strong> (<em>str</em>) – Path to the onnx model.</p></li>
<li><p><strong>use_external_data_format</strong> (<em>bool</em>) – If not None, this path will be used to store the weights of the quantized model.</p></li>
<li><p><strong>nodes_to_exclude</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – List of Nodes to exclude from quantization.</p></li>
<li><p><strong>disable_mha_qdq</strong> (<em>bool</em>) – If True, all MHA’s BMM1 and BMM2 will be added to nodes_to_exclude.
Else, each MHA will be checked whether to enable QDQ or not when is_fp8fp16 is True.</p></li>
<li><p><strong>quantize_mode</strong> (<em>str</em>) – Quantization mode. One of ‘int8’ (default), ‘int4’ and ‘fp8’.</p></li>
<li><p><strong>high_precision_dtype</strong> (<em>str</em>) – High precision data type, one of [‘fp32’, ‘fp16’]. If high_precision_dtype == ‘fp16’, model’s weight and
activation will be converted to fp16.</p></li>
<li><p><strong>intermediate_generated_files</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – List of intermediate generated files that will be deleted after quantization.</p></li>
<li><p><strong>calibration_shapes</strong> (<em>str</em>) – Model input shapes for inferenece.</p></li>
<li><p><strong>calibration_eps</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – Priority list of execution providers (EP) for calibration.</p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) – If True, print the matmul nodes to exclude.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>List of Nodes to exclude from quantization.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>List</em>[<em>str</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="modelopt.onnx.quantization.graph_utils.find_nodes_to_exclude">
<span class="sig-name descname"><span class="pre">find_nodes_to_exclude</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">graph</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nodes_to_exclude</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">op_types_to_exclude</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#modelopt.onnx.quantization.graph_utils.find_nodes_to_exclude" title="Link to this definition"></a></dt>
<dd><p>Find the node names from the ONNX graph which matches user’s exclusion patterns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>graph</strong> (<em>Graph</em>) – </p></li>
<li><p><strong>nodes_to_exclude</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – </p></li>
<li><p><strong>op_types_to_exclude</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="modelopt.onnx.quantization.graph_utils.get_fusible_backbone">
<span class="sig-name descname"><span class="pre">get_fusible_backbone</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">graph</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#modelopt.onnx.quantization.graph_utils.get_fusible_backbone" title="Link to this definition"></a></dt>
<dd><p>Returns the linear backbone node for a given node if it matches the pattern.</p>
<p>TensorRT fuses convolution with BN, Relu etc. when in some specific pattern.
This rule tries to match some of those patterns.
Note. BiasAdd and ConstMul are optional in path types.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>node</strong> (<em>Node</em>) – Start node of the pattern.</p></li>
<li><p><strong>graph</strong> (<em>Graph</em>) – ONNX model graph.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Backbone node of the given node, None if not found.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Node</em> | <em>None</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="modelopt.onnx.quantization.graph_utils.get_tensor_consumer_nodes">
<span class="sig-name descname"><span class="pre">get_tensor_consumer_nodes</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">graph</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#modelopt.onnx.quantization.graph_utils.get_tensor_consumer_nodes" title="Link to this definition"></a></dt>
<dd><p>Returns a dictionary of tensor name and their consumer node object mapping.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>graph</strong> (<em>GraphProto</em>) – ONNX model graph.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Dictionary, key is tensor name and value is their consumer node object</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Dict</em>[<em>str</em>, <em>List</em>[<em>NodeProto</em>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="modelopt.onnx.quantization.graph_utils.get_tensor_producer_nodes">
<span class="sig-name descname"><span class="pre">get_tensor_producer_nodes</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">graph</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#modelopt.onnx.quantization.graph_utils.get_tensor_producer_nodes" title="Link to this definition"></a></dt>
<dd><p>Returns a dictionary of tensor name and their producer node object mapping.</p>
<p>Note. we create a special Root type node as external inputs producer for ease of implementation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>graph</strong> (<em>GraphProto</em>) – ONNX model graph.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Dictionary, key is tensor name and value is their producer node object</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Dict</em>[<em>str</em>, <em>NodeProto</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="modelopt.onnx.quantization.graph_utils.has_const_input">
<span class="sig-name descname"><span class="pre">has_const_input</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#modelopt.onnx.quantization.graph_utils.has_const_input" title="Link to this definition"></a></dt>
<dd><p>Returns whether the given node has any constant input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>node</strong> (<em>Node</em>) – </p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>bool</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="modelopt.onnx.quantization.graph_utils.has_path_type">
<span class="sig-name descname"><span class="pre">has_path_type</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">graph</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">path_type</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_forward</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">wild_card_types</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">path_nodes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#modelopt.onnx.quantization.graph_utils.has_path_type" title="Link to this definition"></a></dt>
<dd><p>Checks if the given node is start/end of a given forward/backward path type.</p>
<p>Note, Path can be forward or backward wrt a node depending on the next level nodes.
Additionally, this method can work with optional nodes and collect the traversed path.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>node</strong> (<em>Node</em>) – Start node of the path.</p></li>
<li><p><strong>graph</strong> (<em>Graph</em>) – ONNX model graph.</p></li>
<li><p><strong>path_type</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – Path types to match from the given node.</p></li>
<li><p><strong>is_forward</strong> (<em>bool</em>) – Whether to match forward or backward path.</p></li>
<li><p><strong>wild_card_types</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – Wild card types, these type of nodes are skipped and not matched with the path_type.</p></li>
<li><p><strong>path_nodes</strong> (<em>List</em><em>[</em><em>Node</em><em>]</em>) – Accumulated nodes in the matched path.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Bool, whether the given node is start/end of the given forward/backward path type.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>bool</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="modelopt.onnx.quantization.graph_utils.insert_fp8_mha_casts">
<span class="sig-name descname"><span class="pre">insert_fp8_mha_casts</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">onnx_model</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#modelopt.onnx.quantization.graph_utils.insert_fp8_mha_casts" title="Link to this definition"></a></dt>
<dd><p>Insert three cast ops.</p>
<p>The first cast will be added before the input0 of MatMul to cast fp16 to fp32.
The second cast will be added before the input1 of MatMul to cast fp16 to fp32.
The third cast will be added after the output of MatMul to cast fp32 back to fp16.
The insertion of Cast ops in the FP8 MHA part actually forbids the MHAs to run
with FP16 accumulation because the compiler only has FP32 accumulation kernels for FP8 MHAs.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="modelopt.onnx.quantization.graph_utils.insert_matmul_casts">
<span class="sig-name descname"><span class="pre">insert_matmul_casts</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">graph</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">matmul_node</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#modelopt.onnx.quantization.graph_utils.insert_matmul_casts" title="Link to this definition"></a></dt>
<dd><p>Insert three cast nodes for MatMul’s two inputs and output.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="modelopt.onnx.quantization.graph_utils.is_const_input">
<span class="sig-name descname"><span class="pre">is_const_input</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#modelopt.onnx.quantization.graph_utils.is_const_input" title="Link to this definition"></a></dt>
<dd><p>Returns whether the given tensor is an initializer or produced by const-foldable nodes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>tensor</strong> (<em>Tensor</em>) – </p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>bool</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="modelopt.onnx.quantization.graph_utils.print_stat">
<span class="sig-name descname"><span class="pre">print_stat</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">graph</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#modelopt.onnx.quantization.graph_utils.print_stat" title="Link to this definition"></a></dt>
<dd><p>Collect and print stats of the quantized model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>graph</strong> (<em>Graph</em>) – </p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>None</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="modelopt.onnx.quantization.graph_utils.remove_partial_input_qdq">
<span class="sig-name descname"><span class="pre">remove_partial_input_qdq</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">graph</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">no_quantize_inputs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#modelopt.onnx.quantization.graph_utils.remove_partial_input_qdq" title="Link to this definition"></a></dt>
<dd><p>Modifies the onnx model by removing QDQ nodes from the marked inputs, ex. non-residual inputs etc.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>graph</strong> (<em>Graph</em>) – Onnx model graph.</p></li>
<li><p><strong>no_quantize_inputs</strong> (<em>List</em><em>[</em><em>Tuple</em><em>[</em><em>Node</em><em>, </em><em>Node</em><em>, </em><em>str</em><em>]</em><em>]</em>) – List non-quantizable input info as (src, dst, input_name)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>None</em></p>
</dd>
</dl>
</dd></dl>

</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="modelopt.onnx.quantization.fp8.html" class="btn btn-neutral float-left" title="fp8" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="modelopt.onnx.quantization.gs_patching.html" class="btn btn-neutral float-right" title="gs_patching" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023-2024, NVIDIA Corporation.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>