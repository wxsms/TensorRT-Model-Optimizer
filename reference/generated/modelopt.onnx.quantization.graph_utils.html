<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>graph_utils &mdash; Model Optimizer 0.15.0</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../../_static/tabs.css?v=4c969af8" />
      <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
      <link rel="stylesheet" type="text/css" href="../../_static/autodoc_pydantic.css" />
      <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=d10054b6" />

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../../_static/documentation_options.js?v=5929fcd5"></script>
        <script src="../../_static/doctools.js?v=888ff710"></script>
        <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
        <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
        <script src="../../_static/copybutton.js?v=20d3d275"></script>
        <script src="../../_static/tabs.js?v=3ee01567"></script>
        <script>let toggleHintShow = 'Click to show';</script>
        <script>let toggleHintHide = 'Click to hide';</script>
        <script>let toggleOpenOnPrint = 'true';</script>
        <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
        <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="gs_patching" href="modelopt.onnx.quantization.gs_patching.html" />
    <link rel="prev" title="fp8" href="modelopt.onnx.quantization.fp8.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            TensorRT Model Optimizer
          </a>
              <div class="version">
                0.15.0
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started/1_overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started/2_installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started/3_quantization.html">Quick Start: Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started/5_distillation.html">Quick Start: Distillation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started/6_sparsity.html">Quick Start: Sparsity</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Optimization Guides</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../guides/1_quantization.html">Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../guides/4_distillation.html">Distillation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../guides/5_sparsity.html">Sparsity</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Deployment</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../deployment/1_tensorrt_llm_deployment.html">TensorRT-LLM Deployment</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../examples/0_all_examples.html">GitHub Examples</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Reference</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../0_versions.html">Changelog</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../1_modelopt_api.html">modelopt API</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="modelopt.deploy.html">deploy</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="modelopt.onnx.html">onnx</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="modelopt.onnx.op_types.html">op_types</a></li>
<li class="toctree-l3 current"><a class="reference internal" href="modelopt.onnx.quantization.html">quantization</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="modelopt.onnx.quantization.calib_utils.html">calib_utils</a></li>
<li class="toctree-l4"><a class="reference internal" href="modelopt.onnx.quantization.extensions.html">extensions</a></li>
<li class="toctree-l4"><a class="reference internal" href="modelopt.onnx.quantization.fp8.html">fp8</a></li>
<li class="toctree-l4 current"><a class="current reference internal" href="#">graph_utils</a></li>
<li class="toctree-l4"><a class="reference internal" href="modelopt.onnx.quantization.gs_patching.html">gs_patching</a></li>
<li class="toctree-l4"><a class="reference internal" href="modelopt.onnx.quantization.int4.html">int4</a></li>
<li class="toctree-l4"><a class="reference internal" href="modelopt.onnx.quantization.int8.html">int8</a></li>
<li class="toctree-l4"><a class="reference internal" href="modelopt.onnx.quantization.operators.html">operators</a></li>
<li class="toctree-l4"><a class="reference internal" href="modelopt.onnx.quantization.ort_patching.html">ort_patching</a></li>
<li class="toctree-l4"><a class="reference internal" href="modelopt.onnx.quantization.ort_utils.html">ort_utils</a></li>
<li class="toctree-l4"><a class="reference internal" href="modelopt.onnx.quantization.partitioning.html">partitioning</a></li>
<li class="toctree-l4"><a class="reference internal" href="modelopt.onnx.quantization.qdq_utils.html">qdq_utils</a></li>
<li class="toctree-l4"><a class="reference internal" href="modelopt.onnx.quantization.quant_utils.html">quant_utils</a></li>
<li class="toctree-l4"><a class="reference internal" href="modelopt.onnx.quantization.quantize.html">modelopt.onnx.quantization.quantize</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="modelopt.onnx.utils.html">utils</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="modelopt.torch.html">torch</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Support</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../support/1_contact.html">Contact us</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../support/2_faqs.html">FAQs</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">TensorRT Model Optimizer</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../1_modelopt_api.html">modelopt API</a></li>
          <li class="breadcrumb-item"><a href="modelopt.onnx.html">onnx</a></li>
          <li class="breadcrumb-item"><a href="modelopt.onnx.quantization.html">quantization</a></li>
      <li class="breadcrumb-item active">graph_utils</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/reference/generated/modelopt.onnx.quantization.graph_utils.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="graph-utils">
<h1>graph_utils<a class="headerlink" href="#graph-utils" title="Link to this heading"></a></h1>
<p id="module-modelopt.onnx.quantization.graph_utils">Provides ONNX graph related utils for QDQ placement.</p>
<p class="rubric">Functions</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#modelopt.onnx.quantization.graph_utils.add_fp16_fp32_cast" title="modelopt.onnx.quantization.graph_utils.add_fp16_fp32_cast"><code class="xref py py-obj docutils literal notranslate"><span class="pre">add_fp16_fp32_cast</span></code></a></p></td>
<td><p>Adds cast_to_fp16 nodes to the inputs of a layer and cast_to_fp32 to the outputs.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#modelopt.onnx.quantization.graph_utils.build_non_residual_input_map" title="modelopt.onnx.quantization.graph_utils.build_non_residual_input_map"><code class="xref py py-obj docutils literal notranslate"><span class="pre">build_non_residual_input_map</span></code></a></p></td>
<td><p>Builds a map of non-residual Add input name to the Add node name from the given graph.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#modelopt.onnx.quantization.graph_utils.classify_partition_nodes" title="modelopt.onnx.quantization.graph_utils.classify_partition_nodes"><code class="xref py py-obj docutils literal notranslate"><span class="pre">classify_partition_nodes</span></code></a></p></td>
<td><p>We should partially quantize the partition nodes with inputs outside of the partition.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#modelopt.onnx.quantization.graph_utils.filter_quantizable_kgen_heads" title="modelopt.onnx.quantization.graph_utils.filter_quantizable_kgen_heads"><code class="xref py py-obj docutils literal notranslate"><span class="pre">filter_quantizable_kgen_heads</span></code></a></p></td>
<td><p>Returns the list of kgen head names if it follows a CASK partition.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#modelopt.onnx.quantization.graph_utils.find_fp8_mha_partitions" title="modelopt.onnx.quantization.graph_utils.find_fp8_mha_partitions"><code class="xref py py-obj docutils literal notranslate"><span class="pre">find_fp8_mha_partitions</span></code></a></p></td>
<td><p>Match FP8 MHA: Q -&gt; DQ -&gt; BMM1 -&gt; (Mul/Div) -&gt; (Add) -&gt; Softmax -&gt; (Cast) -&gt; Q -&gt; DQ -&gt; BMM2 -&gt; Q -&gt; DQ.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#modelopt.onnx.quantization.graph_utils.find_mha_partitions" title="modelopt.onnx.quantization.graph_utils.find_mha_partitions"><code class="xref py py-obj docutils literal notranslate"><span class="pre">find_mha_partitions</span></code></a></p></td>
<td><p>Match MHA: BMM1 -&gt; (Mul/Div) -&gt; (Add) -&gt; Softmax -&gt; (Cast) -&gt; BMM2.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#modelopt.onnx.quantization.graph_utils.find_nodes_to_exclude" title="modelopt.onnx.quantization.graph_utils.find_nodes_to_exclude"><code class="xref py py-obj docutils literal notranslate"><span class="pre">find_nodes_to_exclude</span></code></a></p></td>
<td><p>Find the node names from the ONNX graph which matches user's exclusion patterns.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#modelopt.onnx.quantization.graph_utils.get_fusible_backbone" title="modelopt.onnx.quantization.graph_utils.get_fusible_backbone"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_fusible_backbone</span></code></a></p></td>
<td><p>Returns the linear backbone node for a given node if it matches the pattern.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#modelopt.onnx.quantization.graph_utils.has_const_input" title="modelopt.onnx.quantization.graph_utils.has_const_input"><code class="xref py py-obj docutils literal notranslate"><span class="pre">has_const_input</span></code></a></p></td>
<td><p>Returns whether the given node has any constant input.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#modelopt.onnx.quantization.graph_utils.has_path_type" title="modelopt.onnx.quantization.graph_utils.has_path_type"><code class="xref py py-obj docutils literal notranslate"><span class="pre">has_path_type</span></code></a></p></td>
<td><p>Checks if the given node is start/end of a given forward/backward path type.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#modelopt.onnx.quantization.graph_utils.insert_fp8_mha_casts" title="modelopt.onnx.quantization.graph_utils.insert_fp8_mha_casts"><code class="xref py py-obj docutils literal notranslate"><span class="pre">insert_fp8_mha_casts</span></code></a></p></td>
<td><p>Insert three cast ops.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#modelopt.onnx.quantization.graph_utils.insert_matmul_casts" title="modelopt.onnx.quantization.graph_utils.insert_matmul_casts"><code class="xref py py-obj docutils literal notranslate"><span class="pre">insert_matmul_casts</span></code></a></p></td>
<td><p>Insert three cast nodes for MatMul's two inputs and output.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#modelopt.onnx.quantization.graph_utils.is_const_input" title="modelopt.onnx.quantization.graph_utils.is_const_input"><code class="xref py py-obj docutils literal notranslate"><span class="pre">is_const_input</span></code></a></p></td>
<td><p>Returns whether the given tensor is an initializer or produced by const-foldable nodes.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#modelopt.onnx.quantization.graph_utils.print_stat" title="modelopt.onnx.quantization.graph_utils.print_stat"><code class="xref py py-obj docutils literal notranslate"><span class="pre">print_stat</span></code></a></p></td>
<td><p>Collect and print stats of the quantized model.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#modelopt.onnx.quantization.graph_utils.remove_partial_input_qdq" title="modelopt.onnx.quantization.graph_utils.remove_partial_input_qdq"><code class="xref py py-obj docutils literal notranslate"><span class="pre">remove_partial_input_qdq</span></code></a></p></td>
<td><p>Modifies the onnx model by removing QDQ nodes from the marked inputs, ex.</p></td>
</tr>
</tbody>
</table>
<dl class="py function">
<dt class="sig sig-object py" id="modelopt.onnx.quantization.graph_utils.add_fp16_fp32_cast">
<span class="sig-name descname"><span class="pre">add_fp16_fp32_cast</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">onnx_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">custom_ops_to_cast_to_fp16</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#modelopt.onnx.quantization.graph_utils.add_fp16_fp32_cast" title="Link to this definition"></a></dt>
<dd><p>Adds cast_to_fp16 nodes to the inputs of a layer and cast_to_fp32 to the outputs.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="modelopt.onnx.quantization.graph_utils.build_non_residual_input_map">
<span class="sig-name descname"><span class="pre">build_non_residual_input_map</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">graph</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#modelopt.onnx.quantization.graph_utils.build_non_residual_input_map" title="Link to this definition"></a></dt>
<dd><p>Builds a map of non-residual Add input name to the Add node name from the given graph.</p>
<p>This assumes that the Add layer only has 2 inputs.</p>
<p>We will refer to a subgraph which has a Convolution node with a single output that is summed (element-wise)
with another non-constant input-tensor as a “residual-add” subgraph, because it occurs in modern
convnets that use residual connections.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>graph</strong> (<em>Graph</em>) – Onnx model graph.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Dictionary of Add node names vs their non-residual input name.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Dict</em>[<em>str</em>, <em>str</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="modelopt.onnx.quantization.graph_utils.classify_partition_nodes">
<span class="sig-name descname"><span class="pre">classify_partition_nodes</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">partitions</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#modelopt.onnx.quantization.graph_utils.classify_partition_nodes" title="Link to this definition"></a></dt>
<dd><p>We should partially quantize the partition nodes with inputs outside of the partition.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>partitions</strong> (<em>List</em><em>[</em><em>List</em><em>[</em><em>Node</em><em>]</em><em>]</em>) – Partitions created by modelopt ptq algo.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>List of non-quantizable nodes.
List of quantizable nodes.
List of partially-quantizable inputs with non-quantizable input info as (src, dst, input_name)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tuple</em>[<em>List</em>[<em>Node</em>], <em>List</em>[<em>Node</em>], <em>List</em>[<em>Tuple</em>[<em>Node</em>, <em>Node</em>, <em>str</em>]]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="modelopt.onnx.quantization.graph_utils.filter_quantizable_kgen_heads">
<span class="sig-name descname"><span class="pre">filter_quantizable_kgen_heads</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cask_fusible_partitions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kgen_partitions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">quantizable_op_types</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#modelopt.onnx.quantization.graph_utils.filter_quantizable_kgen_heads" title="Link to this definition"></a></dt>
<dd><p>Returns the list of kgen head names if it follows a CASK partition.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cask_fusible_partitions</strong> (<em>List</em><em>[</em><em>List</em><em>[</em><em>Node</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>kgen_partitions</strong> (<em>List</em><em>[</em><em>List</em><em>[</em><em>Node</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>quantizable_op_types</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tuple</em>[<em>List</em>[<em>Node</em>], <em>List</em>[<em>Tuple</em>[<em>Node</em>, <em>Node</em>, <em>str</em>]]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="modelopt.onnx.quantization.graph_utils.find_fp8_mha_partitions">
<span class="sig-name descname"><span class="pre">find_fp8_mha_partitions</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">graph</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#modelopt.onnx.quantization.graph_utils.find_fp8_mha_partitions" title="Link to this definition"></a></dt>
<dd><p>Match FP8 MHA: Q -&gt; DQ -&gt; BMM1 -&gt; (Mul/Div) -&gt; (Add) -&gt; Softmax -&gt; (Cast) -&gt; Q -&gt; DQ -&gt; BMM2 -&gt; Q -&gt; DQ.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="modelopt.onnx.quantization.graph_utils.find_mha_partitions">
<span class="sig-name descname"><span class="pre">find_mha_partitions</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">graph</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#modelopt.onnx.quantization.graph_utils.find_mha_partitions" title="Link to this definition"></a></dt>
<dd><p>Match MHA: BMM1 -&gt; (Mul/Div) -&gt; (Add) -&gt; Softmax -&gt; (Cast) -&gt; BMM2.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="modelopt.onnx.quantization.graph_utils.find_nodes_to_exclude">
<span class="sig-name descname"><span class="pre">find_nodes_to_exclude</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">graph</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nodes_to_exclude</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">op_types_to_exclude</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#modelopt.onnx.quantization.graph_utils.find_nodes_to_exclude" title="Link to this definition"></a></dt>
<dd><p>Find the node names from the ONNX graph which matches user’s exclusion patterns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>graph</strong> (<em>Graph</em>) – </p></li>
<li><p><strong>nodes_to_exclude</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – </p></li>
<li><p><strong>op_types_to_exclude</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="modelopt.onnx.quantization.graph_utils.get_fusible_backbone">
<span class="sig-name descname"><span class="pre">get_fusible_backbone</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">graph</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#modelopt.onnx.quantization.graph_utils.get_fusible_backbone" title="Link to this definition"></a></dt>
<dd><p>Returns the linear backbone node for a given node if it matches the pattern.</p>
<p>TensorRT fuses convolution with BN, Relu etc. when in some specific pattern.
This rule tries to match some of those patterns.
Note. BiasAdd and ConstMul are optional in path types.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>node</strong> (<em>Node</em>) – Start node of the pattern.</p></li>
<li><p><strong>graph</strong> (<em>Graph</em>) – ONNX model graph.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Backbone node of the given node, None if not found.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Node</em> | <em>None</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="modelopt.onnx.quantization.graph_utils.has_const_input">
<span class="sig-name descname"><span class="pre">has_const_input</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#modelopt.onnx.quantization.graph_utils.has_const_input" title="Link to this definition"></a></dt>
<dd><p>Returns whether the given node has any constant input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>node</strong> (<em>Node</em>) – </p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>bool</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="modelopt.onnx.quantization.graph_utils.has_path_type">
<span class="sig-name descname"><span class="pre">has_path_type</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">graph</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">path_type</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_forward</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">wild_card_types</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">path_nodes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#modelopt.onnx.quantization.graph_utils.has_path_type" title="Link to this definition"></a></dt>
<dd><p>Checks if the given node is start/end of a given forward/backward path type.</p>
<p>Note, Path can be forward or backward wrt a node depending on the next level nodes.
Additionally, this method can work with optional nodes and collect the traversed path.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>node</strong> (<em>Node</em>) – Start node of the path.</p></li>
<li><p><strong>graph</strong> (<em>Graph</em>) – ONNX model graph.</p></li>
<li><p><strong>path_type</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – Path types to match from the given node.</p></li>
<li><p><strong>is_forward</strong> (<em>bool</em>) – Whether to match forward or backward path.</p></li>
<li><p><strong>wild_card_types</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – Wild card types, these type of nodes are skipped and not matched with the path_type.</p></li>
<li><p><strong>path_nodes</strong> (<em>List</em><em>[</em><em>Node</em><em>]</em>) – Accumulated nodes in the matched path.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Bool, whether the given node is start/end of the given forward/backward path type.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>bool</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="modelopt.onnx.quantization.graph_utils.insert_fp8_mha_casts">
<span class="sig-name descname"><span class="pre">insert_fp8_mha_casts</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">onnx_model</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#modelopt.onnx.quantization.graph_utils.insert_fp8_mha_casts" title="Link to this definition"></a></dt>
<dd><p>Insert three cast ops.</p>
<p>The first cast will be added before the input0 of MatMul to cast fp16 to fp32.
The second cast will be added before the input1 of MatMul to cast fp16 to fp32.
The third cast will be added after the output of MatMul to cast fp32 back to fp16.
The insertion of Cast ops in the FP8 MHA part actually forbids the MHAs to run
with FP16 accumulation because Myelin only has FP32 accumulation kernels for FP8 MHAs.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="modelopt.onnx.quantization.graph_utils.insert_matmul_casts">
<span class="sig-name descname"><span class="pre">insert_matmul_casts</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">graph</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">matmul_node</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#modelopt.onnx.quantization.graph_utils.insert_matmul_casts" title="Link to this definition"></a></dt>
<dd><p>Insert three cast nodes for MatMul’s two inputs and output.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="modelopt.onnx.quantization.graph_utils.is_const_input">
<span class="sig-name descname"><span class="pre">is_const_input</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#modelopt.onnx.quantization.graph_utils.is_const_input" title="Link to this definition"></a></dt>
<dd><p>Returns whether the given tensor is an initializer or produced by const-foldable nodes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>tensor</strong> (<em>Tensor</em>) – </p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>bool</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="modelopt.onnx.quantization.graph_utils.print_stat">
<span class="sig-name descname"><span class="pre">print_stat</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">graph</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#modelopt.onnx.quantization.graph_utils.print_stat" title="Link to this definition"></a></dt>
<dd><p>Collect and print stats of the quantized model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>graph</strong> (<em>Graph</em>) – </p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>None</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="modelopt.onnx.quantization.graph_utils.remove_partial_input_qdq">
<span class="sig-name descname"><span class="pre">remove_partial_input_qdq</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">graph</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">no_quantize_inputs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#modelopt.onnx.quantization.graph_utils.remove_partial_input_qdq" title="Link to this definition"></a></dt>
<dd><p>Modifies the onnx model by removing QDQ nodes from the marked inputs, ex. non-residual inputs etc.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>graph</strong> (<em>Graph</em>) – Onnx model graph.</p></li>
<li><p><strong>no_quantize_inputs</strong> (<em>List</em><em>[</em><em>Tuple</em><em>[</em><em>Node</em><em>, </em><em>Node</em><em>, </em><em>str</em><em>]</em><em>]</em>) – List non-quantizable input info as (src, dst, input_name)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>None</em></p>
</dd>
</dl>
</dd></dl>

</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="modelopt.onnx.quantization.fp8.html" class="btn btn-neutral float-left" title="fp8" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="modelopt.onnx.quantization.gs_patching.html" class="btn btn-neutral float-right" title="gs_patching" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023-2024, NVIDIA Corporation.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>