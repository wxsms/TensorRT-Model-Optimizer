

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>HF BERT: Prune, Distill &amp; Quantize &mdash; Model Optimizer 0.19.0</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../_static/tabs.css?v=4c969af8" />
      <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
      <link rel="stylesheet" type="text/css" href="../_static/autodoc_pydantic.css" />
      <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=7a224f4b" />

  
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=5929fcd5"></script>
      <script src="../_static/doctools.js?v=888ff710"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="../_static/copybutton.js?v=20d3d275"></script>
      <script src="../_static/tabs.js?v=3ee01567"></script>
      <script>let toggleHintShow = 'Click to show';</script>
      <script>let toggleHintHide = 'Click to hide';</script>
      <script>let toggleOpenOnPrint = 'true';</script>
      <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
      <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
      <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
      <script src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>
      <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Model Optimizer Changelog" href="../reference/0_changelog.html" />
    <link rel="prev" title="ResNet20 on CIFAR-10: Pruning" href="1_cifar_resnet.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            TensorRT Model Optimizer
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/1_overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/2_installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/3_quantization.html">Quick Start: Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/4_pruning.html">Quick Start: Pruning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/5_distillation.html">Quick Start: Distillation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/6_sparsity.html">Quick Start: Sparsity</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Guides</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../guides/1_quantization.html">Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../guides/2_pruning.html">Pruning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../guides/3_nas.html">NAS</a></li>
<li class="toctree-l1"><a class="reference internal" href="../guides/4_distillation.html">Distillation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../guides/5_sparsity.html">Sparsity</a></li>
<li class="toctree-l1"><a class="reference internal" href="../guides/6_save_load.html">Saving &amp; Restoring</a></li>
<li class="toctree-l1"><a class="reference internal" href="../guides/7_speculative_decoding.html">Speculative Decoding</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Deployment</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../deployment/1_tensorrt_llm_deployment.html">TensorRT-LLM Deployment</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Examples</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="0_all_examples.html">All GitHub Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="1_cifar_resnet.html">ResNet20 on CIFAR-10: Pruning</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">HF BERT: Prune, Distill &amp; Quantize</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#prerequisites">Prerequisites</a></li>
<li class="toctree-l2"><a class="reference internal" href="#full-code">Full code</a></li>
<li class="toctree-l2"><a class="reference internal" href="#commands">Commands</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../reference/0_changelog.html">Model Optimizer Changelog</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reference/1_modelopt_api.html">modelopt API</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Support</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../support/1_contact.html">Contact us</a></li>
<li class="toctree-l1"><a class="reference internal" href="../support/2_faqs.html">FAQs</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">TensorRT Model Optimizer</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">HF BERT: Prune, Distill &amp; Quantize</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/examples/2_bert_prune_distill_quantize.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="hf-bert-prune-distill-quantize">
<h1>HF BERT: Prune, Distill &amp; Quantize<a class="headerlink" href="#hf-bert-prune-distill-quantize" title="Link to this heading"></a></h1>
<p>This example shows how to compress a <a class="reference external" href="https://huggingface.co/bert-large-uncased-whole-word-masking-finetuned-squad" rel="noopener noreferrer" target="_blank">Hugging Face Bert large model for Question Answering</a>
using the combination of <code class="docutils literal notranslate"><span class="pre">modelopt.torch.prune</span></code>, <code class="docutils literal notranslate"><span class="pre">modelopt.torch.distill</span></code> and <code class="docutils literal notranslate"><span class="pre">modelopt.torch.quantize</span></code>. More specifically, we will:</p>
<ol class="arabic simple">
<li><p>Prune the Bert large model to 50% FLOPs with GradNAS algorithm and fine-tune with distillation</p></li>
<li><p>Quantize the fine-tuned model to INT8 precision with Post-Training Quantization (PTQ) and Quantize Aware Training (QAT) with distillation</p></li>
<li><p>Export the quantized model to ONNX format for deployment with TensorRT</p></li>
</ol>
<section id="prerequisites">
<h2>Prerequisites<a class="headerlink" href="#prerequisites" title="Link to this heading"></a></h2>
<ol class="arabic">
<li><p>Install the Model Optimizer and optional torch and huggingface dependencies:</p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span><span class="s2">&quot;nvidia-modelopt[torch,hf]&quot;</span><span class="w"> </span>--extra-index-url<span class="w"> </span>https://pypi.nvidia.com
</pre></div>
</div>
</div></blockquote>
</li>
</ol>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This example has been tested on 8 x 24GB A5000 GPUs with PyTorch 2.4 and CUDA 12.4. It takes
about 2 hours to complete all the stages of the optimization. Most of the time is spent
on fine-tuning and QAT.</p>
</div>
</section>
<section id="full-code">
<h2>Full code<a class="headerlink" href="#full-code" title="Link to this heading"></a></h2>
<p>You can view the full code below with ModelOpt integration points highlighted.
The source code and scripts are also available on <a class="reference external" href="https://github.com/NVIDIA/TensorRT-Model-Optimizer/tree/main/chained_optimizations" rel="noopener noreferrer" target="_blank">ModelOpt GitHub</a></p>
<div class="toggle docutils container">
<div class="literal-block-wrapper docutils container" id="id1">
<div class="code-block-caption"><span class="caption-text">bert_prune_distill_quantize.py</span><a class="headerlink" href="#id1" title="Link to this code"></a></div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="linenos">   1</span><span class="c1"># NOTE: This is adapted from run_qa_no_trainer.py and utils_qa.py from https://github.com/huggingface/</span>
<span class="linenos">   2</span><span class="c1"># transformers/blob/c52b515e948fc12ff58ad773a0385860d0162f61/examples/pytorch/question-answering</span>
<span class="linenos">   3</span><span class="c1">#</span>
<span class="linenos">   4</span><span class="c1"># Copyright 2021 The HuggingFace Inc. team. All rights reserved.</span>
<span class="linenos">   5</span><span class="c1">#</span>
<span class="linenos">   6</span><span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="linenos">   7</span><span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="linenos">   8</span><span class="c1"># You may obtain a copy of the License at</span>
<span class="linenos">   9</span><span class="c1">#</span>
<span class="linenos">  10</span><span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="linenos">  11</span><span class="c1">#</span>
<span class="linenos">  12</span><span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="linenos">  13</span><span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="linenos">  14</span><span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="linenos">  15</span><span class="c1"># See the License for the specific language governing permissions and</span>
<span class="linenos">  16</span><span class="c1"># limitations under the License.</span>
<span class="linenos">  17</span>
<span class="linenos">  18</span><span class="c1"># SPDX-FileCopyrightText: Copyright (c) 2024 NVIDIA CORPORATION &amp; AFFILIATES. All rights reserved.</span>
<span class="linenos">  19</span><span class="c1"># SPDX-License-Identifier: MIT</span>
<span class="linenos">  20</span>
<span class="linenos">  21</span><span class="c1"># Permission is hereby granted, free of charge, to any person obtaining a</span>
<span class="linenos">  22</span><span class="c1"># copy of this software and associated documentation files (the &quot;Software&quot;),</span>
<span class="linenos">  23</span><span class="c1"># to deal in the Software without restriction, including without limitation</span>
<span class="linenos">  24</span><span class="c1"># the rights to use, copy, modify, merge, publish, distribute, sublicense,</span>
<span class="linenos">  25</span><span class="c1"># and/or sell copies of the Software, and to permit persons to whom the</span>
<span class="linenos">  26</span><span class="c1"># Software is furnished to do so, subject to the following conditions:</span>
<span class="linenos">  27</span>
<span class="linenos">  28</span><span class="c1"># The above copyright notice and this permission notice shall be included in</span>
<span class="linenos">  29</span><span class="c1"># all copies or substantial portions of the Software.</span>
<span class="linenos">  30</span>
<span class="linenos">  31</span><span class="c1"># THE SOFTWARE IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR</span>
<span class="linenos">  32</span><span class="c1"># IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,</span>
<span class="linenos">  33</span><span class="c1"># FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL</span>
<span class="linenos">  34</span><span class="c1"># THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER</span>
<span class="linenos">  35</span><span class="c1"># LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING</span>
<span class="linenos">  36</span><span class="c1"># FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER</span>
<span class="linenos">  37</span><span class="c1"># DEALINGS IN THE SOFTWARE.</span>
<span class="linenos">  38</span><span class="sd">&quot;&quot;&quot;</span>
<span class="linenos">  39</span><span class="sd">Example showcasing how to do end-to-end optimization of a BERT model on SQuAD using Model Optimizer.</span>
<span class="linenos">  40</span><span class="sd">This includes GradNAS pruning, INT8 quantization, fine-tuning / QAT with distillation, and ONNX export.</span>
<span class="linenos">  41</span><span class="sd">&quot;&quot;&quot;</span>
<span class="linenos">  42</span>
<span class="linenos">  43</span><span class="kn">import</span> <span class="nn">argparse</span>
<span class="linenos">  44</span><span class="kn">import</span> <span class="nn">collections</span>
<span class="linenos">  45</span><span class="kn">import</span> <span class="nn">json</span>
<span class="linenos">  46</span><span class="kn">import</span> <span class="nn">logging</span>
<span class="linenos">  47</span><span class="kn">import</span> <span class="nn">math</span>
<span class="linenos">  48</span><span class="kn">import</span> <span class="nn">os</span>
<span class="linenos">  49</span><span class="kn">import</span> <span class="nn">random</span>
<span class="linenos">  50</span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Tuple</span>
<span class="linenos">  51</span>
<span class="linenos">  52</span><span class="kn">import</span> <span class="nn">datasets</span>
<span class="linenos">  53</span><span class="kn">import</span> <span class="nn">evaluate</span>
<span class="linenos">  54</span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="linenos">  55</span><span class="kn">import</span> <span class="nn">torch</span>
<span class="linenos">  56</span><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="linenos">  57</span><span class="kn">import</span> <span class="nn">transformers</span>
<span class="linenos">  58</span><span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>
<span class="linenos">  59</span><span class="kn">from</span> <span class="nn">accelerate.logging</span> <span class="kn">import</span> <span class="n">get_logger</span>
<span class="linenos">  60</span><span class="kn">from</span> <span class="nn">accelerate.utils</span> <span class="kn">import</span> <span class="n">set_seed</span>
<span class="linenos">  61</span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="linenos">  62</span><span class="kn">from</span> <span class="nn">tqdm.auto</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="linenos">  63</span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="p">(</span>
<span class="linenos">  64</span>    <span class="n">AutoModelForQuestionAnswering</span><span class="p">,</span>
<span class="linenos">  65</span>    <span class="n">AutoTokenizer</span><span class="p">,</span>
<span class="linenos">  66</span>    <span class="n">DataCollatorWithPadding</span><span class="p">,</span>
<span class="linenos">  67</span>    <span class="n">EvalPrediction</span><span class="p">,</span>
<span class="linenos">  68</span>    <span class="n">PreTrainedTokenizer</span><span class="p">,</span>
<span class="linenos">  69</span>    <span class="n">SchedulerType</span><span class="p">,</span>
<span class="linenos">  70</span>    <span class="n">default_data_collator</span><span class="p">,</span>
<span class="linenos">  71</span>    <span class="n">get_scheduler</span><span class="p">,</span>
<span class="linenos">  72</span><span class="p">)</span>
<span class="linenos">  73</span>
<span class="hll"><span class="linenos">  74</span><span class="kn">import</span> <span class="nn">modelopt.torch.distill</span> <span class="k">as</span> <span class="nn">mtd</span>
</span><span class="hll"><span class="linenos">  75</span><span class="kn">import</span> <span class="nn">modelopt.torch.opt</span> <span class="k">as</span> <span class="nn">mto</span>
</span><span class="hll"><span class="linenos">  76</span><span class="kn">import</span> <span class="nn">modelopt.torch.prune</span> <span class="k">as</span> <span class="nn">mtp</span>
</span><span class="hll"><span class="linenos">  77</span><span class="kn">import</span> <span class="nn">modelopt.torch.quantization</span> <span class="k">as</span> <span class="nn">mtq</span>
</span><span class="hll"><span class="linenos">  78</span><span class="kn">from</span> <span class="nn">modelopt.torch._deploy.utils</span> <span class="kn">import</span> <span class="n">get_onnx_bytes</span>
</span><span class="linenos">  79</span>
<span class="linenos">  80</span><span class="n">logger</span> <span class="o">=</span> <span class="n">get_logger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>
<span class="linenos">  81</span>
<span class="linenos">  82</span><span class="n">SEED</span> <span class="o">=</span> <span class="mi">123</span>
<span class="linenos">  83</span>
<span class="linenos">  84</span>
<span class="linenos">  85</span><span class="k">def</span> <span class="nf">parse_args</span><span class="p">(</span><span class="n">input_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="linenos">  86</span>    <span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span>
<span class="linenos">  87</span>        <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Finetune a transformers model on a Question Answering task&quot;</span>
<span class="linenos">  88</span>    <span class="p">)</span>
<span class="linenos">  89</span>
<span class="linenos">  90</span>    <span class="c1"># Training arguments</span>
<span class="linenos">  91</span>    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
<span class="linenos">  92</span>        <span class="s2">&quot;--model_name_or_path&quot;</span><span class="p">,</span>
<span class="linenos">  93</span>        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
<span class="linenos">  94</span>        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;bert-large-uncased-whole-word-masking-finetuned-squad&quot;</span><span class="p">,</span>
<span class="linenos">  95</span>        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Path to pretrained model or model identifier from huggingface.co/models.&quot;</span><span class="p">,</span>
<span class="linenos">  96</span>    <span class="p">)</span>
<span class="linenos">  97</span>    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
<span class="linenos">  98</span>        <span class="s2">&quot;--do_train&quot;</span><span class="p">,</span>
<span class="linenos">  99</span>        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
<span class="linenos"> 100</span>        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Whether to run training / fine-tuning.&quot;</span><span class="p">,</span>
<span class="linenos"> 101</span>    <span class="p">)</span>
<span class="linenos"> 102</span>    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
<span class="linenos"> 103</span>        <span class="s2">&quot;--per_device_train_batch_size&quot;</span><span class="p">,</span>
<span class="linenos"> 104</span>        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
<span class="linenos"> 105</span>        <span class="n">default</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
<span class="linenos"> 106</span>        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Batch size (per device) for the training dataloader.&quot;</span><span class="p">,</span>
<span class="linenos"> 107</span>    <span class="p">)</span>
<span class="linenos"> 108</span>    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
<span class="linenos"> 109</span>        <span class="s2">&quot;--per_device_eval_batch_size&quot;</span><span class="p">,</span>
<span class="linenos"> 110</span>        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
<span class="linenos"> 111</span>        <span class="n">default</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
<span class="linenos"> 112</span>        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Batch size (per device) for the evaluation dataloader.&quot;</span><span class="p">,</span>
<span class="linenos"> 113</span>    <span class="p">)</span>
<span class="linenos"> 114</span>    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
<span class="linenos"> 115</span>        <span class="s2">&quot;--learning_rate&quot;</span><span class="p">,</span>
<span class="linenos"> 116</span>        <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
<span class="linenos"> 117</span>        <span class="n">default</span><span class="o">=</span><span class="mf">5e-5</span><span class="p">,</span>
<span class="linenos"> 118</span>        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Initial learning rate (after the potential warmup period) to use.&quot;</span><span class="p">,</span>
<span class="linenos"> 119</span>    <span class="p">)</span>
<span class="linenos"> 120</span>    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--weight_decay&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Weight decay to use.&quot;</span><span class="p">)</span>
<span class="linenos"> 121</span>    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
<span class="linenos"> 122</span>        <span class="s2">&quot;--lr_scheduler_type&quot;</span><span class="p">,</span>
<span class="linenos"> 123</span>        <span class="nb">type</span><span class="o">=</span><span class="n">SchedulerType</span><span class="p">,</span>
<span class="linenos"> 124</span>        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">,</span>
<span class="linenos"> 125</span>        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;The scheduler type to use.&quot;</span><span class="p">,</span>
<span class="linenos"> 126</span>        <span class="n">choices</span><span class="o">=</span><span class="p">[</span>
<span class="linenos"> 127</span>            <span class="s2">&quot;linear&quot;</span><span class="p">,</span>
<span class="linenos"> 128</span>            <span class="s2">&quot;cosine&quot;</span><span class="p">,</span>
<span class="linenos"> 129</span>            <span class="s2">&quot;cosine_with_restarts&quot;</span><span class="p">,</span>
<span class="linenos"> 130</span>            <span class="s2">&quot;polynomial&quot;</span><span class="p">,</span>
<span class="linenos"> 131</span>            <span class="s2">&quot;constant&quot;</span><span class="p">,</span>
<span class="linenos"> 132</span>            <span class="s2">&quot;constant_with_warmup&quot;</span><span class="p">,</span>
<span class="linenos"> 133</span>        <span class="p">],</span>
<span class="linenos"> 134</span>    <span class="p">)</span>
<span class="linenos"> 135</span>    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
<span class="linenos"> 136</span>        <span class="s2">&quot;--num_warmup_steps&quot;</span><span class="p">,</span>
<span class="linenos"> 137</span>        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
<span class="linenos"> 138</span>        <span class="n">default</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span class="linenos"> 139</span>        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Number of steps for the warmup in the lr scheduler.&quot;</span><span class="p">,</span>
<span class="linenos"> 140</span>    <span class="p">)</span>
<span class="linenos"> 141</span>    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
<span class="linenos"> 142</span>        <span class="s2">&quot;--num_train_epochs&quot;</span><span class="p">,</span>
<span class="linenos"> 143</span>        <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
<span class="linenos"> 144</span>        <span class="n">default</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span>
<span class="linenos"> 145</span>        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Total number of training epochs to perform.&quot;</span><span class="p">,</span>
<span class="linenos"> 146</span>    <span class="p">)</span>
<span class="linenos"> 147</span>    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
<span class="linenos"> 148</span>        <span class="s2">&quot;--max_train_steps&quot;</span><span class="p">,</span>
<span class="linenos"> 149</span>        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
<span class="linenos"> 150</span>        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="linenos"> 151</span>        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Total number of training steps to perform. If provided, overrides num_train_epochs.&quot;</span><span class="p">,</span>
<span class="linenos"> 152</span>    <span class="p">)</span>
<span class="linenos"> 153</span>    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
<span class="linenos"> 154</span>        <span class="s2">&quot;--gradient_accumulation_steps&quot;</span><span class="p">,</span>
<span class="linenos"> 155</span>        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
<span class="linenos"> 156</span>        <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="linenos"> 157</span>        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Number of updates steps to accumulate before performing a backward/update pass.&quot;</span><span class="p">,</span>
<span class="linenos"> 158</span>    <span class="p">)</span>
<span class="linenos"> 159</span>    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
<span class="linenos"> 160</span>        <span class="s2">&quot;--preprocessing_num_workers&quot;</span><span class="p">,</span>
<span class="linenos"> 161</span>        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
<span class="linenos"> 162</span>        <span class="n">default</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
<span class="linenos"> 163</span>        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;The number of processes to use for preprocessing the dataset.&quot;</span><span class="p">,</span>
<span class="linenos"> 164</span>    <span class="p">)</span>
<span class="linenos"> 165</span>
<span class="linenos"> 166</span>    <span class="c1"># Logging and checkpointing arguments</span>
<span class="linenos"> 167</span>    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
<span class="linenos"> 168</span>        <span class="s2">&quot;--output_dir&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;results&quot;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Where to store the optimized models.&quot;</span>
<span class="linenos"> 169</span>    <span class="p">)</span>
<span class="linenos"> 170</span>    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
<span class="linenos"> 171</span>        <span class="s2">&quot;--with_tracking&quot;</span><span class="p">,</span>
<span class="linenos"> 172</span>        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
<span class="linenos"> 173</span>        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Whether to enable experiment trackers for logging.&quot;</span><span class="p">,</span>
<span class="linenos"> 174</span>    <span class="p">)</span>
<span class="linenos"> 175</span>    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
<span class="linenos"> 176</span>        <span class="s2">&quot;--checkpointing_steps&quot;</span><span class="p">,</span>
<span class="linenos"> 177</span>        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
<span class="linenos"> 178</span>        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="linenos"> 179</span>        <span class="n">help</span><span class="o">=</span><span class="p">(</span>
<span class="linenos"> 180</span>            <span class="s2">&quot;Whether the various states should be saved at the end of every n steps, or &#39;epoch&#39; for&quot;</span>
<span class="linenos"> 181</span>            <span class="s2">&quot; each epoch.&quot;</span>
<span class="linenos"> 182</span>        <span class="p">),</span>
<span class="linenos"> 183</span>    <span class="p">)</span>
<span class="linenos"> 184</span>    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
<span class="linenos"> 185</span>        <span class="s2">&quot;--resume_from_last_ckpt&quot;</span><span class="p">,</span>
<span class="linenos"> 186</span>        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
<span class="linenos"> 187</span>        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;If the training should continue from the latest checkpoint in output_dir.&quot;</span><span class="p">,</span>
<span class="linenos"> 188</span>    <span class="p">)</span>
<span class="linenos"> 189</span>
<span class="linenos"> 190</span>    <span class="c1"># Misc arguments for Bert (should not be modified in most cases)</span>
<span class="linenos"> 191</span>    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
<span class="linenos"> 192</span>        <span class="s2">&quot;--max_seq_length&quot;</span><span class="p">,</span>
<span class="linenos"> 193</span>        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
<span class="linenos"> 194</span>        <span class="n">default</span><span class="o">=</span><span class="mi">384</span><span class="p">,</span>
<span class="linenos"> 195</span>        <span class="n">help</span><span class="o">=</span><span class="p">(</span>
<span class="linenos"> 196</span>            <span class="s2">&quot;The maximum total input sequence length after tokenization. Sequences longer than this&quot;</span>
<span class="linenos"> 197</span>            <span class="s2">&quot; will be truncated, and shorter will be padded if `--pad_to_max_lengh` is passed.&quot;</span>
<span class="linenos"> 198</span>        <span class="p">),</span>
<span class="linenos"> 199</span>    <span class="p">)</span>
<span class="linenos"> 200</span>    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
<span class="linenos"> 201</span>        <span class="s2">&quot;--pad_to_max_length&quot;</span><span class="p">,</span>
<span class="linenos"> 202</span>        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
<span class="linenos"> 203</span>        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;If passed, pad all samples to `max_seq_length`. Otherwise, dynamic padding is used.&quot;</span><span class="p">,</span>
<span class="linenos"> 204</span>    <span class="p">)</span>
<span class="linenos"> 205</span>    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
<span class="linenos"> 206</span>        <span class="s2">&quot;--doc_stride&quot;</span><span class="p">,</span>
<span class="linenos"> 207</span>        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
<span class="linenos"> 208</span>        <span class="n">default</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
<span class="linenos"> 209</span>        <span class="n">help</span><span class="o">=</span><span class="p">(</span>
<span class="linenos"> 210</span>            <span class="s2">&quot;When splitting up a long document into chunks how much stride to take between chunks.&quot;</span>
<span class="linenos"> 211</span>        <span class="p">),</span>
<span class="linenos"> 212</span>    <span class="p">)</span>
<span class="linenos"> 213</span>    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
<span class="linenos"> 214</span>        <span class="s2">&quot;--n_best_size&quot;</span><span class="p">,</span>
<span class="linenos"> 215</span>        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
<span class="linenos"> 216</span>        <span class="n">default</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
<span class="linenos"> 217</span>        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;The total number of n-best predictions to generate when looking for an answer.&quot;</span><span class="p">,</span>
<span class="linenos"> 218</span>    <span class="p">)</span>
<span class="linenos"> 219</span>    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
<span class="linenos"> 220</span>        <span class="s2">&quot;--max_answer_length&quot;</span><span class="p">,</span>
<span class="linenos"> 221</span>        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
<span class="linenos"> 222</span>        <span class="n">default</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
<span class="linenos"> 223</span>        <span class="n">help</span><span class="o">=</span><span class="p">(</span>
<span class="linenos"> 224</span>            <span class="s2">&quot;The maximum length of an answer that can be generated. This is needed because the&quot;</span>
<span class="linenos"> 225</span>            <span class="s2">&quot; start and end predictions are not conditioned on one another.&quot;</span>
<span class="linenos"> 226</span>        <span class="p">),</span>
<span class="linenos"> 227</span>    <span class="p">)</span>
<span class="linenos"> 228</span>
<span class="linenos"> 229</span>    <span class="c1"># Debugging arguments</span>
<span class="linenos"> 230</span>    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
<span class="linenos"> 231</span>        <span class="s2">&quot;--max_train_samples&quot;</span><span class="p">,</span>
<span class="linenos"> 232</span>        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
<span class="linenos"> 233</span>        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="linenos"> 234</span>        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;For debugging purposes or quicker training.&quot;</span><span class="p">,</span>
<span class="linenos"> 235</span>    <span class="p">)</span>
<span class="linenos"> 236</span>    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
<span class="linenos"> 237</span>        <span class="s2">&quot;--max_eval_samples&quot;</span><span class="p">,</span>
<span class="linenos"> 238</span>        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
<span class="linenos"> 239</span>        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="linenos"> 240</span>        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;For debugging purposes or quicker training.&quot;</span><span class="p">,</span>
<span class="linenos"> 241</span>    <span class="p">)</span>
<span class="linenos"> 242</span>
<span class="hll"><span class="linenos"> 243</span>    <span class="c1"># Model Optimizer: pruning arguments</span>
</span><span class="hll"><span class="linenos"> 244</span>    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
</span><span class="hll"><span class="linenos"> 245</span>        <span class="s2">&quot;--do_modelopt_prune&quot;</span><span class="p">,</span>
</span><span class="hll"><span class="linenos"> 246</span>        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
</span><span class="hll"><span class="linenos"> 247</span>        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Whether or not to use Model Optimizer pruning.&quot;</span><span class="p">,</span>
</span><span class="hll"><span class="linenos"> 248</span>    <span class="p">)</span>
</span><span class="hll"><span class="linenos"> 249</span>    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
</span><span class="hll"><span class="linenos"> 250</span>        <span class="s2">&quot;--modelopt_prune_flops_percent&quot;</span><span class="p">,</span>
</span><span class="hll"><span class="linenos"> 251</span>        <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
</span><span class="hll"><span class="linenos"> 252</span>        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span class="hll"><span class="linenos"> 253</span>        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;The percentage (between 0 and 100) of FLOPs to retain in the pruned model.&quot;</span><span class="p">,</span>
</span><span class="hll"><span class="linenos"> 254</span>    <span class="p">)</span>
</span><span class="hll"><span class="linenos"> 255</span>
</span><span class="hll"><span class="linenos"> 256</span>    <span class="c1"># Model Optimizer: quantization arguments</span>
</span><span class="hll"><span class="linenos"> 257</span>    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
</span><span class="hll"><span class="linenos"> 258</span>        <span class="s2">&quot;--modelopt_quantize_cfg&quot;</span><span class="p">,</span>
</span><span class="hll"><span class="linenos"> 259</span>        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Model Optimizer quantization config.&quot;</span><span class="p">,</span>
</span><span class="hll"><span class="linenos"> 260</span>        <span class="n">choices</span><span class="o">=</span><span class="n">mtq</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">choices</span><span class="p">,</span>
</span><span class="hll"><span class="linenos"> 261</span>    <span class="p">)</span>
</span><span class="hll"><span class="linenos"> 262</span>
</span><span class="hll"><span class="linenos"> 263</span>    <span class="c1"># Model Optimizer: Distillation arguments</span>
</span><span class="hll"><span class="linenos"> 264</span>    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
</span><span class="hll"><span class="linenos"> 265</span>        <span class="s2">&quot;--do_modelopt_distill&quot;</span><span class="p">,</span>
</span><span class="hll"><span class="linenos"> 266</span>        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
</span><span class="hll"><span class="linenos"> 267</span>        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Whether or not to use distillation. A teacher model must be specified.&quot;</span><span class="p">,</span>
</span><span class="hll"><span class="linenos"> 268</span>    <span class="p">)</span>
</span><span class="hll"><span class="linenos"> 269</span>    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
</span><span class="hll"><span class="linenos"> 270</span>        <span class="s2">&quot;--temperature&quot;</span><span class="p">,</span>
</span><span class="hll"><span class="linenos"> 271</span>        <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
</span><span class="hll"><span class="linenos"> 272</span>        <span class="n">default</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span>
</span><span class="hll"><span class="linenos"> 273</span>        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;The temperature to use when distilling.&quot;</span><span class="p">,</span>
</span><span class="hll"><span class="linenos"> 274</span>    <span class="p">)</span>
</span><span class="hll"><span class="linenos"> 275</span>
</span><span class="hll"><span class="linenos"> 276</span>    <span class="c1"># Model Optimizer: save and restore arguments</span>
</span><span class="hll"><span class="linenos"> 277</span>    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
</span><span class="hll"><span class="linenos"> 278</span>        <span class="s2">&quot;--modelopt_save_file&quot;</span><span class="p">,</span>
</span><span class="hll"><span class="linenos"> 279</span>        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
</span><span class="hll"><span class="linenos"> 280</span>        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span class="hll"><span class="linenos"> 281</span>        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;File (inside output_dir) to save the modelopt modified model to.&quot;</span><span class="p">,</span>
</span><span class="hll"><span class="linenos"> 282</span>    <span class="p">)</span>
</span><span class="hll"><span class="linenos"> 283</span>    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
</span><span class="hll"><span class="linenos"> 284</span>        <span class="s2">&quot;--modelopt_restore_path&quot;</span><span class="p">,</span>
</span><span class="hll"><span class="linenos"> 285</span>        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
</span><span class="hll"><span class="linenos"> 286</span>        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span class="hll"><span class="linenos"> 287</span>        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Path to restore the modelopt modified model from.&quot;</span><span class="p">,</span>
</span><span class="hll"><span class="linenos"> 288</span>    <span class="p">)</span>
</span><span class="linenos"> 289</span>
<span class="linenos"> 290</span>    <span class="c1"># ONNX export arguments</span>
<span class="linenos"> 291</span>    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
<span class="linenos"> 292</span>        <span class="s2">&quot;--onnx_export_file&quot;</span><span class="p">,</span>
<span class="linenos"> 293</span>        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
<span class="linenos"> 294</span>        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="linenos"> 295</span>        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;File (inside output_dir) to export the ONNX model to.&quot;</span><span class="p">,</span>
<span class="linenos"> 296</span>    <span class="p">)</span>
<span class="linenos"> 297</span>
<span class="linenos"> 298</span>    <span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">(</span><span class="n">input_args</span><span class="p">)</span>
<span class="linenos"> 299</span>
<span class="linenos"> 300</span>    <span class="c1"># Sanity checks</span>
<span class="linenos"> 301</span>    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">do_modelopt_prune</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">args</span><span class="o">.</span><span class="n">modelopt_prune_flops_percent</span><span class="p">:</span>
<span class="linenos"> 302</span>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<span class="linenos"> 303</span>            <span class="s2">&quot;Need a `modelopt_prune_flops_percent` when `do_modelopt_prune` is passed.&quot;</span>
<span class="linenos"> 304</span>        <span class="p">)</span>
<span class="linenos"> 305</span>
<span class="linenos"> 306</span>    <span class="k">return</span> <span class="n">args</span>
<span class="linenos"> 307</span>
<span class="linenos"> 308</span>
<span class="linenos"> 309</span><span class="k">def</span> <span class="nf">get_datasets_and_dataloaders</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">:</span> <span class="n">PreTrainedTokenizer</span><span class="p">,</span> <span class="n">accelerator</span><span class="p">:</span> <span class="n">Accelerator</span><span class="p">):</span>
<span class="linenos"> 310</span><span class="w">    </span><span class="sd">&quot;&quot;&quot;Get the examples, dataset, dataloader, answer_column_name</span>
<span class="linenos"> 311</span>
<span class="linenos"> 312</span><span class="sd">    You can either provide your own CSV/JSON/TXT training and evaluation files (see below)</span>
<span class="linenos"> 313</span><span class="sd">    or just provide the name of one of the public datasets available on the hub at https://huggingface.co/datasets/</span>
<span class="linenos"> 314</span><span class="sd">    (the dataset will be downloaded automatically from the datasets Hub).</span>
<span class="linenos"> 315</span>
<span class="linenos"> 316</span><span class="sd">    For CSV/JSON files, this script will use the column called &#39;text&#39; or the first column if no column called</span>
<span class="linenos"> 317</span><span class="sd">    &#39;text&#39; is found. You can easily tweak this behavior (see below).</span>
<span class="linenos"> 318</span><span class="sd">    &quot;&quot;&quot;</span>
<span class="linenos"> 319</span>
<span class="linenos"> 320</span>    <span class="k">def</span> <span class="nf">prepare_train_features</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>
<span class="linenos"> 321</span>        <span class="c1"># Some of the questions have lots of whitespace on the left, which is not useful and will make the</span>
<span class="linenos"> 322</span>        <span class="c1"># truncation of the context fail (the tokenized question will take a lots of space). So we remove that</span>
<span class="linenos"> 323</span>        <span class="c1"># left whitespace</span>
<span class="linenos"> 324</span>        <span class="n">examples</span><span class="p">[</span><span class="n">question_column_name</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">q</span><span class="o">.</span><span class="n">lstrip</span><span class="p">()</span> <span class="k">for</span> <span class="n">q</span> <span class="ow">in</span> <span class="n">examples</span><span class="p">[</span><span class="n">question_column_name</span><span class="p">]]</span>
<span class="linenos"> 325</span>
<span class="linenos"> 326</span>        <span class="c1"># Tokenize our examples with truncation and maybe padding, but keep the overflows using a stride. This results</span>
<span class="linenos"> 327</span>        <span class="c1"># in one example possible giving several features when a context is long, each of those features having a</span>
<span class="linenos"> 328</span>        <span class="c1"># context that overlaps a bit the context of the previous feature.</span>
<span class="linenos"> 329</span>        <span class="n">tokenized_examples</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
<span class="linenos"> 330</span>            <span class="n">examples</span><span class="p">[</span><span class="n">question_column_name</span> <span class="k">if</span> <span class="n">pad_on_right</span> <span class="k">else</span> <span class="n">context_column_name</span><span class="p">],</span>
<span class="linenos"> 331</span>            <span class="n">examples</span><span class="p">[</span><span class="n">context_column_name</span> <span class="k">if</span> <span class="n">pad_on_right</span> <span class="k">else</span> <span class="n">question_column_name</span><span class="p">],</span>
<span class="linenos"> 332</span>            <span class="n">truncation</span><span class="o">=</span><span class="s2">&quot;only_second&quot;</span> <span class="k">if</span> <span class="n">pad_on_right</span> <span class="k">else</span> <span class="s2">&quot;only_first&quot;</span><span class="p">,</span>
<span class="linenos"> 333</span>            <span class="n">max_length</span><span class="o">=</span><span class="n">max_seq_length</span><span class="p">,</span>
<span class="linenos"> 334</span>            <span class="n">stride</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">doc_stride</span><span class="p">,</span>
<span class="linenos"> 335</span>            <span class="n">return_overflowing_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="linenos"> 336</span>            <span class="n">return_offsets_mapping</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="linenos"> 337</span>            <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span> <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">pad_to_max_length</span> <span class="k">else</span> <span class="kc">False</span><span class="p">,</span>
<span class="linenos"> 338</span>        <span class="p">)</span>
<span class="linenos"> 339</span>
<span class="linenos"> 340</span>        <span class="c1"># Since one example might give us several features if it has a long context, we need a map from a feature to</span>
<span class="linenos"> 341</span>        <span class="c1"># its corresponding example. This key gives us just that.</span>
<span class="linenos"> 342</span>        <span class="n">sample_mapping</span> <span class="o">=</span> <span class="n">tokenized_examples</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;overflow_to_sample_mapping&quot;</span><span class="p">)</span>
<span class="linenos"> 343</span>        <span class="c1"># The offset mappings will give us a map from token to character position in the original context. This will</span>
<span class="linenos"> 344</span>        <span class="c1"># help us compute the start_positions and end_positions.</span>
<span class="linenos"> 345</span>        <span class="n">offset_mapping</span> <span class="o">=</span> <span class="n">tokenized_examples</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;offset_mapping&quot;</span><span class="p">)</span>
<span class="linenos"> 346</span>
<span class="linenos"> 347</span>        <span class="c1"># Let&#39;s label those examples!</span>
<span class="linenos"> 348</span>        <span class="n">tokenized_examples</span><span class="p">[</span><span class="s2">&quot;start_positions&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
<span class="linenos"> 349</span>        <span class="n">tokenized_examples</span><span class="p">[</span><span class="s2">&quot;end_positions&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
<span class="linenos"> 350</span>
<span class="linenos"> 351</span>        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">offsets</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">offset_mapping</span><span class="p">):</span>
<span class="linenos"> 352</span>            <span class="c1"># We will label impossible answers with the index of the CLS token.</span>
<span class="linenos"> 353</span>            <span class="n">input_ids</span> <span class="o">=</span> <span class="n">tokenized_examples</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>
<span class="linenos"> 354</span>            <span class="n">cls_index</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">cls_token_id</span><span class="p">)</span>
<span class="linenos"> 355</span>
<span class="linenos"> 356</span>            <span class="c1"># Grab the sequence corresponding to that example (to know what is the context and what is the question).</span>
<span class="linenos"> 357</span>            <span class="n">sequence_ids</span> <span class="o">=</span> <span class="n">tokenized_examples</span><span class="o">.</span><span class="n">sequence_ids</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
<span class="linenos"> 358</span>
<span class="linenos"> 359</span>            <span class="c1"># One example can give several spans, this is the index of the example containing this span of text.</span>
<span class="linenos"> 360</span>            <span class="n">sample_index</span> <span class="o">=</span> <span class="n">sample_mapping</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
<span class="linenos"> 361</span>            <span class="n">answers</span> <span class="o">=</span> <span class="n">examples</span><span class="p">[</span><span class="n">answer_column_name</span><span class="p">][</span><span class="n">sample_index</span><span class="p">]</span>
<span class="linenos"> 362</span>            <span class="c1"># If no answers are given, set the cls_index as answer.</span>
<span class="linenos"> 363</span>            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">answers</span><span class="p">[</span><span class="s2">&quot;answer_start&quot;</span><span class="p">])</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
<span class="linenos"> 364</span>                <span class="n">tokenized_examples</span><span class="p">[</span><span class="s2">&quot;start_positions&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cls_index</span><span class="p">)</span>
<span class="linenos"> 365</span>                <span class="n">tokenized_examples</span><span class="p">[</span><span class="s2">&quot;end_positions&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cls_index</span><span class="p">)</span>
<span class="linenos"> 366</span>            <span class="k">else</span><span class="p">:</span>
<span class="linenos"> 367</span>                <span class="c1"># Start/end character index of the answer in the text.</span>
<span class="linenos"> 368</span>                <span class="n">start_char</span> <span class="o">=</span> <span class="n">answers</span><span class="p">[</span><span class="s2">&quot;answer_start&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<span class="linenos"> 369</span>                <span class="n">end_char</span> <span class="o">=</span> <span class="n">start_char</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">answers</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
<span class="linenos"> 370</span>
<span class="linenos"> 371</span>                <span class="c1"># Start token index of the current span in the text.</span>
<span class="linenos"> 372</span>                <span class="n">token_start_index</span> <span class="o">=</span> <span class="mi">0</span>
<span class="linenos"> 373</span>                <span class="k">while</span> <span class="n">sequence_ids</span><span class="p">[</span><span class="n">token_start_index</span><span class="p">]</span> <span class="o">!=</span> <span class="p">(</span><span class="mi">1</span> <span class="k">if</span> <span class="n">pad_on_right</span> <span class="k">else</span> <span class="mi">0</span><span class="p">):</span>
<span class="linenos"> 374</span>                    <span class="n">token_start_index</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="linenos"> 375</span>
<span class="linenos"> 376</span>                <span class="c1"># End token index of the current span in the text.</span>
<span class="linenos"> 377</span>                <span class="n">token_end_index</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
<span class="linenos"> 378</span>                <span class="k">while</span> <span class="n">sequence_ids</span><span class="p">[</span><span class="n">token_end_index</span><span class="p">]</span> <span class="o">!=</span> <span class="p">(</span><span class="mi">1</span> <span class="k">if</span> <span class="n">pad_on_right</span> <span class="k">else</span> <span class="mi">0</span><span class="p">):</span>
<span class="linenos"> 379</span>                    <span class="n">token_end_index</span> <span class="o">-=</span> <span class="mi">1</span>
<span class="linenos"> 380</span>
<span class="linenos"> 381</span>                <span class="c1"># Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).</span>
<span class="linenos"> 382</span>                <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span>
<span class="linenos"> 383</span>                    <span class="n">offsets</span><span class="p">[</span><span class="n">token_start_index</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">start_char</span>
<span class="linenos"> 384</span>                    <span class="ow">and</span> <span class="n">offsets</span><span class="p">[</span><span class="n">token_end_index</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">end_char</span>
<span class="linenos"> 385</span>                <span class="p">):</span>
<span class="linenos"> 386</span>                    <span class="n">tokenized_examples</span><span class="p">[</span><span class="s2">&quot;start_positions&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cls_index</span><span class="p">)</span>
<span class="linenos"> 387</span>                    <span class="n">tokenized_examples</span><span class="p">[</span><span class="s2">&quot;end_positions&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cls_index</span><span class="p">)</span>
<span class="linenos"> 388</span>                <span class="k">else</span><span class="p">:</span>
<span class="linenos"> 389</span>                    <span class="c1"># Otherwise move the token_start_index and token_end_index to the two ends of the answer.</span>
<span class="linenos"> 390</span>                    <span class="c1"># Note: we could go after the last offset if the answer is the last word (edge case).</span>
<span class="linenos"> 391</span>                    <span class="k">while</span> <span class="p">(</span>
<span class="linenos"> 392</span>                        <span class="n">token_start_index</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">offsets</span><span class="p">)</span>
<span class="linenos"> 393</span>                        <span class="ow">and</span> <span class="n">offsets</span><span class="p">[</span><span class="n">token_start_index</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">start_char</span>
<span class="linenos"> 394</span>                    <span class="p">):</span>
<span class="linenos"> 395</span>                        <span class="n">token_start_index</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="linenos"> 396</span>                    <span class="n">tokenized_examples</span><span class="p">[</span><span class="s2">&quot;start_positions&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">token_start_index</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
<span class="linenos"> 397</span>                    <span class="k">while</span> <span class="n">offsets</span><span class="p">[</span><span class="n">token_end_index</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">end_char</span><span class="p">:</span>
<span class="linenos"> 398</span>                        <span class="n">token_end_index</span> <span class="o">-=</span> <span class="mi">1</span>
<span class="linenos"> 399</span>                    <span class="n">tokenized_examples</span><span class="p">[</span><span class="s2">&quot;end_positions&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">token_end_index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="linenos"> 400</span>
<span class="linenos"> 401</span>        <span class="k">return</span> <span class="n">tokenized_examples</span>
<span class="linenos"> 402</span>
<span class="linenos"> 403</span>    <span class="k">def</span> <span class="nf">prepare_validation_features</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>
<span class="linenos"> 404</span>        <span class="c1"># Some of the questions have lots of whitespace on the left, which is not useful and will make the</span>
<span class="linenos"> 405</span>        <span class="c1"># truncation of the context fail (the tokenized question will take a lots of space). So we remove that</span>
<span class="linenos"> 406</span>        <span class="c1"># left whitespace</span>
<span class="linenos"> 407</span>        <span class="n">examples</span><span class="p">[</span><span class="n">question_column_name</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">q</span><span class="o">.</span><span class="n">lstrip</span><span class="p">()</span> <span class="k">for</span> <span class="n">q</span> <span class="ow">in</span> <span class="n">examples</span><span class="p">[</span><span class="n">question_column_name</span><span class="p">]]</span>
<span class="linenos"> 408</span>
<span class="linenos"> 409</span>        <span class="c1"># Tokenize our examples with truncation and maybe padding, but keep the overflows using a stride. This results</span>
<span class="linenos"> 410</span>        <span class="c1"># in one example possible giving several features when a context is long, each of those features having a</span>
<span class="linenos"> 411</span>        <span class="c1"># context that overlaps a bit the context of the previous feature.</span>
<span class="linenos"> 412</span>        <span class="n">tokenized_examples</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
<span class="linenos"> 413</span>            <span class="n">examples</span><span class="p">[</span><span class="n">question_column_name</span> <span class="k">if</span> <span class="n">pad_on_right</span> <span class="k">else</span> <span class="n">context_column_name</span><span class="p">],</span>
<span class="linenos"> 414</span>            <span class="n">examples</span><span class="p">[</span><span class="n">context_column_name</span> <span class="k">if</span> <span class="n">pad_on_right</span> <span class="k">else</span> <span class="n">question_column_name</span><span class="p">],</span>
<span class="linenos"> 415</span>            <span class="n">truncation</span><span class="o">=</span><span class="s2">&quot;only_second&quot;</span> <span class="k">if</span> <span class="n">pad_on_right</span> <span class="k">else</span> <span class="s2">&quot;only_first&quot;</span><span class="p">,</span>
<span class="linenos"> 416</span>            <span class="n">max_length</span><span class="o">=</span><span class="n">max_seq_length</span><span class="p">,</span>
<span class="linenos"> 417</span>            <span class="n">stride</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">doc_stride</span><span class="p">,</span>
<span class="linenos"> 418</span>            <span class="n">return_overflowing_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="linenos"> 419</span>            <span class="n">return_offsets_mapping</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="linenos"> 420</span>            <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span> <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">pad_to_max_length</span> <span class="k">else</span> <span class="kc">False</span><span class="p">,</span>
<span class="linenos"> 421</span>        <span class="p">)</span>
<span class="linenos"> 422</span>
<span class="linenos"> 423</span>        <span class="c1"># Since one example might give us several features if it has a long context, we need a map from a feature to</span>
<span class="linenos"> 424</span>        <span class="c1"># its corresponding example. This key gives us just that.</span>
<span class="linenos"> 425</span>        <span class="n">sample_mapping</span> <span class="o">=</span> <span class="n">tokenized_examples</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;overflow_to_sample_mapping&quot;</span><span class="p">)</span>
<span class="linenos"> 426</span>
<span class="linenos"> 427</span>        <span class="c1"># For evaluation, we will need to convert our predictions to substrings of the context, so we keep the</span>
<span class="linenos"> 428</span>        <span class="c1"># corresponding example_id and we will store the offset mappings.</span>
<span class="linenos"> 429</span>        <span class="n">tokenized_examples</span><span class="p">[</span><span class="s2">&quot;example_id&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
<span class="linenos"> 430</span>
<span class="linenos"> 431</span>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tokenized_examples</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">])):</span>
<span class="linenos"> 432</span>            <span class="c1"># Grab the sequence corresponding to that example (to know what is the context and what is the question).</span>
<span class="linenos"> 433</span>            <span class="n">sequence_ids</span> <span class="o">=</span> <span class="n">tokenized_examples</span><span class="o">.</span><span class="n">sequence_ids</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
<span class="linenos"> 434</span>            <span class="n">context_index</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">pad_on_right</span> <span class="k">else</span> <span class="mi">0</span>
<span class="linenos"> 435</span>
<span class="linenos"> 436</span>            <span class="c1"># One example can give several spans, this is the index of the example containing this span of text.</span>
<span class="linenos"> 437</span>            <span class="n">sample_index</span> <span class="o">=</span> <span class="n">sample_mapping</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
<span class="linenos"> 438</span>            <span class="n">tokenized_examples</span><span class="p">[</span><span class="s2">&quot;example_id&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">][</span><span class="n">sample_index</span><span class="p">])</span>
<span class="linenos"> 439</span>
<span class="linenos"> 440</span>            <span class="c1"># Set to None the offset_mapping that are not part of the context so it&#39;s easy to determine if a token</span>
<span class="linenos"> 441</span>            <span class="c1"># position is part of the context or not.</span>
<span class="linenos"> 442</span>            <span class="n">tokenized_examples</span><span class="p">[</span><span class="s2">&quot;offset_mapping&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
<span class="linenos"> 443</span>                <span class="p">(</span><span class="n">o</span> <span class="k">if</span> <span class="n">sequence_ids</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">==</span> <span class="n">context_index</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>
<span class="linenos"> 444</span>                <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">o</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tokenized_examples</span><span class="p">[</span><span class="s2">&quot;offset_mapping&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">])</span>
<span class="linenos"> 445</span>            <span class="p">]</span>
<span class="linenos"> 446</span>
<span class="linenos"> 447</span>        <span class="k">return</span> <span class="n">tokenized_examples</span>
<span class="linenos"> 448</span>
<span class="linenos"> 449</span>    <span class="n">examples</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">dataloader</span> <span class="o">=</span> <span class="p">{},</span> <span class="p">{},</span> <span class="p">{}</span>
<span class="linenos"> 450</span>
<span class="linenos"> 451</span>    <span class="c1"># In distributed training, the load_dataset function guarantee that only one local process can concurrently</span>
<span class="linenos"> 452</span>    <span class="c1"># download the dataset.</span>
<span class="linenos"> 453</span>    <span class="c1"># Downloading and loading a dataset from the hub.</span>
<span class="linenos"> 454</span>    <span class="n">raw_datasets</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;squad&quot;</span><span class="p">)</span>
<span class="linenos"> 455</span>    <span class="c1"># See more about loading any type of standard or custom dataset (from files, python dict, pandas DataFrame, etc) at</span>
<span class="linenos"> 456</span>    <span class="c1"># https://huggingface.co/docs/datasets/loading_datasets.</span>
<span class="linenos"> 457</span>
<span class="linenos"> 458</span>    <span class="c1"># Preprocessing the datasets.</span>
<span class="linenos"> 459</span>    <span class="c1"># Preprocessing is slighlty different for training and evaluation.</span>
<span class="linenos"> 460</span>
<span class="linenos"> 461</span>    <span class="n">column_names</span> <span class="o">=</span> <span class="n">raw_datasets</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">column_names</span>
<span class="linenos"> 462</span>
<span class="linenos"> 463</span>    <span class="n">question_column_name</span> <span class="o">=</span> <span class="s2">&quot;question&quot;</span> <span class="k">if</span> <span class="s2">&quot;question&quot;</span> <span class="ow">in</span> <span class="n">column_names</span> <span class="k">else</span> <span class="n">column_names</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="linenos"> 464</span>    <span class="n">context_column_name</span> <span class="o">=</span> <span class="s2">&quot;context&quot;</span> <span class="k">if</span> <span class="s2">&quot;context&quot;</span> <span class="ow">in</span> <span class="n">column_names</span> <span class="k">else</span> <span class="n">column_names</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="linenos"> 465</span>    <span class="n">answer_column_name</span> <span class="o">=</span> <span class="s2">&quot;answers&quot;</span> <span class="k">if</span> <span class="s2">&quot;answers&quot;</span> <span class="ow">in</span> <span class="n">column_names</span> <span class="k">else</span> <span class="n">column_names</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
<span class="linenos"> 466</span>
<span class="linenos"> 467</span>    <span class="c1"># Padding side determines if we do (question|context) or (context|question).</span>
<span class="linenos"> 468</span>    <span class="n">pad_on_right</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">padding_side</span> <span class="o">==</span> <span class="s2">&quot;right&quot;</span>
<span class="linenos"> 469</span>
<span class="linenos"> 470</span>    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">max_seq_length</span> <span class="o">&gt;</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">model_max_length</span><span class="p">:</span>
<span class="linenos"> 471</span>        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
<span class="linenos"> 472</span>            <span class="sa">f</span><span class="s2">&quot;The max_seq_length passed (</span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span class="n">max_seq_length</span><span class="si">}</span><span class="s2">) is larger than the maximum length&quot;</span>
<span class="linenos"> 473</span>            <span class="sa">f</span><span class="s2">&quot; for the model (</span><span class="si">{</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">model_max_length</span><span class="si">}</span><span class="s2">). Using&quot;</span>
<span class="linenos"> 474</span>            <span class="sa">f</span><span class="s2">&quot; max_seq_length=</span><span class="si">{</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">model_max_length</span><span class="si">}</span><span class="s2">.&quot;</span>
<span class="linenos"> 475</span>        <span class="p">)</span>
<span class="linenos"> 476</span>
<span class="linenos"> 477</span>    <span class="n">max_seq_length</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">max_seq_length</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">model_max_length</span><span class="p">)</span>
<span class="linenos"> 478</span>
<span class="linenos"> 479</span>    <span class="n">examples</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">raw_datasets</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span>
<span class="linenos"> 480</span>    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">max_train_samples</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span class="linenos"> 481</span>        <span class="c1"># We will select sample from whole data if agument is specified</span>
<span class="linenos"> 482</span>        <span class="n">examples</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">examples</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">max_train_samples</span><span class="p">))</span>
<span class="linenos"> 483</span>
<span class="linenos"> 484</span>    <span class="c1"># Create train feature from dataset</span>
<span class="linenos"> 485</span>    <span class="k">with</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">main_process_first</span><span class="p">():</span>
<span class="linenos"> 486</span>        <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">examples</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
<span class="linenos"> 487</span>            <span class="n">prepare_train_features</span><span class="p">,</span>
<span class="linenos"> 488</span>            <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="linenos"> 489</span>            <span class="n">num_proc</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">preprocessing_num_workers</span><span class="p">,</span>
<span class="linenos"> 490</span>            <span class="n">remove_columns</span><span class="o">=</span><span class="n">column_names</span><span class="p">,</span>
<span class="linenos"> 491</span>            <span class="n">load_from_cache_file</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="linenos"> 492</span>            <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Running tokenizer on train dataset&quot;</span><span class="p">,</span>
<span class="linenos"> 493</span>        <span class="p">)</span>
<span class="linenos"> 494</span>        <span class="c1"># if args.max_train_samples is not None:</span>
<span class="linenos"> 495</span>        <span class="c1">#     # Number of samples might increase during Feature Creation, We select only specified max samples</span>
<span class="linenos"> 496</span>        <span class="c1">#     dataset[&quot;train&quot;] = dataset[&quot;train&quot;].select(range(args.max_train_samples))</span>
<span class="linenos"> 497</span>
<span class="linenos"> 498</span>    <span class="n">examples</span><span class="p">[</span><span class="s2">&quot;eval&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">raw_datasets</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span>
<span class="linenos"> 499</span>    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">max_eval_samples</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span class="linenos"> 500</span>        <span class="c1"># We will select sample from whole data</span>
<span class="linenos"> 501</span>        <span class="n">examples</span><span class="p">[</span><span class="s2">&quot;eval&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">examples</span><span class="p">[</span><span class="s2">&quot;eval&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">max_eval_samples</span><span class="p">))</span>
<span class="linenos"> 502</span>    <span class="c1"># Validation Feature Creation</span>
<span class="linenos"> 503</span>    <span class="k">with</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">main_process_first</span><span class="p">():</span>
<span class="linenos"> 504</span>        <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;eval&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">examples</span><span class="p">[</span><span class="s2">&quot;eval&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
<span class="linenos"> 505</span>            <span class="n">prepare_validation_features</span><span class="p">,</span>
<span class="linenos"> 506</span>            <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="linenos"> 507</span>            <span class="n">num_proc</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">preprocessing_num_workers</span><span class="p">,</span>
<span class="linenos"> 508</span>            <span class="n">remove_columns</span><span class="o">=</span><span class="n">column_names</span><span class="p">,</span>
<span class="linenos"> 509</span>            <span class="n">load_from_cache_file</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="linenos"> 510</span>            <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Running tokenizer on validation dataset&quot;</span><span class="p">,</span>
<span class="linenos"> 511</span>        <span class="p">)</span>
<span class="linenos"> 512</span>        <span class="c1"># if args.max_eval_samples is not None:</span>
<span class="linenos"> 513</span>        <span class="c1">#     # During Feature creation dataset samples might increase, we will select required samples again</span>
<span class="linenos"> 514</span>        <span class="c1">#     dataset[&quot;eval&quot;] = dataset[&quot;eval&quot;].select(range(args.max_eval_samples))</span>
<span class="linenos"> 515</span>
<span class="linenos"> 516</span>    <span class="c1"># Log a random sample from the training set:</span>
<span class="linenos"> 517</span>    <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">])),</span> <span class="mi">1</span><span class="p">):</span>
<span class="linenos"> 518</span>        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sample </span><span class="si">{</span><span class="n">index</span><span class="si">}</span><span class="s2"> of the training set: </span><span class="si">{</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">][</span><span class="n">index</span><span class="p">]</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
<span class="linenos"> 519</span>
<span class="linenos"> 520</span>    <span class="c1"># DataLoaders creation:</span>
<span class="linenos"> 521</span>    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">pad_to_max_length</span><span class="p">:</span>
<span class="linenos"> 522</span>        <span class="c1"># If padding was already done ot max length, we use the default data collator that will just convert everything</span>
<span class="linenos"> 523</span>        <span class="c1"># to tensors.</span>
<span class="linenos"> 524</span>        <span class="n">data_collator</span> <span class="o">=</span> <span class="n">default_data_collator</span>
<span class="linenos"> 525</span>    <span class="k">else</span><span class="p">:</span>
<span class="linenos"> 526</span>        <span class="c1"># Otherwise, `DataCollatorWithPadding` will apply dynamic padding for us (by padding to the maximum length of</span>
<span class="linenos"> 527</span>        <span class="c1"># the samples passed). When using mixed precision, we add `pad_to_multiple_of=8` to pad all tensors to multiple</span>
<span class="linenos"> 528</span>        <span class="c1"># of 8s, which will enable the use of Tensor Cores on NVIDIA hardware with compute capability &gt;= 7.5 (Volta).</span>
<span class="linenos"> 529</span>        <span class="n">data_collator</span> <span class="o">=</span> <span class="n">DataCollatorWithPadding</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">pad_to_multiple_of</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<span class="linenos"> 530</span>
<span class="linenos"> 531</span>    <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
<span class="linenos"> 532</span>        <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span>
<span class="linenos"> 533</span>        <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="linenos"> 534</span>        <span class="n">collate_fn</span><span class="o">=</span><span class="n">data_collator</span><span class="p">,</span>
<span class="linenos"> 535</span>        <span class="n">batch_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">per_device_train_batch_size</span><span class="p">,</span>
<span class="linenos"> 536</span>    <span class="p">)</span>
<span class="linenos"> 537</span>
<span class="linenos"> 538</span>    <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;eval&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
<span class="linenos"> 539</span>        <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;eval&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">remove_columns</span><span class="p">([</span><span class="s2">&quot;example_id&quot;</span><span class="p">,</span> <span class="s2">&quot;offset_mapping&quot;</span><span class="p">]),</span>
<span class="linenos"> 540</span>        <span class="n">collate_fn</span><span class="o">=</span><span class="n">data_collator</span><span class="p">,</span>
<span class="linenos"> 541</span>        <span class="n">batch_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">per_device_eval_batch_size</span><span class="p">,</span>
<span class="linenos"> 542</span>    <span class="p">)</span>
<span class="linenos"> 543</span>
<span class="linenos"> 544</span>    <span class="k">return</span> <span class="n">examples</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">,</span> <span class="n">answer_column_name</span>
<span class="linenos"> 545</span>
<span class="linenos"> 546</span>
<span class="linenos"> 547</span><span class="k">def</span> <span class="nf">evaluate_model</span><span class="p">(</span>
<span class="linenos"> 548</span>    <span class="n">args</span><span class="p">,</span>
<span class="linenos"> 549</span>    <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
<span class="linenos"> 550</span>    <span class="n">accelerator</span><span class="p">:</span> <span class="n">Accelerator</span><span class="p">,</span>
<span class="linenos"> 551</span>    <span class="n">eval_examples</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
<span class="linenos"> 552</span>    <span class="n">eval_dataset</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
<span class="linenos"> 553</span>    <span class="n">eval_dataloader</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">,</span>
<span class="linenos"> 554</span>    <span class="n">answer_column_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
<span class="linenos"> 555</span>    <span class="n">prefix</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;Eval&quot;</span><span class="p">,</span>
<span class="linenos"> 556</span><span class="p">):</span>
<span class="linenos"> 557</span>    <span class="k">def</span> <span class="nf">create_and_fill_np_array</span><span class="p">(</span><span class="n">start_or_end_logits</span><span class="p">,</span> <span class="n">max_len</span><span class="p">):</span>
<span class="linenos"> 558</span><span class="w">        </span><span class="sd">&quot;&quot;&quot;Create and fill numpy array of size len_of_validation_data * max_length_of_output_tensor</span>
<span class="linenos"> 559</span>
<span class="linenos"> 560</span><span class="sd">        Args:</span>
<span class="linenos"> 561</span><span class="sd">            start_or_end_logits: This is the output predictions of the model.</span>
<span class="linenos"> 562</span><span class="sd">                We can only enter either start or end logits.</span>
<span class="linenos"> 563</span><span class="sd">            max_len: The maximum length of the output tensor. (See the model.eval() part for more details)</span>
<span class="linenos"> 564</span><span class="sd">        &quot;&quot;&quot;</span>
<span class="linenos"> 565</span>        <span class="n">step</span> <span class="o">=</span> <span class="mi">0</span>
<span class="linenos"> 566</span>        <span class="c1"># create a numpy array and fill it with -100.</span>
<span class="linenos"> 567</span>        <span class="n">logits_concat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">eval_dataset</span><span class="p">),</span> <span class="n">max_len</span><span class="p">),</span> <span class="o">-</span><span class="mi">100</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="linenos"> 568</span>        <span class="c1"># Now since we have create an array we will populate it with the outputs using accelerator.gather_for_metrics</span>
<span class="linenos"> 569</span>        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">output_logit</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">start_or_end_logits</span><span class="p">):</span>  <span class="c1"># populate columns</span>
<span class="linenos"> 570</span>            <span class="c1"># We have to fill it such that we have to take the whole tensor and replace it on the newly created array</span>
<span class="linenos"> 571</span>            <span class="c1"># And after every iteration we have to change the step</span>
<span class="linenos"> 572</span>            <span class="n">batch_size</span> <span class="o">=</span> <span class="n">output_logit</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="linenos"> 573</span>            <span class="n">cols</span> <span class="o">=</span> <span class="n">output_logit</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="linenos"> 574</span>
<span class="linenos"> 575</span>            <span class="k">if</span> <span class="n">step</span> <span class="o">+</span> <span class="n">batch_size</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">eval_dataset</span><span class="p">):</span>
<span class="linenos"> 576</span>                <span class="n">logits_concat</span><span class="p">[</span><span class="n">step</span> <span class="p">:</span> <span class="n">step</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">,</span> <span class="p">:</span><span class="n">cols</span><span class="p">]</span> <span class="o">=</span> <span class="n">output_logit</span>
<span class="linenos"> 577</span>            <span class="k">else</span><span class="p">:</span>
<span class="linenos"> 578</span>                <span class="n">logits_concat</span><span class="p">[</span><span class="n">step</span><span class="p">:,</span> <span class="p">:</span><span class="n">cols</span><span class="p">]</span> <span class="o">=</span> <span class="n">output_logit</span><span class="p">[:</span> <span class="nb">len</span><span class="p">(</span><span class="n">eval_dataset</span><span class="p">)</span> <span class="o">-</span> <span class="n">step</span><span class="p">]</span>
<span class="linenos"> 579</span>
<span class="linenos"> 580</span>            <span class="n">step</span> <span class="o">+=</span> <span class="n">batch_size</span>
<span class="linenos"> 581</span>
<span class="linenos"> 582</span>        <span class="k">return</span> <span class="n">logits_concat</span>
<span class="linenos"> 583</span>
<span class="linenos"> 584</span>    <span class="k">def</span> <span class="nf">postprocess_qa_predictions</span><span class="p">(</span>
<span class="linenos"> 585</span>        <span class="n">examples</span><span class="p">,</span>
<span class="linenos"> 586</span>        <span class="n">features</span><span class="p">,</span>
<span class="linenos"> 587</span>        <span class="n">predictions</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
<span class="linenos"> 588</span>        <span class="n">version_2_with_negative</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="linenos"> 589</span>        <span class="n">n_best_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span>
<span class="linenos"> 590</span>        <span class="n">max_answer_length</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">30</span><span class="p">,</span>
<span class="linenos"> 591</span>        <span class="n">null_score_diff_threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
<span class="linenos"> 592</span>        <span class="n">output_dir</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="linenos"> 593</span>        <span class="n">prefix</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="linenos"> 594</span>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">EvalPrediction</span><span class="p">:</span>
<span class="linenos"> 595</span><span class="w">        </span><span class="sd">&quot;&quot;&quot;Post-processes the predictions of a question-answering model to convert them to answers</span>
<span class="linenos"> 596</span><span class="sd">        that are substrings of  the original contexts. This is the base postprocessing functions for</span>
<span class="linenos"> 597</span><span class="sd">        models that only return start and end logits.</span>
<span class="linenos"> 598</span>
<span class="linenos"> 599</span><span class="sd">        Args:</span>
<span class="linenos"> 600</span><span class="sd">            examples: The non-preprocessed dataset.</span>
<span class="linenos"> 601</span><span class="sd">            features: The processed dataset.</span>
<span class="linenos"> 602</span><span class="sd">            predictions: The predictions of the model: two arrays containing the start logits and the end logits</span>
<span class="linenos"> 603</span><span class="sd">                respectively. Its first dimension must match the number of elements of `features`.</span>
<span class="linenos"> 604</span><span class="sd">            version_2_with_negative: Whether or not the underlying dataset contains examples with no answers.</span>
<span class="linenos"> 605</span><span class="sd">            n_best_size: The total number of n-best predictions to generate when looking for an answer.</span>
<span class="linenos"> 606</span><span class="sd">            max_answer_length: The maximum length of an answer that can be generated. This is needed</span>
<span class="linenos"> 607</span><span class="sd">                because the start and end predictions are not conditioned on one another.</span>
<span class="linenos"> 608</span><span class="sd">            null_score_diff_threshold: The threshold used to select the null answer: if the best answer</span>
<span class="linenos"> 609</span><span class="sd">                has a score that is less than the score of the null answer minus this threshold, the</span>
<span class="linenos"> 610</span><span class="sd">                null answer is selected for this example (note that the score of the null answer for</span>
<span class="linenos"> 611</span><span class="sd">                an example giving several features is the minimum of the scores for the null answer on</span>
<span class="linenos"> 612</span><span class="sd">                each feature: all features must be aligned on the fact they `want` to predict a null answer).</span>
<span class="linenos"> 613</span><span class="sd">                Only useful when `version_2_with_negative` is `True`.</span>
<span class="linenos"> 614</span><span class="sd">            output_dir: If provided, the dictionaries of predictions, n_best predictions (with their scores and logits)</span>
<span class="linenos"> 615</span><span class="sd">                and, if `version_2_with_negative=True`, the dictionary of the scores differences between best and null</span>
<span class="linenos"> 616</span><span class="sd">                answers, are saved in `output_dir`.</span>
<span class="linenos"> 617</span><span class="sd">            prefix: If provided, the dictionaries mentioned above are saved with `prefix` added to their names.</span>
<span class="linenos"> 618</span><span class="sd">        &quot;&quot;&quot;</span>
<span class="linenos"> 619</span>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
<span class="linenos"> 620</span>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<span class="linenos"> 621</span>                <span class="s2">&quot;`predictions` should be a tuple with two elements (start_logits, end_logits).&quot;</span>
<span class="linenos"> 622</span>            <span class="p">)</span>
<span class="linenos"> 623</span>        <span class="n">all_start_logits</span><span class="p">,</span> <span class="n">all_end_logits</span> <span class="o">=</span> <span class="n">predictions</span>
<span class="linenos"> 624</span>
<span class="linenos"> 625</span>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">predictions</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">features</span><span class="p">):</span>
<span class="linenos"> 626</span>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Got </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">predictions</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="si">}</span><span class="s2"> predictions and </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">features</span><span class="p">)</span><span class="si">}</span><span class="s2"> features.&quot;</span><span class="p">)</span>
<span class="linenos"> 627</span>
<span class="linenos"> 628</span>        <span class="c1"># Build a map example to its corresponding features.</span>
<span class="linenos"> 629</span>        <span class="n">example_id_to_index</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">])}</span>
<span class="linenos"> 630</span>        <span class="n">features_per_example</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
<span class="linenos"> 631</span>        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">feature</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">features</span><span class="p">):</span>
<span class="linenos"> 632</span>            <span class="n">features_per_example</span><span class="p">[</span><span class="n">example_id_to_index</span><span class="p">[</span><span class="n">feature</span><span class="p">[</span><span class="s2">&quot;example_id&quot;</span><span class="p">]]]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
<span class="linenos"> 633</span>
<span class="linenos"> 634</span>        <span class="c1"># The dictionaries we have to fill.</span>
<span class="linenos"> 635</span>        <span class="n">all_predictions</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">OrderedDict</span><span class="p">()</span>
<span class="linenos"> 636</span>        <span class="n">all_nbest_json</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">OrderedDict</span><span class="p">()</span>
<span class="linenos"> 637</span>        <span class="k">if</span> <span class="n">version_2_with_negative</span><span class="p">:</span>
<span class="linenos"> 638</span>            <span class="n">scores_diff_json</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">OrderedDict</span><span class="p">()</span>
<span class="linenos"> 639</span>
<span class="linenos"> 640</span>        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
<span class="linenos"> 641</span>            <span class="sa">f</span><span class="s2">&quot;Post-processing </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">examples</span><span class="p">)</span><span class="si">}</span><span class="s2"> example predictions split into&quot;</span>
<span class="linenos"> 642</span>            <span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">features</span><span class="p">)</span><span class="si">}</span><span class="s2"> features.&quot;</span>
<span class="linenos"> 643</span>        <span class="p">)</span>
<span class="linenos"> 644</span>
<span class="linenos"> 645</span>        <span class="c1"># Let&#39;s loop over all the examples!</span>
<span class="linenos"> 646</span>        <span class="k">for</span> <span class="n">example_index</span><span class="p">,</span> <span class="n">example</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>
<span class="linenos"> 647</span>            <span class="c1"># Those are the indices of the features associated to the current example.</span>
<span class="linenos"> 648</span>            <span class="n">feature_indices</span> <span class="o">=</span> <span class="n">features_per_example</span><span class="p">[</span><span class="n">example_index</span><span class="p">]</span>
<span class="linenos"> 649</span>
<span class="linenos"> 650</span>            <span class="n">min_null_prediction</span> <span class="o">=</span> <span class="kc">None</span>
<span class="linenos"> 651</span>            <span class="n">prelim_predictions</span> <span class="o">=</span> <span class="p">[]</span>
<span class="linenos"> 652</span>
<span class="linenos"> 653</span>            <span class="c1"># Looping through all the features associated to the current example.</span>
<span class="linenos"> 654</span>            <span class="k">for</span> <span class="n">feature_index</span> <span class="ow">in</span> <span class="n">feature_indices</span><span class="p">:</span>
<span class="linenos"> 655</span>                <span class="c1"># We grab the predictions of the model for this feature.</span>
<span class="linenos"> 656</span>                <span class="n">start_logits</span> <span class="o">=</span> <span class="n">all_start_logits</span><span class="p">[</span><span class="n">feature_index</span><span class="p">]</span>
<span class="linenos"> 657</span>                <span class="n">end_logits</span> <span class="o">=</span> <span class="n">all_end_logits</span><span class="p">[</span><span class="n">feature_index</span><span class="p">]</span>
<span class="linenos"> 658</span>                <span class="c1"># This is what will allow us to map some the positions in our logits to span of texts in the original</span>
<span class="linenos"> 659</span>                <span class="c1"># context.</span>
<span class="linenos"> 660</span>                <span class="n">offset_mapping</span> <span class="o">=</span> <span class="n">features</span><span class="p">[</span><span class="n">feature_index</span><span class="p">][</span><span class="s2">&quot;offset_mapping&quot;</span><span class="p">]</span>
<span class="linenos"> 661</span>                <span class="c1"># Optional `token_is_max_context`, if provided we will remove answers that do not have the maximum</span>
<span class="linenos"> 662</span>                <span class="c1"># context available in the current feature.</span>
<span class="linenos"> 663</span>                <span class="n">token_is_max_context</span> <span class="o">=</span> <span class="n">features</span><span class="p">[</span><span class="n">feature_index</span><span class="p">]</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;token_is_max_context&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
<span class="linenos"> 664</span>
<span class="linenos"> 665</span>                <span class="c1"># Update minimum null prediction.</span>
<span class="linenos"> 666</span>                <span class="n">feature_null_score</span> <span class="o">=</span> <span class="n">start_logits</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">end_logits</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="linenos"> 667</span>                <span class="k">if</span> <span class="n">min_null_prediction</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">min_null_prediction</span><span class="p">[</span><span class="s2">&quot;score&quot;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">feature_null_score</span><span class="p">:</span>
<span class="linenos"> 668</span>                    <span class="n">min_null_prediction</span> <span class="o">=</span> <span class="p">{</span>
<span class="linenos"> 669</span>                        <span class="s2">&quot;offsets&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
<span class="linenos"> 670</span>                        <span class="s2">&quot;score&quot;</span><span class="p">:</span> <span class="n">feature_null_score</span><span class="p">,</span>
<span class="linenos"> 671</span>                        <span class="s2">&quot;start_logit&quot;</span><span class="p">:</span> <span class="n">start_logits</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
<span class="linenos"> 672</span>                        <span class="s2">&quot;end_logit&quot;</span><span class="p">:</span> <span class="n">end_logits</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
<span class="linenos"> 673</span>                    <span class="p">}</span>
<span class="linenos"> 674</span>
<span class="linenos"> 675</span>                <span class="c1"># Go through all possibilities for the `n_best_size` greater start and end logits.</span>
<span class="linenos"> 676</span>                <span class="n">start_indexes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">start_logits</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span> <span class="p">:</span> <span class="o">-</span><span class="n">n_best_size</span> <span class="o">-</span> <span class="mi">1</span> <span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="linenos"> 677</span>                <span class="n">end_indexes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">end_logits</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span> <span class="p">:</span> <span class="o">-</span><span class="n">n_best_size</span> <span class="o">-</span> <span class="mi">1</span> <span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="linenos"> 678</span>                <span class="k">for</span> <span class="n">start_index</span> <span class="ow">in</span> <span class="n">start_indexes</span><span class="p">:</span>
<span class="linenos"> 679</span>                    <span class="k">for</span> <span class="n">end_index</span> <span class="ow">in</span> <span class="n">end_indexes</span><span class="p">:</span>
<span class="linenos"> 680</span>                        <span class="c1"># Don&#39;t consider out-of-scope answers, either because the indices are out of bounds or</span>
<span class="linenos"> 681</span>                        <span class="c1"># correspond to part of the input_ids that are not in the context.</span>
<span class="linenos"> 682</span>                        <span class="k">if</span> <span class="p">(</span>
<span class="linenos"> 683</span>                            <span class="n">start_index</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="n">offset_mapping</span><span class="p">)</span>
<span class="linenos"> 684</span>                            <span class="ow">or</span> <span class="n">end_index</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="n">offset_mapping</span><span class="p">)</span>
<span class="linenos"> 685</span>                            <span class="ow">or</span> <span class="n">offset_mapping</span><span class="p">[</span><span class="n">start_index</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">None</span>
<span class="linenos"> 686</span>                            <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">offset_mapping</span><span class="p">[</span><span class="n">start_index</span><span class="p">])</span> <span class="o">&lt;</span> <span class="mi">2</span>
<span class="linenos"> 687</span>                            <span class="ow">or</span> <span class="n">offset_mapping</span><span class="p">[</span><span class="n">end_index</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">None</span>
<span class="linenos"> 688</span>                            <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">offset_mapping</span><span class="p">[</span><span class="n">end_index</span><span class="p">])</span> <span class="o">&lt;</span> <span class="mi">2</span>
<span class="linenos"> 689</span>                        <span class="p">):</span>
<span class="linenos"> 690</span>                            <span class="k">continue</span>
<span class="linenos"> 691</span>                        <span class="c1"># Don&#39;t consider answers with a length that is either &lt; 0 or &gt; max_answer_length.</span>
<span class="linenos"> 692</span>                        <span class="k">if</span> <span class="p">(</span>
<span class="linenos"> 693</span>                            <span class="n">end_index</span> <span class="o">&lt;</span> <span class="n">start_index</span>
<span class="linenos"> 694</span>                            <span class="ow">or</span> <span class="n">end_index</span> <span class="o">-</span> <span class="n">start_index</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">&gt;</span> <span class="n">max_answer_length</span>
<span class="linenos"> 695</span>                        <span class="p">):</span>
<span class="linenos"> 696</span>                            <span class="k">continue</span>
<span class="linenos"> 697</span>                        <span class="c1"># Don&#39;t consider answer that don&#39;t have the maximum context available (if such information is</span>
<span class="linenos"> 698</span>                        <span class="c1"># provided).</span>
<span class="linenos"> 699</span>                        <span class="k">if</span> <span class="n">token_is_max_context</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">token_is_max_context</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
<span class="linenos"> 700</span>                            <span class="nb">str</span><span class="p">(</span><span class="n">start_index</span><span class="p">),</span> <span class="kc">False</span>
<span class="linenos"> 701</span>                        <span class="p">):</span>
<span class="linenos"> 702</span>                            <span class="k">continue</span>
<span class="linenos"> 703</span>
<span class="linenos"> 704</span>                        <span class="n">prelim_predictions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
<span class="linenos"> 705</span>                            <span class="p">{</span>
<span class="linenos"> 706</span>                                <span class="s2">&quot;offsets&quot;</span><span class="p">:</span> <span class="p">(</span>
<span class="linenos"> 707</span>                                    <span class="n">offset_mapping</span><span class="p">[</span><span class="n">start_index</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span>
<span class="linenos"> 708</span>                                    <span class="n">offset_mapping</span><span class="p">[</span><span class="n">end_index</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span>
<span class="linenos"> 709</span>                                <span class="p">),</span>
<span class="linenos"> 710</span>                                <span class="s2">&quot;score&quot;</span><span class="p">:</span> <span class="n">start_logits</span><span class="p">[</span><span class="n">start_index</span><span class="p">]</span> <span class="o">+</span> <span class="n">end_logits</span><span class="p">[</span><span class="n">end_index</span><span class="p">],</span>
<span class="linenos"> 711</span>                                <span class="s2">&quot;start_logit&quot;</span><span class="p">:</span> <span class="n">start_logits</span><span class="p">[</span><span class="n">start_index</span><span class="p">],</span>
<span class="linenos"> 712</span>                                <span class="s2">&quot;end_logit&quot;</span><span class="p">:</span> <span class="n">end_logits</span><span class="p">[</span><span class="n">end_index</span><span class="p">],</span>
<span class="linenos"> 713</span>                            <span class="p">}</span>
<span class="linenos"> 714</span>                        <span class="p">)</span>
<span class="linenos"> 715</span>            <span class="k">if</span> <span class="n">version_2_with_negative</span> <span class="ow">and</span> <span class="n">min_null_prediction</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span class="linenos"> 716</span>                <span class="c1"># Add the minimum null prediction</span>
<span class="linenos"> 717</span>                <span class="n">prelim_predictions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">min_null_prediction</span><span class="p">)</span>
<span class="linenos"> 718</span>                <span class="n">null_score</span> <span class="o">=</span> <span class="n">min_null_prediction</span><span class="p">[</span><span class="s2">&quot;score&quot;</span><span class="p">]</span>
<span class="linenos"> 719</span>
<span class="linenos"> 720</span>            <span class="c1"># Only keep the best `n_best_size` predictions.</span>
<span class="linenos"> 721</span>            <span class="n">n_best_preds</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">prelim_predictions</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s2">&quot;score&quot;</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span>
<span class="linenos"> 722</span>                <span class="p">:</span><span class="n">n_best_size</span>
<span class="linenos"> 723</span>            <span class="p">]</span>
<span class="linenos"> 724</span>
<span class="linenos"> 725</span>            <span class="c1"># Add back the minimum null prediction if it was removed because of its low score.</span>
<span class="linenos"> 726</span>            <span class="k">if</span> <span class="p">(</span>
<span class="linenos"> 727</span>                <span class="n">version_2_with_negative</span>
<span class="linenos"> 728</span>                <span class="ow">and</span> <span class="n">min_null_prediction</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
<span class="linenos"> 729</span>                <span class="ow">and</span> <span class="ow">not</span> <span class="nb">any</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="s2">&quot;offsets&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">n_best_preds</span><span class="p">)</span>
<span class="linenos"> 730</span>            <span class="p">):</span>
<span class="linenos"> 731</span>                <span class="n">n_best_preds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">min_null_prediction</span><span class="p">)</span>
<span class="linenos"> 732</span>
<span class="linenos"> 733</span>            <span class="c1"># Use the offsets to gather the answer text in the original context.</span>
<span class="linenos"> 734</span>            <span class="n">context</span> <span class="o">=</span> <span class="n">example</span><span class="p">[</span><span class="s2">&quot;context&quot;</span><span class="p">]</span>
<span class="linenos"> 735</span>            <span class="k">for</span> <span class="n">pred</span> <span class="ow">in</span> <span class="n">n_best_preds</span><span class="p">:</span>
<span class="linenos"> 736</span>                <span class="n">offsets</span> <span class="o">=</span> <span class="n">pred</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;offsets&quot;</span><span class="p">)</span>
<span class="linenos"> 737</span>                <span class="n">pred</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">context</span><span class="p">[</span><span class="n">offsets</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="p">:</span> <span class="n">offsets</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
<span class="linenos"> 738</span>
<span class="linenos"> 739</span>            <span class="c1"># In the very rare edge case we have not a single non-null prediction, we create a fake prediction to avoid</span>
<span class="linenos"> 740</span>            <span class="c1"># failure.</span>
<span class="linenos"> 741</span>            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">n_best_preds</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">n_best_preds</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">n_best_preds</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;text&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;&quot;</span><span class="p">):</span>
<span class="linenos"> 742</span>                <span class="n">n_best_preds</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span>
<span class="linenos"> 743</span>                    <span class="mi">0</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;text&quot;</span><span class="p">:</span> <span class="s2">&quot;empty&quot;</span><span class="p">,</span> <span class="s2">&quot;start_logit&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span> <span class="s2">&quot;end_logit&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span> <span class="s2">&quot;score&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">}</span>
<span class="linenos"> 744</span>                <span class="p">)</span>
<span class="linenos"> 745</span>
<span class="linenos"> 746</span>            <span class="c1"># Compute the softmax of all scores (we do it with numpy to stay independent from torch/tf in this file,</span>
<span class="linenos"> 747</span>            <span class="c1"># using the LogSumExp trick).</span>
<span class="linenos"> 748</span>            <span class="n">scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">pred</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;score&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">pred</span> <span class="ow">in</span> <span class="n">n_best_preds</span><span class="p">])</span>
<span class="linenos"> 749</span>            <span class="n">exp_scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">scores</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">scores</span><span class="p">))</span>
<span class="linenos"> 750</span>            <span class="n">probs</span> <span class="o">=</span> <span class="n">exp_scores</span> <span class="o">/</span> <span class="n">exp_scores</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="linenos"> 751</span>
<span class="linenos"> 752</span>            <span class="c1"># Include the probabilities in our n_best_preds.</span>
<span class="linenos"> 753</span>            <span class="k">for</span> <span class="n">prob</span><span class="p">,</span> <span class="n">pred</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">probs</span><span class="p">,</span> <span class="n">n_best_preds</span><span class="p">):</span>
<span class="linenos"> 754</span>                <span class="n">pred</span><span class="p">[</span><span class="s2">&quot;probability&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">prob</span>
<span class="linenos"> 755</span>
<span class="linenos"> 756</span>            <span class="c1"># Pick the best prediction. If the null answer is not possible, this is easy.</span>
<span class="linenos"> 757</span>            <span class="k">if</span> <span class="ow">not</span> <span class="n">version_2_with_negative</span><span class="p">:</span>
<span class="linenos"> 758</span>                <span class="n">all_predictions</span><span class="p">[</span><span class="n">example</span><span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">]]</span> <span class="o">=</span> <span class="n">n_best_preds</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;text&quot;</span><span class="p">]</span>
<span class="linenos"> 759</span>            <span class="k">else</span><span class="p">:</span>
<span class="linenos"> 760</span>                <span class="c1"># Otherwise we first need to find the best non-empty prediction.</span>
<span class="linenos"> 761</span>                <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
<span class="linenos"> 762</span>                <span class="k">while</span> <span class="n">n_best_preds</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s2">&quot;text&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;&quot;</span><span class="p">:</span>
<span class="linenos"> 763</span>                    <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="linenos"> 764</span>                <span class="n">best_non_null_pred</span> <span class="o">=</span> <span class="n">n_best_preds</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
<span class="linenos"> 765</span>
<span class="linenos"> 766</span>                <span class="c1"># Then we compare to the null prediction using the threshold.</span>
<span class="linenos"> 767</span>                <span class="n">score_diff</span> <span class="o">=</span> <span class="p">(</span>
<span class="linenos"> 768</span>                    <span class="n">null_score</span> <span class="o">-</span> <span class="n">best_non_null_pred</span><span class="p">[</span><span class="s2">&quot;start_logit&quot;</span><span class="p">]</span> <span class="o">-</span> <span class="n">best_non_null_pred</span><span class="p">[</span><span class="s2">&quot;end_logit&quot;</span><span class="p">]</span>
<span class="linenos"> 769</span>                <span class="p">)</span>
<span class="linenos"> 770</span>                <span class="n">scores_diff_json</span><span class="p">[</span><span class="n">example</span><span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">]]</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">score_diff</span><span class="p">)</span>  <span class="c1"># To be JSON-serializable.</span>
<span class="linenos"> 771</span>                <span class="k">if</span> <span class="n">score_diff</span> <span class="o">&gt;</span> <span class="n">null_score_diff_threshold</span><span class="p">:</span>
<span class="linenos"> 772</span>                    <span class="n">all_predictions</span><span class="p">[</span><span class="n">example</span><span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">]]</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
<span class="linenos"> 773</span>                <span class="k">else</span><span class="p">:</span>
<span class="linenos"> 774</span>                    <span class="n">all_predictions</span><span class="p">[</span><span class="n">example</span><span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">]]</span> <span class="o">=</span> <span class="n">best_non_null_pred</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span>
<span class="linenos"> 775</span>
<span class="linenos"> 776</span>            <span class="c1"># Make `n_best_preds` JSON-serializable by casting np.float back to float.</span>
<span class="linenos"> 777</span>            <span class="n">all_nbest_json</span><span class="p">[</span><span class="n">example</span><span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[</span>
<span class="linenos"> 778</span>                <span class="p">{</span>
<span class="linenos"> 779</span>                    <span class="n">k</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float16</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">))</span> <span class="k">else</span> <span class="n">v</span>
<span class="linenos"> 780</span>                    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">pred</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
<span class="linenos"> 781</span>                <span class="p">}</span>
<span class="linenos"> 782</span>                <span class="k">for</span> <span class="n">pred</span> <span class="ow">in</span> <span class="n">n_best_preds</span>
<span class="linenos"> 783</span>            <span class="p">]</span>
<span class="linenos"> 784</span>
<span class="linenos"> 785</span>        <span class="c1"># If we have an output_dir, let&#39;s save all those dicts.</span>
<span class="linenos"> 786</span>        <span class="k">if</span> <span class="n">output_dir</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span class="linenos"> 787</span>            <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isdir</span><span class="p">(</span><span class="n">output_dir</span><span class="p">):</span>
<span class="linenos"> 788</span>                <span class="k">raise</span> <span class="ne">EnvironmentError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">output_dir</span><span class="si">}</span><span class="s2"> is not a directory.&quot;</span><span class="p">)</span>
<span class="linenos"> 789</span>
<span class="linenos"> 790</span>            <span class="n">prediction_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
<span class="linenos"> 791</span>                <span class="n">output_dir</span><span class="p">,</span> <span class="s2">&quot;predictions.json&quot;</span> <span class="k">if</span> <span class="n">prefix</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_predictions.json&quot;</span>
<span class="linenos"> 792</span>            <span class="p">)</span>
<span class="linenos"> 793</span>            <span class="n">nbest_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
<span class="linenos"> 794</span>                <span class="n">output_dir</span><span class="p">,</span>
<span class="linenos"> 795</span>                <span class="s2">&quot;nbest_predictions.json&quot;</span> <span class="k">if</span> <span class="n">prefix</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_nbest_predictions.json&quot;</span><span class="p">,</span>
<span class="linenos"> 796</span>            <span class="p">)</span>
<span class="linenos"> 797</span>            <span class="k">if</span> <span class="n">version_2_with_negative</span><span class="p">:</span>
<span class="linenos"> 798</span>                <span class="n">null_odds_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
<span class="linenos"> 799</span>                    <span class="n">output_dir</span><span class="p">,</span> <span class="s2">&quot;null_odds.json&quot;</span> <span class="k">if</span> <span class="n">prefix</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_null_odds.json&quot;</span>
<span class="linenos"> 800</span>                <span class="p">)</span>
<span class="linenos"> 801</span>
<span class="linenos"> 802</span>            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Saving predictions to </span><span class="si">{</span><span class="n">prediction_file</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
<span class="linenos"> 803</span>            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">prediction_file</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">writer</span><span class="p">:</span>
<span class="linenos"> 804</span>                <span class="n">writer</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">all_predictions</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="linenos"> 805</span>            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Saving nbest_preds to </span><span class="si">{</span><span class="n">nbest_file</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
<span class="linenos"> 806</span>            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">nbest_file</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">writer</span><span class="p">:</span>
<span class="linenos"> 807</span>                <span class="n">writer</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">all_nbest_json</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="linenos"> 808</span>            <span class="k">if</span> <span class="n">version_2_with_negative</span><span class="p">:</span>
<span class="linenos"> 809</span>                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Saving null_odds to </span><span class="si">{</span><span class="n">null_odds_file</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
<span class="linenos"> 810</span>                <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">null_odds_file</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">writer</span><span class="p">:</span>
<span class="linenos"> 811</span>                    <span class="n">writer</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">scores_diff_json</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="linenos"> 812</span>
<span class="linenos"> 813</span>        <span class="c1"># Format the result to the format the metric expects.</span>
<span class="linenos"> 814</span>        <span class="n">formatted_predictions</span> <span class="o">=</span> <span class="p">[</span>
<span class="linenos"> 815</span>            <span class="p">{</span><span class="s2">&quot;id&quot;</span><span class="p">:</span> <span class="n">k</span><span class="p">,</span> <span class="s2">&quot;prediction_text&quot;</span><span class="p">:</span> <span class="n">v</span><span class="p">}</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">all_predictions</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
<span class="linenos"> 816</span>        <span class="p">]</span>
<span class="linenos"> 817</span>
<span class="linenos"> 818</span>        <span class="n">references</span> <span class="o">=</span> <span class="p">[{</span><span class="s2">&quot;id&quot;</span><span class="p">:</span> <span class="n">ex</span><span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">],</span> <span class="s2">&quot;answers&quot;</span><span class="p">:</span> <span class="n">ex</span><span class="p">[</span><span class="n">answer_column_name</span><span class="p">]}</span> <span class="k">for</span> <span class="n">ex</span> <span class="ow">in</span> <span class="n">examples</span><span class="p">]</span>
<span class="linenos"> 819</span>        <span class="k">return</span> <span class="n">EvalPrediction</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">formatted_predictions</span><span class="p">,</span> <span class="n">label_ids</span><span class="o">=</span><span class="n">references</span><span class="p">)</span>
<span class="linenos"> 820</span>
<span class="linenos"> 821</span>    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;***** Running </span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2"> *****&quot;</span><span class="p">)</span>
<span class="linenos"> 822</span>    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Num examples = </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">eval_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="linenos"> 823</span>    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Batch size = </span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span class="n">per_device_eval_batch_size</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="linenos"> 824</span>
<span class="linenos"> 825</span>    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="linenos"> 826</span>    <span class="n">all_start_logits</span> <span class="o">=</span> <span class="p">[]</span>
<span class="linenos"> 827</span>    <span class="n">all_end_logits</span> <span class="o">=</span> <span class="p">[]</span>
<span class="linenos"> 828</span>    <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">eval_dataloader</span><span class="p">):</span>
<span class="linenos"> 829</span>        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<span class="linenos"> 830</span>            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">batch</span><span class="p">)</span>
<span class="linenos"> 831</span>            <span class="n">start_logits</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">start_logits</span>
<span class="linenos"> 832</span>            <span class="n">end_logits</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">end_logits</span>
<span class="linenos"> 833</span>
<span class="linenos"> 834</span>            <span class="k">if</span> <span class="p">(</span>
<span class="linenos"> 835</span>                <span class="ow">not</span> <span class="n">args</span><span class="o">.</span><span class="n">pad_to_max_length</span>
<span class="linenos"> 836</span>            <span class="p">):</span>  <span class="c1"># necessary to pad predictions and labels for being gathered</span>
<span class="linenos"> 837</span>                <span class="n">start_logits</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">pad_across_processes</span><span class="p">(</span><span class="n">start_logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">pad_index</span><span class="o">=-</span><span class="mi">100</span><span class="p">)</span>
<span class="linenos"> 838</span>                <span class="n">end_logits</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">pad_across_processes</span><span class="p">(</span><span class="n">end_logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">pad_index</span><span class="o">=-</span><span class="mi">100</span><span class="p">)</span>
<span class="linenos"> 839</span>
<span class="linenos"> 840</span>            <span class="n">all_start_logits</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">start_logits</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
<span class="linenos"> 841</span>            <span class="n">all_end_logits</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accelerator</span><span class="o">.</span><span class="n">gather_for_metrics</span><span class="p">(</span><span class="n">end_logits</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
<span class="linenos"> 842</span>
<span class="linenos"> 843</span>    <span class="c1"># Model Optimizer: clear the intermediate states of the distillation model from the forward passes</span>
<span class="linenos"> 844</span>    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">do_modelopt_distill</span><span class="p">:</span>
<span class="linenos"> 845</span>        <span class="n">model</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">compute_kd_loss</span><span class="p">()</span>
<span class="linenos"> 846</span>
<span class="linenos"> 847</span>    <span class="n">max_len</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">all_start_logits</span><span class="p">])</span>  <span class="c1"># Get the max_length of the tensor</span>
<span class="linenos"> 848</span>
<span class="linenos"> 849</span>    <span class="c1"># concatenate the numpy array</span>
<span class="linenos"> 850</span>    <span class="n">start_logits_concat</span> <span class="o">=</span> <span class="n">create_and_fill_np_array</span><span class="p">(</span><span class="n">all_start_logits</span><span class="p">,</span> <span class="n">max_len</span><span class="p">)</span>
<span class="linenos"> 851</span>    <span class="n">end_logits_concat</span> <span class="o">=</span> <span class="n">create_and_fill_np_array</span><span class="p">(</span><span class="n">all_end_logits</span><span class="p">,</span> <span class="n">max_len</span><span class="p">)</span>
<span class="linenos"> 852</span>
<span class="linenos"> 853</span>    <span class="n">outputs_numpy</span> <span class="o">=</span> <span class="p">(</span><span class="n">start_logits_concat</span><span class="p">,</span> <span class="n">end_logits_concat</span><span class="p">)</span>
<span class="linenos"> 854</span>    <span class="n">prediction</span> <span class="o">=</span> <span class="n">postprocess_qa_predictions</span><span class="p">(</span>
<span class="linenos"> 855</span>        <span class="n">examples</span><span class="o">=</span><span class="n">eval_examples</span><span class="p">,</span>
<span class="linenos"> 856</span>        <span class="n">features</span><span class="o">=</span><span class="n">eval_dataset</span><span class="p">,</span>
<span class="linenos"> 857</span>        <span class="n">predictions</span><span class="o">=</span><span class="n">outputs_numpy</span><span class="p">,</span>
<span class="linenos"> 858</span>        <span class="n">n_best_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">n_best_size</span><span class="p">,</span>
<span class="linenos"> 859</span>        <span class="n">max_answer_length</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">max_answer_length</span><span class="p">,</span>
<span class="linenos"> 860</span>        <span class="c1"># output_dir=args.output_dir,</span>
<span class="linenos"> 861</span>        <span class="n">prefix</span><span class="o">=</span><span class="n">prefix</span><span class="p">,</span>
<span class="linenos"> 862</span>    <span class="p">)</span>
<span class="linenos"> 863</span>
<span class="linenos"> 864</span>    <span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;squad&quot;</span><span class="p">)</span>
<span class="linenos"> 865</span>    <span class="n">eval_metric</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span>
<span class="linenos"> 866</span>        <span class="n">predictions</span><span class="o">=</span><span class="n">prediction</span><span class="o">.</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">prediction</span><span class="o">.</span><span class="n">label_ids</span>
<span class="linenos"> 867</span>    <span class="p">)</span>
<span class="linenos"> 868</span>    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2"> metrics: </span><span class="si">{</span><span class="n">eval_metric</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="linenos"> 869</span>    <span class="k">return</span> <span class="n">eval_metric</span>
<span class="linenos"> 870</span>
<span class="linenos"> 871</span>
<span class="hll"><span class="linenos"> 872</span><span class="c1"># Model Optimizer: Define a teacher factory for initializing the distillation model</span>
</span><span class="hll"><span class="linenos"> 873</span><span class="k">def</span> <span class="nf">teacher_factory</span><span class="p">(</span><span class="n">model_name_or_path</span><span class="p">):</span>
</span><span class="hll"><span class="linenos"> 874</span>    <span class="k">return</span> <span class="n">AutoModelForQuestionAnswering</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name_or_path</span><span class="p">)</span>
</span><span class="hll"><span class="linenos"> 875</span>
</span><span class="hll"><span class="linenos"> 876</span>
</span><span class="hll"><span class="linenos"> 877</span><span class="c1"># Model Optimizer: Define a custom distillation loss function that uses start and end logits</span>
</span><span class="hll"><span class="linenos"> 878</span><span class="k">class</span> <span class="nc">StartEndLogitsDistillationLoss</span><span class="p">(</span><span class="n">mtd</span><span class="o">.</span><span class="n">LogitsDistillationLoss</span><span class="p">):</span>
</span><span class="hll"><span class="linenos"> 879</span>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">outputs_s</span><span class="p">,</span> <span class="n">outputs_t</span><span class="p">):</span>
</span><span class="hll"><span class="linenos"> 880</span>        <span class="n">loss_start</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">outputs_s</span><span class="o">.</span><span class="n">start_logits</span><span class="p">,</span> <span class="n">outputs_t</span><span class="o">.</span><span class="n">start_logits</span><span class="p">)</span>
</span><span class="hll"><span class="linenos"> 881</span>        <span class="n">loss_end</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">outputs_s</span><span class="o">.</span><span class="n">end_logits</span><span class="p">,</span> <span class="n">outputs_t</span><span class="o">.</span><span class="n">end_logits</span><span class="p">)</span>
</span><span class="hll"><span class="linenos"> 882</span>        <span class="n">loss</span> <span class="o">=</span> <span class="p">(</span><span class="n">loss_start</span> <span class="o">+</span> <span class="n">loss_end</span><span class="p">)</span> <span class="o">/</span> <span class="mf">2.0</span>
</span><span class="hll"><span class="linenos"> 883</span>
</span><span class="hll"><span class="linenos"> 884</span>        <span class="k">return</span> <span class="n">loss</span>
</span><span class="linenos"> 885</span>
<span class="linenos"> 886</span>
<span class="linenos"> 887</span><span class="k">def</span> <span class="nf">train_and_evaluate_model</span><span class="p">(</span>
<span class="linenos"> 888</span>    <span class="n">args</span><span class="p">,</span>
<span class="linenos"> 889</span>    <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
<span class="linenos"> 890</span>    <span class="n">tokenizer</span><span class="p">:</span> <span class="n">PreTrainedTokenizer</span><span class="p">,</span>
<span class="linenos"> 891</span>    <span class="n">accelerator</span><span class="p">:</span> <span class="n">Accelerator</span><span class="p">,</span>
<span class="linenos"> 892</span>    <span class="n">examples</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span>
<span class="linenos"> 893</span>    <span class="n">dataset</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span>
<span class="linenos"> 894</span>    <span class="n">dataloader</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">DataLoader</span><span class="p">],</span>
<span class="linenos"> 895</span>    <span class="n">answer_column_name</span><span class="p">,</span>
<span class="linenos"> 896</span><span class="p">):</span>
<span class="linenos"> 897</span>    <span class="c1"># Optimizer</span>
<span class="linenos"> 898</span>    <span class="c1"># Split weights in two groups, one with weight decay and the other not.</span>
<span class="linenos"> 899</span>    <span class="n">no_decay</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;bias&quot;</span><span class="p">,</span> <span class="s2">&quot;LayerNorm.weight&quot;</span><span class="p">]</span>
<span class="linenos"> 900</span>    <span class="n">optimizer_grouped_parameters</span> <span class="o">=</span> <span class="p">[</span>
<span class="linenos"> 901</span>        <span class="p">{</span>
<span class="linenos"> 902</span>            <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">[</span>
<span class="linenos"> 903</span>                <span class="n">p</span>
<span class="linenos"> 904</span>                <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">()</span>
<span class="linenos"> 905</span>                <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">any</span><span class="p">(</span><span class="n">nd</span> <span class="ow">in</span> <span class="n">n</span> <span class="k">for</span> <span class="n">nd</span> <span class="ow">in</span> <span class="n">no_decay</span><span class="p">)</span>
<span class="linenos"> 906</span>            <span class="p">],</span>
<span class="linenos"> 907</span>            <span class="s2">&quot;weight_decay&quot;</span><span class="p">:</span> <span class="n">args</span><span class="o">.</span><span class="n">weight_decay</span><span class="p">,</span>
<span class="linenos"> 908</span>        <span class="p">},</span>
<span class="linenos"> 909</span>        <span class="p">{</span>
<span class="linenos"> 910</span>            <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">[</span>
<span class="linenos"> 911</span>                <span class="n">p</span>
<span class="linenos"> 912</span>                <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">()</span>
<span class="linenos"> 913</span>                <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span> <span class="ow">and</span> <span class="nb">any</span><span class="p">(</span><span class="n">nd</span> <span class="ow">in</span> <span class="n">n</span> <span class="k">for</span> <span class="n">nd</span> <span class="ow">in</span> <span class="n">no_decay</span><span class="p">)</span>
<span class="linenos"> 914</span>            <span class="p">],</span>
<span class="linenos"> 915</span>            <span class="s2">&quot;weight_decay&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>
<span class="linenos"> 916</span>        <span class="p">},</span>
<span class="linenos"> 917</span>    <span class="p">]</span>
<span class="linenos"> 918</span>    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span><span class="n">optimizer_grouped_parameters</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">)</span>
<span class="linenos"> 919</span>
<span class="linenos"> 920</span>    <span class="c1"># Scheduler and math around the number of training steps.</span>
<span class="linenos"> 921</span>    <span class="n">overrode_max_train_steps</span> <span class="o">=</span> <span class="kc">False</span>
<span class="linenos"> 922</span>    <span class="n">num_update_steps_per_epoch</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span>
<span class="linenos"> 923</span>        <span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">])</span> <span class="o">/</span> <span class="n">args</span><span class="o">.</span><span class="n">gradient_accumulation_steps</span>
<span class="linenos"> 924</span>    <span class="p">)</span>
<span class="linenos"> 925</span>    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">max_train_steps</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<span class="linenos"> 926</span>        <span class="n">args</span><span class="o">.</span><span class="n">max_train_steps</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">num_train_epochs</span> <span class="o">*</span> <span class="n">num_update_steps_per_epoch</span><span class="p">)</span>
<span class="linenos"> 927</span>        <span class="n">overrode_max_train_steps</span> <span class="o">=</span> <span class="kc">True</span>
<span class="linenos"> 928</span>
<span class="linenos"> 929</span>    <span class="n">lr_scheduler</span> <span class="o">=</span> <span class="n">get_scheduler</span><span class="p">(</span>
<span class="linenos"> 930</span>        <span class="n">name</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">lr_scheduler_type</span><span class="p">,</span>
<span class="linenos"> 931</span>        <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
<span class="linenos"> 932</span>        <span class="n">num_warmup_steps</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">num_warmup_steps</span> <span class="o">*</span> <span class="n">args</span><span class="o">.</span><span class="n">gradient_accumulation_steps</span><span class="p">,</span>
<span class="linenos"> 933</span>        <span class="n">num_training_steps</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">max_train_steps</span> <span class="o">*</span> <span class="n">args</span><span class="o">.</span><span class="n">gradient_accumulation_steps</span><span class="p">,</span>
<span class="linenos"> 934</span>    <span class="p">)</span>
<span class="linenos"> 935</span>
<span class="linenos"> 936</span>    <span class="c1"># Prepare everything with our `accelerator`.</span>
<span class="linenos"> 937</span>    <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;eval&quot;</span><span class="p">],</span> <span class="n">lr_scheduler</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span>
<span class="linenos"> 938</span>        <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;eval&quot;</span><span class="p">],</span> <span class="n">lr_scheduler</span>
<span class="linenos"> 939</span>    <span class="p">)</span>
<span class="linenos"> 940</span>
<span class="linenos"> 941</span>    <span class="c1"># We need to recalculate our total training steps as the size of the training dataloader may have changed.</span>
<span class="linenos"> 942</span>    <span class="n">num_update_steps_per_epoch</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span>
<span class="linenos"> 943</span>        <span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">])</span> <span class="o">/</span> <span class="n">args</span><span class="o">.</span><span class="n">gradient_accumulation_steps</span>
<span class="linenos"> 944</span>    <span class="p">)</span>
<span class="linenos"> 945</span>    <span class="k">if</span> <span class="n">overrode_max_train_steps</span><span class="p">:</span>
<span class="linenos"> 946</span>        <span class="n">args</span><span class="o">.</span><span class="n">max_train_steps</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">num_train_epochs</span> <span class="o">*</span> <span class="n">num_update_steps_per_epoch</span><span class="p">)</span>
<span class="linenos"> 947</span>    <span class="c1"># Afterwards we recalculate our number of training epochs</span>
<span class="linenos"> 948</span>    <span class="n">args</span><span class="o">.</span><span class="n">num_train_epochs</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">max_train_steps</span> <span class="o">/</span> <span class="n">num_update_steps_per_epoch</span><span class="p">)</span>
<span class="linenos"> 949</span>
<span class="linenos"> 950</span>    <span class="c1"># Figure out how many steps we should save the Accelerator states</span>
<span class="linenos"> 951</span>    <span class="n">checkpointing_steps</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">checkpointing_steps</span>
<span class="linenos"> 952</span>    <span class="k">if</span> <span class="n">checkpointing_steps</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">checkpointing_steps</span><span class="o">.</span><span class="n">isdigit</span><span class="p">():</span>
<span class="linenos"> 953</span>        <span class="n">checkpointing_steps</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">checkpointing_steps</span><span class="p">)</span>
<span class="linenos"> 954</span>
<span class="linenos"> 955</span>    <span class="c1"># We need to initialize the trackers we use, and also store our configuration.</span>
<span class="linenos"> 956</span>    <span class="c1"># The trackers initializes automatically on the main process.</span>
<span class="linenos"> 957</span>    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">with_tracking</span><span class="p">:</span>
<span class="linenos"> 958</span>        <span class="n">experiment_config</span> <span class="o">=</span> <span class="nb">vars</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
<span class="linenos"> 959</span>        <span class="c1"># TensorBoard cannot log Enums, need the raw value</span>
<span class="linenos"> 960</span>        <span class="n">experiment_config</span><span class="p">[</span><span class="s2">&quot;lr_scheduler_type&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">experiment_config</span><span class="p">[</span><span class="s2">&quot;lr_scheduler_type&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">value</span>
<span class="linenos"> 961</span>        <span class="n">accelerator</span><span class="o">.</span><span class="n">init_trackers</span><span class="p">(</span><span class="s2">&quot;tensorboard&quot;</span><span class="p">,</span> <span class="n">experiment_config</span><span class="p">)</span>
<span class="linenos"> 962</span>
<span class="linenos"> 963</span>    <span class="c1"># Train!</span>
<span class="linenos"> 964</span>    <span class="n">total_batch_size</span> <span class="o">=</span> <span class="p">(</span>
<span class="linenos"> 965</span>        <span class="n">args</span><span class="o">.</span><span class="n">per_device_train_batch_size</span>
<span class="linenos"> 966</span>        <span class="o">*</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">num_processes</span>
<span class="linenos"> 967</span>        <span class="o">*</span> <span class="n">args</span><span class="o">.</span><span class="n">gradient_accumulation_steps</span>
<span class="linenos"> 968</span>    <span class="p">)</span>
<span class="linenos"> 969</span>
<span class="linenos"> 970</span>    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;***** Running training *****&quot;</span><span class="p">)</span>
<span class="linenos"> 971</span>    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Num examples = </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">])</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="linenos"> 972</span>    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Num Epochs = </span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span class="n">num_train_epochs</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="linenos"> 973</span>    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Instantaneous batch size per device = </span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span class="n">per_device_train_batch_size</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="linenos"> 974</span>    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
<span class="linenos"> 975</span>        <span class="sa">f</span><span class="s2">&quot;  Total train batch size (w. parallel, distributed &amp; accumulation) = </span><span class="si">{</span><span class="n">total_batch_size</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="linenos"> 976</span>    <span class="p">)</span>
<span class="linenos"> 977</span>    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Gradient Accumulation steps = </span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span class="n">gradient_accumulation_steps</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="linenos"> 978</span>    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Total optimization steps = </span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span class="n">max_train_steps</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="linenos"> 979</span>
<span class="linenos"> 980</span>    <span class="c1"># Only show the progress bar once on each machine.</span>
<span class="linenos"> 981</span>    <span class="n">progress_bar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">max_train_steps</span><span class="p">),</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">)</span>
<span class="linenos"> 982</span>    <span class="n">completed_steps</span> <span class="o">=</span> <span class="mi">0</span>
<span class="linenos"> 983</span>    <span class="n">starting_epoch</span> <span class="o">=</span> <span class="mi">0</span>
<span class="linenos"> 984</span>    <span class="n">resume_step</span> <span class="o">=</span> <span class="kc">None</span>
<span class="linenos"> 985</span>
<span class="linenos"> 986</span>    <span class="c1"># Potentially load in the weights and states from a previous save</span>
<span class="linenos"> 987</span>    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">resume_from_last_ckpt</span><span class="p">:</span>
<span class="linenos"> 988</span>        <span class="c1"># Get the most recent checkpoint</span>
<span class="linenos"> 989</span>        <span class="n">dirs</span> <span class="o">=</span> <span class="p">[</span>
<span class="linenos"> 990</span>            <span class="n">f</span><span class="o">.</span><span class="n">path</span>
<span class="linenos"> 991</span>            <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">scandir</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">output_dir</span><span class="p">)</span>
<span class="linenos"> 992</span>            <span class="k">if</span> <span class="n">f</span><span class="o">.</span><span class="n">is_dir</span><span class="p">()</span> <span class="ow">and</span> <span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;epoch_&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="n">f</span><span class="o">.</span><span class="n">name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;step_&quot;</span><span class="p">))</span>
<span class="linenos"> 993</span>        <span class="p">]</span>
<span class="linenos"> 994</span>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">dirs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
<span class="linenos"> 995</span>            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;No checkpoint found in output_dir. Training from scratch!&quot;</span><span class="p">)</span>
<span class="linenos"> 996</span>        <span class="k">else</span><span class="p">:</span>
<span class="linenos"> 997</span>            <span class="n">latest_dir</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">dirs</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">getctime</span><span class="p">)</span>
<span class="linenos"> 998</span>            <span class="n">accelerator</span><span class="o">.</span><span class="n">load_state</span><span class="p">(</span><span class="n">latest_dir</span><span class="p">)</span>
<span class="linenos"> 999</span>
<span class="linenos">1000</span>            <span class="c1"># Extract `epoch_{i}` or `step_{i}`</span>
<span class="linenos">1001</span>            <span class="n">latest_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">latest_dir</span><span class="p">)</span>
<span class="linenos">1002</span>            <span class="k">if</span> <span class="s2">&quot;epoch&quot;</span> <span class="ow">in</span> <span class="n">latest_dir</span><span class="p">:</span>
<span class="linenos">1003</span>                <span class="n">starting_epoch</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">latest_dir</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;epoch_&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span>
<span class="linenos">1004</span>                <span class="n">completed_steps</span> <span class="o">=</span> <span class="n">starting_epoch</span> <span class="o">*</span> <span class="n">num_update_steps_per_epoch</span>
<span class="linenos">1005</span>            <span class="k">else</span><span class="p">:</span>
<span class="linenos">1006</span>                <span class="c1"># need to multiply `gradient_accumulation_steps` to reflect real steps</span>
<span class="linenos">1007</span>                <span class="n">resume_step</span> <span class="o">=</span> <span class="p">(</span>
<span class="linenos">1008</span>                    <span class="nb">int</span><span class="p">(</span><span class="n">latest_dir</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;step_&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">))</span> <span class="o">*</span> <span class="n">args</span><span class="o">.</span><span class="n">gradient_accumulation_steps</span>
<span class="linenos">1009</span>                <span class="p">)</span>
<span class="linenos">1010</span>                <span class="n">starting_epoch</span> <span class="o">=</span> <span class="n">resume_step</span> <span class="o">//</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">])</span>
<span class="linenos">1011</span>                <span class="n">completed_steps</span> <span class="o">=</span> <span class="n">resume_step</span> <span class="o">//</span> <span class="n">args</span><span class="o">.</span><span class="n">gradient_accumulation_steps</span>
<span class="linenos">1012</span>                <span class="n">resume_step</span> <span class="o">-=</span> <span class="n">starting_epoch</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">])</span>
<span class="linenos">1013</span>
<span class="linenos">1014</span>    <span class="c1"># update the progress_bar if load from checkpoint</span>
<span class="linenos">1015</span>    <span class="n">progress_bar</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">completed_steps</span><span class="p">)</span>
<span class="linenos">1016</span>
<span class="linenos">1017</span>    <span class="c1"># Evaluate before training (e.g. PTQ accuracy before QAT)</span>
<span class="linenos">1018</span>    <span class="n">eval_metric</span> <span class="o">=</span> <span class="n">evaluate_model</span><span class="p">(</span>
<span class="linenos">1019</span>        <span class="n">args</span><span class="p">,</span>
<span class="linenos">1020</span>        <span class="n">model</span><span class="p">,</span>
<span class="linenos">1021</span>        <span class="n">accelerator</span><span class="p">,</span>
<span class="linenos">1022</span>        <span class="n">examples</span><span class="p">[</span><span class="s2">&quot;eval&quot;</span><span class="p">],</span>
<span class="linenos">1023</span>        <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;eval&quot;</span><span class="p">],</span>
<span class="linenos">1024</span>        <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;eval&quot;</span><span class="p">],</span>
<span class="linenos">1025</span>        <span class="n">answer_column_name</span><span class="p">,</span>
<span class="linenos">1026</span>    <span class="p">)</span>
<span class="linenos">1027</span>    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">starting_epoch</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">num_train_epochs</span><span class="p">):</span>
<span class="linenos">1028</span>        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="linenos">1029</span>        <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">with_tracking</span><span class="p">:</span>
<span class="linenos">1030</span>            <span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span>
<span class="linenos">1031</span>        <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">resume_from_last_ckpt</span> <span class="ow">and</span> <span class="n">epoch</span> <span class="o">==</span> <span class="n">starting_epoch</span> <span class="ow">and</span> <span class="n">resume_step</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span class="linenos">1032</span>            <span class="c1"># We skip the first `n` batches in the dataloader when resuming from a checkpoint</span>
<span class="linenos">1033</span>            <span class="n">active_dataloader</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">skip_first_batches</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">resume_step</span><span class="p">)</span>
<span class="linenos">1034</span>        <span class="k">else</span><span class="p">:</span>
<span class="linenos">1035</span>            <span class="n">active_dataloader</span> <span class="o">=</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span>
<span class="linenos">1036</span>        <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">active_dataloader</span><span class="p">:</span>
<span class="linenos">1037</span>            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="linenos">1038</span>            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">batch</span><span class="p">)</span>
<span class="linenos">1039</span>
<span class="hll"><span class="linenos">1040</span>            <span class="c1"># Model Optimizer: If using distillation, we unwrap the model and extract the custom loss function</span>
</span><span class="hll"><span class="linenos">1041</span>            <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">do_modelopt_distill</span><span class="p">:</span>
</span><span class="hll"><span class="linenos">1042</span>                <span class="n">loss</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">compute_kd_loss</span><span class="p">()</span>
</span><span class="hll"><span class="linenos">1043</span>            <span class="k">else</span><span class="p">:</span>
</span><span class="hll"><span class="linenos">1044</span>                <span class="n">loss</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">to_tuple</span><span class="p">()</span>
</span><span class="linenos">1045</span>
<span class="linenos">1046</span>            <span class="c1"># We keep track of the loss at each epoch</span>
<span class="linenos">1047</span>            <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">with_tracking</span><span class="p">:</span>
<span class="linenos">1048</span>                <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<span class="linenos">1049</span>
<span class="linenos">1050</span>            <span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
<span class="linenos">1051</span>            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<span class="linenos">1052</span>            <span class="n">lr_scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<span class="linenos">1053</span>
<span class="linenos">1054</span>            <span class="c1"># Checks if the accelerator has performed an optimization step behind the scenes</span>
<span class="linenos">1055</span>            <span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">sync_gradients</span><span class="p">:</span>
<span class="linenos">1056</span>                <span class="n">progress_bar</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="linenos">1057</span>                <span class="n">completed_steps</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="linenos">1058</span>
<span class="linenos">1059</span>            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">checkpointing_steps</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="n">completed_steps</span> <span class="o">%</span> <span class="n">checkpointing_steps</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
<span class="linenos">1060</span>                <span class="n">accelerator</span><span class="o">.</span><span class="n">save_state</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">output_dir</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;step_</span><span class="si">{</span><span class="n">completed_steps</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">))</span>
<span class="linenos">1061</span>
<span class="linenos">1062</span>            <span class="k">if</span> <span class="n">completed_steps</span> <span class="o">&gt;=</span> <span class="n">args</span><span class="o">.</span><span class="n">max_train_steps</span><span class="p">:</span>
<span class="linenos">1063</span>                <span class="k">break</span>
<span class="linenos">1064</span>
<span class="linenos">1065</span>        <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">checkpointing_steps</span> <span class="o">==</span> <span class="s2">&quot;epoch&quot;</span><span class="p">:</span>
<span class="linenos">1066</span>            <span class="n">accelerator</span><span class="o">.</span><span class="n">save_state</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">output_dir</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;epoch_</span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">))</span>
<span class="linenos">1067</span>
<span class="linenos">1068</span>        <span class="n">eval_metric</span> <span class="o">=</span> <span class="n">evaluate_model</span><span class="p">(</span>
<span class="linenos">1069</span>            <span class="n">args</span><span class="p">,</span>
<span class="linenos">1070</span>            <span class="n">model</span><span class="p">,</span>
<span class="linenos">1071</span>            <span class="n">accelerator</span><span class="p">,</span>
<span class="linenos">1072</span>            <span class="n">examples</span><span class="p">[</span><span class="s2">&quot;eval&quot;</span><span class="p">],</span>
<span class="linenos">1073</span>            <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;eval&quot;</span><span class="p">],</span>
<span class="linenos">1074</span>            <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;eval&quot;</span><span class="p">],</span>
<span class="linenos">1075</span>            <span class="n">answer_column_name</span><span class="p">,</span>
<span class="linenos">1076</span>        <span class="p">)</span>
<span class="linenos">1077</span>
<span class="linenos">1078</span>        <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">with_tracking</span><span class="p">:</span>
<span class="linenos">1079</span>            <span class="n">log</span> <span class="o">=</span> <span class="p">{</span>
<span class="linenos">1080</span>                <span class="s2">&quot;squad&quot;</span><span class="p">:</span> <span class="n">eval_metric</span><span class="p">,</span>
<span class="linenos">1081</span>                <span class="s2">&quot;train_loss&quot;</span><span class="p">:</span> <span class="n">total_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]),</span>  <span class="c1"># type: ignore[attr-defined]</span>
<span class="linenos">1082</span>                <span class="s2">&quot;epoch&quot;</span><span class="p">:</span> <span class="n">epoch</span><span class="p">,</span>
<span class="linenos">1083</span>                <span class="s2">&quot;step&quot;</span><span class="p">:</span> <span class="n">completed_steps</span><span class="p">,</span>
<span class="linenos">1084</span>            <span class="p">}</span>
<span class="linenos">1085</span>            <span class="n">accelerator</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">log</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">completed_steps</span><span class="p">)</span>
<span class="linenos">1086</span>
<span class="linenos">1087</span>    <span class="n">accelerator</span><span class="o">.</span><span class="n">wait_for_everyone</span><span class="p">()</span>
<span class="linenos">1088</span>    <span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_main_process</span> <span class="ow">and</span> <span class="n">eval_metric</span><span class="p">:</span>
<span class="linenos">1089</span>        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">eval_metric</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">4</span><span class="p">))</span>
<span class="linenos">1090</span>        <span class="c1"># Prefix all keys with prefix + &#39;_&#39;</span>
<span class="linenos">1091</span>        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">eval_metric</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
<span class="linenos">1092</span>            <span class="n">eval_metric</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;Eval_</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">eval_metric</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
<span class="linenos">1093</span>
<span class="linenos">1094</span>        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">output_dir</span><span class="p">,</span> <span class="s2">&quot;results.json&quot;</span><span class="p">),</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
<span class="linenos">1095</span>            <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">eval_metric</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="linenos">1096</span>
<span class="linenos">1097</span>
<span class="linenos">1098</span><span class="k">def</span> <span class="nf">main</span><span class="p">(</span><span class="n">input_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="linenos">1099</span>    <span class="n">args</span> <span class="o">=</span> <span class="n">parse_args</span><span class="p">(</span><span class="n">input_args</span><span class="p">)</span>
<span class="linenos">1100</span>
<span class="linenos">1101</span>    <span class="c1"># Initialize the accelerator</span>
<span class="linenos">1102</span>    <span class="n">accelerator_log_kwargs</span> <span class="o">=</span> <span class="p">{}</span>
<span class="linenos">1103</span>    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">with_tracking</span><span class="p">:</span>
<span class="linenos">1104</span>        <span class="n">accelerator_log_kwargs</span><span class="p">[</span><span class="s2">&quot;log_with&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;tensorboard&quot;</span>
<span class="linenos">1105</span>        <span class="n">accelerator_log_kwargs</span><span class="p">[</span><span class="s2">&quot;project_dir&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">output_dir</span>
<span class="linenos">1106</span>    <span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">(</span>
<span class="linenos">1107</span>        <span class="n">gradient_accumulation_steps</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">gradient_accumulation_steps</span><span class="p">,</span> <span class="o">**</span><span class="n">accelerator_log_kwargs</span>
<span class="linenos">1108</span>    <span class="p">)</span>
<span class="linenos">1109</span>
<span class="linenos">1110</span>    <span class="c1"># Setup logging</span>
<span class="linenos">1111</span>    <span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span>
<span class="linenos">1112</span>        <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;</span><span class="si">%(asctime)s</span><span class="s2"> [</span><span class="si">%(levelname)s</span><span class="s2">] </span><span class="si">%(name)s</span><span class="s2"> - </span><span class="si">%(message)s</span><span class="s2">&quot;</span><span class="p">,</span>
<span class="linenos">1113</span>        <span class="n">datefmt</span><span class="o">=</span><span class="s2">&quot;%m/</span><span class="si">%d</span><span class="s2">/%Y %H:%M:%S&quot;</span><span class="p">,</span>
<span class="linenos">1114</span>        <span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">INFO</span><span class="p">,</span>
<span class="linenos">1115</span>    <span class="p">)</span>
<span class="linenos">1116</span>    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">accelerator</span><span class="o">.</span><span class="n">state</span><span class="p">,</span> <span class="n">main_process_only</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="linenos">1117</span>    <span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">:</span>
<span class="linenos">1118</span>        <span class="n">datasets</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">set_verbosity_warning</span><span class="p">()</span>
<span class="linenos">1119</span>        <span class="n">transformers</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">set_verbosity_info</span><span class="p">()</span>
<span class="linenos">1120</span>    <span class="k">else</span><span class="p">:</span>
<span class="linenos">1121</span>        <span class="n">datasets</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">set_verbosity_error</span><span class="p">()</span>
<span class="linenos">1122</span>        <span class="n">transformers</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">set_verbosity_error</span><span class="p">()</span>
<span class="linenos">1123</span>
<span class="linenos">1124</span>    <span class="c1"># Set the training seed</span>
<span class="linenos">1125</span>    <span class="n">set_seed</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>
<span class="linenos">1126</span>
<span class="linenos">1127</span>    <span class="c1"># Handle the output_dir creation</span>
<span class="linenos">1128</span>    <span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_main_process</span><span class="p">:</span>
<span class="linenos">1129</span>        <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">output_dir</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="linenos">1130</span>    <span class="n">accelerator</span><span class="o">.</span><span class="n">wait_for_everyone</span><span class="p">()</span>
<span class="linenos">1131</span>
<span class="linenos">1132</span>    <span class="c1"># Load pretrained model and tokenizer</span>
<span class="linenos">1133</span>    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">model_name_or_path</span><span class="p">,</span> <span class="n">use_fast</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="linenos">1134</span>    <span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForQuestionAnswering</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">model_name_or_path</span><span class="p">)</span>
<span class="linenos">1135</span>    <span class="n">dummy_input</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">dummy_inputs</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span>
<span class="linenos">1136</span>
<span class="linenos">1137</span>    <span class="c1"># Get datasets</span>
<span class="linenos">1138</span>    <span class="n">examples</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">,</span> <span class="n">answer_column_name</span> <span class="o">=</span> <span class="n">get_datasets_and_dataloaders</span><span class="p">(</span>
<span class="linenos">1139</span>        <span class="n">args</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">accelerator</span>
<span class="linenos">1140</span>    <span class="p">)</span>
<span class="linenos">1141</span>
<span class="hll"><span class="linenos">1142</span>    <span class="c1"># Model Optimizer: Save the pruned or quantized model</span>
</span><span class="hll"><span class="linenos">1143</span>    <span class="k">def</span> <span class="nf">save_modelopt_model</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
</span><span class="hll"><span class="linenos">1144</span>        <span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_main_process</span> <span class="ow">and</span> <span class="n">args</span><span class="o">.</span><span class="n">modelopt_save_file</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span class="hll"><span class="linenos">1145</span>            <span class="n">save_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">output_dir</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">modelopt_save_file</span><span class="p">)</span>
</span><span class="hll"><span class="linenos">1146</span>            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Saving modelopt optimized model to </span><span class="si">{</span><span class="n">save_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span class="hll"><span class="linenos">1147</span>            <span class="n">mto</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">save_path</span><span class="p">)</span>
</span><span class="hll"><span class="linenos">1148</span>
</span><span class="hll"><span class="linenos">1149</span>    <span class="c1"># Model Optimizer: Restore the pruned or quantized model from a checkpoint</span>
</span><span class="hll"><span class="linenos">1150</span>    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">modelopt_restore_path</span><span class="p">:</span>
</span><span class="hll"><span class="linenos">1151</span>        <span class="k">assert</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span>
</span><span class="hll"><span class="linenos">1152</span>            <span class="n">args</span><span class="o">.</span><span class="n">modelopt_restore_path</span>
</span><span class="hll"><span class="linenos">1153</span>        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span class="n">modelopt_restore_path</span><span class="si">}</span><span class="s2"> does not exist.&quot;</span>
</span><span class="hll"><span class="linenos">1154</span>        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Restoring model from </span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span class="n">modelopt_restore_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span class="hll"><span class="linenos">1155</span>        <span class="n">model</span> <span class="o">=</span> <span class="n">mto</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">modelopt_restore_path</span><span class="p">)</span>
</span><span class="linenos">1156</span>
<span class="hll"><span class="linenos">1157</span>    <span class="c1"># Model Optimizer: Prune the model to given FLOPS target using GradNAS algorithm</span>
</span><span class="hll"><span class="linenos">1158</span>    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">do_modelopt_prune</span><span class="p">:</span>
</span><span class="hll"><span class="linenos">1159</span>        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Pruning model to </span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span class="n">modelopt_prune_flops_percent</span><span class="si">}</span><span class="s2">% FLOPS&quot;</span><span class="p">)</span>
</span><span class="hll"><span class="linenos">1160</span>
</span><span class="hll"><span class="linenos">1161</span>        <span class="c1"># NOTE: gradnas does not perform synchronization across data parallel groups</span>
</span><span class="hll"><span class="linenos">1162</span>        <span class="c1"># Use unwrapped model &amp; non-distributed dataloader for gradnas so that all the processes</span>
</span><span class="hll"><span class="linenos">1163</span>        <span class="c1"># in the data parallel group have the same gradients for pruning</span>
</span><span class="hll"><span class="linenos">1164</span>        <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">accelerator</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span class="hll"><span class="linenos">1165</span>        <span class="n">dummy_input</span> <span class="o">=</span> <span class="n">dummy_input</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">accelerator</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span class="hll"><span class="linenos">1166</span>
</span><span class="hll"><span class="linenos">1167</span>        <span class="c1"># Search for the best pruned model</span>
</span><span class="hll"><span class="linenos">1168</span>        <span class="c1"># To use other NAS algorithms, you can use `mtn.convert` + `mtn.search` here.</span>
</span><span class="hll"><span class="linenos">1169</span>        <span class="n">model</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">mtp</span><span class="o">.</span><span class="n">prune</span><span class="p">(</span>
</span><span class="hll"><span class="linenos">1170</span>            <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
</span><span class="hll"><span class="linenos">1171</span>            <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;gradnas&quot;</span><span class="p">,</span>
</span><span class="hll"><span class="linenos">1172</span>            <span class="n">constraints</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;flops&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span class="n">modelopt_prune_flops_percent</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">},</span>
</span><span class="hll"><span class="linenos">1173</span>            <span class="n">dummy_input</span><span class="o">=</span><span class="n">dummy_input</span><span class="p">,</span>
</span><span class="hll"><span class="linenos">1174</span>            <span class="n">config</span><span class="o">=</span><span class="p">{</span>
</span><span class="hll"><span class="linenos">1175</span>                <span class="s2">&quot;data_loader&quot;</span><span class="p">:</span> <span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span>
</span><span class="hll"><span class="linenos">1176</span>                <span class="s2">&quot;collect_func&quot;</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">batch</span><span class="p">:</span> <span class="p">(</span><span class="n">batch</span><span class="p">,),</span>
</span><span class="hll"><span class="linenos">1177</span>                <span class="s2">&quot;loss_func&quot;</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">output</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="p">(</span>
</span><span class="hll"><span class="linenos">1178</span>                    <span class="n">output</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">]</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="k">else</span> <span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span class="hll"><span class="linenos">1179</span>                <span class="p">),</span>
</span><span class="hll"><span class="linenos">1180</span>            <span class="p">},</span>
</span><span class="hll"><span class="linenos">1181</span>        <span class="p">)</span>
</span><span class="hll"><span class="linenos">1182</span>        <span class="n">save_modelopt_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</span><span class="linenos">1183</span>
<span class="hll"><span class="linenos">1184</span>    <span class="c1"># Model Optimizer: Quantize the model to INT8 precision</span>
</span><span class="hll"><span class="linenos">1185</span>    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">modelopt_quantize_cfg</span><span class="p">:</span>
</span><span class="hll"><span class="linenos">1186</span>        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Quantizing model with </span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span class="n">modelopt_quantize_cfg</span><span class="si">}</span><span class="s2"> config&quot;</span><span class="p">)</span>
</span><span class="hll"><span class="linenos">1187</span>
</span><span class="hll"><span class="linenos">1188</span>        <span class="c1"># NOTE: `mtq.quantize` does not perform synchronization across data parallel groups</span>
</span><span class="hll"><span class="linenos">1189</span>        <span class="c1"># Use unwrapped model &amp; non-distributed dataloader for PTQ calibration so that all the processes</span>
</span><span class="hll"><span class="linenos">1190</span>        <span class="c1"># in the data parallel group have same calibration statistics</span>
</span><span class="hll"><span class="linenos">1191</span>        <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">accelerator</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span class="hll"><span class="linenos">1192</span>
</span><span class="hll"><span class="linenos">1193</span>        <span class="k">def</span> <span class="nf">forward_loop</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
</span><span class="hll"><span class="linenos">1194</span>            <span class="n">num_samples</span> <span class="o">=</span> <span class="mi">256</span>  <span class="c1"># Use only 256 samples for PTQ calibration</span>
</span><span class="hll"><span class="linenos">1195</span>            <span class="n">num_batches</span> <span class="o">=</span> <span class="n">num_samples</span> <span class="o">//</span> <span class="n">args</span><span class="o">.</span><span class="n">per_device_train_batch_size</span>
</span><span class="hll"><span class="linenos">1196</span>            <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]),</span> <span class="n">total</span><span class="o">=</span><span class="n">num_batches</span><span class="p">):</span>
</span><span class="hll"><span class="linenos">1197</span>                <span class="n">batch</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">accelerator</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">batch</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
</span><span class="hll"><span class="linenos">1198</span>                <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">batch</span><span class="p">)</span>
</span><span class="hll"><span class="linenos">1199</span>                <span class="k">if</span> <span class="n">idx</span> <span class="o">&gt;=</span> <span class="n">num_batches</span><span class="p">:</span>
</span><span class="hll"><span class="linenos">1200</span>                    <span class="k">break</span>
</span><span class="hll"><span class="linenos">1201</span>
</span><span class="hll"><span class="linenos">1202</span>        <span class="n">model</span> <span class="o">=</span> <span class="n">mtq</span><span class="o">.</span><span class="n">quantize</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">mtq</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">modelopt_quantize_cfg</span><span class="p">),</span> <span class="n">forward_loop</span><span class="p">)</span>
</span><span class="hll"><span class="linenos">1203</span>        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
</span><span class="hll"><span class="linenos">1204</span>        <span class="n">save_modelopt_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</span><span class="linenos">1205</span>
<span class="linenos">1206</span>    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">do_train</span><span class="p">:</span>
<span class="hll"><span class="linenos">1207</span>        <span class="c1"># Model Optimizer: Convert to a DistillationModel containing teacher to train with distillation</span>
</span><span class="hll"><span class="linenos">1208</span>        <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">do_modelopt_distill</span><span class="p">:</span>
</span><span class="hll"><span class="linenos">1209</span>            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using distillation with teacher </span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span class="n">model_name_or_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span class="hll"><span class="linenos">1210</span>
</span><span class="hll"><span class="linenos">1211</span>            <span class="n">kd_config</span> <span class="o">=</span> <span class="p">{</span>
</span><span class="hll"><span class="linenos">1212</span>                <span class="s2">&quot;teacher_model&quot;</span><span class="p">:</span> <span class="p">(</span><span class="n">teacher_factory</span><span class="p">,</span> <span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">model_name_or_path</span><span class="p">,),</span> <span class="p">{}),</span>
</span><span class="hll"><span class="linenos">1213</span>                <span class="s2">&quot;criterion&quot;</span><span class="p">:</span> <span class="n">StartEndLogitsDistillationLoss</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">temperature</span><span class="p">),</span>
</span><span class="hll"><span class="linenos">1214</span>            <span class="p">}</span>
</span><span class="hll"><span class="linenos">1215</span>            <span class="n">model</span> <span class="o">=</span> <span class="n">mtd</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;kd_loss&quot;</span><span class="p">,</span> <span class="n">kd_config</span><span class="p">)])</span>
</span><span class="linenos">1216</span>
<span class="linenos">1217</span>        <span class="n">train_and_evaluate_model</span><span class="p">(</span>
<span class="linenos">1218</span>            <span class="n">args</span><span class="p">,</span>
<span class="linenos">1219</span>            <span class="n">model</span><span class="p">,</span>
<span class="linenos">1220</span>            <span class="n">tokenizer</span><span class="p">,</span>
<span class="linenos">1221</span>            <span class="n">accelerator</span><span class="p">,</span>
<span class="linenos">1222</span>            <span class="n">examples</span><span class="p">,</span>
<span class="linenos">1223</span>            <span class="n">dataset</span><span class="p">,</span>
<span class="linenos">1224</span>            <span class="n">dataloader</span><span class="p">,</span>
<span class="linenos">1225</span>            <span class="n">answer_column_name</span><span class="p">,</span>
<span class="linenos">1226</span>        <span class="p">)</span>
<span class="linenos">1227</span>
<span class="hll"><span class="linenos">1228</span>        <span class="c1"># Model Optimizer: Export the distilled model</span>
</span><span class="hll"><span class="linenos">1229</span>        <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">do_modelopt_distill</span><span class="p">:</span>
</span><span class="hll"><span class="linenos">1230</span>            <span class="n">model</span> <span class="o">=</span> <span class="n">mtd</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</span><span class="hll"><span class="linenos">1231</span>
</span><span class="hll"><span class="linenos">1232</span>        <span class="n">save_modelopt_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</span><span class="linenos">1233</span>
<span class="linenos">1234</span>    <span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_main_process</span> <span class="ow">and</span> <span class="n">args</span><span class="o">.</span><span class="n">onnx_export_file</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span class="linenos">1235</span>        <span class="n">save_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">output_dir</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">onnx_export_file</span><span class="p">)</span>
<span class="linenos">1236</span>        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Exporting ONNX model to </span><span class="si">{</span><span class="n">save_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="linenos">1237</span>
<span class="linenos">1238</span>        <span class="c1"># Move the model and dummy_input to the device</span>
<span class="linenos">1239</span>        <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">accelerator</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<span class="linenos">1240</span>        <span class="n">dummy_input</span> <span class="o">=</span> <span class="n">dummy_input</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">accelerator</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<span class="linenos">1241</span>
<span class="linenos">1242</span>        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">save_path</span><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
<span class="linenos">1243</span>            <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">get_onnx_bytes</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dummy_input</span><span class="p">,</span> <span class="n">onnx_opset</span><span class="o">=</span><span class="mi">14</span><span class="p">))</span>
<span class="linenos">1244</span>
<span class="linenos">1245</span>    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Done!&quot;</span><span class="p">)</span>
<span class="linenos">1246</span>
<span class="linenos">1247</span>
<span class="linenos">1248</span><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
<span class="linenos">1249</span>    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="commands">
<h2>Commands<a class="headerlink" href="#commands" title="Link to this heading"></a></h2>
<ol class="arabic">
<li><p>First we prune the Bert large model to 50% FLOPs with GradNAS algorithm. Then, we fine-tune the pruned
model with distillation from unpruned teacher model to recover 99+% of the initial F1 score (93.15).
We recommend using multiple GPUs for fine-tuning. Note that we use more epochs
for fine-tuning, which is different from the 2 epochs used originally in fine-tuning Bert without distillation since
distillation requires more epochs to converge but achieves much better results.</p>
<blockquote>
<div><div class="literal-block-wrapper docutils container" id="id2">
<div class="code-block-caption"><span class="caption-text">1_prune.sh</span><a class="headerlink" href="#id2" title="Link to this code"></a></div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="nb">set</span><span class="w"> </span>-e
<span class="nb">set</span><span class="w"> </span>-x

<span class="nv">FLOPS_PERCENT</span><span class="o">=</span><span class="m">50</span>
<span class="nv">BASE_DIR</span><span class="o">=</span>results/bert_large_pruned_<span class="si">${</span><span class="nv">FLOPS_PERCENT</span><span class="si">}</span>_percent

<span class="k">if</span><span class="w"> </span><span class="o">[</span><span class="w"> </span>!<span class="w"> </span>-f<span class="w"> </span><span class="s2">&quot;</span><span class="si">${</span><span class="nv">BASE_DIR</span><span class="si">}</span><span class="s2">/pruned_model.pth&quot;</span><span class="w"> </span><span class="o">]</span><span class="p">;</span><span class="w"> </span><span class="k">then</span>
<span class="w">    </span><span class="nv">modelopt_args</span><span class="o">=</span><span class="s2">&quot;--do_modelopt_prune --modelopt_prune_flops_percent </span><span class="si">${</span><span class="nv">FLOPS_PERCENT</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="k">else</span>
<span class="w">    </span><span class="nv">modelopt_args</span><span class="o">=</span><span class="s2">&quot;--modelopt_restore_path </span><span class="si">${</span><span class="nv">BASE_DIR</span><span class="si">}</span><span class="s2">/pruned_model.pth&quot;</span>
<span class="k">fi</span>
<span class="nv">modelopt_args</span><span class="o">=</span><span class="s2">&quot;</span><span class="si">${</span><span class="nv">modelopt_args</span><span class="si">}</span><span class="s2"> --modelopt_save_file pruned_model.pth&quot;</span>

<span class="c1"># Run pruning followed by distributed fine-tuning on the pruned model</span>
accelerate<span class="w"> </span>launch<span class="w"> </span>--multi_gpu<span class="w"> </span>--mixed_precision<span class="w"> </span>bf16<span class="w"> </span>bert_prune_distill_quantize.py<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model_name_or_path<span class="w"> </span>bert-large-uncased-whole-word-masking-finetuned-squad<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--output_dir<span class="w"> </span><span class="si">${</span><span class="nv">BASE_DIR</span><span class="si">}</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span><span class="si">${</span><span class="nv">modelopt_args</span><span class="si">}</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--do_train<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--do_modelopt_distill<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--lr_scheduler_type<span class="w"> </span>cosine<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--learning_rate<span class="w"> </span>1e-4<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--per_device_train_batch_size<span class="w"> </span><span class="m">16</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--num_train_epochs<span class="w"> </span><span class="m">15</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--with_tracking<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--checkpointing_steps<span class="w"> </span>epoch<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--resume_from_last_ckpt
</pre></div>
</div>
</div>
</div></blockquote>
</li>
<li><p>Quantize the fine-tuned model to INT8 precision and run calibration (PTQ).
Note that PTQ will result in a slight drop in F1 score but we will be able to recover the F1 score with QAT.
We run QAT with distillation as well from unpruned teacher model.</p>
<blockquote>
<div><div class="literal-block-wrapper docutils container" id="id3">
<div class="code-block-caption"><span class="caption-text">2_int8_quantize.sh</span><a class="headerlink" href="#id3" title="Link to this code"></a></div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="nb">set</span><span class="w"> </span>-e
<span class="nb">set</span><span class="w"> </span>-x

<span class="nv">FLOPS_PERCENT</span><span class="o">=</span><span class="m">50</span>
<span class="nv">BASE_DIR</span><span class="o">=</span>results/bert_large_pruned_<span class="si">${</span><span class="nv">FLOPS_PERCENT</span><span class="si">}</span>_percent
<span class="nv">OUTPUT_DIR</span><span class="o">=</span><span class="si">${</span><span class="nv">BASE_DIR</span><span class="si">}</span>/int8_quantized

<span class="k">if</span><span class="w"> </span><span class="o">[</span><span class="w"> </span>!<span class="w"> </span>-f<span class="w"> </span><span class="s2">&quot;</span><span class="si">${</span><span class="nv">OUTPUT_DIR</span><span class="si">}</span><span class="s2">/quantized_model.pth&quot;</span><span class="w"> </span><span class="o">]</span><span class="p">;</span><span class="w"> </span><span class="k">then</span>
<span class="w">    </span><span class="nv">modelopt_args</span><span class="o">=</span><span class="s2">&quot;--modelopt_quantize_cfg INT8_DEFAULT_CFG --modelopt_restore_path </span><span class="si">${</span><span class="nv">BASE_DIR</span><span class="si">}</span><span class="s2">/pruned_model.pth&quot;</span>
<span class="k">else</span>
<span class="w">    </span><span class="nv">modelopt_args</span><span class="o">=</span><span class="s2">&quot;--modelopt_restore_path </span><span class="si">${</span><span class="nv">OUTPUT_DIR</span><span class="si">}</span><span class="s2">/quantized_model.pth&quot;</span>
<span class="k">fi</span>

<span class="nv">modelopt_args</span><span class="o">=</span><span class="s2">&quot;</span><span class="si">${</span><span class="nv">modelopt_args</span><span class="si">}</span><span class="s2"> --modelopt_save_file quantized_model.pth&quot;</span>

<span class="c1"># Run distributed QAT on the pruned model with 0.1x LR and less epochs</span>
accelerate<span class="w"> </span>launch<span class="w"> </span>--multi_gpu<span class="w"> </span>--mixed_precision<span class="w"> </span>bf16<span class="w"> </span>bert_prune_distill_quantize.py<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model_name_or_path<span class="w"> </span>bert-large-uncased-whole-word-masking-finetuned-squad<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--output_dir<span class="w"> </span><span class="si">${</span><span class="nv">OUTPUT_DIR</span><span class="si">}</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span><span class="si">${</span><span class="nv">modelopt_args</span><span class="si">}</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--do_train<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--do_modelopt_distill<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--lr_scheduler_type<span class="w"> </span>cosine<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--learning_rate<span class="w"> </span>5e-6<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--per_device_train_batch_size<span class="w"> </span><span class="m">16</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--num_train_epochs<span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--with_tracking<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--checkpointing_steps<span class="w"> </span>epoch<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--resume_from_last_ckpt
</pre></div>
</div>
</div>
</div></blockquote>
</li>
<li><p>Export the quantized model to ONNX format for deployment with TensorRT.</p>
<blockquote>
<div><div class="literal-block-wrapper docutils container" id="id4">
<div class="code-block-caption"><span class="caption-text">3_onnx_export.sh</span><a class="headerlink" href="#id4" title="Link to this code"></a></div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="nb">set</span><span class="w"> </span>-e
<span class="nb">set</span><span class="w"> </span>-x

<span class="nv">FLOPS_PERCENT</span><span class="o">=</span><span class="m">50</span>
<span class="nv">BASE_DIR</span><span class="o">=</span>results/bert_large_pruned_<span class="si">${</span><span class="nv">FLOPS_PERCENT</span><span class="si">}</span>_percent

<span class="c1"># Export to ONNX on a single GPU</span>
python3<span class="w"> </span>bert_prune_distill_quantize.py<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model_name_or_path<span class="w"> </span>bert-large-uncased-whole-word-masking-finetuned-squad<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--output_dir<span class="w"> </span><span class="si">${</span><span class="nv">BASE_DIR</span><span class="si">}</span>/onnx<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--modelopt_restore_path<span class="w"> </span><span class="si">${</span><span class="nv">BASE_DIR</span><span class="si">}</span>/int8_quantized/quantized_model.pth<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--onnx_export_file<span class="w"> </span>pruned_model_int8.onnx<span class="w"> </span><span class="se">\</span>
</pre></div>
</div>
</div>
</div></blockquote>
</li>
</ol>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="1_cifar_resnet.html" class="btn btn-neutral float-left" title="ResNet20 on CIFAR-10: Pruning" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../reference/0_changelog.html" class="btn btn-neutral float-right" title="Model Optimizer Changelog" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023-2024, NVIDIA Corporation.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>