<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>ResNet20 on CIFAR-10: Pruning &mdash; Model Optimizer 0.17.0</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../_static/tabs.css?v=4c969af8" />
      <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
      <link rel="stylesheet" type="text/css" href="../_static/autodoc_pydantic.css" />
      <link rel="stylesheet" type="text/css" href="../_static/nbsphinx-code-cells.css?v=2aa19091" />
      <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=d10054b6" />

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js?v=5d32c60e"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../_static/documentation_options.js?v=5929fcd5"></script>
        <script src="../_static/doctools.js?v=888ff710"></script>
        <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
        <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
        <script src="../_static/copybutton.js?v=20d3d275"></script>
        <script src="../_static/tabs.js?v=3ee01567"></script>
        <script>let toggleHintShow = 'Click to show';</script>
        <script>let toggleHintHide = 'Click to hide';</script>
        <script>let toggleOpenOnPrint = 'true';</script>
        <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
        <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>
        <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="HF BERT: Prune, Distill &amp; Quantize" href="2_bert_prune_distill_quantize.html" />
    <link rel="prev" title="All GitHub Examples" href="0_all_examples.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            TensorRT Model Optimizer
          </a>
              <div class="version">
                0.17.0
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/1_overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/2_installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/3_quantization.html">Quick Start: Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/4_pruning.html">Quick Start: Pruning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/5_distillation.html">Quick Start: Distillation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/6_sparsity.html">Quick Start: Sparsity</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Guides</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../guides/1_quantization.html">Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../guides/2_pruning.html">Pruning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../guides/3_nas.html">NAS</a></li>
<li class="toctree-l1"><a class="reference internal" href="../guides/4_distillation.html">Distillation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../guides/5_sparsity.html">Sparsity</a></li>
<li class="toctree-l1"><a class="reference internal" href="../guides/6_save_load.html">Saving &amp; Restoring</a></li>
<li class="toctree-l1"><a class="reference internal" href="../guides/6_speculative_decoding.html">Speculative Decoding</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Deployment</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../deployment/1_tensorrt_llm_deployment.html">TensorRT-LLM Deployment</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Examples</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="0_all_examples.html">All GitHub Examples</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">ResNet20 on CIFAR-10: Pruning</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#CIFAR-10-Dataset-for-Image-Classification">CIFAR-10 Dataset for Image Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="#ResNet-for-CIFAR-dataset">ResNet for CIFAR dataset</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Setting-up-the-model">Setting up the model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Training-a-baseline-model">Training a baseline model</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#FastNAS-Pruning-with-Model-Optimizer">FastNAS Pruning with Model Optimizer</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Prune-base-model-and-store-pruned-net">Prune base model and store pruned net</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#Restore-the-pruned-subnet-using-mto.restore">Restore the pruned subnet using mto.restore</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#Fine-tuning">Fine-tuning</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Evaluate-the-searched-subnet">Evaluate the searched subnet</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="2_bert_prune_distill_quantize.html">HF BERT: Prune, Distill &amp; Quantize</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../reference/0_changelog.html">Changelog</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reference/1_modelopt_api.html">modelopt API</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Support</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../support/1_contact.html">Contact us</a></li>
<li class="toctree-l1"><a class="reference internal" href="../support/2_faqs.html">FAQs</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">TensorRT Model Optimizer</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">ResNet20 on CIFAR-10: Pruning</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/examples/1_cifar_resnet.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="admonition note">
    This tutorial is available as a Jupyter Notebook!
    <a href="1_cifar_resnet.ipynb">Download notebook from here</a>.
</div><section id="ResNet20-on-CIFAR-10:-Pruning">
<h1>ResNet20 on CIFAR-10: Pruning<a class="headerlink" href="#ResNet20-on-CIFAR-10:-Pruning" title="Link to this heading"></a></h1>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>It would take about 3 hours on Google Colab but can be run as fast as in 1 hour if you use a better GPU. You can expect slightly different accuracies than reported below depending on the system you run this notebook in. The purpose of this notebook is to demonstrate the workflow of pruning using Model Optimizer and not to achieve the best accuracy.</p>
</div>
<p>In this tutorial, we will use Model Optimizer to make the ResNet model faster for our target deployment constraints using pruning without sacrificing much accuracy!</p>
<p>By the end of this tutorial, you will:</p>
<ul class="simple">
<li><p>Understand how to use Model Optimizer to prune a user-provided model to the best performing subnet architecture fitting your target deployment constraints.</p></li>
<li><p>Save and restore your pruned model for downstream tasks like fine-tuning and inference.</p></li>
</ul>
<p>All of this with just a few lines of code! Yes, it’s that simple!</p>
<p>Let’s first install <code class="docutils literal notranslate"><span class="pre">Model</span> <span class="pre">Optimizer</span></code> following the <a class="reference external" href="https://nvidia.github.io/TensorRT-Model-Optimizer/getting_started/2_installation.html" rel="noopener noreferrer" target="_blank">installation steps</a>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">pip</span> install &quot;nvidia-modelopt[torch]&quot; --extra-index-url https://pypi.nvidia.com
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">random</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
<span class="kn">from</span> <span class="nn">torchvision.models.resnet</span> <span class="kn">import</span> <span class="n">BasicBlock</span>
<span class="kn">from</span> <span class="nn">tqdm.auto</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="n">seed</span> <span class="o">=</span> <span class="mi">123</span>
<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<section id="CIFAR-10-Dataset-for-Image-Classification">
<h2>CIFAR-10 Dataset for Image Classification<a class="headerlink" href="#CIFAR-10-Dataset-for-Image-Classification" title="Link to this heading"></a></h2>
<p>For this tutorial, we will be working with the well known <a class="reference external" href="https://www.cs.toronto.edu/~kriz/cifar.html" rel="noopener noreferrer" target="_blank">CIFAR-10</a> dataset for image classification. The dataset consists of 60k 32x32 images from 10 classes split into 50k training and 10k testing images. We will further take 5k randomly out from the training set to make it our validation set.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_cifar10_dataloaders</span><span class="p">(</span><span class="n">train_batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Return Train-Val-Test data loaders for the CIFAR-10 dataset.&quot;&quot;&quot;</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

    <span class="n">normalize</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">0.4914</span><span class="p">,</span> <span class="mf">0.4822</span><span class="p">,</span> <span class="mf">0.4465</span><span class="p">],</span> <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.2470</span><span class="p">,</span> <span class="mf">0.2435</span><span class="p">,</span> <span class="mf">0.2616</span><span class="p">])</span>

    <span class="c1"># Split Train dataset into Train-Val datasets</span>
    <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">CIFAR10</span><span class="p">(</span>
        <span class="n">root</span><span class="o">=</span><span class="s2">&quot;./data&quot;</span><span class="p">,</span>
        <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                <span class="n">transforms</span><span class="o">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(),</span>
                <span class="n">transforms</span><span class="o">.</span><span class="n">RandomCrop</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span>
                <span class="n">normalize</span><span class="p">,</span>
            <span class="p">]</span>
        <span class="p">),</span>
        <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">n_trainval</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span>
    <span class="n">n_train</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_trainval</span> <span class="o">*</span> <span class="mf">0.9</span><span class="p">)</span>
    <span class="n">ids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_trainval</span><span class="p">)</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">ids</span><span class="p">)</span>
    <span class="n">train_ids</span><span class="p">,</span> <span class="n">val_ids</span> <span class="o">=</span> <span class="n">ids</span><span class="p">[:</span><span class="n">n_train</span><span class="p">],</span> <span class="n">ids</span><span class="p">[</span><span class="n">n_train</span><span class="p">:]</span>

    <span class="n">train_dataset</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">train_ids</span><span class="p">]</span>
    <span class="n">train_dataset</span><span class="o">.</span><span class="n">targets</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">targets</span><span class="p">)[</span><span class="n">train_ids</span><span class="p">]</span>

    <span class="n">val_dataset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">CIFAR10</span><span class="p">(</span>
        <span class="n">root</span><span class="o">=</span><span class="s2">&quot;./data&quot;</span><span class="p">,</span>
        <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span> <span class="n">normalize</span><span class="p">]),</span>
        <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">val_dataset</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">val_dataset</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">val_ids</span><span class="p">]</span>
    <span class="n">val_dataset</span><span class="o">.</span><span class="n">targets</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">val_dataset</span><span class="o">.</span><span class="n">targets</span><span class="p">)[</span><span class="n">val_ids</span><span class="p">]</span>

    <span class="n">test_dataset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">CIFAR10</span><span class="p">(</span>
        <span class="n">root</span><span class="o">=</span><span class="s2">&quot;./data&quot;</span><span class="p">,</span>
        <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">transform</span><span class="o">=</span><span class="n">val_dataset</span><span class="o">.</span><span class="n">transform</span><span class="p">,</span>
        <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">num_workers</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">cpu_count</span><span class="p">())</span>
    <span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">train_batch_size</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">val_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">val_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Train: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">, Val: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">val_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">, Test: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="n">test_loader</span>
</pre></div>
</div>
</div>
</section>
<section id="ResNet-for-CIFAR-dataset">
<h2>ResNet for CIFAR dataset<a class="headerlink" href="#ResNet-for-CIFAR-dataset" title="Link to this heading"></a></h2>
<p>We will be working with the ResNet variants for CIFAR dataset, namely ResNet-20 and ResNet-32 since these are very small models to train. You can find more details about these models in <a class="reference external" href="https://arxiv.org/abs/1512.03385" rel="noopener noreferrer" target="_blank">this paper</a>. Below is an example of a regular PyTorch model without anything new.</p>
<section id="Setting-up-the-model">
<h3>Setting up the model<a class="headerlink" href="#Setting-up-the-model" title="Link to this heading"></a></h3>
<p>We first set up and add some helper functions for training</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">_weights_init</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">)):</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">kaiming_normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">LambdaLayer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lambd</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lambd</span> <span class="o">=</span> <span class="n">lambd</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">lambd</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">ResNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_blocks</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">in_planes</span> <span class="o">=</span> <span class="mi">16</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">16</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_make_layer</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">num_blocks</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_make_layer</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">num_blocks</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_make_layer</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">num_blocks</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveAvgPool2d</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">_weights_init</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_make_layer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">planes</span><span class="p">,</span> <span class="n">num_blocks</span><span class="p">,</span> <span class="n">stride</span><span class="p">):</span>
        <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="n">stride</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">num_blocks</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">stride</span> <span class="ow">in</span> <span class="n">strides</span><span class="p">:</span>
            <span class="n">downsample</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="n">stride</span> <span class="o">!=</span> <span class="mi">1</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_planes</span> <span class="o">!=</span> <span class="n">planes</span><span class="p">:</span>
                <span class="n">downsample</span> <span class="o">=</span> <span class="n">LambdaLayer</span><span class="p">(</span>
                    <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">F</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span>
                        <span class="n">x</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">::</span><span class="mi">2</span><span class="p">,</span> <span class="p">::</span><span class="mi">2</span><span class="p">],</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">planes</span> <span class="o">//</span> <span class="mi">4</span><span class="p">,</span> <span class="n">planes</span> <span class="o">//</span> <span class="mi">4</span><span class="p">),</span> <span class="s2">&quot;constant&quot;</span><span class="p">,</span> <span class="mi">0</span>
                    <span class="p">)</span>
                <span class="p">)</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">BasicBlock</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_planes</span><span class="p">,</span> <span class="n">planes</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">downsample</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">in_planes</span> <span class="o">=</span> <span class="n">planes</span>
        <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">resnet20</span><span class="p">(</span><span class="n">ckpt</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">ResNet</span><span class="p">(</span><span class="n">num_blocks</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">ckpt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">ckpt</span><span class="p">,</span> <span class="n">device</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">model</span>

<span class="k">def</span> <span class="nf">resnet32</span><span class="p">(</span><span class="n">ckpt</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">ResNet</span><span class="p">(</span><span class="n">num_blocks</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">ckpt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">ckpt</span><span class="p">,</span> <span class="n">device</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">model</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">CosineLRwithWarmup</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">_LRScheduler</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">optimizer</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">,</span>
        <span class="n">warmup_steps</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">decay_steps</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">warmup_lr</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
        <span class="n">last_epoch</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">warmup_steps</span> <span class="o">=</span> <span class="n">warmup_steps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">warmup_lr</span> <span class="o">=</span> <span class="n">warmup_lr</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decay_steps</span> <span class="o">=</span> <span class="n">decay_steps</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">last_epoch</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_lr</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_epoch</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">warmup_steps</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[</span>
                <span class="p">(</span><span class="n">base_lr</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">warmup_lr</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_epoch</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">warmup_steps</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">warmup_lr</span>
                <span class="k">for</span> <span class="n">base_lr</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_lrs</span>
            <span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">current_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_epoch</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">warmup_steps</span>
            <span class="k">return</span> <span class="p">[</span>
                <span class="mf">0.5</span> <span class="o">*</span> <span class="n">base_lr</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">math</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">current_steps</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">decay_steps</span><span class="p">))</span>
                <span class="k">for</span> <span class="n">base_lr</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_lrs</span>
            <span class="p">]</span>


<span class="k">def</span> <span class="nf">get_optimizer_scheduler</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">weight_decay</span><span class="p">,</span> <span class="n">warmup_steps</span><span class="p">,</span> <span class="n">decay_steps</span><span class="p">):</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span>
        <span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">p</span><span class="p">:</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()),</span>
        <span class="n">lr</span><span class="p">,</span>
        <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
        <span class="n">weight_decay</span><span class="o">=</span><span class="n">weight_decay</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">lr_scheduler</span> <span class="o">=</span> <span class="n">CosineLRwithWarmup</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">warmup_steps</span><span class="p">,</span> <span class="n">decay_steps</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">lr_scheduler</span>


<span class="k">def</span> <span class="nf">train_one_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">lr_scheduler</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Train the given model for 1 epoch.&quot;&quot;&quot;</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">epoch_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">for</span> <span class="n">imgs</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">imgs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
        <span class="n">epoch_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">lr_scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="n">epoch_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">epoch_loss</span>


<span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Evaluate the model on the given test_loader and return accuracy percentage.&quot;&quot;&quot;</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="n">total</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">for</span> <span class="n">imgs</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">imgs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
        <span class="n">predicted</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
        <span class="n">correct</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">labels</span> <span class="o">==</span> <span class="n">predicted</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">total</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>

    <span class="n">accuracy</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span>
    <span class="k">return</span> <span class="n">accuracy</span>


<span class="k">def</span> <span class="nf">loss_fn_default</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">train_loader</span><span class="p">,</span>
    <span class="n">val_loader</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="p">,</span>
    <span class="n">lr_scheduler</span><span class="p">,</span>
    <span class="n">num_epochs</span><span class="p">,</span>
    <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">loss_fn_default</span><span class="p">,</span>
    <span class="n">print_freq</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span>
    <span class="n">ckpt_path</span><span class="o">=</span><span class="s2">&quot;temp_saved_model.pth&quot;</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Train the given model with provided parameters.</span>

<span class="sd">    loss_fn: function that takes model, output, labels and returns loss. This allows us to obtain the loss</span>
<span class="sd">        from the model as well if needed.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">best_val_acc</span><span class="p">,</span> <span class="n">best_ep</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mi">0</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training the model for </span><span class="si">{</span><span class="n">num_epochs</span><span class="si">}</span><span class="s2"> epochs...&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">ep</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)):</span>
        <span class="n">train_loss</span> <span class="o">=</span> <span class="n">train_one_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">lr_scheduler</span><span class="p">)</span>

        <span class="n">val_acc</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">val_acc</span> <span class="o">&gt;=</span> <span class="n">best_val_acc</span><span class="p">:</span>
            <span class="n">best_val_acc</span><span class="p">,</span> <span class="n">best_ep</span> <span class="o">=</span> <span class="n">val_acc</span><span class="p">,</span> <span class="n">ep</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">ckpt_path</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">ep</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">ep</span> <span class="o">%</span> <span class="n">print_freq</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">ep</span> <span class="o">==</span> <span class="n">num_epochs</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">ep</span><span class="si">:</span><span class="s2">3d</span><span class="si">}</span><span class="se">\t</span><span class="s2"> Training loss: </span><span class="si">{</span><span class="n">train_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="se">\t</span><span class="s2"> Val Accuracy: </span><span class="si">{</span><span class="n">val_acc</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;Model Trained! Restoring to parameters that gave best Val Accuracy (</span><span class="si">{</span><span class="n">best_val_acc</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">% at Epoch </span><span class="si">{</span><span class="n">best_ep</span><span class="si">}</span><span class="s2">).&quot;</span>
    <span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">ckpt_path</span><span class="p">),</span> <span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>You can uncomment the print statement below to see the ResNet20 model details.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># print(resnet20())</span>
</pre></div>
</div>
</div>
</section>
<section id="Training-a-baseline-model">
<h3>Training a baseline model<a class="headerlink" href="#Training-a-baseline-model" title="Link to this heading"></a></h3>
<p>It should take about 10-30 mins to train depending on your GPU and CPU. We use slightly different training hyperparameters compared to the original setup described in the paper to make the training faster for this tutorial.</p>
<p>You can also reduce the <code class="docutils literal notranslate"><span class="pre">num_epochs</span></code> parameter below to make the whole notebook run faster at the cost of accuracy.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">512</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">120</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.1</span> <span class="o">*</span> <span class="n">batch_size</span> <span class="o">/</span> <span class="mi">128</span>
<span class="n">weight_decay</span> <span class="o">=</span> <span class="mf">1e-4</span>

<span class="n">train_loader</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="n">test_loader</span> <span class="o">=</span> <span class="n">get_cifar10_dataloaders</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>

<span class="n">batch_per_epoch</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>
<span class="n">warmup_steps</span> <span class="o">=</span> <span class="mi">5</span> <span class="o">*</span> <span class="n">batch_per_epoch</span>
<span class="n">decay_steps</span> <span class="o">=</span> <span class="n">num_epochs</span> <span class="o">*</span> <span class="n">batch_per_epoch</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Train: 45000, Val: 5000, Test: 10000
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">resnet20_model</span> <span class="o">=</span> <span class="n">resnet20</span><span class="p">()</span>
<span class="n">optimizer</span><span class="p">,</span> <span class="n">lr_scheduler</span> <span class="o">=</span> <span class="n">get_optimizer_scheduler</span><span class="p">(</span>
    <span class="n">resnet20_model</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">weight_decay</span><span class="p">,</span> <span class="n">warmup_steps</span><span class="p">,</span> <span class="n">decay_steps</span>
<span class="p">)</span>
<span class="n">train_model</span><span class="p">(</span>
    <span class="n">resnet20_model</span><span class="p">,</span>
    <span class="n">train_loader</span><span class="p">,</span>
    <span class="n">val_loader</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="p">,</span>
    <span class="n">lr_scheduler</span><span class="p">,</span>
    <span class="n">num_epochs</span><span class="p">,</span>
    <span class="n">ckpt_path</span><span class="o">=</span><span class="s2">&quot;resnet20.pth&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test Accuracy of ResNet20: </span><span class="si">{</span><span class="n">evaluate</span><span class="p">(</span><span class="n">resnet20_model</span><span class="p">,</span><span class="w"> </span><span class="n">test_loader</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Training the model for 120 epochs...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "e1b4d24068af46dca443e8dbd3f3103c", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Epoch   1        Training loss: 0.0049   Val Accuracy: 22.82%
Epoch  25        Training loss: 0.0006   Val Accuracy: 78.84%
Epoch  50        Training loss: 0.0004   Val Accuracy: 85.06%
Epoch  75        Training loss: 0.0002   Val Accuracy: 88.12%
Epoch 100        Training loss: 0.0001   Val Accuracy: 90.34%
Epoch 120        Training loss: 0.0000   Val Accuracy: 90.80%
Model Trained! Restoring to parameters that gave best Val Accuracy (90.92% at Epoch 119).
Test Accuracy of ResNet20: 90.97
</pre></div></div>
</div>
<p>We have now established a baseline model and accuracy that we will be comparing with using Model Optimizer.</p>
<p>So far, we have seen a regular PyTorch model trained without anything new. Now, lets optimize the model for our target constraints using Model Optimizer!</p>
</section>
</section>
<section id="FastNAS-Pruning-with-Model-Optimizer">
<h2>FastNAS Pruning with Model Optimizer<a class="headerlink" href="#FastNAS-Pruning-with-Model-Optimizer" title="Link to this heading"></a></h2>
<p>The Model Optimizer’s <code class="docutils literal notranslate"><span class="pre">modelopt.torch.prune</span></code> module provides advanced state-of-the-art pruning algorithms that enable you to search for the best subnet architecture from your provided base model.</p>
<p>Model Optimizer can be used in one of the following complementary modes to create a search space for optimizing the model:</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">fastnas</span></code>: A pruning method recommended for Computer Vision models. Given a pretrained model, FastNAS finds the subnet which maximizes the score function while meeting the given constraints.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mcore_gpt_minitron</span></code>: A pruning method developed by NVIDIA Research for pruning GPT-style models in NVIDIA NeMo or Megatron-LM framework that are using Pipeline Parallellism. It uses the activation magnitudes to prune the mlp, attention heads, and GQA query groups.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">gradnas</span></code>: A light-weight pruning method recommended for language models like Hugging Face BERT, GPT-J. It uses the gradient information to prune the model’s linear layers and attention heads to meet the given constraints.</p></li>
</ol>
<p>In this example, we will use the <code class="docutils literal notranslate"><span class="pre">fastnas</span></code> mode to prune the ResNet20 model for CIFAR-10 dataset. Checkout the <a class="reference external" href="https://github.com/NVIDIA/TensorRT-Model-Optimizer" rel="noopener noreferrer" target="_blank">Model Optimizer GitHub repository</a> for more examples.</p>
<p>Let’s first use the FastNAS mode to convert a ResNet model and reduce its FLOPs, number of parameters, and latency.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">modelopt.torch.opt</span> <span class="k">as</span> <span class="nn">mto</span>
<span class="kn">import</span> <span class="nn">modelopt.torch.prune</span> <span class="k">as</span> <span class="nn">mtp</span>
</pre></div>
</div>
</div>
<section id="Prune-base-model-and-store-pruned-net">
<h3>Prune base model and store pruned net<a class="headerlink" href="#Prune-base-model-and-store-pruned-net" title="Link to this heading"></a></h3>
<p>Using <a class="reference internal" href="../reference/generated/modelopt.torch.prune.pruning.html#modelopt.torch.prune.pruning.prune"><span class="std std-ref">mtp.prune</span></a> you can</p>
<ul class="simple">
<li><p>generate a search space for pruning from your base model;</p></li>
<li><p>prune the model;</p></li>
<li><p>obtain a valid pytorch model that can be used for fine-tuning.</p></li>
</ul>
<p>Let’s say you have the ResNet20 model as our base model to prune from and we are looking for a model with at most 30M FLOPs. We can provide search constraints for <code class="docutils literal notranslate"><span class="pre">flops</span></code> and/or <code class="docutils literal notranslate"><span class="pre">params</span></code> by an upper bound. The values can either be absolute numbers (e.g. <code class="docutils literal notranslate"><span class="pre">30e6</span></code>) or a string percentage (e.g. <code class="docutils literal notranslate"><span class="pre">&quot;75%&quot;</span></code>). In addition, we should also provide our training data loader to <a class="reference internal" href="../reference/generated/modelopt.torch.prune.pruning.html#modelopt.torch.prune.pruning.prune"><span class="std std-ref">mtp.prune</span></a>. The training data
loader will be used to calibrate the normalization layers in the model. Finally, we will also specify a custom config for configuring the pruning search space to get a more fine-grained selection of pruned nets.</p>
<p>Finally, we can store the pruned architecture and weights using <a class="reference internal" href="../reference/generated/modelopt.torch.opt.conversion.html#modelopt.torch.opt.conversion.save"><span class="std std-ref">mto.save</span></a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>We are optimizing a relatively smaller model here. A finer-grained search could be more effective in such a case. This is why we are specifying custom configs. In general however, it is recommended to convert models with the default config itself.</p>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># config with more fine-grained channel choices for fastnas</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">mtp</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">FastNASConfig</span><span class="p">()</span>
<span class="n">config</span><span class="p">[</span><span class="s2">&quot;nn.Conv2d&quot;</span><span class="p">][</span><span class="s2">&quot;*&quot;</span><span class="p">][</span><span class="s2">&quot;channel_divisor&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">16</span>
<span class="n">config</span><span class="p">[</span><span class="s2">&quot;nn.BatchNorm2d&quot;</span><span class="p">][</span><span class="s2">&quot;*&quot;</span><span class="p">][</span><span class="s2">&quot;feature_divisor&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">16</span>

<span class="c1"># A single 32x32 image for computing FLOPs</span>
<span class="n">dummy_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># Wrap your original validation function to only take the model as input.</span>
<span class="c1"># This function acts as the score function to rank models.</span>
<span class="k">def</span> <span class="nf">score_func</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">)</span>

<span class="c1"># prune the model</span>
<span class="n">pruned_model</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">mtp</span><span class="o">.</span><span class="n">prune</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">resnet20</span><span class="p">(</span><span class="n">ckpt</span><span class="o">=</span><span class="s2">&quot;resnet20.pth&quot;</span><span class="p">),</span>
    <span class="n">mode</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;fastnas&quot;</span><span class="p">,</span> <span class="n">config</span><span class="p">)],</span>
    <span class="n">constraints</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;flops&quot;</span><span class="p">:</span> <span class="mf">30e6</span><span class="p">},</span>
    <span class="n">dummy_input</span><span class="o">=</span><span class="n">dummy_input</span><span class="p">,</span>
    <span class="n">config</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;data_loader&quot;</span><span class="p">:</span> <span class="n">train_loader</span><span class="p">,</span>
        <span class="s2">&quot;score_func&quot;</span><span class="p">:</span> <span class="n">score_func</span><span class="p">,</span>
        <span class="s2">&quot;checkpoint&quot;</span><span class="p">:</span> <span class="s2">&quot;modelopt_seaarch_checkpoint_fastnas.pth&quot;</span><span class="p">,</span>
    <span class="p">},</span>
<span class="p">)</span>

<span class="c1"># save the pruned model for future use</span>
<span class="n">mto</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">pruned_model</span><span class="p">,</span> <span class="s2">&quot;modelopt_pruned_model_fastnas.pth&quot;</span><span class="p">)</span>

<span class="c1"># evaluate the pruned model</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test Accuracy of Pruned ResNet20: </span><span class="si">{</span><span class="n">evaluate</span><span class="p">(</span><span class="n">pruned_model</span><span class="p">,</span><span class="w"> </span><span class="n">test_loader</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Profiling the following subnets from the given model: (&#39;min&#39;, &#39;centroid&#39;, &#39;max&#39;).
--------------------------------------------------------------------------------
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

                              Profiling Results
┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃<span class="ansi-bold"> </span><span class="ansi-bold">Constraint  </span><span class="ansi-bold"> </span>┃<span class="ansi-bold"> </span><span class="ansi-bold">min         </span><span class="ansi-bold"> </span>┃<span class="ansi-bold"> </span><span class="ansi-bold">centroid    </span><span class="ansi-bold"> </span>┃<span class="ansi-bold"> </span><span class="ansi-bold">max         </span><span class="ansi-bold"> </span>┃<span class="ansi-bold"> </span><span class="ansi-bold">max/min ratio</span><span class="ansi-bold"> </span>┃
┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ flops        │ 24.33M       │ 27.57M       │ 40.55M       │ 1.67          │
│ params       │ 90.94K       │ 141.63K      │ 268.35K      │ 2.95          │
└──────────────┴──────────────┴──────────────┴──────────────┴───────────────┘

            Constraints Evaluation
┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┓
┃<span class="ansi-bold">              </span>┃<span class="ansi-bold">              </span>┃<span class="ansi-bold"> </span><span class="ansi-bold">Satisfiable </span><span class="ansi-bold"> </span>┃
┃<span class="ansi-bold"> </span><span class="ansi-bold">Constraint  </span><span class="ansi-bold"> </span>┃<span class="ansi-bold"> </span><span class="ansi-bold">Upper Bound </span><span class="ansi-bold"> </span>┃<span class="ansi-bold"> </span><span class="ansi-bold">Upper Bound </span><span class="ansi-bold"> </span>┃
┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━┩
│ flops        │ 30.00M       │ True         │
└──────────────┴──────────────┴──────────────┘


Search Space Summary:
----------------------------------------------------------------------------------------------------
  layers.depth                                                                     [9]
  layers.0.out_channels                                                            [16]
  layers.0.in_channels                                                             [3]
  layers.3.depth                                                                   [3]
  layers.3.0.conv1.out_channels                                                    [16]
  layers.3.0.conv1.in_channels                                                     [16]
  layers.3.0.bn1.num_features                                                      [16]
  layers.3.0.conv2.out_channels                                                    [16]
  layers.3.0.conv2.in_channels                                                     [16]
  layers.3.1.conv1.out_channels                                                    [16]
  layers.3.1.conv1.in_channels                                                     [16]
  layers.3.1.bn1.num_features                                                      [16]
  layers.3.1.conv2.out_channels                                                    [16]
  layers.3.1.conv2.in_channels                                                     [16]
  layers.3.2.conv1.out_channels                                                    [16]
  layers.3.2.conv1.in_channels                                                     [16]
  layers.3.2.bn1.num_features                                                      [16]
  layers.3.2.conv2.out_channels                                                    [16]
  layers.3.2.conv2.in_channels                                                     [16]
  layers.4.depth                                                                   [3]
* layers.4.0.conv1.out_channels                                                    [16, 32]
  layers.4.0.conv1.in_channels                                                     [16]
  layers.4.0.bn1.num_features                                                      [16, 32]
  layers.4.0.conv2.out_channels                                                    [32]
  layers.4.0.conv2.in_channels                                                     [16, 32]
* layers.4.1.conv1.out_channels                                                    [16, 32]
  layers.4.1.conv1.in_channels                                                     [32]
  layers.4.1.bn1.num_features                                                      [16, 32]
  layers.4.1.conv2.out_channels                                                    [32]
  layers.4.1.conv2.in_channels                                                     [16, 32]
* layers.4.2.conv1.out_channels                                                    [16, 32]
  layers.4.2.conv1.in_channels                                                     [32]
  layers.4.2.bn1.num_features                                                      [16, 32]
  layers.4.2.conv2.out_channels                                                    [32]
  layers.4.2.conv2.in_channels                                                     [16, 32]
  layers.5.depth                                                                   [3]
* layers.5.0.conv1.out_channels                                                    [16, 32, 48, 64]
  layers.5.0.conv1.in_channels                                                     [32]
  layers.5.0.bn1.num_features                                                      [16, 32, 48, 64]
  layers.5.0.conv2.out_channels                                                    [64]
  layers.5.0.conv2.in_channels                                                     [16, 32, 48, 64]
* layers.5.1.conv1.out_channels                                                    [16, 32, 48, 64]
  layers.5.1.conv1.in_channels                                                     [64]
  layers.5.1.bn1.num_features                                                      [16, 32, 48, 64]
  layers.5.1.conv2.out_channels                                                    [64]
  layers.5.1.conv2.in_channels                                                     [16, 32, 48, 64]
* layers.5.2.conv1.out_channels                                                    [16, 32, 48, 64]
  layers.5.2.conv1.in_channels                                                     [64]
  layers.5.2.bn1.num_features                                                      [16, 32, 48, 64]
  layers.5.2.conv2.out_channels                                                    [64]
  layers.5.2.conv2.in_channels                                                     [16, 32, 48, 64]
----------------------------------------------------------------------------------------------------
Number of configurable hparams: 6
Total size of the search space: 5.12e+02
Note: all constraints can be satisfied within the search space!


Beginning pre-search estimation. If the runtime of score function is longer than a few minutes, consider subsampling the dataset used in score function.
A PyTorch dataset can be subsampled using torch.utils.data.Subset (https://pytorch.org/docs/stable/data.html#torch.utils.data.Subset) as following:
 subset_dataset = torch.utils.data.Subset(dataset, indices)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Collecting pre-search statistics: 100%|██████████| 18/18 [00:10&lt;00:00,  1.76it/s, cur=layers.5.2.conv1.out_channels(64/64): 0.00]
[num_satisfied] = 11:   0%|          | 20/10000 [00:02&lt;17:43,  9.39it/s]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[best_subnet_constraints] = {&#39;params&#39;: &#39;173.88K&#39;, &#39;flops&#39;: &#39;29.64M&#39;}
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>

</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Test Accuracy of Pruned ResNet20: 60.37
</pre></div></div>
</div>
<p>As we can see, the best subnet (29.6M FLOPs) has fitted our constraint of 30M FLOPs. We can also see a drop in validation accuracy for the searched model. This is very common after pruning and fine-tuning is necessary for this model.</p>
<section id="Restore-the-pruned-subnet-using-mto.restore">
<h4>Restore the pruned subnet using <a class="reference internal" href="../reference/generated/modelopt.torch.opt.conversion.html#modelopt.torch.opt.conversion.restore"><span class="std std-ref">mto.restore</span></a><a class="headerlink" href="#Restore-the-pruned-subnet-using-mto.restore" title="Link to this heading"></a></h4>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pruned_model</span> <span class="o">=</span> <span class="n">mto</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">resnet20</span><span class="p">(),</span> <span class="s2">&quot;modelopt_pruned_model_fastnas.pth&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
</section>
<section id="Fine-tuning">
<h3>Fine-tuning<a class="headerlink" href="#Fine-tuning" title="Link to this heading"></a></h3>
<p>To fine-tune the subnet, you can simply repeat the training pipeline of the original model (1x training time, 0.5x-1x of original learning rate). The fine-tuned model constitutes the final model with the optimal trade-off between accuracy and your provided constraints that is used for deployment.</p>
<p>Note that it would take about 5 - 15 mins to train depending on your GPU and CPU.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">optimizer</span><span class="p">,</span> <span class="n">lr_scheduler</span> <span class="o">=</span> <span class="n">get_optimizer_scheduler</span><span class="p">(</span>
    <span class="n">pruned_model</span><span class="p">,</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">weight_decay</span><span class="p">,</span> <span class="n">warmup_steps</span><span class="p">,</span> <span class="n">decay_steps</span>
<span class="p">)</span>
<span class="n">train_model</span><span class="p">(</span>
    <span class="n">pruned_model</span><span class="p">,</span>
    <span class="n">train_loader</span><span class="p">,</span>
    <span class="n">val_loader</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="p">,</span>
    <span class="n">lr_scheduler</span><span class="p">,</span>
    <span class="n">num_epochs</span><span class="p">,</span>
<span class="p">)</span>
<span class="c1"># store final model</span>
<span class="n">mto</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">pruned_model</span><span class="p">,</span> <span class="s2">&quot;modelopt_pruned_model_fastnas_finetuned.pth&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Training the model for 120 epochs...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "a5c29f88d1014d1ea86923484ca900e4", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Epoch   1        Training loss: 0.0011   Val Accuracy: 79.90%
Epoch  25        Training loss: 0.0004   Val Accuracy: 82.82%
Epoch  50        Training loss: 0.0003   Val Accuracy: 87.00%
Epoch  75        Training loss: 0.0002   Val Accuracy: 88.62%
Epoch 100        Training loss: 0.0000   Val Accuracy: 90.62%
Epoch 120        Training loss: 0.0000   Val Accuracy: 90.58%
Model Trained! Restoring to parameters that gave best Val Accuracy (90.70% at Epoch 101).
</pre></div></div>
</div>
</section>
<section id="Evaluate-the-searched-subnet">
<h3>Evaluate the searched subnet<a class="headerlink" href="#Evaluate-the-searched-subnet" title="Link to this heading"></a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># you can restore the fine-tuned model from the vanilla model</span>
<span class="n">optimized_model</span> <span class="o">=</span> <span class="n">mto</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">resnet20</span><span class="p">(),</span> <span class="s2">&quot;modelopt_pruned_model_fastnas_finetuned.pth&quot;</span><span class="p">)</span>

<span class="c1"># test the accuracy</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test Accuracy of the fine-tuned pruned net: </span><span class="si">{</span><span class="n">evaluate</span><span class="p">(</span><span class="n">optimized_model</span><span class="p">,</span><span class="w"> </span><span class="n">test_loader</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Test Accuracy of the fine-tuned pruned net: 90.28
</pre></div></div>
</div>
<p><strong>Conclusion?</strong></p>
<p>The comparison can be summarized as below:</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Model</p></th>
<th class="head"><p>FLOPs</p></th>
<th class="head"><p>Params</p></th>
<th class="head"><p>Test Accuracy</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>ResNet20</p></td>
<td><p>40.6M</p></td>
<td><p>268k</p></td>
<td><p>90.9%</p></td>
</tr>
<tr class="row-odd"><td><p>FastNAS subnet</p></td>
<td><p>29.6M</p></td>
<td><p>174k</p></td>
<td><p>90.3%</p></td>
</tr>
</tbody>
</table>
<p>As we see here, we have reduced the FLOPs and number of parameters which would also result in a improvement in latency with very little loss in accuracy. Good job!</p>
<p>Next: checkout the <a class="reference external" href="https://github.com/NVIDIA/TensorRT-Model-Optimizer" rel="noopener noreferrer" target="_blank">Model Optimizer GitHub repository</a> for more examples.</p>
<script type="application/vnd.jupyter.widget-state+json">
{"035cadfcae714f83b7ed8a13ec6f48c6": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "0559a40230e94f88a212426a40e5c92d": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "HTMLModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_035cadfcae714f83b7ed8a13ec6f48c6", "placeholder": "\u200b", "style": "IPY_MODEL_c580e2b02dfa47659ed459439d4e9a56", "value": " 19%"}}, "2174f714f4f4476c8841bd01126e5512": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "HBoxModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HBoxView", "box_style": "", "children": ["IPY_MODEL_0559a40230e94f88a212426a40e5c92d", "IPY_MODEL_62284610548147bf881561241fc5832d", "IPY_MODEL_85362535a5784199bdae9c330773971f"], "layout": "IPY_MODEL_ff41c573e19d4689b036020f88688b6a"}}, "62284610548147bf881561241fc5832d": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "FloatProgressModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "ProgressView", "bar_style": "", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_ac8b225332f3457b93930e9eca943083", "max": 180, "min": 0, "orientation": "horizontal", "style": "IPY_MODEL_7f96f7dcfc754aa49c8c4508a9eddb5d", "value": 35}}, "7a455069150e47ed8c8c6d0dbcceb3f8": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "DescriptionStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "7f96f7dcfc754aa49c8c4508a9eddb5d": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "ProgressStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "bar_color": null, "description_width": ""}}, "85362535a5784199bdae9c330773971f": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "HTMLModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_f1ecf7bf05f14d22a8c4d220b6002ced", "placeholder": "\u200b", "style": "IPY_MODEL_7a455069150e47ed8c8c6d0dbcceb3f8", "value": " 35/180 [11:53&lt;48:21, 20.01s/it]"}}, "ac8b225332f3457b93930e9eca943083": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "c580e2b02dfa47659ed459439d4e9a56": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "DescriptionStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "f1ecf7bf05f14d22a8c4d220b6002ced": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "ff41c573e19d4689b036020f88688b6a": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}}
</script></section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="0_all_examples.html" class="btn btn-neutral float-left" title="All GitHub Examples" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="2_bert_prune_distill_quantize.html" class="btn btn-neutral float-right" title="HF BERT: Prune, Distill &amp; Quantize" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023-2024, NVIDIA Corporation.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>